herringrun: Starting task with 8 workers and 0 servers
[1,19]<stderr>:2020-09-18 19:25:32.640541: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,23]<stderr>:2020-09-18 19:25:32.640555: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,17]<stderr>:2020-09-18 19:25:32.640757: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,16]<stderr>:2020-09-18 19:25:32.647147: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,18]<stderr>:2020-09-18 19:25:32.647131: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,22]<stderr>:2020-09-18 19:25:32.647142: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,21]<stderr>:2020-09-18 19:25:32.654209: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,20]<stderr>:2020-09-18 19:25:32.669912: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,99]<stderr>:2020-09-18 19:25:32.731238: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,103]<stderr>:2020-09-18 19:25:32.731514: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,97]<stderr>:2020-09-18 19:25:32.731993: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,101]<stderr>:2020-09-18 19:25:32.732001: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,96]<stderr>:2020-09-18 19:25:32.757763: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,98]<stderr>:2020-09-18 19:25:32.757753: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,100]<stderr>:2020-09-18 19:25:32.757763: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,102]<stderr>:2020-09-18 19:25:32.757765: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,7]<stderr>:2020-09-18 19:25:32.768940: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,3]<stderr>:2020-09-18 19:25:32.769123: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,5]<stderr>:2020-09-18 19:25:32.769317: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,1]<stderr>:2020-09-18 19:25:32.769490: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,68]<stderr>:2020-09-18 19:25:32.778719: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,69]<stderr>:2020-09-18 19:25:32.779084: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,67]<stderr>:2020-09-18 19:25:32.779269: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,71]<stderr>:2020-09-18 19:25:32.779509: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,65]<stderr>:2020-09-18 19:25:32.779717: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,0]<stderr>:2020-09-18 19:25:32.781580: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,2]<stderr>:2020-09-18 19:25:32.781583: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,4]<stderr>:2020-09-18 19:25:32.781621: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,6]<stderr>:2020-09-18 19:25:32.781585: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,70]<stderr>:2020-09-18 19:25:32.784854: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,66]<stderr>:2020-09-18 19:25:32.788147: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,64]<stderr>:2020-09-18 19:25:32.788558: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,55]<stderr>:2020-09-18 19:25:32.790333: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,49]<stderr>:2020-09-18 19:25:32.790487: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,53]<stderr>:2020-09-18 19:25:32.790729: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,51]<stderr>:2020-09-18 19:25:32.790911: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,87]<stderr>:2020-09-18 19:25:32.790668: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,81]<stderr>:2020-09-18 19:25:32.790820: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,84]<stderr>:2020-09-18 19:25:32.797929: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,86]<stderr>:2020-09-18 19:25:32.797929: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,48]<stderr>:2020-09-18 19:25:32.805480: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,50]<stderr>:2020-09-18 19:25:32.805483: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,52]<stderr>:2020-09-18 19:25:32.805483: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,54]<stderr>:2020-09-18 19:25:32.805486: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,117]<stderr>:2020-09-18 19:25:32.811166: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,119]<stderr>:2020-09-18 19:25:32.811321: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,113]<stderr>:2020-09-18 19:25:32.811500: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,115]<stderr>:2020-09-18 19:25:32.811717: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,37]<stderr>:2020-09-18 19:25:32.812421: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,39]<stderr>:2020-09-18 19:25:32.812638: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,33]<stderr>:2020-09-18 19:25:32.812806: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,35]<stderr>:2020-09-18 19:25:32.812969: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,114]<stderr>:2020-09-18 19:25:32.816907: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,118]<stderr>:2020-09-18 19:25:32.816914: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,112]<stderr>:2020-09-18 19:25:32.816967: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,116]<stderr>:2020-09-18 19:25:32.816970: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,32]<stderr>:2020-09-18 19:25:32.820464: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,34]<stderr>:2020-09-18 19:25:32.820465: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,36]<stderr>:2020-09-18 19:25:32.820382: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,38]<stderr>:2020-09-18 19:25:32.820464: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,83]<stderr>:2020-09-18 19:25:32.859270: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,85]<stderr>:2020-09-18 19:25:32.860387: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,80]<stderr>:2020-09-18 19:25:32.866743: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,82]<stderr>:2020-09-18 19:25:32.866740: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Bootstrap : Using [0]ens5:192.168.83.55<0>
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Bootstrap : Using [0]ens5:192.168.71.105<0>
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Bootstrap : Using [0]ens5:192.168.90.179<0>
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Bootstrap : Using [0]ens5:192.168.72.95<0>
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Bootstrap : Using [0]ens5:192.168.64.81<0>
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO NET/OFI Selected Provider is efa
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Using network AWS Libfabric
[1,64]<stdout>:NCCL version 2.6.4+cuda10.1
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO NET/OFI Selected Provider is efa
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Using network AWS Libfabric
[1,16]<stdout>:NCCL version 2.6.4+cuda10.1
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Bootstrap : Using [0]ens5:192.168.64.19<0>
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO NET/OFI Selected Provider is efa
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Using network AWS Libfabric
[1,112]<stdout>:NCCL version 2.6.4+cuda10.1
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO NET/OFI Selected Provider is efa
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Using network AWS Libfabric
[1,32]<stdout>:NCCL version 2.6.4+cuda10.1
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO NET/OFI Selected Provider is efa
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Using network AWS Libfabric
[1,0]<stdout>:NCCL version 2.6.4+cuda10.1
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Bootstrap : Using [0]ens5:192.168.87.97<0>
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO NET/OFI Selected Provider is efa
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Using network AWS Libfabric
[1,96]<stdout>:NCCL version 2.6.4+cuda10.1
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO NET/OFI Selected Provider is efa
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Using network AWS Libfabric
[1,80]<stdout>:NCCL version 2.6.4+cuda10.1
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Bootstrap : Using [0]ens5:192.168.95.203<0>
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO NET/OFI Selected Provider is efa
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Using network AWS Libfabric
[1,48]<stdout>:NCCL version 2.6.4+cuda10.1
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Bootstrap : Using [0]ens5:192.168.90.179<0>
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Bootstrap : Using [0]ens5:192.168.90.179<0>
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Bootstrap : Using [0]ens5:192.168.90.179<0>
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Bootstrap : Using [0]ens5:192.168.90.179<0>
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Bootstrap : Using [0]ens5:192.168.90.179<0>
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Bootstrap : Using [0]ens5:192.168.90.179<0>
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Bootstrap : Using [0]ens5:192.168.90.179<0>
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Bootstrap : Using [0]ens5:192.168.71.105<0>
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Bootstrap : Using [0]ens5:192.168.71.105<0>
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Bootstrap : Using [0]ens5:192.168.71.105<0>
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Bootstrap : Using [0]ens5:192.168.71.105<0>
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Bootstrap : Using [0]ens5:192.168.71.105<0>
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Bootstrap : Using [0]ens5:192.168.71.105<0>
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Bootstrap : Using [0]ens5:192.168.71.105<0>
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Bootstrap : Using [0]ens5:192.168.83.55<0>
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Bootstrap : Using [0]ens5:192.168.64.81<0>
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Bootstrap : Using [0]ens5:192.168.83.55<0>
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Bootstrap : Using [0]ens5:192.168.64.81<0>
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Bootstrap : Using [0]ens5:192.168.83.55<0>
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Bootstrap : Using [0]ens5:192.168.64.81<0>
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Bootstrap : Using [0]ens5:192.168.83.55<0>
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Bootstrap : Using [0]ens5:192.168.64.81<0>
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Bootstrap : Using [0]ens5:192.168.83.55<0>
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Bootstrap : Using [0]ens5:192.168.64.81<0>
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Bootstrap : Using [0]ens5:192.168.83.55<0>
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Bootstrap : Using [0]ens5:192.168.64.81<0>
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Bootstrap : Using [0]ens5:192.168.83.55<0>
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Bootstrap : Using [0]ens5:192.168.72.95<0>
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Bootstrap : Using [0]ens5:192.168.72.95<0>
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Bootstrap : Using [0]ens5:192.168.72.95<0>
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Bootstrap : Using [0]ens5:192.168.72.95<0>
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Bootstrap : Using [0]ens5:192.168.72.95<0>
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Bootstrap : Using [0]ens5:192.168.64.81<0>
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Bootstrap : Using [0]ens5:192.168.72.95<0>
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Bootstrap : Using [0]ens5:192.168.72.95<0>
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Bootstrap : Using [0]ens5:192.168.64.19<0>
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Bootstrap : Using [0]ens5:192.168.87.97<0>
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Bootstrap : Using [0]ens5:192.168.64.19<0>
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Bootstrap : Using [0]ens5:192.168.87.97<0>
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Bootstrap : Using [0]ens5:192.168.64.19<0>
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Bootstrap : Using [0]ens5:192.168.64.19<0>
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Bootstrap : Using [0]ens5:192.168.64.19<0>
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Bootstrap : Using [0]ens5:192.168.64.19<0>
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Bootstrap : Using [0]ens5:192.168.64.19<0>
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Bootstrap : Using [0]ens5:192.168.87.97<0>
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Bootstrap : Using [0]ens5:192.168.87.97<0>
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Bootstrap : Using [0]ens5:192.168.87.97<0>
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Bootstrap : Using [0]ens5:192.168.87.97<0>
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Bootstrap : Using [0]ens5:192.168.87.97<0>
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO NET/OFI Selected Provider is efa
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Using network AWS Libfabric
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO NET/OFI Selected Provider is efa
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Using network AWS Libfabric
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO NET/OFI Selected Provider is efa
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Using network AWS Libfabric
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO NET/OFI Selected Provider is efa
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Using network AWS Libfabric
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO NET/OFI Selected Provider is efa
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Using network AWS Libfabric
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO NET/OFI Selected Provider is efa
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Using network AWS Libfabric
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO NET/OFI Selected Provider is efa
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Using network AWS Libfabric
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO NET/OFI Selected Provider is efa
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Using network AWS Libfabric
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO NET/OFI Selected Provider is efa
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Using network AWS Libfabric
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO NET/OFI Selected Provider is efa
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Using network AWS Libfabric
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO NET/OFI Selected Provider is efa
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Using network AWS Libfabric
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO NET/OFI Selected Provider is efa
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Using network AWS Libfabric
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO NET/OFI Selected Provider is efa
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Using network AWS Libfabric
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO NET/OFI Selected Provider is efa
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO NET/OFI Selected Provider is efa
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Using network AWS Libfabric
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO NET/OFI Selected Provider is efa
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Using network AWS Libfabric
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Using network AWS Libfabric
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO NET/OFI Selected Provider is efa
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Using network AWS Libfabric
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO NET/OFI Selected Provider is efa
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Using network AWS Libfabric
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO NET/OFI Selected Provider is efa
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Using network AWS Libfabric
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO NET/OFI Selected Provider is efa
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Using network AWS Libfabric
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO NET/OFI Selected Provider is efa
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Using network AWS Libfabric
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO NET/OFI Selected Provider is efa
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Using network AWS Libfabric
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO NET/OFI Selected Provider is efa
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Using network AWS Libfabric
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO NET/OFI Selected Provider is efa
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Using network AWS Libfabric
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO NET/OFI Selected Provider is efa
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO NET/OFI Selected Provider is efa
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Using network AWS Libfabric
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Using network AWS Libfabric
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO NET/OFI Selected Provider is efa
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO NET/OFI Selected Provider is efa
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Using network AWS Libfabric
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Using network AWS Libfabric
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Bootstrap : Using [0]ens5:192.168.95.203<0>
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Bootstrap : Using [0]ens5:192.168.95.203<0>
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Bootstrap : Using [0]ens5:192.168.95.203<0>
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Bootstrap : Using [0]ens5:192.168.95.203<0>
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Bootstrap : Using [0]ens5:192.168.95.203<0>
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Bootstrap : Using [0]ens5:192.168.95.203<0>
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Bootstrap : Using [0]ens5:192.168.95.203<0>
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO NET/OFI Selected Provider is efa
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Using network AWS Libfabric
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO NET/OFI Selected Provider is efa
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Using network AWS Libfabric
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO NET/OFI Selected Provider is efa
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Using network AWS Libfabric
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO NET/OFI Selected Provider is efa
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Using network AWS Libfabric
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO NET/OFI Selected Provider is efa
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Using network AWS Libfabric
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO NET/OFI Selected Provider is efa
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Using network AWS Libfabric
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO NET/OFI Selected Provider is efa
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Using network AWS Libfabric
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO NET/OFI Selected Provider is efa
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Using network AWS Libfabric
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO NET/OFI Selected Provider is efa
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Using network AWS Libfabric
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO NET/OFI Selected Provider is efa
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Using network AWS Libfabric
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO NET/OFI Selected Provider is efa
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Using network AWS Libfabric
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO NET/OFI Selected Provider is efa
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Using network AWS Libfabric
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO NET/OFI Selected Provider is efa
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Using network AWS Libfabric
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO NET/OFI Selected Provider is efa
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Using network AWS Libfabric
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO NET/OFI Selected Provider is efa
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Using network AWS Libfabric
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO NET/OFI Selected Provider is efa
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Using network AWS Libfabric
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO NET/OFI Selected Provider is efa
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Using network AWS Libfabric
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO NET/OFI Selected Provider is efa
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Using network AWS Libfabric
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO NET/OFI Selected Provider is efa
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Using network AWS Libfabric
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO NET/OFI Selected Provider is efa
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Using network AWS Libfabric
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO NET/OFI Selected Provider is efa
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Using network AWS Libfabric
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO NET/OFI Selected Provider is efa
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Using network AWS Libfabric
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO NET/OFI Selected Provider is efa
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Using network AWS Libfabric
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO NET/OFI Selected Provider is efa
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Using network AWS Libfabric
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO NET/OFI Selected Provider is efa
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Using network AWS Libfabric
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO NET/OFI Selected Provider is efa
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Using network AWS Libfabric
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO NET/OFI Selected Provider is efa
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Using network AWS Libfabric
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO NET/OFI Forcing AWS OFI ndev 4
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO NET/OFI Selected Provider is efa
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v3 symbol.
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Using network AWS Libfabric
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1 [2] 5/-1/-1->6->7|7->6->5/-1/-1 [3] 5/-1/-1->6->7|7->6->5/-1/-1 [4] 2/-1/-1->6->4|4->6->2/-1/-1 [5] 4/-1/-1->6->2|2->6->4/-1/-1 [6] 7/-1/-1->6->5|5->6->7/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1 [8] 5/-1/-1->6->7|7->6->5/-1/-1 [9] 5/-1/-1->6->7|7->6->5/-1/-1 [10] 2/-1/-1->6->4|4->6->2/-1/-1 [11] 4/-1/-1->6->2|2->6->4/-1/-1
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1|-1->0->3/-1/-1 [1] 3/-1/-1->0->-1|-1->0->3/-1/-1 [2] 4/-1/-1->0->-1|-1->0->4/-1/-1 [3] 4/-1/-1->0->-1|-1->0->4/-1/-1 [4] 1/-1/-1->0->-1|-1->0->1/-1/-1 [5] 2/-1/-1->0->-1|-1->0->2/-1/-1 [6] 3/-1/-1->0->-1|-1->0->3/-1/-1 [7] 3/-1/-1->0->-1|-1->0->3/-1/-1 [8] 4/-1/-1->0->-1|-1->0->4/-1/-1 [9] 4/-1/-1->0->-1|-1->0->4/-1/-1 [10] 1/-1/-1->0->-1|-1->0->1/-1/-1 [11] 2/-1/-1->0->-1|-1->0->2/-1/-1
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Trees [0] 6/-1/-1->5->1|1->5->6/-1/-1 [1] 6/-1/-1->5->1|1->5->6/-1/-1 [2] 1/-1/-1->5->6|6->5->1/-1/-1 [3] 1/-1/-1->5->6|6->5->1/-1/-1 [4] 4/-1/-1->5->7|7->5->4/-1/-1 [5] 7/-1/-1->5->4|4->5->7/-1/-1 [6] 6/-1/-1->5->1|1->5->6/-1/-1 [7] 6/-1/-1->5->1|1->5->6/-1/-1 [8] 1/-1/-1->5->6|6->5->1/-1/-1 [9] 1/-1/-1->5->6|6->5->1/-1/-1 [10] 4/-1/-1->5->7|7->5->4/-1/-1 [11] 7/-1/-1->5->4|4->5->7/-1/-1
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Trees [0] 1/-1/-1->2->3|3->2->1/-1/-1 [1] 1/-1/-1->2->3|3->2->1/-1/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 3/-1/-1->2->1|1->2->3/-1/-1 [4] -1/-1/-1->2->6|6->2->-1/-1/-1 [5] 6/-1/-1->2->0|0->2->6/-1/-1 [6] 1/-1/-1->2->3|3->2->1/-1/-1 [7] 1/-1/-1->2->3|3->2->1/-1/-1 [8] 3/-1/-1->2->1|1->2->3/-1/-1 [9] 3/-1/-1->2->1|1->2->3/-1/-1 [10] -1/-1/-1->2->6|6->2->-1/-1/-1 [11] 6/-1/-1->2->0|0->2->6/-1/-1
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Trees [0] 4/-1/-1->7->6|6->7->4/-1/-1 [1] 4/-1/-1->7->6|6->7->4/-1/-1 [2] 6/-1/-1->7->4|4->7->6/-1/-1 [3] 6/-1/-1->7->4|4->7->6/-1/-1 [4] 5/-1/-1->7->3|3->7->5/-1/-1 [5] 3/-1/-1->7->5|5->7->3/-1/-1 [6] 4/-1/-1->7->6|6->7->4/-1/-1 [7] 4/-1/-1->7->6|6->7->4/-1/-1 [8] 6/-1/-1->7->4|4->7->6/-1/-1 [9] 6/-1/-1->7->4|4->7->6/-1/-1 [10] 5/-1/-1->7->3|3->7->5/-1/-1 [11] 3/-1/-1->7->5|5->7->3/-1/-1
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Trees [0] 5/-1/-1->1->2|2->1->5/-1/-1 [1] 5/-1/-1->1->2|2->1->5/-1/-1 [2] 2/-1/-1->1->5|5->1->2/-1/-1 [3] 2/-1/-1->1->5|5->1->2/-1/-1 [4] 3/-1/-1->1->0|0->1->3/-1/-1 [5] -1/-1/-1->1->3|3->1->-1/-1/-1 [6] 5/-1/-1->1->2|2->1->5/-1/-1 [7] 5/-1/-1->1->2|2->1->5/-1/-1 [8] 2/-1/-1->1->5|5->1->2/-1/-1 [9] 2/-1/-1->1->5|5->1->2/-1/-1 [10] 3/-1/-1->1->0|0->1->3/-1/-1 [11] -1/-1/-1->1->3|3->1->-1/-1/-1
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Trees [0] -1/-1/-1->4->7|7->4->-1/-1/-1 [1] -1/-1/-1->4->7|7->4->-1/-1/-1 [2] 7/-1/-1->4->0|0->4->7/-1/-1 [3] 7/-1/-1->4->0|0->4->7/-1/-1 [4] 6/-1/-1->4->5|5->4->6/-1/-1 [5] 5/-1/-1->4->6|6->4->5/-1/-1 [6] -1/-1/-1->4->7|7->4->-1/-1/-1 [7] -1/-1/-1->4->7|7->4->-1/-1/-1 [8] 7/-1/-1->4->0|0->4->7/-1/-1 [9] 7/-1/-1->4->0|0->4->7/-1/-1 [10] 6/-1/-1->4->5|5->4->6/-1/-1 [11] 5/-1/-1->4->6|6->4->5/-1/-1
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Trees [0] 2/-1/-1->3->0|0->3->2/-1/-1 [1] 2/-1/-1->3->0|0->3->2/-1/-1 [2] -1/-1/-1->3->2|2->3->-1/-1/-1 [3] -1/-1/-1->3->2|2->3->-1/-1/-1 [4] 7/-1/-1->3->1|1->3->7/-1/-1 [5] 1/-1/-1->3->7|7->3->1/-1/-1 [6] 2/-1/-1->3->0|0->3->2/-1/-1 [7] 2/-1/-1->3->0|0->3->2/-1/-1 [8] -1/-1/-1->3->2|2->3->-1/-1/-1 [9] -1/-1/-1->3->2|2->3->-1/-1/-1 [10] 7/-1/-1->3->1|1->3->7/-1/-1 [11] 1/-1/-1->3->7|7->3->1/-1/-1
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Trees [0] 5/-1/-1->1->2|2->1->5/-1/-1 [1] 5/-1/-1->1->2|2->1->5/-1/-1 [2] 2/-1/-1->1->5|5->1->2/-1/-1 [3] 2/-1/-1->1->5|5->1->2/-1/-1 [4] 3/-1/-1->1->0|0->1->3/-1/-1 [5] -1/-1/-1->1->3|3->1->-1/-1/-1 [6] 5/-1/-1->1->2|2->1->5/-1/-1 [7] 5/-1/-1->1->2|2->1->5/-1/-1 [8] 2/-1/-1->1->5|5->1->2/-1/-1 [9] 2/-1/-1->1->5|5->1->2/-1/-1 [10] 3/-1/-1->1->0|0->1->3/-1/-1 [11] -1/-1/-1->1->3|3->1->-1/-1/-1
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Trees [0] -1/-1/-1->4->7|7->4->-1/-1/-1 [1] -1/-1/-1->4->7|7->4->-1/-1/-1 [2] 7/-1/-1->4->0|0->4->7/-1/-1 [3] 7/-1/-1->4->0|0->4->7/-1/-1 [4] 6/-1/-1->4->5|5->4->6/-1/-1 [5] 5/-1/-1->4->6|6->4->5/-1/-1 [6] -1/-1/-1->4->7|7->4->-1/-1/-1 [7] -1/-1/-1->4->7|7->4->-1/-1/-1 [8] 7/-1/-1->4->0|0->4->7/-1/-1 [9] 7/-1/-1->4->0|0->4->7/-1/-1 [10] 6/-1/-1->4->5|5->4->6/-1/-1 [11] 5/-1/-1->4->6|6->4->5/-1/-1
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Trees [0] 6/-1/-1->5->1|1->5->6/-1/-1 [1] 6/-1/-1->5->1|1->5->6/-1/-1 [2] 1/-1/-1->5->6|6->5->1/-1/-1 [3] 1/-1/-1->5->6|6->5->1/-1/-1 [4] 4/-1/-1->5->7|7->5->4/-1/-1 [5] 7/-1/-1->5->4|4->5->7/-1/-1 [6] 6/-1/-1->5->1|1->5->6/-1/-1 [7] 6/-1/-1->5->1|1->5->6/-1/-1 [8] 1/-1/-1->5->6|6->5->1/-1/-1 [9] 1/-1/-1->5->6|6->5->1/-1/-1 [10] 4/-1/-1->5->7|7->5->4/-1/-1 [11] 7/-1/-1->5->4|4->5->7/-1/-1
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Trees [0] 1/-1/-1->2->3|3->2->1/-1/-1 [1] 1/-1/-1->2->3|3->2->1/-1/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 3/-1/-1->2->1|1->2->3/-1/-1 [4] -1/-1/-1->2->6|6->2->-1/-1/-1 [5] 6/-1/-1->2->0|0->2->6/-1/-1 [6] 1/-1/-1->2->3|3->2->1/-1/-1 [7] 1/-1/-1->2->3|3->2->1/-1/-1 [8] 3/-1/-1->2->1|1->2->3/-1/-1 [9] 3/-1/-1->2->1|1->2->3/-1/-1 [10] -1/-1/-1->2->6|6->2->-1/-1/-1 [11] 6/-1/-1->2->0|0->2->6/-1/-1
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Trees [0] 4/-1/-1->7->6|6->7->4/-1/-1 [1] 4/-1/-1->7->6|6->7->4/-1/-1 [2] 6/-1/-1->7->4|4->7->6/-1/-1 [3] 6/-1/-1->7->4|4->7->6/-1/-1 [4] 5/-1/-1->7->3|3->7->5/-1/-1 [5] 3/-1/-1->7->5|5->7->3/-1/-1 [6] 4/-1/-1->7->6|6->7->4/-1/-1 [7] 4/-1/-1->7->6|6->7->4/-1/-1 [8] 6/-1/-1->7->4|4->7->6/-1/-1 [9] 6/-1/-1->7->4|4->7->6/-1/-1 [10] 5/-1/-1->7->3|3->7->5/-1/-1 [11] 3/-1/-1->7->5|5->7->3/-1/-1
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1|-1->0->3/-1/-1 [1] 3/-1/-1->0->-1|-1->0->3/-1/-1 [2] 4/-1/-1->0->-1|-1->0->4/-1/-1 [3] 4/-1/-1->0->-1|-1->0->4/-1/-1 [4] 1/-1/-1->0->-1|-1->0->1/-1/-1 [5] 2/-1/-1->0->-1|-1->0->2/-1/-1 [6] 3/-1/-1->0->-1|-1->0->3/-1/-1 [7] 3/-1/-1->0->-1|-1->0->3/-1/-1 [8] 4/-1/-1->0->-1|-1->0->4/-1/-1 [9] 4/-1/-1->0->-1|-1->0->4/-1/-1 [10] 1/-1/-1->0->-1|-1->0->1/-1/-1 [11] 2/-1/-1->0->-1|-1->0->2/-1/-1
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Trees [0] 2/-1/-1->3->0|0->3->2/-1/-1 [1] 2/-1/-1->3->0|0->3->2/-1/-1 [2] -1/-1/-1->3->2|2->3->-1/-1/-1 [3] -1/-1/-1->3->2|2->3->-1/-1/-1 [4] 7/-1/-1->3->1|1->3->7/-1/-1 [5] 1/-1/-1->3->7|7->3->1/-1/-1 [6] 2/-1/-1->3->0|0->3->2/-1/-1 [7] 2/-1/-1->3->0|0->3->2/-1/-1 [8] -1/-1/-1->3->2|2->3->-1/-1/-1 [9] -1/-1/-1->3->2|2->3->-1/-1/-1 [10] 7/-1/-1->3->1|1->3->7/-1/-1 [11] 1/-1/-1->3->7|7->3->1/-1/-1
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1 [2] 5/-1/-1->6->7|7->6->5/-1/-1 [3] 5/-1/-1->6->7|7->6->5/-1/-1 [4] 2/-1/-1->6->4|4->6->2/-1/-1 [5] 4/-1/-1->6->2|2->6->4/-1/-1 [6] 7/-1/-1->6->5|5->6->7/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1 [8] 5/-1/-1->6->7|7->6->5/-1/-1 [9] 5/-1/-1->6->7|7->6->5/-1/-1 [10] 2/-1/-1->6->4|4->6->2/-1/-1 [11] 4/-1/-1->6->2|2->6->4/-1/-1
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 00 : 1[170] -> 5[1b0] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 00 : 3[190] -> 2[180] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 00 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 00 : 2[180] -> 1[170] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 00 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 00 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 00 : 4[1a0] -> 0[160] via P2P/IPC
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 00 : 0[160] -> 3[190] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 00 : 2[180] -> 1[170] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 00 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 00 : 4[1a0] -> 0[160] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 00 : 1[170] -> 5[1b0] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 00 : 3[190] -> 2[180] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 00 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 00 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 00 : 0[160] -> 3[190] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Trees [0] 6/-1/-1->5->1|1->5->6/-1/-1 [1] 6/-1/-1->5->1|1->5->6/-1/-1 [2] 1/-1/-1->5->6|6->5->1/-1/-1 [3] 1/-1/-1->5->6|6->5->1/-1/-1 [4] 4/-1/-1->5->7|7->5->4/-1/-1 [5] 7/-1/-1->5->4|4->5->7/-1/-1 [6] 6/-1/-1->5->1|1->5->6/-1/-1 [7] 6/-1/-1->5->1|1->5->6/-1/-1 [8] 1/-1/-1->5->6|6->5->1/-1/-1 [9] 1/-1/-1->5->6|6->5->1/-1/-1 [10] 4/-1/-1->5->7|7->5->4/-1/-1 [11] 7/-1/-1->5->4|4->5->7/-1/-1
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Trees [0] 4/-1/-1->7->6|6->7->4/-1/-1 [1] 4/-1/-1->7->6|6->7->4/-1/-1 [2] 6/-1/-1->7->4|4->7->6/-1/-1 [3] 6/-1/-1->7->4|4->7->6/-1/-1 [4] 5/-1/-1->7->3|3->7->5/-1/-1 [5] 3/-1/-1->7->5|5->7->3/-1/-1 [6] 4/-1/-1->7->6|6->7->4/-1/-1 [7] 4/-1/-1->7->6|6->7->4/-1/-1 [8] 6/-1/-1->7->4|4->7->6/-1/-1 [9] 6/-1/-1->7->4|4->7->6/-1/-1 [10] 5/-1/-1->7->3|3->7->5/-1/-1 [11] 3/-1/-1->7->5|5->7->3/-1/-1
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Trees [0] 5/-1/-1->1->2|2->1->5/-1/-1 [1] 5/-1/-1->1->2|2->1->5/-1/-1 [2] 2/-1/-1->1->5|5->1->2/-1/-1 [3] 2/-1/-1->1->5|5->1->2/-1/-1 [4] 3/-1/-1->1->0|0->1->3/-1/-1 [5] -1/-1/-1->1->3|3->1->-1/-1/-1 [6] 5/-1/-1->1->2|2->1->5/-1/-1 [7] 5/-1/-1->1->2|2->1->5/-1/-1 [8] 2/-1/-1->1->5|5->1->2/-1/-1 [9] 2/-1/-1->1->5|5->1->2/-1/-1 [10] 3/-1/-1->1->0|0->1->3/-1/-1 [11] -1/-1/-1->1->3|3->1->-1/-1/-1
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Trees [0] -1/-1/-1->4->7|7->4->-1/-1/-1 [1] -1/-1/-1->4->7|7->4->-1/-1/-1 [2] 7/-1/-1->4->0|0->4->7/-1/-1 [3] 7/-1/-1->4->0|0->4->7/-1/-1 [4] 6/-1/-1->4->5|5->4->6/-1/-1 [5] 5/-1/-1->4->6|6->4->5/-1/-1 [6] -1/-1/-1->4->7|7->4->-1/-1/-1 [7] -1/-1/-1->4->7|7->4->-1/-1/-1 [8] 7/-1/-1->4->0|0->4->7/-1/-1 [9] 7/-1/-1->4->0|0->4->7/-1/-1 [10] 6/-1/-1->4->5|5->4->6/-1/-1 [11] 5/-1/-1->4->6|6->4->5/-1/-1
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1 [2] 5/-1/-1->6->7|7->6->5/-1/-1 [3] 5/-1/-1->6->7|7->6->5/-1/-1 [4] 2/-1/-1->6->4|4->6->2/-1/-1 [5] 4/-1/-1->6->2|2->6->4/-1/-1 [6] 7/-1/-1->6->5|5->6->7/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1 [8] 5/-1/-1->6->7|7->6->5/-1/-1 [9] 5/-1/-1->6->7|7->6->5/-1/-1 [10] 2/-1/-1->6->4|4->6->2/-1/-1 [11] 4/-1/-1->6->2|2->6->4/-1/-1
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Trees [0] 1/-1/-1->2->3|3->2->1/-1/-1 [1] 1/-1/-1->2->3|3->2->1/-1/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 3/-1/-1->2->1|1->2->3/-1/-1 [4] -1/-1/-1->2->6|6->2->-1/-1/-1 [5] 6/-1/-1->2->0|0->2->6/-1/-1 [6] 1/-1/-1->2->3|3->2->1/-1/-1 [7] 1/-1/-1->2->3|3->2->1/-1/-1 [8] 3/-1/-1->2->1|1->2->3/-1/-1 [9] 3/-1/-1->2->1|1->2->3/-1/-1 [10] -1/-1/-1->2->6|6->2->-1/-1/-1 [11] 6/-1/-1->2->0|0->2->6/-1/-1
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1|-1->0->3/-1/-1 [1] 3/-1/-1->0->-1|-1->0->3/-1/-1 [2] 4/-1/-1->0->-1|-1->0->4/-1/-1 [3] 4/-1/-1->0->-1|-1->0->4/-1/-1 [4] 1/-1/-1->0->-1|-1->0->1/-1/-1 [5] 2/-1/-1->0->-1|-1->0->2/-1/-1 [6] 3/-1/-1->0->-1|-1->0->3/-1/-1 [7] 3/-1/-1->0->-1|-1->0->3/-1/-1 [8] 4/-1/-1->0->-1|-1->0->4/-1/-1 [9] 4/-1/-1->0->-1|-1->0->4/-1/-1 [10] 1/-1/-1->0->-1|-1->0->1/-1/-1 [11] 2/-1/-1->0->-1|-1->0->2/-1/-1
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Trees [0] 2/-1/-1->3->0|0->3->2/-1/-1 [1] 2/-1/-1->3->0|0->3->2/-1/-1 [2] -1/-1/-1->3->2|2->3->-1/-1/-1 [3] -1/-1/-1->3->2|2->3->-1/-1/-1 [4] 7/-1/-1->3->1|1->3->7/-1/-1 [5] 1/-1/-1->3->7|7->3->1/-1/-1 [6] 2/-1/-1->3->0|0->3->2/-1/-1 [7] 2/-1/-1->3->0|0->3->2/-1/-1 [8] -1/-1/-1->3->2|2->3->-1/-1/-1 [9] -1/-1/-1->3->2|2->3->-1/-1/-1 [10] 7/-1/-1->3->1|1->3->7/-1/-1 [11] 1/-1/-1->3->7|7->3->1/-1/-1
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 00 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 00 : 3[190] -> 0[160] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 00 : 1[170] -> 2[180] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 00 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 00 : 2[180] -> 3[190] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 00 : 5[1b0] -> 1[170] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 00 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Trees [0] 5/-1/-1->1->2|2->1->5/-1/-1 [1] 5/-1/-1->1->2|2->1->5/-1/-1 [2] 2/-1/-1->1->5|5->1->2/-1/-1 [3] 2/-1/-1->1->5|5->1->2/-1/-1 [4] 3/-1/-1->1->0|0->1->3/-1/-1 [5] -1/-1/-1->1->3|3->1->-1/-1/-1 [6] 5/-1/-1->1->2|2->1->5/-1/-1 [7] 5/-1/-1->1->2|2->1->5/-1/-1 [8] 2/-1/-1->1->5|5->1->2/-1/-1 [9] 2/-1/-1->1->5|5->1->2/-1/-1 [10] 3/-1/-1->1->0|0->1->3/-1/-1 [11] -1/-1/-1->1->3|3->1->-1/-1/-1
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1 [2] 5/-1/-1->6->7|7->6->5/-1/-1 [3] 5/-1/-1->6->7|7->6->5/-1/-1 [4] 2/-1/-1->6->4|4->6->2/-1/-1 [5] 4/-1/-1->6->2|2->6->4/-1/-1 [6] 7/-1/-1->6->5|5->6->7/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1 [8] 5/-1/-1->6->7|7->6->5/-1/-1 [9] 5/-1/-1->6->7|7->6->5/-1/-1 [10] 2/-1/-1->6->4|4->6->2/-1/-1 [11] 4/-1/-1->6->2|2->6->4/-1/-1
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Trees [0] 4/-1/-1->7->6|6->7->4/-1/-1 [1] 4/-1/-1->7->6|6->7->4/-1/-1 [2] 6/-1/-1->7->4|4->7->6/-1/-1 [3] 6/-1/-1->7->4|4->7->6/-1/-1 [4] 5/-1/-1->7->3|3->7->5/-1/-1 [5] 3/-1/-1->7->5|5->7->3/-1/-1 [6] 4/-1/-1->7->6|6->7->4/-1/-1 [7] 4/-1/-1->7->6|6->7->4/-1/-1 [8] 6/-1/-1->7->4|4->7->6/-1/-1 [9] 6/-1/-1->7->4|4->7->6/-1/-1 [10] 5/-1/-1->7->3|3->7->5/-1/-1 [11] 3/-1/-1->7->5|5->7->3/-1/-1
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Trees [0] 2/-1/-1->3->0|0->3->2/-1/-1 [1] 2/-1/-1->3->0|0->3->2/-1/-1 [2] -1/-1/-1->3->2|2->3->-1/-1/-1 [3] -1/-1/-1->3->2|2->3->-1/-1/-1 [4] 7/-1/-1->3->1|1->3->7/-1/-1 [5] 1/-1/-1->3->7|7->3->1/-1/-1 [6] 2/-1/-1->3->0|0->3->2/-1/-1 [7] 2/-1/-1->3->0|0->3->2/-1/-1 [8] -1/-1/-1->3->2|2->3->-1/-1/-1 [9] -1/-1/-1->3->2|2->3->-1/-1/-1 [10] 7/-1/-1->3->1|1->3->7/-1/-1 [11] 1/-1/-1->3->7|7->3->1/-1/-1
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Trees [0] 6/-1/-1->5->1|1->5->6/-1/-1 [1] 6/-1/-1->5->1|1->5->6/-1/-1 [2] 1/-1/-1->5->6|6->5->1/-1/-1 [3] 1/-1/-1->5->6|6->5->1/-1/-1 [4] 4/-1/-1->5->7|7->5->4/-1/-1 [5] 7/-1/-1->5->4|4->5->7/-1/-1 [6] 6/-1/-1->5->1|1->5->6/-1/-1 [7] 6/-1/-1->5->1|1->5->6/-1/-1 [8] 1/-1/-1->5->6|6->5->1/-1/-1 [9] 1/-1/-1->5->6|6->5->1/-1/-1 [10] 4/-1/-1->5->7|7->5->4/-1/-1 [11] 7/-1/-1->5->4|4->5->7/-1/-1
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Trees [0] -1/-1/-1->4->7|7->4->-1/-1/-1 [1] -1/-1/-1->4->7|7->4->-1/-1/-1 [2] 7/-1/-1->4->0|0->4->7/-1/-1 [3] 7/-1/-1->4->0|0->4->7/-1/-1 [4] 6/-1/-1->4->5|5->4->6/-1/-1 [5] 5/-1/-1->4->6|6->4->5/-1/-1 [6] -1/-1/-1->4->7|7->4->-1/-1/-1 [7] -1/-1/-1->4->7|7->4->-1/-1/-1 [8] 7/-1/-1->4->0|0->4->7/-1/-1 [9] 7/-1/-1->4->0|0->4->7/-1/-1 [10] 6/-1/-1->4->5|5->4->6/-1/-1 [11] 5/-1/-1->4->6|6->4->5/-1/-1
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Trees [0] 1/-1/-1->2->3|3->2->1/-1/-1 [1] 1/-1/-1->2->3|3->2->1/-1/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 3/-1/-1->2->1|1->2->3/-1/-1 [4] -1/-1/-1->2->6|6->2->-1/-1/-1 [5] 6/-1/-1->2->0|0->2->6/-1/-1 [6] 1/-1/-1->2->3|3->2->1/-1/-1 [7] 1/-1/-1->2->3|3->2->1/-1/-1 [8] 3/-1/-1->2->1|1->2->3/-1/-1 [9] 3/-1/-1->2->1|1->2->3/-1/-1 [10] -1/-1/-1->2->6|6->2->-1/-1/-1 [11] 6/-1/-1->2->0|0->2->6/-1/-1
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1|-1->0->3/-1/-1 [1] 3/-1/-1->0->-1|-1->0->3/-1/-1 [2] 4/-1/-1->0->-1|-1->0->4/-1/-1 [3] 4/-1/-1->0->-1|-1->0->4/-1/-1 [4] 1/-1/-1->0->-1|-1->0->1/-1/-1 [5] 2/-1/-1->0->-1|-1->0->2/-1/-1 [6] 3/-1/-1->0->-1|-1->0->3/-1/-1 [7] 3/-1/-1->0->-1|-1->0->3/-1/-1 [8] 4/-1/-1->0->-1|-1->0->4/-1/-1 [9] 4/-1/-1->0->-1|-1->0->4/-1/-1 [10] 1/-1/-1->0->-1|-1->0->1/-1/-1 [11] 2/-1/-1->0->-1|-1->0->2/-1/-1
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 00 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 00 : 2[180] -> 3[190] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 00 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 00 : 1[170] -> 2[180] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 00 : 3[190] -> 0[160] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 00 : 5[1b0] -> 1[170] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 00 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 00 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 00 : 4[1a0] -> 0[160] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 00 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 00 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 00 : 1[170] -> 5[1b0] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 00 : 3[190] -> 2[180] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 00 : 2[180] -> 1[170] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 00 : 0[160] -> 3[190] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 01 : 4[1a0] -> 0[160] via P2P/IPC
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 01 : 0[160] -> 3[190] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 00 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 00 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 00 : 1[170] -> 5[1b0] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 00 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 00 : 4[1a0] -> 0[160] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 00 : 2[180] -> 1[170] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 00 : 3[190] -> 2[180] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 00 : 0[160] -> 3[190] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 01 : 1[170] -> 5[1b0] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 01 : 3[190] -> 2[180] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 01 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 01 : 2[180] -> 1[170] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 01 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 01 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 01 : 4[1a0] -> 0[160] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 01 : 0[160] -> 3[190] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1 [2] 5/-1/-1->6->7|7->6->5/-1/-1 [3] 5/-1/-1->6->7|7->6->5/-1/-1 [4] 2/-1/-1->6->4|4->6->2/-1/-1 [5] 4/-1/-1->6->2|2->6->4/-1/-1 [6] 7/-1/-1->6->5|5->6->7/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1 [8] 5/-1/-1->6->7|7->6->5/-1/-1 [9] 5/-1/-1->6->7|7->6->5/-1/-1 [10] 2/-1/-1->6->4|4->6->2/-1/-1 [11] 4/-1/-1->6->2|2->6->4/-1/-1
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Trees [0] 4/-1/-1->7->6|6->7->4/-1/-1 [1] 4/-1/-1->7->6|6->7->4/-1/-1 [2] 6/-1/-1->7->4|4->7->6/-1/-1 [3] 6/-1/-1->7->4|4->7->6/-1/-1 [4] 5/-1/-1->7->3|3->7->5/-1/-1 [5] 3/-1/-1->7->5|5->7->3/-1/-1 [6] 4/-1/-1->7->6|6->7->4/-1/-1 [7] 4/-1/-1->7->6|6->7->4/-1/-1 [8] 6/-1/-1->7->4|4->7->6/-1/-1 [9] 6/-1/-1->7->4|4->7->6/-1/-1 [10] 5/-1/-1->7->3|3->7->5/-1/-1 [11] 3/-1/-1->7->5|5->7->3/-1/-1
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Trees [0] 6/-1/-1->5->1|1->5->6/-1/-1 [1] 6/-1/-1->5->1|1->5->6/-1/-1 [2] 1/-1/-1->5->6|6->5->1/-1/-1 [3] 1/-1/-1->5->6|6->5->1/-1/-1 [4] 4/-1/-1->5->7|7->5->4/-1/-1 [5] 7/-1/-1->5->4|4->5->7/-1/-1 [6] 6/-1/-1->5->1|1->5->6/-1/-1 [7] 6/-1/-1->5->1|1->5->6/-1/-1 [8] 1/-1/-1->5->6|6->5->1/-1/-1 [9] 1/-1/-1->5->6|6->5->1/-1/-1 [10] 4/-1/-1->5->7|7->5->4/-1/-1 [11] 7/-1/-1->5->4|4->5->7/-1/-1
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Trees [0] 2/-1/-1->3->0|0->3->2/-1/-1 [1] 2/-1/-1->3->0|0->3->2/-1/-1 [2] -1/-1/-1->3->2|2->3->-1/-1/-1 [3] -1/-1/-1->3->2|2->3->-1/-1/-1 [4] 7/-1/-1->3->1|1->3->7/-1/-1 [5] 1/-1/-1->3->7|7->3->1/-1/-1 [6] 2/-1/-1->3->0|0->3->2/-1/-1 [7] 2/-1/-1->3->0|0->3->2/-1/-1 [8] -1/-1/-1->3->2|2->3->-1/-1/-1 [9] -1/-1/-1->3->2|2->3->-1/-1/-1 [10] 7/-1/-1->3->1|1->3->7/-1/-1 [11] 1/-1/-1->3->7|7->3->1/-1/-1
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Trees [0] 1/-1/-1->2->3|3->2->1/-1/-1 [1] 1/-1/-1->2->3|3->2->1/-1/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 3/-1/-1->2->1|1->2->3/-1/-1 [4] -1/-1/-1->2->6|6->2->-1/-1/-1 [5] 6/-1/-1->2->0|0->2->6/-1/-1 [6] 1/-1/-1->2->3|3->2->1/-1/-1 [7] 1/-1/-1->2->3|3->2->1/-1/-1 [8] 3/-1/-1->2->1|1->2->3/-1/-1 [9] 3/-1/-1->2->1|1->2->3/-1/-1 [10] -1/-1/-1->2->6|6->2->-1/-1/-1 [11] 6/-1/-1->2->0|0->2->6/-1/-1
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Trees [0] -1/-1/-1->4->7|7->4->-1/-1/-1 [1] -1/-1/-1->4->7|7->4->-1/-1/-1 [2] 7/-1/-1->4->0|0->4->7/-1/-1 [3] 7/-1/-1->4->0|0->4->7/-1/-1 [4] 6/-1/-1->4->5|5->4->6/-1/-1 [5] 5/-1/-1->4->6|6->4->5/-1/-1 [6] -1/-1/-1->4->7|7->4->-1/-1/-1 [7] -1/-1/-1->4->7|7->4->-1/-1/-1 [8] 7/-1/-1->4->0|0->4->7/-1/-1 [9] 7/-1/-1->4->0|0->4->7/-1/-1 [10] 6/-1/-1->4->5|5->4->6/-1/-1 [11] 5/-1/-1->4->6|6->4->5/-1/-1
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1|-1->0->3/-1/-1 [1] 3/-1/-1->0->-1|-1->0->3/-1/-1 [2] 4/-1/-1->0->-1|-1->0->4/-1/-1 [3] 4/-1/-1->0->-1|-1->0->4/-1/-1 [4] 1/-1/-1->0->-1|-1->0->1/-1/-1 [5] 2/-1/-1->0->-1|-1->0->2/-1/-1 [6] 3/-1/-1->0->-1|-1->0->3/-1/-1 [7] 3/-1/-1->0->-1|-1->0->3/-1/-1 [8] 4/-1/-1->0->-1|-1->0->4/-1/-1 [9] 4/-1/-1->0->-1|-1->0->4/-1/-1 [10] 1/-1/-1->0->-1|-1->0->1/-1/-1 [11] 2/-1/-1->0->-1|-1->0->2/-1/-1
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Trees [0] 5/-1/-1->1->2|2->1->5/-1/-1 [1] 5/-1/-1->1->2|2->1->5/-1/-1 [2] 2/-1/-1->1->5|5->1->2/-1/-1 [3] 2/-1/-1->1->5|5->1->2/-1/-1 [4] 3/-1/-1->1->0|0->1->3/-1/-1 [5] -1/-1/-1->1->3|3->1->-1/-1/-1 [6] 5/-1/-1->1->2|2->1->5/-1/-1 [7] 5/-1/-1->1->2|2->1->5/-1/-1 [8] 2/-1/-1->1->5|5->1->2/-1/-1 [9] 2/-1/-1->1->5|5->1->2/-1/-1 [10] 3/-1/-1->1->0|0->1->3/-1/-1 [11] -1/-1/-1->1->3|3->1->-1/-1/-1
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 01 : 2[180] -> 1[170] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 01 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 01 : 1[170] -> 5[1b0] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 01 : 3[190] -> 2[180] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 00 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 01 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 01 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 01 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 00 : 5[1b0] -> 1[170] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 00 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 00 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 00 : 1[170] -> 2[180] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 00 : 3[190] -> 0[160] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 00 : 2[180] -> 3[190] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 00 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 01 : 1[170] -> 2[180] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 01 : 3[190] -> 0[160] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 01 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 01 : 2[180] -> 3[190] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 01 : 5[1b0] -> 1[170] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 01 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 00 : 1[170] -> 5[1b0] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 00 : 5[1b0] -> 1[170] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 00 : 3[190] -> 2[180] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 00 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 00 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 00 : 1[170] -> 2[180] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 01 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 00 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 00 : 4[1a0] -> 0[160] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 00 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 00 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 00 : 2[180] -> 3[190] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 00 : 3[190] -> 0[160] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 00 : 2[180] -> 1[170] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 00 : 0[160] -> 3[190] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 01 : 4[1a0] -> 0[160] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 01 : 2[180] -> 3[190] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 01 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 01 : 1[170] -> 2[180] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 01 : 3[190] -> 0[160] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 01 : 5[1b0] -> 1[170] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 01 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 02 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 01 : 0[160] -> 3[190] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Trees [0] 4/-1/-1->7->6|6->7->4/-1/-1 [1] 4/-1/-1->7->6|6->7->4/-1/-1 [2] 6/-1/-1->7->4|4->7->6/-1/-1 [3] 6/-1/-1->7->4|4->7->6/-1/-1 [4] 5/-1/-1->7->3|3->7->5/-1/-1 [5] 3/-1/-1->7->5|5->7->3/-1/-1 [6] 4/-1/-1->7->6|6->7->4/-1/-1 [7] 4/-1/-1->7->6|6->7->4/-1/-1 [8] 6/-1/-1->7->4|4->7->6/-1/-1 [9] 6/-1/-1->7->4|4->7->6/-1/-1 [10] 5/-1/-1->7->3|3->7->5/-1/-1 [11] 3/-1/-1->7->5|5->7->3/-1/-1
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 01 : 4[1a0] -> 0[160] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 01 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1 [2] 5/-1/-1->6->7|7->6->5/-1/-1 [3] 5/-1/-1->6->7|7->6->5/-1/-1 [4] 2/-1/-1->6->4|4->6->2/-1/-1 [5] 4/-1/-1->6->2|2->6->4/-1/-1 [6] 7/-1/-1->6->5|5->6->7/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1 [8] 5/-1/-1->6->7|7->6->5/-1/-1 [9] 5/-1/-1->6->7|7->6->5/-1/-1 [10] 2/-1/-1->6->4|4->6->2/-1/-1 [11] 4/-1/-1->6->2|2->6->4/-1/-1
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Trees [0] 1/-1/-1->2->3|3->2->1/-1/-1 [1] 1/-1/-1->2->3|3->2->1/-1/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 3/-1/-1->2->1|1->2->3/-1/-1 [4] -1/-1/-1->2->6|6->2->-1/-1/-1 [5] 6/-1/-1->2->0|0->2->6/-1/-1 [6] 1/-1/-1->2->3|3->2->1/-1/-1 [7] 1/-1/-1->2->3|3->2->1/-1/-1 [8] 3/-1/-1->2->1|1->2->3/-1/-1 [9] 3/-1/-1->2->1|1->2->3/-1/-1 [10] -1/-1/-1->2->6|6->2->-1/-1/-1 [11] 6/-1/-1->2->0|0->2->6/-1/-1
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Trees [0] 2/-1/-1->3->0|0->3->2/-1/-1 [1] 2/-1/-1->3->0|0->3->2/-1/-1 [2] -1/-1/-1->3->2|2->3->-1/-1/-1 [3] -1/-1/-1->3->2|2->3->-1/-1/-1 [4] 7/-1/-1->3->1|1->3->7/-1/-1 [5] 1/-1/-1->3->7|7->3->1/-1/-1 [6] 2/-1/-1->3->0|0->3->2/-1/-1 [7] 2/-1/-1->3->0|0->3->2/-1/-1 [8] -1/-1/-1->3->2|2->3->-1/-1/-1 [9] -1/-1/-1->3->2|2->3->-1/-1/-1 [10] 7/-1/-1->3->1|1->3->7/-1/-1 [11] 1/-1/-1->3->7|7->3->1/-1/-1
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Trees [0] 5/-1/-1->1->2|2->1->5/-1/-1 [1] 5/-1/-1->1->2|2->1->5/-1/-1 [2] 2/-1/-1->1->5|5->1->2/-1/-1 [3] 2/-1/-1->1->5|5->1->2/-1/-1 [4] 3/-1/-1->1->0|0->1->3/-1/-1 [5] -1/-1/-1->1->3|3->1->-1/-1/-1 [6] 5/-1/-1->1->2|2->1->5/-1/-1 [7] 5/-1/-1->1->2|2->1->5/-1/-1 [8] 2/-1/-1->1->5|5->1->2/-1/-1 [9] 2/-1/-1->1->5|5->1->2/-1/-1 [10] 3/-1/-1->1->0|0->1->3/-1/-1 [11] -1/-1/-1->1->3|3->1->-1/-1/-1
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Trees [0] 6/-1/-1->5->1|1->5->6/-1/-1 [1] 6/-1/-1->5->1|1->5->6/-1/-1 [2] 1/-1/-1->5->6|6->5->1/-1/-1 [3] 1/-1/-1->5->6|6->5->1/-1/-1 [4] 4/-1/-1->5->7|7->5->4/-1/-1 [5] 7/-1/-1->5->4|4->5->7/-1/-1 [6] 6/-1/-1->5->1|1->5->6/-1/-1 [7] 6/-1/-1->5->1|1->5->6/-1/-1 [8] 1/-1/-1->5->6|6->5->1/-1/-1 [9] 1/-1/-1->5->6|6->5->1/-1/-1 [10] 4/-1/-1->5->7|7->5->4/-1/-1 [11] 7/-1/-1->5->4|4->5->7/-1/-1
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Trees [0] -1/-1/-1->4->7|7->4->-1/-1/-1 [1] -1/-1/-1->4->7|7->4->-1/-1/-1 [2] 7/-1/-1->4->0|0->4->7/-1/-1 [3] 7/-1/-1->4->0|0->4->7/-1/-1 [4] 6/-1/-1->4->5|5->4->6/-1/-1 [5] 5/-1/-1->4->6|6->4->5/-1/-1 [6] -1/-1/-1->4->7|7->4->-1/-1/-1 [7] -1/-1/-1->4->7|7->4->-1/-1/-1 [8] 7/-1/-1->4->0|0->4->7/-1/-1 [9] 7/-1/-1->4->0|0->4->7/-1/-1 [10] 6/-1/-1->4->5|5->4->6/-1/-1 [11] 5/-1/-1->4->6|6->4->5/-1/-1
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1|-1->0->3/-1/-1 [1] 3/-1/-1->0->-1|-1->0->3/-1/-1 [2] 4/-1/-1->0->-1|-1->0->4/-1/-1 [3] 4/-1/-1->0->-1|-1->0->4/-1/-1 [4] 1/-1/-1->0->-1|-1->0->1/-1/-1 [5] 2/-1/-1->0->-1|-1->0->2/-1/-1 [6] 3/-1/-1->0->-1|-1->0->3/-1/-1 [7] 3/-1/-1->0->-1|-1->0->3/-1/-1 [8] 4/-1/-1->0->-1|-1->0->4/-1/-1 [9] 4/-1/-1->0->-1|-1->0->4/-1/-1 [10] 1/-1/-1->0->-1|-1->0->1/-1/-1 [11] 2/-1/-1->0->-1|-1->0->2/-1/-1
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 01 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 01 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 01 : 1[170] -> 5[1b0] via P2P/IPC
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 02 : 0[160] -> 4[1a0] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 01 : 3[190] -> 2[180] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 01 : 2[180] -> 1[170] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 02 : 1[170] -> 2[180] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 02 : 3[190] -> 0[160] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 01 : 0[160] -> 3[190] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 02 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 02 : 2[180] -> 3[190] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 02 : 5[1b0] -> 1[170] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 02 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 01 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 01 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 01 : 1[170] -> 5[1b0] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 02 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 01 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 01 : 2[180] -> 1[170] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 01 : 3[190] -> 2[180] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 00 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 02 : 0[160] -> 4[1a0] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Trees [0] 1/-1/-1->2->3|3->2->1/-1/-1 [1] 1/-1/-1->2->3|3->2->1/-1/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 3/-1/-1->2->1|1->2->3/-1/-1 [4] -1/-1/-1->2->6|6->2->-1/-1/-1 [5] 6/-1/-1->2->0|0->2->6/-1/-1 [6] 1/-1/-1->2->3|3->2->1/-1/-1 [7] 1/-1/-1->2->3|3->2->1/-1/-1 [8] 3/-1/-1->2->1|1->2->3/-1/-1 [9] 3/-1/-1->2->1|1->2->3/-1/-1 [10] -1/-1/-1->2->6|6->2->-1/-1/-1 [11] 6/-1/-1->2->0|0->2->6/-1/-1
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1 [2] 5/-1/-1->6->7|7->6->5/-1/-1 [3] 5/-1/-1->6->7|7->6->5/-1/-1 [4] 2/-1/-1->6->4|4->6->2/-1/-1 [5] 4/-1/-1->6->2|2->6->4/-1/-1 [6] 7/-1/-1->6->5|5->6->7/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1 [8] 5/-1/-1->6->7|7->6->5/-1/-1 [9] 5/-1/-1->6->7|7->6->5/-1/-1 [10] 2/-1/-1->6->4|4->6->2/-1/-1 [11] 4/-1/-1->6->2|2->6->4/-1/-1
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Trees [0] 4/-1/-1->7->6|6->7->4/-1/-1 [1] 4/-1/-1->7->6|6->7->4/-1/-1 [2] 6/-1/-1->7->4|4->7->6/-1/-1 [3] 6/-1/-1->7->4|4->7->6/-1/-1 [4] 5/-1/-1->7->3|3->7->5/-1/-1 [5] 3/-1/-1->7->5|5->7->3/-1/-1 [6] 4/-1/-1->7->6|6->7->4/-1/-1 [7] 4/-1/-1->7->6|6->7->4/-1/-1 [8] 6/-1/-1->7->4|4->7->6/-1/-1 [9] 6/-1/-1->7->4|4->7->6/-1/-1 [10] 5/-1/-1->7->3|3->7->5/-1/-1 [11] 3/-1/-1->7->5|5->7->3/-1/-1
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Trees [0] 5/-1/-1->1->2|2->1->5/-1/-1 [1] 5/-1/-1->1->2|2->1->5/-1/-1 [2] 2/-1/-1->1->5|5->1->2/-1/-1 [3] 2/-1/-1->1->5|5->1->2/-1/-1 [4] 3/-1/-1->1->0|0->1->3/-1/-1 [5] -1/-1/-1->1->3|3->1->-1/-1/-1 [6] 5/-1/-1->1->2|2->1->5/-1/-1 [7] 5/-1/-1->1->2|2->1->5/-1/-1 [8] 2/-1/-1->1->5|5->1->2/-1/-1 [9] 2/-1/-1->1->5|5->1->2/-1/-1 [10] 3/-1/-1->1->0|0->1->3/-1/-1 [11] -1/-1/-1->1->3|3->1->-1/-1/-1
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Trees [0] -1/-1/-1->4->7|7->4->-1/-1/-1 [1] -1/-1/-1->4->7|7->4->-1/-1/-1 [2] 7/-1/-1->4->0|0->4->7/-1/-1 [3] 7/-1/-1->4->0|0->4->7/-1/-1 [4] 6/-1/-1->4->5|5->4->6/-1/-1 [5] 5/-1/-1->4->6|6->4->5/-1/-1 [6] -1/-1/-1->4->7|7->4->-1/-1/-1 [7] -1/-1/-1->4->7|7->4->-1/-1/-1 [8] 7/-1/-1->4->0|0->4->7/-1/-1 [9] 7/-1/-1->4->0|0->4->7/-1/-1 [10] 6/-1/-1->4->5|5->4->6/-1/-1 [11] 5/-1/-1->4->6|6->4->5/-1/-1
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Trees [0] 6/-1/-1->5->1|1->5->6/-1/-1 [1] 6/-1/-1->5->1|1->5->6/-1/-1 [2] 1/-1/-1->5->6|6->5->1/-1/-1 [3] 1/-1/-1->5->6|6->5->1/-1/-1 [4] 4/-1/-1->5->7|7->5->4/-1/-1 [5] 7/-1/-1->5->4|4->5->7/-1/-1 [6] 6/-1/-1->5->1|1->5->6/-1/-1 [7] 6/-1/-1->5->1|1->5->6/-1/-1 [8] 1/-1/-1->5->6|6->5->1/-1/-1 [9] 1/-1/-1->5->6|6->5->1/-1/-1 [10] 4/-1/-1->5->7|7->5->4/-1/-1 [11] 7/-1/-1->5->4|4->5->7/-1/-1
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1|-1->0->3/-1/-1 [1] 3/-1/-1->0->-1|-1->0->3/-1/-1 [2] 4/-1/-1->0->-1|-1->0->4/-1/-1 [3] 4/-1/-1->0->-1|-1->0->4/-1/-1 [4] 1/-1/-1->0->-1|-1->0->1/-1/-1 [5] 2/-1/-1->0->-1|-1->0->2/-1/-1 [6] 3/-1/-1->0->-1|-1->0->3/-1/-1 [7] 3/-1/-1->0->-1|-1->0->3/-1/-1 [8] 4/-1/-1->0->-1|-1->0->4/-1/-1 [9] 4/-1/-1->0->-1|-1->0->4/-1/-1 [10] 1/-1/-1->0->-1|-1->0->1/-1/-1 [11] 2/-1/-1->0->-1|-1->0->2/-1/-1
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Trees [0] 2/-1/-1->3->0|0->3->2/-1/-1 [1] 2/-1/-1->3->0|0->3->2/-1/-1 [2] -1/-1/-1->3->2|2->3->-1/-1/-1 [3] -1/-1/-1->3->2|2->3->-1/-1/-1 [4] 7/-1/-1->3->1|1->3->7/-1/-1 [5] 1/-1/-1->3->7|7->3->1/-1/-1 [6] 2/-1/-1->3->0|0->3->2/-1/-1 [7] 2/-1/-1->3->0|0->3->2/-1/-1 [8] -1/-1/-1->3->2|2->3->-1/-1/-1 [9] -1/-1/-1->3->2|2->3->-1/-1/-1 [10] 7/-1/-1->3->1|1->3->7/-1/-1 [11] 1/-1/-1->3->7|7->3->1/-1/-1
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 01 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 00 : 1[170] -> 2[180] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 00 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 00 : 3[190] -> 0[160] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 00 : 5[1b0] -> 1[170] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 00 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 00 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 02 : 2[180] -> 3[190] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 02 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 02 : 1[170] -> 2[180] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 00 : 2[180] -> 3[190] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 00 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 00 : 1[170] -> 5[1b0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 00 : 3[190] -> 2[180] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 02 : 3[190] -> 0[160] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 00 : 2[180] -> 1[170] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 02 : 5[1b0] -> 1[170] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 00 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 02 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 00 : 0[160] -> 3[190] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 00 : 4[1a0] -> 0[160] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 01 : 5[1b0] -> 1[170] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 01 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 01 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 01 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 02 : 3[190] -> 2[180] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 01 : 1[170] -> 2[180] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 01 : 3[190] -> 0[160] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 02 : 4[1a0] -> 0[160] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 01 : 2[180] -> 3[190] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 02 : 1[170] -> 5[1b0] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 01 : 4[1a0] -> 0[160] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 01 : 5[1b0] -> 1[170] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 02 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 02 : 2[180] -> 1[170] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 02 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 01 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 01 : 1[170] -> 2[180] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 00 : 3[190] -> 2[180] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 02 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 00 : 1[170] -> 5[1b0] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 00 : 4[1a0] -> 0[160] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 01 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 00 : 2[180] -> 1[170] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 00 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 01 : 2[180] -> 3[190] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 00 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 00 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 01 : 3[190] -> 0[160] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 00 : 0[160] -> 3[190] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 01 : 0[160] -> 3[190] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 02 : 3[190] -> 2[180] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 02 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 02 : 4[1a0] -> 0[160] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 01 : 1[170] -> 5[1b0] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 01 : 3[190] -> 2[180] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 01 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 02 : 2[180] -> 1[170] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 01 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 01 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 02 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 02 : 1[170] -> 5[1b0] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 01 : 2[180] -> 1[170] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 02 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 02 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 00 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 02 : 0[160] -> 4[1a0] via P2P/IPC
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 03 : 0[160] -> 4[1a0] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 03 : 3[190] -> 0[160] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 00 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 02 : 5[1b0] -> 1[170] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 02 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 02 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 02 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 00 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 00 : 1[170] -> 2[180] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 00 : 3[190] -> 0[160] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 02 : 1[170] -> 2[180] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 00 : 2[180] -> 3[190] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 02 : 3[190] -> 0[160] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 00 : 5[1b0] -> 1[170] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 02 : 2[180] -> 3[190] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 03 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 02 : 0[160] -> 4[1a0] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 02 : 5[1b0] -> 1[170] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 03 : 1[170] -> 2[180] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 03 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 01 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 02 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 03 : 3[190] -> 0[160] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 02 : 1[170] -> 2[180] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 03 : 2[180] -> 3[190] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 03 : 5[1b0] -> 1[170] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 00 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 03 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 02 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 02 : 2[180] -> 3[190] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 02 : 3[190] -> 0[160] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 03 : 0[160] -> 4[1a0] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 00 : 3[190] -> 0[160] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 00 : 1[170] -> 2[180] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 00 : 2[180] -> 3[190] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 00 : 5[1b0] -> 1[170] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 00 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 01 : 1[170] -> 2[180] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 01 : 3[190] -> 0[160] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 00 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 01 : 5[1b0] -> 1[170] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 01 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 03 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 01 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 01 : 4[1a0] -> 0[160] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 03 : 2[180] -> 3[190] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 01 : 2[180] -> 3[190] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 03 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 03 : 1[170] -> 2[180] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 02 : 4[1a0] -> 0[160] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 02 : 3[190] -> 2[180] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 03 : 5[1b0] -> 1[170] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 01 : 0[160] -> 3[190] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 03 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 03 : 3[190] -> 2[180] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 01 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 02 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 02 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 02 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 01 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 01 : 1[170] -> 5[1b0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 01 : 3[190] -> 2[180] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 02 : 1[170] -> 5[1b0] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 03 : 4[1a0] -> 0[160] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 01 : 2[180] -> 1[170] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 02 : 2[180] -> 1[170] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 01 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 02 : 4[1a0] -> 0[160] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 02 : 3[190] -> 2[180] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 01 : 4[1a0] -> 0[160] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 03 : 1[170] -> 5[1b0] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 03 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 03 : 2[180] -> 1[170] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 03 : 3[190] -> 2[180] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 02 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 03 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 03 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 02 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 02 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 02 : 1[170] -> 5[1b0] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 01 : 0[160] -> 3[190] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 02 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 02 : 2[180] -> 1[170] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 02 : 0[160] -> 4[1a0] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 03 : 0[160] -> 4[1a0] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 01 : 3[190] -> 2[180] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 03 : 4[1a0] -> 0[160] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 01 : 1[170] -> 5[1b0] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 01 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 01 : 2[180] -> 1[170] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 02 : 1[170] -> 2[180] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 01 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 02 : 3[190] -> 0[160] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 01 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 03 : 3[190] -> 0[160] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 02 : 5[1b0] -> 1[170] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 01 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 03 : 2[180] -> 1[170] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 02 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 03 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 02 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 03 : 1[170] -> 5[1b0] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 02 : 2[180] -> 3[190] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 03 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 03 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 04 : 3[190] -> 7[1d0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 03 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 04 : 0[160] -> 1[170] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 01 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 03 : 0[160] -> 4[1a0] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 01 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 01 : 1[170] -> 2[180] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 03 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 01 : 3[190] -> 0[160] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 03 : 3[190] -> 0[160] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 03 : 5[1b0] -> 1[170] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 01 : 2[180] -> 3[190] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 03 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 04 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 03 : 1[170] -> 2[180] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 01 : 5[1b0] -> 1[170] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 03 : 2[180] -> 3[190] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 04 : 1[170] -> 3[190] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 04 : 3[190] -> 7[1d0] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 04 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 01 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 03 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 04 : 2[180] -> 0[160] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 04 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 04 : 6[1c0] -> 2[180] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 03 : 5[1b0] -> 1[170] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 03 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 02 : 3[190] -> 2[180] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 03 : 1[170] -> 2[180] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 03 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 04 : 0[160] -> 1[170] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 03 : 2[180] -> 3[190] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 02 : 4[1a0] -> 0[160] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 01 : 3[190] -> 0[160] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 01 : 1[170] -> 2[180] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 02 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 01 : 2[180] -> 3[190] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 04 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 01 : 5[1b0] -> 1[170] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 01 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 03 : 3[190] -> 2[180] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 01 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 02 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 04 : 2[180] -> 0[160] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 02 : 1[170] -> 5[1b0] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 04 : 6[1c0] -> 2[180] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 04 : 1[170] -> 3[190] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 02 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 02 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 02 : 2[180] -> 1[170] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 03 : 4[1a0] -> 0[160] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 04 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 04 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 02 : 0[160] -> 4[1a0] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 02 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 03 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 03 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 03 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 03 : 3[190] -> 2[180] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 02 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 03 : 1[170] -> 5[1b0] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 02 : 1[170] -> 2[180] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 03 : 2[180] -> 1[170] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 02 : 3[190] -> 0[160] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 02 : 2[180] -> 3[190] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 02 : 5[1b0] -> 1[170] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 03 : 4[1a0] -> 0[160] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 04 : 3[190] -> 1[170] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 04 : 2[180] -> 6[1c0] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 02 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 04 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 03 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 03 : 0[160] -> 4[1a0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 03 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 03 : 1[170] -> 5[1b0] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 03 : 3[190] -> 0[160] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 03 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 02 : 0[160] -> 4[1a0] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 04 : 1[170] -> 0[160] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 04 : 7[1d0] -> 3[190] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 03 : 2[180] -> 1[170] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 04 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 04 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 02 : 3[190] -> 0[160] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 03 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 02 : 1[170] -> 2[180] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 04 : 0[160] -> 1[170] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 02 : 2[180] -> 3[190] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 04 : 2[180] -> 6[1c0] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 04 : 3[190] -> 7[1d0] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 02 : 5[1b0] -> 1[170] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 03 : 1[170] -> 2[180] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 02 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 03 : 5[1b0] -> 1[170] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 02 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 03 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 03 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 04 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 03 : 2[180] -> 3[190] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 04 : 3[190] -> 1[170] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 04 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 02 : 4[1a0] -> 0[160] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 02 : 3[190] -> 2[180] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 04 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 04 : 1[170] -> 0[160] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 04 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 04 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 04 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 02 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 04 : 6[1c0] -> 2[180] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 04 : 3[190] -> 7[1d0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 04 : 7[1d0] -> 3[190] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 04 : 0[160] -> 1[170] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 04 : 1[170] -> 3[190] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 02 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 04 : 2[180] -> 0[160] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 05 : 2[180] -> 6[1c0] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 02 : 1[170] -> 5[1b0] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 02 : 2[180] -> 1[170] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 02 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 04 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 05 : 3[190] -> 1[170] via P2P/IPC
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 05 : 0[160] -> 2[180] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 05 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 04 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 02 : 3[190] -> 2[180] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 03 : 3[190] -> 2[180] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 04 : 6[1c0] -> 2[180] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 04 : 1[170] -> 3[190] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 04 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 05 : 2[180] -> 6[1c0] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 05 : 1[170] -> 0[160] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 04 : 2[180] -> 0[160] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 02 : 4[1a0] -> 0[160] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 05 : 7[1d0] -> 3[190] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 03 : 4[1a0] -> 0[160] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 05 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 05 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 03 : 1[170] -> 5[1b0] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 02 : 1[170] -> 5[1b0] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 03 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 02 : 2[180] -> 1[170] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 03 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 03 : 0[160] -> 4[1a0] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 02 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 03 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 02 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 05 : 0[160] -> 2[180] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 02 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 03 : 3[190] -> 0[160] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 03 : 2[180] -> 1[170] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 05 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 05 : 3[190] -> 1[170] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 05 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 05 : 1[170] -> 0[160] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 03 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 04 : 3[190] -> 1[170] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 04 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 04 : 2[180] -> 6[1c0] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 05 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 03 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 05 : 7[1d0] -> 3[190] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 03 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 04 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 04 : 7[1d0] -> 3[190] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 03 : 1[170] -> 2[180] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 04 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 03 : 3[190] -> 0[160] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 03 : 2[180] -> 3[190] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 04 : 1[170] -> 0[160] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 03 : 5[1b0] -> 1[170] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 05 : 1[170] -> 3[190] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 03 : 0[160] -> 4[1a0] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 05 : 3[190] -> 7[1d0] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 04 : 3[190] -> 7[1d0] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 04 : 3[190] -> 1[170] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 05 : 2[180] -> 0[160] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 04 : 0[160] -> 1[170] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 05 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 04 : 2[180] -> 6[1c0] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 04 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 04 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 04 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 03 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 05 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 04 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 04 : 1[170] -> 0[160] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 04 : 7[1d0] -> 3[190] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 05 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 03 : 1[170] -> 2[180] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 03 : 2[180] -> 3[190] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 04 : 1[170] -> 3[190] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 05 : 6[1c0] -> 2[180] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 04 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 04 : 6[1c0] -> 2[180] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 03 : 5[1b0] -> 1[170] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 05 : 1[170] -> 3[190] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 05 : 2[180] -> 0[160] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 04 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 03 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 03 : 3[190] -> 2[180] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 03 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 04 : 2[180] -> 0[160] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 05 : 2[180] -> 6[1c0] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 05 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 03 : 4[1a0] -> 0[160] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 05 : 3[190] -> 7[1d0] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 05 : 6[1c0] -> 2[180] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 05 : 3[190] -> 1[170] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 03 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 05 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 05 : 0[160] -> 2[180] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 05 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 03 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 06 : 1[170] -> 5[1b0] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 03 : 1[170] -> 5[1b0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 05 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 05 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 05 : 7[1d0] -> 3[190] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 03 : 3[190] -> 2[180] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 03 : 2[180] -> 1[170] via P2P/IPC
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 06 : 0[160] -> 3[190] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 03 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 05 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 05 : 2[180] -> 6[1c0] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 05 : 1[170] -> 0[160] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 06 : 3[190] -> 2[180] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 05 : 0[160] -> 2[180] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 06 : 4[1a0] -> 0[160] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 05 : 3[190] -> 1[170] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 05 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 06 : 2[180] -> 1[170] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 03 : 4[1a0] -> 0[160] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 06 : 0[160] -> 3[190] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 06 : 1[170] -> 5[1b0] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 03 : 1[170] -> 5[1b0] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 05 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 05 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 06 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 06 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 05 : 1[170] -> 0[160] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 03 : 2[180] -> 1[170] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 03 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 05 : 7[1d0] -> 3[190] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 03 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 04 : 3[190] -> 1[170] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 06 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 04 : 2[180] -> 6[1c0] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 04 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 06 : 2[180] -> 1[170] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 03 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 04 : 0[160] -> 1[170] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 04 : 3[190] -> 7[1d0] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 04 : 1[170] -> 0[160] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 04 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 06 : 4[1a0] -> 0[160] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 04 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 06 : 3[190] -> 2[180] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 04 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 06 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 04 : 7[1d0] -> 3[190] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 05 : 2[180] -> 0[160] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 05 : 1[170] -> 3[190] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 05 : 3[190] -> 7[1d0] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 06 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 04 : 6[1c0] -> 2[180] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 05 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 04 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 06 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 04 : 1[170] -> 3[190] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 06 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 04 : 3[190] -> 7[1d0] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 05 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 04 : 2[180] -> 0[160] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 04 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 05 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 05 : 6[1c0] -> 2[180] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 06 : 1[170] -> 2[180] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 06 : 3[190] -> 0[160] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 04 : 0[160] -> 1[170] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 05 : 2[180] -> 0[160] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 05 : 1[170] -> 3[190] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 06 : 2[180] -> 3[190] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 05 : 3[190] -> 7[1d0] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 05 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 04 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 05 : 2[180] -> 6[1c0] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 04 : 1[170] -> 3[190] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 06 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 06 : 5[1b0] -> 1[170] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 04 : 2[180] -> 0[160] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 06 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 05 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 05 : 6[1c0] -> 2[180] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 04 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 06 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 05 : 0[160] -> 2[180] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 05 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 04 : 6[1c0] -> 2[180] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 06 : 2[180] -> 3[190] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 05 : 3[190] -> 1[170] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 06 : 1[170] -> 2[180] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 04 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 05 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 05 : 1[170] -> 0[160] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 06 : 0[160] -> 3[190] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 06 : 3[190] -> 0[160] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 06 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 06 : 1[170] -> 5[1b0] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 05 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 05 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 05 : 7[1d0] -> 3[190] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 06 : 5[1b0] -> 1[170] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 06 : 3[190] -> 2[180] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 06 : 2[180] -> 1[170] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 06 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 04 : 3[190] -> 1[170] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 06 : 4[1a0] -> 0[160] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 04 : 2[180] -> 6[1c0] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 04 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 07 : 4[1a0] -> 0[160] via P2P/IPC
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 07 : 0[160] -> 3[190] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 04 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 06 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 06 : 0[160] -> 3[190] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 06 : 1[170] -> 5[1b0] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 06 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 06 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 04 : 7[1d0] -> 3[190] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 04 : 1[170] -> 0[160] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 07 : 3[190] -> 2[180] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 04 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 07 : 1[170] -> 5[1b0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 07 : 2[180] -> 1[170] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 06 : 2[180] -> 1[170] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 06 : 3[190] -> 2[180] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 06 : 4[1a0] -> 0[160] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 04 : 2[180] -> 6[1c0] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 06 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 05 : 1[170] -> 3[190] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 07 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 07 : 4[1a0] -> 0[160] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 07 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 04 : 3[190] -> 1[170] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 07 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 05 : 2[180] -> 0[160] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 06 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 06 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 04 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 07 : 0[160] -> 3[190] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 07 : 2[180] -> 1[170] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 04 : 1[170] -> 0[160] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 05 : 3[190] -> 7[1d0] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 05 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 07 : 1[170] -> 5[1b0] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 04 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 04 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 06 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 07 : 3[190] -> 2[180] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 07 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 05 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 04 : 7[1d0] -> 3[190] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 05 : 2[180] -> 6[1c0] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 06 : 1[170] -> 2[180] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 05 : 6[1c0] -> 2[180] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 05 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 06 : 3[190] -> 0[160] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 07 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 06 : 2[180] -> 3[190] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 07 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 05 : 3[190] -> 1[170] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 07 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 05 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 05 : 0[160] -> 2[180] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 06 : 5[1b0] -> 1[170] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 05 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 06 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 06 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 07 : 3[190] -> 0[160] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 06 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 06 : 1[170] -> 2[180] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 07 : 1[170] -> 2[180] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 05 : 7[1d0] -> 3[190] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 07 : 2[180] -> 3[190] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 05 : 1[170] -> 0[160] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 06 : 2[180] -> 3[190] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 06 : 3[190] -> 0[160] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 06 : 1[170] -> 5[1b0] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 05 : 2[180] -> 6[1c0] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 05 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 06 : 0[160] -> 3[190] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 07 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 06 : 5[1b0] -> 1[170] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 07 : 5[1b0] -> 1[170] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 05 : 0[160] -> 2[180] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 07 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 06 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 07 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 06 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 07 : 2[180] -> 3[190] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 05 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 05 : 3[190] -> 1[170] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 05 : 1[170] -> 0[160] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 07 : 1[170] -> 2[180] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 06 : 2[180] -> 1[170] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 06 : 3[190] -> 2[180] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 07 : 4[1a0] -> 0[160] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 06 : 4[1a0] -> 0[160] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 07 : 3[190] -> 0[160] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 05 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 07 : 0[160] -> 3[190] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 07 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 06 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 05 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 07 : 5[1b0] -> 1[170] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 05 : 7[1d0] -> 3[190] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 06 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 06 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 07 : 1[170] -> 5[1b0] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 07 : 3[190] -> 2[180] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 07 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 05 : 2[180] -> 0[160] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 07 : 2[180] -> 1[170] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 08 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 08 : 0[160] -> 4[1a0] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 05 : 1[170] -> 3[190] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 05 : 3[190] -> 7[1d0] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 07 : 4[1a0] -> 0[160] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 07 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 07 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 05 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 07 : 0[160] -> 3[190] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 08 : 3[190] -> 0[160] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 05 : 6[1c0] -> 2[180] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 07 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 08 : 1[170] -> 2[180] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 07 : 1[170] -> 5[1b0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 08 : 2[180] -> 3[190] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 07 : 2[180] -> 1[170] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 05 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 07 : 3[190] -> 2[180] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 05 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 08 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 08 : 5[1b0] -> 1[170] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 05 : 1[170] -> 3[190] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 06 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 07 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 08 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 08 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 07 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 05 : 2[180] -> 0[160] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 06 : 1[170] -> 2[180] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 07 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 08 : 0[160] -> 4[1a0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 08 : 2[180] -> 3[190] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 05 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 08 : 1[170] -> 2[180] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 06 : 2[180] -> 3[190] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 06 : 3[190] -> 0[160] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 07 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 05 : 3[190] -> 7[1d0] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 08 : 3[190] -> 0[160] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 06 : 5[1b0] -> 1[170] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 08 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 05 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 06 : 0[160] -> 3[190] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 05 : 6[1c0] -> 2[180] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 06 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 07 : 1[170] -> 2[180] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 06 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 08 : 5[1b0] -> 1[170] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 06 : 1[170] -> 5[1b0] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 07 : 3[190] -> 0[160] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 05 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 07 : 2[180] -> 3[190] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 08 : 3[190] -> 2[180] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 08 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 06 : 2[180] -> 1[170] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 07 : 5[1b0] -> 1[170] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 07 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 06 : 3[190] -> 2[180] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 07 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 08 : 4[1a0] -> 0[160] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 06 : 4[1a0] -> 0[160] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 07 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 06 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 07 : 1[170] -> 2[180] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 08 : 1[170] -> 5[1b0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 08 : 2[180] -> 1[170] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 06 : 1[170] -> 5[1b0] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 07 : 2[180] -> 3[190] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 07 : 3[190] -> 0[160] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 06 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 06 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 06 : 0[160] -> 3[190] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 08 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 07 : 4[1a0] -> 0[160] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 07 : 5[1b0] -> 1[170] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 08 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 08 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 07 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 08 : 3[190] -> 2[180] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 07 : 0[160] -> 3[190] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 07 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 07 : 1[170] -> 5[1b0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 08 : 2[180] -> 1[170] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 06 : 2[180] -> 1[170] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 06 : 4[1a0] -> 0[160] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 08 : 4[1a0] -> 0[160] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 08 : 1[170] -> 5[1b0] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 08 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 06 : 3[190] -> 2[180] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 07 : 2[180] -> 1[170] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 07 : 3[190] -> 2[180] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 08 : 0[160] -> 4[1a0] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 06 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 08 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 07 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 06 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 09 : 3[190] -> 0[160] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 07 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 08 : 1[170] -> 2[180] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 08 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 07 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 08 : 3[190] -> 0[160] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 06 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 06 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 08 : 2[180] -> 3[190] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 06 : 2[180] -> 3[190] via P2P/IPC
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 09 : 0[160] -> 4[1a0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 08 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 06 : 3[190] -> 0[160] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 08 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 06 : 1[170] -> 2[180] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 08 : 5[1b0] -> 1[170] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 08 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 08 : 0[160] -> 4[1a0] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 06 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 08 : 1[170] -> 2[180] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 08 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 09 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 09 : 1[170] -> 2[180] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 06 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 09 : 2[180] -> 3[190] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 08 : 2[180] -> 3[190] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 08 : 3[190] -> 0[160] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 09 : 3[190] -> 0[160] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 06 : 5[1b0] -> 1[170] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 06 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 07 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 08 : 5[1b0] -> 1[170] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 09 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 08 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 09 : 5[1b0] -> 1[170] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 06 : 1[170] -> 2[180] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 09 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 09 : 0[160] -> 4[1a0] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 07 : 1[170] -> 2[180] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 06 : 2[180] -> 3[190] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 08 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 07 : 2[180] -> 3[190] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 06 : 3[190] -> 0[160] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 09 : 2[180] -> 3[190] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 07 : 3[190] -> 0[160] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 08 : 3[190] -> 2[180] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 09 : 1[170] -> 2[180] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 06 : 5[1b0] -> 1[170] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 06 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 07 : 5[1b0] -> 1[170] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 09 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 09 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 07 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 07 : 4[1a0] -> 0[160] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 09 : 3[190] -> 2[180] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 07 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 06 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 08 : 4[1a0] -> 0[160] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 08 : 1[170] -> 5[1b0] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 09 : 5[1b0] -> 1[170] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 07 : 0[160] -> 3[190] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 08 : 2[180] -> 1[170] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 09 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 07 : 2[180] -> 1[170] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 08 : 3[190] -> 2[180] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 08 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 08 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 07 : 3[190] -> 2[180] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 09 : 3[190] -> 2[180] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 09 : 4[1a0] -> 0[160] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 07 : 1[170] -> 5[1b0] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 07 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 08 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 09 : 1[170] -> 5[1b0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 09 : 2[180] -> 1[170] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 08 : 1[170] -> 5[1b0] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 07 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 08 : 4[1a0] -> 0[160] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 08 : 2[180] -> 1[170] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 07 : 4[1a0] -> 0[160] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 08 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 07 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 09 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 08 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 07 : 0[160] -> 3[190] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 09 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 09 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 08 : 0[160] -> 4[1a0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 08 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 09 : 3[190] -> 0[160] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 07 : 1[170] -> 5[1b0] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 08 : 1[170] -> 2[180] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 07 : 2[180] -> 1[170] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 08 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 09 : 2[180] -> 1[170] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 08 : 2[180] -> 3[190] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 07 : 3[190] -> 2[180] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 09 : 1[170] -> 5[1b0] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 08 : 3[190] -> 0[160] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 09 : 0[160] -> 4[1a0] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 07 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 09 : 4[1a0] -> 0[160] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 09 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 07 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 08 : 5[1b0] -> 1[170] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 10 : 3[190] -> 7[1d0] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 09 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 07 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 08 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 09 : 3[190] -> 0[160] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 08 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 07 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 09 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 09 : 1[170] -> 2[180] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 09 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 09 : 2[180] -> 3[190] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 07 : 2[180] -> 3[190] via P2P/IPC
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 10 : 0[160] -> 1[170] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 07 : 3[190] -> 0[160] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 09 : 5[1b0] -> 1[170] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 09 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 09 : 0[160] -> 4[1a0] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 10 : 3[190] -> 7[1d0] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 07 : 1[170] -> 2[180] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 07 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 10 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 10 : 2[180] -> 0[160] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 10 : 1[170] -> 3[190] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 07 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 09 : 1[170] -> 2[180] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 09 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 09 : 2[180] -> 3[190] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 09 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 07 : 5[1b0] -> 1[170] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 10 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 07 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 10 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 10 : 6[1c0] -> 2[180] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 08 : 3[190] -> 2[180] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 09 : 5[1b0] -> 1[170] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 09 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 07 : 1[170] -> 2[180] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 07 : 2[180] -> 3[190] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 09 : 3[190] -> 2[180] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 10 : 0[160] -> 1[170] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 10 : 2[180] -> 0[160] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 07 : 3[190] -> 0[160] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 09 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 08 : 1[170] -> 5[1b0] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 08 : 4[1a0] -> 0[160] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 08 : 2[180] -> 1[170] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 10 : 1[170] -> 3[190] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 07 : 5[1b0] -> 1[170] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 07 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 10 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 10 : 6[1c0] -> 2[180] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 08 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 08 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 10 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 07 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 08 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 09 : 4[1a0] -> 0[160] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 09 : 1[170] -> 5[1b0] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 09 : 3[190] -> 2[180] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 08 : 0[160] -> 4[1a0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 08 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 10 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 09 : 2[180] -> 1[170] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 09 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 09 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 10 : 2[180] -> 6[1c0] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 08 : 2[180] -> 3[190] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 08 : 3[190] -> 0[160] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 10 : 3[190] -> 1[170] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 08 : 1[170] -> 2[180] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 08 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 10 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 10 : 1[170] -> 0[160] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 09 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 09 : 3[190] -> 0[160] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 09 : 1[170] -> 5[1b0] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 09 : 2[180] -> 1[170] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 09 : 4[1a0] -> 0[160] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 08 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 10 : 2[180] -> 6[1c0] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 10 : 7[1d0] -> 3[190] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 09 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 08 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 10 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 10 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 08 : 0[160] -> 4[1a0] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 08 : 5[1b0] -> 1[170] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 09 : 0[160] -> 4[1a0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 09 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 08 : 1[170] -> 2[180] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 08 : 2[180] -> 3[190] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 10 : 3[190] -> 7[1d0] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 09 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 08 : 3[190] -> 0[160] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 09 : 1[170] -> 2[180] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 10 : 3[190] -> 1[170] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 10 : 1[170] -> 0[160] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 09 : 2[180] -> 3[190] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 09 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 10 : 0[160] -> 1[170] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 10 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 08 : 5[1b0] -> 1[170] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 10 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 08 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 09 : 5[1b0] -> 1[170] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 10 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 10 : 3[190] -> 7[1d0] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 10 : 1[170] -> 3[190] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 08 : 3[190] -> 2[180] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 10 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 09 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 08 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 10 : 7[1d0] -> 3[190] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 10 : 2[180] -> 0[160] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 09 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 10 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 11 : 2[180] -> 6[1c0] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 10 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 08 : 4[1a0] -> 0[160] via P2P/IPC
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 11 : 0[160] -> 2[180] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 08 : 2[180] -> 1[170] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 10 : 0[160] -> 1[170] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 11 : 3[190] -> 1[170] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 08 : 1[170] -> 5[1b0] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 10 : 1[170] -> 3[190] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 10 : 6[1c0] -> 2[180] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 11 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 08 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 11 : 1[170] -> 0[160] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 09 : 3[190] -> 2[180] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 10 : 2[180] -> 0[160] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 10 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 08 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 11 : 2[180] -> 6[1c0] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 10 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 08 : 3[190] -> 2[180] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 08 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 11 : 7[1d0] -> 3[190] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 11 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 10 : 6[1c0] -> 2[180] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 11 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 11 : 0[160] -> 2[180] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 08 : 1[170] -> 5[1b0] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 08 : 2[180] -> 1[170] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 10 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 08 : 4[1a0] -> 0[160] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 09 : 1[170] -> 5[1b0] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 09 : 2[180] -> 1[170] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 09 : 3[190] -> 0[160] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 09 : 4[1a0] -> 0[160] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 11 : 1[170] -> 0[160] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 08 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 08 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 10 : 2[180] -> 6[1c0] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 11 : 3[190] -> 1[170] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 09 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 11 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 11 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 10 : 3[190] -> 1[170] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 09 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 10 : 1[170] -> 0[160] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 11 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 10 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 09 : 0[160] -> 4[1a0] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 08 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 09 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 11 : 7[1d0] -> 3[190] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 10 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 10 : 7[1d0] -> 3[190] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 11 : 1[170] -> 3[190] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 10 : 2[180] -> 6[1c0] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 09 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 09 : 2[180] -> 3[190] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 10 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 11 : 2[180] -> 0[160] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 09 : 3[190] -> 0[160] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 10 : 1[170] -> 0[160] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 11 : 3[190] -> 7[1d0] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 10 : 3[190] -> 7[1d0] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 09 : 1[170] -> 2[180] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO comm 0x55644e83e980 rank 1 nranks 8 cudaDev 1 busId 170 - Init COMPLETE
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 11 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 09 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 10 : 3[190] -> 1[170] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 10 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 09 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 10 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 09 : 0[160] -> 4[1a0] via P2P/IPC
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO comm 0x55d574e29400 rank 0 nranks 8 cudaDev 0 busId 160 - Init COMPLETE
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 11 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 11 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 11 : 6[1c0] -> 2[180] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 10 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 11 : 1[170] -> 3[190] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 09 : 5[1b0] -> 1[170] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 10 : 0[160] -> 1[170] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 10 : 7[1d0] -> 3[190] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 11 : 2[180] -> 0[160] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 10 : 1[170] -> 3[190] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 09 : 1[170] -> 2[180] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 09 : 2[180] -> 3[190] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 10 : 2[180] -> 0[160] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 09 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO comm 0x564189a07290 rank 2 nranks 8 cudaDev 2 busId 180 - Init COMPLETE
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 10 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 09 : 3[190] -> 2[180] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO comm 0x556f9d61cc60 rank 3 nranks 8 cudaDev 3 busId 190 - Init COMPLETE
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO comm 0x555870f916c0 rank 4 nranks 8 cudaDev 4 busId 1a0 - Init COMPLETE
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 11 : 0[160] -> 2[180] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 11 : 2[180] -> 6[1c0] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 10 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO comm 0x55e30029fa80 rank 1 nranks 8 cudaDev 1 busId 170 - Init COMPLETE
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 11 : 3[190] -> 7[1d0] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 09 : 5[1b0] -> 1[170] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 09 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO comm 0x560be9ad9150 rank 7 nranks 8 cudaDev 7 busId 1d0 - Init COMPLETE
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 11 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO comm 0x55d5612940f0 rank 5 nranks 8 cudaDev 5 busId 1b0 - Init COMPLETE
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 11 : 6[1c0] -> 2[180] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO comm 0x5581b11f6d60 rank 0 nranks 8 cudaDev 0 busId 160 - Init COMPLETE
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO comm 0x559f17ecc030 rank 6 nranks 8 cudaDev 6 busId 1c0 - Init COMPLETE
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 10 : 6[1c0] -> 2[180] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 11 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 11 : 1[170] -> 0[160] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 11 : 3[190] -> 1[170] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 11 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 11 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 09 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 10 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 11 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO comm 0x556eb7bcf5d0 rank 2 nranks 8 cudaDev 2 busId 180 - Init COMPLETE
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 11 : 2[180] -> 6[1c0] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 11 : 7[1d0] -> 3[190] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 11 : 0[160] -> 2[180] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 09 : 4[1a0] -> 0[160] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 09 : 2[180] -> 1[170] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 09 : 3[190] -> 2[180] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO comm 0x559639a11d20 rank 3 nranks 8 cudaDev 3 busId 190 - Init COMPLETE
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO comm 0x55b3d19e8770 rank 4 nranks 8 cudaDev 4 busId 1a0 - Init COMPLETE
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO comm 0x5616324f9450 rank 6 nranks 8 cudaDev 6 busId 1c0 - Init COMPLETE
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 11 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 11 : 1[170] -> 0[160] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 09 : 1[170] -> 5[1b0] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 09 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO comm 0x558dd1ee2d20 rank 5 nranks 8 cudaDev 5 busId 1b0 - Init COMPLETE
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO comm 0x55c6f5baca00 rank 7 nranks 8 cudaDev 7 busId 1d0 - Init COMPLETE
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 09 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 11 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 11 : 3[190] -> 1[170] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 11 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 09 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 10 : 2[180] -> 6[1c0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 11 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 09 : 1[170] -> 5[1b0] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 09 : 2[180] -> 1[170] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 10 : 1[170] -> 0[160] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 11 : 7[1d0] -> 3[190] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 09 : 4[1a0] -> 0[160] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 11 : 1[170] -> 3[190] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 10 : 3[190] -> 1[170] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 10 : 3[190] -> 7[1d0] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 10 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 09 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 10 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 09 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 10 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 11 : 3[190] -> 7[1d0] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO comm 0x5624196828f0 rank 1 nranks 8 cudaDev 1 busId 170 - Init COMPLETE
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 11 : 2[180] -> 0[160] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 09 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 11 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 10 : 0[160] -> 1[170] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 11 : 1[170] -> 3[190] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 11 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 10 : 7[1d0] -> 3[190] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 11 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Trees [0] 4/-1/-1->7->6|6->7->4/-1/-1 [1] 4/-1/-1->7->6|6->7->4/-1/-1 [2] 6/-1/-1->7->4|4->7->6/-1/-1 [3] 6/-1/-1->7->4|4->7->6/-1/-1 [4] 5/-1/-1->7->3|3->7->5/-1/-1 [5] 3/-1/-1->7->5|5->7->3/-1/-1 [6] 4/-1/-1->7->6|6->7->4/-1/-1 [7] 4/-1/-1->7->6|6->7->4/-1/-1 [8] 6/-1/-1->7->4|4->7->6/-1/-1 [9] 6/-1/-1->7->4|4->7->6/-1/-1 [10] 5/-1/-1->7->3|3->7->5/-1/-1 [11] 3/-1/-1->7->5|5->7->3/-1/-1
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Trees [0] -1/-1/-1->4->7|7->4->-1/-1/-1 [1] -1/-1/-1->4->7|7->4->-1/-1/-1 [2] 7/-1/-1->4->0|0->4->7/-1/-1 [3] 7/-1/-1->4->0|0->4->7/-1/-1 [4] 6/-1/-1->4->5|5->4->6/-1/-1 [5] 5/-1/-1->4->6|6->4->5/-1/-1 [6] -1/-1/-1->4->7|7->4->-1/-1/-1 [7] -1/-1/-1->4->7|7->4->-1/-1/-1 [8] 7/-1/-1->4->0|0->4->7/-1/-1 [9] 7/-1/-1->4->0|0->4->7/-1/-1 [10] 6/-1/-1->4->5|5->4->6/-1/-1 [11] 5/-1/-1->4->6|6->4->5/-1/-1
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1|-1->0->3/-1/-1 [1] 3/-1/-1->0->-1|-1->0->3/-1/-1 [2] 4/-1/-1->0->-1|-1->0->4/-1/-1 [3] 4/-1/-1->0->-1|-1->0->4/-1/-1 [4] 1/-1/-1->0->-1|-1->0->1/-1/-1 [5] 2/-1/-1->0->-1|-1->0->2/-1/-1 [6] 3/-1/-1->0->-1|-1->0->3/-1/-1 [7] 3/-1/-1->0->-1|-1->0->3/-1/-1 [8] 4/-1/-1->0->-1|-1->0->4/-1/-1 [9] 4/-1/-1->0->-1|-1->0->4/-1/-1 [10] 1/-1/-1->0->-1|-1->0->1/-1/-1 [11] 2/-1/-1->0->-1|-1->0->2/-1/-1
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Trees [0] 6/-1/-1->5->1|1->5->6/-1/-1 [1] 6/-1/-1->5->1|1->5->6/-1/-1 [2] 1/-1/-1->5->6|6->5->1/-1/-1 [3] 1/-1/-1->5->6|6->5->1/-1/-1 [4] 4/-1/-1->5->7|7->5->4/-1/-1 [5] 7/-1/-1->5->4|4->5->7/-1/-1 [6] 6/-1/-1->5->1|1->5->6/-1/-1 [7] 6/-1/-1->5->1|1->5->6/-1/-1 [8] 1/-1/-1->5->6|6->5->1/-1/-1 [9] 1/-1/-1->5->6|6->5->1/-1/-1 [10] 4/-1/-1->5->7|7->5->4/-1/-1 [11] 7/-1/-1->5->4|4->5->7/-1/-1
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Trees [0] 2/-1/-1->3->0|0->3->2/-1/-1 [1] 2/-1/-1->3->0|0->3->2/-1/-1 [2] -1/-1/-1->3->2|2->3->-1/-1/-1 [3] -1/-1/-1->3->2|2->3->-1/-1/-1 [4] 7/-1/-1->3->1|1->3->7/-1/-1 [5] 1/-1/-1->3->7|7->3->1/-1/-1 [6] 2/-1/-1->3->0|0->3->2/-1/-1 [7] 2/-1/-1->3->0|0->3->2/-1/-1 [8] -1/-1/-1->3->2|2->3->-1/-1/-1 [9] -1/-1/-1->3->2|2->3->-1/-1/-1 [10] 7/-1/-1->3->1|1->3->7/-1/-1 [11] 1/-1/-1->3->7|7->3->1/-1/-1
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 7/-1/-1->6->5|5->6->7/-1/-1 [2] 5/-1/-1->6->7|7->6->5/-1/-1 [3] 5/-1/-1->6->7|7->6->5/-1/-1 [4] 2/-1/-1->6->4|4->6->2/-1/-1 [5] 4/-1/-1->6->2|2->6->4/-1/-1 [6] 7/-1/-1->6->5|5->6->7/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1 [8] 5/-1/-1->6->7|7->6->5/-1/-1 [9] 5/-1/-1->6->7|7->6->5/-1/-1 [10] 2/-1/-1->6->4|4->6->2/-1/-1 [11] 4/-1/-1->6->2|2->6->4/-1/-1
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Trees [0] 5/-1/-1->1->2|2->1->5/-1/-1 [1] 5/-1/-1->1->2|2->1->5/-1/-1 [2] 2/-1/-1->1->5|5->1->2/-1/-1 [3] 2/-1/-1->1->5|5->1->2/-1/-1 [4] 3/-1/-1->1->0|0->1->3/-1/-1 [5] -1/-1/-1->1->3|3->1->-1/-1/-1 [6] 5/-1/-1->1->2|2->1->5/-1/-1 [7] 5/-1/-1->1->2|2->1->5/-1/-1 [8] 2/-1/-1->1->5|5->1->2/-1/-1 [9] 2/-1/-1->1->5|5->1->2/-1/-1 [10] 3/-1/-1->1->0|0->1->3/-1/-1 [11] -1/-1/-1->1->3|3->1->-1/-1/-1
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/64
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Trees [0] 1/-1/-1->2->3|3->2->1/-1/-1 [1] 1/-1/-1->2->3|3->2->1/-1/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 3/-1/-1->2->1|1->2->3/-1/-1 [4] -1/-1/-1->2->6|6->2->-1/-1/-1 [5] 6/-1/-1->2->0|0->2->6/-1/-1 [6] 1/-1/-1->2->3|3->2->1/-1/-1 [7] 1/-1/-1->2->3|3->2->1/-1/-1 [8] 3/-1/-1->2->1|1->2->3/-1/-1 [9] 3/-1/-1->2->1|1->2->3/-1/-1 [10] -1/-1/-1->2->6|6->2->-1/-1/-1 [11] 6/-1/-1->2->0|0->2->6/-1/-1
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 10 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 10 : 2[180] -> 0[160] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 10 : 3[190] -> 7[1d0] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO comm 0x55c1dc8ba880 rank 0 nranks 8 cudaDev 0 busId 160 - Init COMPLETE
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 11 : 6[1c0] -> 2[180] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 11 : 2[180] -> 0[160] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 10 : 1[170] -> 3[190] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 10 : 6[1c0] -> 2[180] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 11 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO comm 0x555c0d0b9920 rank 1 nranks 8 cudaDev 1 busId 170 - Init COMPLETE
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO comm 0x55bd8e97dfd0 rank 3 nranks 8 cudaDev 3 busId 190 - Init COMPLETE
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 10 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 11 : 3[190] -> 7[1d0] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO comm 0x5575b4f89b20 rank 4 nranks 8 cudaDev 4 busId 1a0 - Init COMPLETE
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO comm 0x55ba85861560 rank 0 nranks 8 cudaDev 0 busId 160 - Init COMPLETE
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 11 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO comm 0x55a6f80af8d0 rank 2 nranks 8 cudaDev 2 busId 180 - Init COMPLETE
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 11 : 2[180] -> 6[1c0] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 10 : 0[160] -> 1[170] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO comm 0x55f83de6e7b0 rank 5 nranks 8 cudaDev 5 busId 1b0 - Init COMPLETE
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 11 : 6[1c0] -> 2[180] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 10 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO comm 0x5572e667a770 rank 7 nranks 8 cudaDev 7 busId 1d0 - Init COMPLETE
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 11 : 0[160] -> 2[180] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO comm 0x5631b38abe50 rank 6 nranks 8 cudaDev 6 busId 1c0 - Init COMPLETE
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 11 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 10 : 2[180] -> 0[160] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 10 : 1[170] -> 3[190] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 11 : 1[170] -> 0[160] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 10 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO comm 0x56184250d920 rank 2 nranks 8 cudaDev 2 busId 180 - Init COMPLETE
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 10 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO comm 0x5648b79278f0 rank 4 nranks 8 cudaDev 4 busId 1a0 - Init COMPLETE
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 00 : 2[180] -> 1[170] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 10 : 6[1c0] -> 2[180] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 11 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 00 : 3[190] -> 2[180] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO comm 0x559808b3b5c0 rank 3 nranks 8 cudaDev 3 busId 190 - Init COMPLETE
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 11 : 3[190] -> 1[170] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO comm 0x55a6babd02b0 rank 5 nranks 8 cudaDev 5 busId 1b0 - Init COMPLETE
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 11 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 00 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO comm 0x55ec1616c6e0 rank 6 nranks 8 cudaDev 6 busId 1c0 - Init COMPLETE
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 00 : 4[1a0] -> 0[160] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 00 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO comm 0x56497ad5a770 rank 7 nranks 8 cudaDev 7 busId 1d0 - Init COMPLETE
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 00 : 1[170] -> 5[1b0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 00 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 00 : 0[160] -> 3[190] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 11 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 10 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 10 : 2[180] -> 6[1c0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 11 : 7[1d0] -> 3[190] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 10 : 3[190] -> 1[170] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 10 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 10 : 1[170] -> 0[160] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 10 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 10 : 7[1d0] -> 3[190] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 10 : 2[180] -> 6[1c0] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 10 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 11 : 1[170] -> 3[190] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 10 : 1[170] -> 0[160] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 10 : 3[190] -> 1[170] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 10 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 11 : 2[180] -> 0[160] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 10 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 10 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO comm 0x5644b87c5fa0 rank 1 nranks 8 cudaDev 1 busId 170 - Init COMPLETE
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 11 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 11 : 3[190] -> 7[1d0] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 11 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 00 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 11 : 2[180] -> 6[1c0] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 11 : 6[1c0] -> 2[180] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO comm 0x563cea0c7dc0 rank 0 nranks 8 cudaDev 0 busId 160 - Init COMPLETE
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 10 : 7[1d0] -> 3[190] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 11 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 00 : 2[180] -> 3[190] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 00 : 3[190] -> 0[160] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 11 : 0[160] -> 2[180] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 00 : 5[1b0] -> 1[170] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 00 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 00 : 1[170] -> 2[180] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO comm 0x563d102f76c0 rank 2 nranks 8 cudaDev 2 busId 180 - Init COMPLETE
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 00 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 11 : 3[190] -> 1[170] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO comm 0x558512d08b20 rank 4 nranks 8 cudaDev 4 busId 1a0 - Init COMPLETE
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO comm 0x556ca95d0450 rank 3 nranks 8 cudaDev 3 busId 190 - Init COMPLETE
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO comm 0x55d1f04abf20 rank 5 nranks 8 cudaDev 5 busId 1b0 - Init COMPLETE
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 11 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 11 : 1[170] -> 0[160] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO comm 0x55b2d4b57790 rank 6 nranks 8 cudaDev 6 busId 1c0 - Init COMPLETE
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 11 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO comm 0x562fe7e0db10 rank 7 nranks 8 cudaDev 7 busId 1d0 - Init COMPLETE
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 11 : 2[180] -> 6[1c0] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 11 : 7[1d0] -> 3[190] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 11 : 0[160] -> 2[180] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 11 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 11 : 1[170] -> 0[160] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 11 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 01 : 4[1a0] -> 0[160] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 11 : 3[190] -> 1[170] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 11 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 11 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 01 : 0[160] -> 3[190] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 11 : 7[1d0] -> 3[190] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 01 : 2[180] -> 1[170] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 11 : 1[170] -> 3[190] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 01 : 3[190] -> 2[180] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 01 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 11 : 2[180] -> 0[160] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 01 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 01 : 1[170] -> 5[1b0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 01 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 11 : 3[190] -> 7[1d0] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO comm 0x5556150ed230 rank 1 nranks 8 cudaDev 1 busId 170 - Init COMPLETE
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO comm 0x559cfc7ff360 rank 0 nranks 8 cudaDev 0 busId 160 - Init COMPLETE
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 11 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 11 : 6[1c0] -> 2[180] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 11 : 1[170] -> 3[190] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 11 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 11 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 11 : 2[180] -> 0[160] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO comm 0x5594e46494e0 rank 2 nranks 8 cudaDev 2 busId 180 - Init COMPLETE
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO comm 0x5565028626c0 rank 3 nranks 8 cudaDev 3 busId 190 - Init COMPLETE
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 01 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 11 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO comm 0x555a8d000450 rank 1 nranks 8 cudaDev 1 busId 170 - Init COMPLETE
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 11 : 3[190] -> 7[1d0] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO comm 0x5596706ca6f0 rank 4 nranks 8 cudaDev 4 busId 1a0 - Init COMPLETE
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO comm 0x555dd41ade40 rank 6 nranks 8 cudaDev 6 busId 1c0 - Init COMPLETE
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 11 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO comm 0x5607c2a399d0 rank 7 nranks 8 cudaDev 7 busId 1d0 - Init COMPLETE
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 11 : 6[1c0] -> 2[180] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO comm 0x5635cc950b80 rank 5 nranks 8 cudaDev 5 busId 1b0 - Init COMPLETE
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO comm 0x56190d826a20 rank 0 nranks 8 cudaDev 0 busId 160 - Init COMPLETE
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 11 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 01 : 2[180] -> 3[190] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 01 : 3[190] -> 0[160] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 01 : 5[1b0] -> 1[170] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 01 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO comm 0x55d84fafc2b0 rank 2 nranks 8 cudaDev 2 busId 180 - Init COMPLETE
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 01 : 1[170] -> 2[180] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 01 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO comm 0x5603173e1c30 rank 4 nranks 8 cudaDev 4 busId 1a0 - Init COMPLETE
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO comm 0x562cf4c0caa0 rank 3 nranks 8 cudaDev 3 busId 190 - Init COMPLETE
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO comm 0x5603d00638c0 rank 5 nranks 8 cudaDev 5 busId 1b0 - Init COMPLETE
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO comm 0x556ffd866f90 rank 6 nranks 8 cudaDev 6 busId 1c0 - Init COMPLETE
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO comm 0x564f30c16920 rank 7 nranks 8 cudaDev 7 busId 1d0 - Init COMPLETE
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 02 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 02 : 0[160] -> 4[1a0] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 02 : 2[180] -> 3[190] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 02 : 3[190] -> 0[160] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 02 : 5[1b0] -> 1[170] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 02 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 02 : 1[170] -> 2[180] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 02 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 02 : 3[190] -> 2[180] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 02 : 4[1a0] -> 0[160] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 02 : 2[180] -> 1[170] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 02 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 02 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 02 : 1[170] -> 5[1b0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 02 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 03 : 3[190] -> 0[160] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 03 : 0[160] -> 4[1a0] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 03 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 03 : 2[180] -> 3[190] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 03 : 5[1b0] -> 1[170] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 03 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 03 : 1[170] -> 2[180] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 03 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 03 : 3[190] -> 2[180] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 03 : 4[1a0] -> 0[160] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 03 : 2[180] -> 1[170] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 03 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 03 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 03 : 1[170] -> 5[1b0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 03 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 04 : 3[190] -> 7[1d0] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 04 : 0[160] -> 1[170] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 04 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 04 : 2[180] -> 0[160] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 04 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 04 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 04 : 1[170] -> 3[190] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 04 : 6[1c0] -> 2[180] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 04 : 2[180] -> 6[1c0] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 04 : 3[190] -> 1[170] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 04 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 04 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 04 : 7[1d0] -> 3[190] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 04 : 1[170] -> 0[160] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 04 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 05 : 2[180] -> 6[1c0] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 05 : 3[190] -> 1[170] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 05 : 0[160] -> 2[180] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 05 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 05 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 05 : 7[1d0] -> 3[190] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 05 : 1[170] -> 0[160] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 05 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 05 : 1[170] -> 3[190] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 05 : 3[190] -> 7[1d0] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 05 : 2[180] -> 0[160] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 05 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 05 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 05 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 05 : 6[1c0] -> 2[180] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 06 : 1[170] -> 5[1b0] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 06 : 0[160] -> 3[190] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 06 : 3[190] -> 2[180] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 06 : 2[180] -> 1[170] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 06 : 4[1a0] -> 0[160] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 06 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 06 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 06 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 06 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 06 : 1[170] -> 2[180] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 06 : 3[190] -> 0[160] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 06 : 2[180] -> 3[190] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 06 : 5[1b0] -> 1[170] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 06 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 06 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 07 : 4[1a0] -> 0[160] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 07 : 0[160] -> 3[190] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 07 : 1[170] -> 5[1b0] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 07 : 3[190] -> 2[180] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 07 : 2[180] -> 1[170] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 07 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 07 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 07 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 07 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 07 : 1[170] -> 2[180] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 07 : 3[190] -> 0[160] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 07 : 2[180] -> 3[190] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 07 : 5[1b0] -> 1[170] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 07 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 07 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 08 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 08 : 0[160] -> 4[1a0] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 08 : 1[170] -> 2[180] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 08 : 3[190] -> 0[160] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 08 : 2[180] -> 3[190] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 08 : 5[1b0] -> 1[170] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 08 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 08 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 08 : 3[190] -> 2[180] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 08 : 4[1a0] -> 0[160] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 08 : 1[170] -> 5[1b0] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 08 : 2[180] -> 1[170] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 08 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 08 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 08 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 09 : 3[190] -> 0[160] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 09 : 0[160] -> 4[1a0] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 09 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 09 : 1[170] -> 2[180] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 09 : 2[180] -> 3[190] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 09 : 5[1b0] -> 1[170] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 09 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 09 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 09 : 3[190] -> 2[180] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 09 : 4[1a0] -> 0[160] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 09 : 1[170] -> 5[1b0] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 09 : 2[180] -> 1[170] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 09 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 09 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 09 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 10 : 3[190] -> 7[1d0] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 10 : 0[160] -> 1[170] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 10 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 10 : 1[170] -> 3[190] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 10 : 2[180] -> 0[160] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 10 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 10 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 10 : 6[1c0] -> 2[180] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 10 : 2[180] -> 6[1c0] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 10 : 3[190] -> 1[170] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 10 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 10 : 1[170] -> 0[160] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 10 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 10 : 7[1d0] -> 3[190] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 10 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 11 : 2[180] -> 6[1c0] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 11 : 0[160] -> 2[180] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 11 : 3[190] -> 1[170] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 11 : 1[170] -> 0[160] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 11 : 4[1a0] -> 5[1b0] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 11 : 5[1b0] -> 7[1d0] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 11 : 7[1d0] -> 3[190] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 11 : 6[1c0] -> 4[1a0] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 11 : 1[170] -> 3[190] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 11 : 3[190] -> 7[1d0] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO comm 0x56164a552660 rank 1 nranks 8 cudaDev 1 busId 170 - Init COMPLETE
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 11 : 2[180] -> 0[160] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 11 : 4[1a0] -> 6[1c0] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 11 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 11 : 7[1d0] -> 5[1b0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 11 : 6[1c0] -> 2[180] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO comm 0x55e06d429050 rank 0 nranks 8 cudaDev 0 busId 160 - Init COMPLETE
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO comm 0x5563ce22b430 rank 3 nranks 8 cudaDev 3 busId 190 - Init COMPLETE
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO comm 0x556cde681b40 rank 2 nranks 8 cudaDev 2 busId 180 - Init COMPLETE
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO comm 0x562fa7efd850 rank 4 nranks 8 cudaDev 4 busId 1a0 - Init COMPLETE
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO comm 0x55ad96568f50 rank 5 nranks 8 cudaDev 5 busId 1b0 - Init COMPLETE
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO comm 0x55bf444c74d0 rank 7 nranks 8 cudaDev 7 busId 1d0 - Init COMPLETE
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO comm 0x55b78ea55c30 rank 6 nranks 8 cudaDev 6 busId 1c0 - Init COMPLETE
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO NET/OFI [7] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO NET/OFI [7] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO NET/OFI [7] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO NET/OFI [7] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO NET/OFI [6] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO NET/OFI [6] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO NET/OFI [5] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO NET/OFI [6] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO NET/OFI [6] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00/
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO NET/OFI [5] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO NET/OFI [5] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO NET/OFI [2] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO NET/OFI [5] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO NET/OFI [2] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO NET/OFI [2] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO NET/OFI [2] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO NET/OFI [3] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO NET/OFI [3] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00/
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO NET/OFI [3] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO NET/OFI [3] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO NET/OFI [1] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO NET/OFI [1] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO NET/OFI [1] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO NET/OFI [1] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO NET/OFI [4] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO NET/OFI [4] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO NET/OFI [4] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00/
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO NET/OFI [4] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO NET/OFI [0] getCudaPath dev 0 busId 0000:00:16.0 path /sys/devices/pci0000:00/
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO NET/OFI [0] getCudaPath dev 1 busId 0000:00:17.0 path /sys/devices/pci0000:00
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO NET/OFI [0] getCudaPath dev 2 busId 0000:00:18.0 path /sys/devices/pci0000:00
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO NET/OFI [0] getCudaPath dev 3 busId 0000:00:19.0 path /sys/devices/pci0000:00
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Trees [0] 62/-1/-1->61->57|57->61->62/-1/-1 [1] -1/-1/-1->61->62|62->61->-1/-1/-1 [2] 57/-1/-1->61->62|62->61->57/-1/-1 [3] 62/-1/-1->61->54|54->61->62/-1/-1 [4] 62/-1/-1->61->57|57->61->62/-1/-1 [5] -1/-1/-1->61->62|62->61->-1/-1/-1 [6] 57/-1/-1->61->62|62->61->57/-1/-1 [7] 62/-1/-1->61->46|46->61->62/-1/-1
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Trees [0] 60/-1/-1->63->62|62->63->60/-1/-1 [1] 62/-1/-1->63->60|60->63->62/-1/-1 [2] 62/-1/-1->63->60|60->63->62/-1/-1 [3] 60/-1/-1->63->62|62->63->60/-1/-1 [4] 60/-1/-1->63->62|62->63->60/-1/-1 [5] 62/-1/-1->63->60|60->63->62/-1/-1 [6] 62/52/4->63->60|60->63->62/52/4 [7] 60/-1/-1->63->62|62->63->60/-1/-1
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Trees [0] 63/-1/-1->62->61|61->62->63/-1/-1 [1] 61/-1/-1->62->63|63->62->61/-1/-1 [2] 61/-1/-1->62->63|63->62->61/-1/-1 [3] 63/-1/-1->62->61|61->62->63/-1/-1 [4] 63/-1/-1->62->61|61->62->63/-1/-1 [5] 61/-1/-1->62->63|63->62->61/-1/-1 [6] 61/-1/-1->62->63|63->62->61/-1/-1 [7] 63/53/5->62->61|61->62->63/53/5
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Trees [0] 6/-1/-1->5->1|1->5->6/-1/-1 [1] -1/-1/-1->5->6|6->5->-1/-1/-1 [2] 1/-1/-1->5->6|6->5->1/-1/-1 [3] 6/-1/-1->5->-1|-1->5->6/-1/-1 [4] 6/-1/-1->5->1|1->5->6/-1/-1 [5] -1/-1/-1->5->6|6->5->-1/-1/-1 [6] 1/-1/-1->5->6|6->5->1/-1/-1 [7] 6/-1/-1->5->62|62->5->6/-1/-1
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Trees [0] -1/-1/-1->12->15|15->12->-1/-1/-1 [1] 15/-1/-1->12->8|8->12->15/-1/-1 [2] 15/-1/-1->12->23|23->12->15/-1/-1 [3] 8/-1/-1->12->15|15->12->8/-1/-1 [4] -1/-1/-1->12->15|15->12->-1/-1/-1 [5] 15/-1/-1->12->8|8->12->15/-1/-1 [6] 15/-1/-1->12->-1|-1->12->15/-1/-1 [7] 8/-1/-1->12->15|15->12->8/-1/-1
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Trees [0] 17/-1/-1->18->19|19->18->17/-1/-1 [1] 19/9/25->18->17|17->18->19/9/25 [2] 19/-1/-1->18->17|17->18->19/-1/-1 [3] 17/-1/-1->18->19|19->18->17/-1/-1 [4] 17/-1/-1->18->19|19->18->17/-1/-1 [5] 19/-1/-1->18->17|17->18->19/-1/-1 [6] 19/-1/-1->18->17|17->18->19/-1/-1 [7] 17/-1/-1->18->19|19->18->17/-1/-1
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Trees [0] 7/-1/-1->6->5|5->6->7/-1/-1 [1] 5/-1/-1->6->7|7->6->5/-1/-1 [2] 5/-1/-1->6->7|7->6->5/-1/-1 [3] 7/37/-1->6->5|5->6->7/37/-1 [4] 7/-1/-1->6->5|5->6->7/-1/-1 [5] 5/-1/-1->6->7|7->6->5/-1/-1 [6] 5/-1/-1->6->7|7->6->5/-1/-1 [7] 7/-1/-1->6->5|5->6->7/-1/-1
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Trees [0] 9/-1/-1->10->11|11->10->9/-1/-1 [1] 11/-1/-1->10->9|9->10->11/-1/-1 [2] 11/-1/-1->10->9|9->10->11/-1/-1 [3] 9/-1/-1->10->11|11->10->9/-1/-1 [4] 9/-1/-1->10->11|11->10->9/-1/-1 [5] 11/41/-1->10->9|9->10->11/41/-1 [6] 11/-1/-1->10->9|9->10->11/-1/-1 [7] 9/-1/-1->10->11|11->10->9/-1/-1
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Trees [0] 18/8/24->19->16|16->19->18/8/24 [1] 16/-1/-1->19->18|18->19->16/-1/-1 [2] 16/-1/-1->19->18|18->19->16/-1/-1 [3] 18/-1/-1->19->16|16->19->18/-1/-1 [4] 18/-1/-1->19->16|16->19->18/-1/-1 [5] 16/-1/-1->19->18|18->19->16/-1/-1 [6] 16/-1/-1->19->18|18->19->16/-1/-1 [7] 18/-1/-1->19->16|16->19->18/-1/-1
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Trees [0] 1/-1/-1->2->3|3->2->1/-1/-1 [1] 3/33/-1->2->1|1->2->3/33/-1 [2] 3/-1/-1->2->1|1->2->3/-1/-1 [3] 1/-1/-1->2->3|3->2->1/-1/-1 [4] 1/-1/-1->2->3|3->2->1/-1/-1 [5] 3/-1/-1->2->1|1->2->3/-1/-1 [6] 3/-1/-1->2->1|1->2->3/-1/-1 [7] 1/-1/-1->2->3|3->2->1/-1/-1
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Trees [0] 10/-1/-1->11->8|8->11->10/-1/-1 [1] 8/-1/-1->11->10|10->11->8/-1/-1 [2] 8/-1/-1->11->10|10->11->8/-1/-1 [3] 10/-1/-1->11->8|8->11->10/-1/-1 [4] 10/40/-1->11->8|8->11->10/40/-1 [5] 8/-1/-1->11->10|10->11->8/-1/-1 [6] 8/-1/-1->11->10|10->11->8/-1/-1 [7] 10/-1/-1->11->8|8->11->10/-1/-1
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Trees [0] 19/-1/-1->16->35|35->16->19/-1/-1 [1] 20/-1/-1->16->19|19->16->20/-1/-1 [2] -1/-1/-1->16->19|19->16->-1/-1/-1 [3] 19/-1/-1->16->20|20->16->19/-1/-1 [4] 19/-1/-1->16->27|27->16->19/-1/-1 [5] 20/-1/-1->16->19|19->16->20/-1/-1 [6] -1/-1/-1->16->19|19->16->-1/-1/-1 [7] 19/-1/-1->16->20|20->16->19/-1/-1
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Trees [0] 5/-1/-1->1->2|2->1->5/-1/-1 [1] 2/-1/-1->1->-1|-1->1->2/-1/-1 [2] 2/-1/-1->1->5|5->1->2/-1/-1 [3] -1/-1/-1->1->2|2->1->-1/-1/-1 [4] 5/-1/-1->1->2|2->1->5/-1/-1 [5] 2/-1/-1->1->58|58->1->2/-1/-1 [6] 2/-1/-1->1->5|5->1->2/-1/-1 [7] -1/-1/-1->1->2|2->1->-1/-1/-1
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Trees [0] 11/-1/-1->8->19|19->8->11/-1/-1 [1] 12/-1/-1->8->11|11->8->12/-1/-1 [2] -1/-1/-1->8->11|11->8->-1/-1/-1 [3] 11/-1/-1->8->12|12->8->11/-1/-1 [4] 11/-1/-1->8->-1|-1->8->11/-1/-1 [5] 12/-1/-1->8->11|11->8->12/-1/-1 [6] -1/-1/-1->8->11|11->8->-1/-1/-1 [7] 11/-1/-1->8->12|12->8->11/-1/-1
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Trees [0] 21/-1/-1->17->18|18->17->21/-1/-1 [1] 18/-1/-1->17->34|34->17->18/-1/-1 [2] 18/-1/-1->17->21|21->17->18/-1/-1 [3] -1/-1/-1->17->18|18->17->-1/-1/-1 [4] 21/-1/-1->17->18|18->17->21/-1/-1 [5] 18/-1/-1->17->26|26->17->18/-1/-1 [6] 18/-1/-1->17->21|21->17->18/-1/-1 [7] -1/-1/-1->17->18|18->17->-1/-1/-1
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Trees [0] 4/-1/-1->7->6|6->7->4/-1/-1 [1] 6/-1/-1->7->4|4->7->6/-1/-1 [2] 6/36/-1->7->4|4->7->6/36/-1 [3] 4/-1/-1->7->6|6->7->4/-1/-1 [4] 4/-1/-1->7->6|6->7->4/-1/-1 [5] 6/-1/-1->7->4|4->7->6/-1/-1 [6] 6/-1/-1->7->4|4->7->6/-1/-1 [7] 4/-1/-1->7->6|6->7->4/-1/-1
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Trees [0] 15/-1/-1->14->13|13->14->15/-1/-1 [1] 13/-1/-1->14->15|15->14->13/-1/-1 [2] 13/-1/-1->14->15|15->14->13/-1/-1 [3] 15/-1/-1->14->13|13->14->15/-1/-1 [4] 15/-1/-1->14->13|13->14->15/-1/-1 [5] 13/-1/-1->14->15|15->14->13/-1/-1 [6] 13/-1/-1->14->15|15->14->13/-1/-1 [7] 15/45/-1->14->13|13->14->15/45/-1
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Trees [0] -1/-1/-1->20->23|23->20->-1/-1/-1 [1] 23/-1/-1->20->16|16->20->23/-1/-1 [2] 23/-1/-1->20->39|39->20->23/-1/-1 [3] 16/-1/-1->20->23|23->20->16/-1/-1 [4] -1/-1/-1->20->23|23->20->-1/-1/-1 [5] 23/-1/-1->20->16|16->20->23/-1/-1 [6] 23/-1/-1->20->31|31->20->23/-1/-1 [7] 16/-1/-1->20->23|23->20->16/-1/-1
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Trees [0] 2/32/-1->3->0|0->3->2/32/-1 [1] 0/-1/-1->3->2|2->3->0/-1/-1 [2] 0/-1/-1->3->2|2->3->0/-1/-1 [3] 2/-1/-1->3->0|0->3->2/-1/-1 [4] 2/-1/-1->3->0|0->3->2/-1/-1 [5] 0/-1/-1->3->2|2->3->0/-1/-1 [6] 0/-1/-1->3->2|2->3->0/-1/-1 [7] 2/-1/-1->3->0|0->3->2/-1/-1
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Trees [0] 13/-1/-1->9->10|10->9->13/-1/-1 [1] 10/-1/-1->9->18|18->9->10/-1/-1 [2] 10/-1/-1->9->13|13->9->10/-1/-1 [3] -1/-1/-1->9->10|10->9->-1/-1/-1 [4] 13/-1/-1->9->10|10->9->13/-1/-1 [5] 10/-1/-1->9->-1|-1->9->10/-1/-1 [6] 10/-1/-1->9->13|13->9->10/-1/-1 [7] -1/-1/-1->9->10|10->9->-1/-1/-1
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Trees [0] 22/-1/-1->21->17|17->21->22/-1/-1 [1] -1/-1/-1->21->22|22->21->-1/-1/-1 [2] 17/-1/-1->21->22|22->21->17/-1/-1 [3] 22/-1/-1->21->38|38->21->22/-1/-1 [4] 22/-1/-1->21->17|17->21->22/-1/-1 [5] -1/-1/-1->21->22|22->21->-1/-1/-1 [6] 17/-1/-1->21->22|22->21->17/-1/-1 [7] 22/-1/-1->21->30|30->21->22/-1/-1
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Channel 00/08 :    0   3   2   1   5   6   7   4   8  11  10   9  13  14  15  12  16  19  18  17
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Channel 01/08 :    0   4   7   6   5   9  10  11   8  12  15  14  13  17  18  19  16  20  23  22
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Channel 02/08 :    0   1   5   6  10  11  15  12   8   9  13  14  18  19  23  20  16  17  21  22
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Channel 03/08 :    0   1   2   6   5   4   7  11   8   9  10  14  13  12  15  19  16  17  18  22
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Channel 04/08 :    0   3   2   1   5   6   7   4   8  11  10   9  13  14  15  12  16  19  18  17
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Channel 05/08 :    0   4   7   6   5   9  10  11   8  12  15  14  13  17  18  19  16  20  23  22
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Channel 06/08 :    0   1   5   6  10  11  15  12   8   9  13  14  18  19  23  20  16  17  21  22
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Channel 07/08 :    0   1   2   6   5   4   7  11   8   9  10  14  13  12  15  19  16  17  18  22
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1|-1->0->3/-1/-1 [1] 4/-1/-1->0->3|3->0->4/-1/-1 [2] -1/-1/-1->0->3|3->0->-1/-1/-1 [3] 3/-1/-1->0->4|4->0->3/-1/-1 [4] 3/-1/-1->0->59|59->0->3/-1/-1 [5] 4/-1/-1->0->3|3->0->4/-1/-1 [6] -1/-1/-1->0->3|3->0->-1/-1/-1 [7] 3/-1/-1->0->4|4->0->3/-1/-1
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Trees [0] 12/-1/-1->15->14|14->15->12/-1/-1 [1] 14/-1/-1->15->12|12->15->14/-1/-1 [2] 14/-1/-1->15->12|12->15->14/-1/-1 [3] 12/-1/-1->15->14|14->15->12/-1/-1 [4] 12/-1/-1->15->14|14->15->12/-1/-1 [5] 14/-1/-1->15->12|12->15->14/-1/-1 [6] 14/44/-1->15->12|12->15->14/44/-1 [7] 12/-1/-1->15->14|14->15->12/-1/-1
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Trees [0] 20/-1/-1->23->22|22->23->20/-1/-1 [1] 22/-1/-1->23->20|20->23->22/-1/-1 [2] 22/12/28->23->20|20->23->22/12/28 [3] 20/-1/-1->23->22|22->23->20/-1/-1 [4] 20/-1/-1->23->22|22->23->20/-1/-1 [5] 22/-1/-1->23->20|20->23->22/-1/-1 [6] 22/-1/-1->23->20|20->23->22/-1/-1 [7] 20/-1/-1->23->22|22->23->20/-1/-1
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Trees [0] -1/-1/-1->4->7|7->4->-1/-1/-1 [1] 7/-1/-1->4->0|0->4->7/-1/-1 [2] 7/-1/-1->4->-1|-1->4->7/-1/-1 [3] 0/-1/-1->4->7|7->4->0/-1/-1 [4] -1/-1/-1->4->7|7->4->-1/-1/-1 [5] 7/-1/-1->4->0|0->4->7/-1/-1 [6] 7/-1/-1->4->63|63->4->7/-1/-1 [7] 0/-1/-1->4->7|7->4->0/-1/-1
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Trees [0] 14/-1/-1->13->9|9->13->14/-1/-1 [1] -1/-1/-1->13->14|14->13->-1/-1/-1 [2] 9/-1/-1->13->14|14->13->9/-1/-1 [3] 14/-1/-1->13->22|22->13->14/-1/-1 [4] 14/-1/-1->13->9|9->13->14/-1/-1 [5] -1/-1/-1->13->14|14->13->-1/-1/-1 [6] 9/-1/-1->13->14|14->13->9/-1/-1 [7] 14/-1/-1->13->-1|-1->13->14/-1/-1
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Trees [0] 25/-1/-1->26->27|27->26->25/-1/-1 [1] 27/-1/-1->26->25|25->26->27/-1/-1 [2] 27/-1/-1->26->25|25->26->27/-1/-1 [3] 25/-1/-1->26->27|27->26->25/-1/-1 [4] 25/-1/-1->26->27|27->26->25/-1/-1 [5] 27/17/33->26->25|25->26->27/17/33 [6] 27/-1/-1->26->25|25->26->27/-1/-1 [7] 25/-1/-1->26->27|27->26->25/-1/-1
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Trees [0] 23/-1/-1->22->21|21->22->23/-1/-1 [1] 21/-1/-1->22->23|23->22->21/-1/-1 [2] 21/-1/-1->22->23|23->22->21/-1/-1 [3] 23/13/29->22->21|21->22->23/13/29 [4] 23/-1/-1->22->21|21->22->23/-1/-1 [5] 21/-1/-1->22->23|23->22->21/-1/-1 [6] 21/-1/-1->22->23|23->22->21/-1/-1 [7] 23/-1/-1->22->21|21->22->23/-1/-1
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Trees [0] 26/-1/-1->27->24|24->27->26/-1/-1 [1] 24/-1/-1->27->26|26->27->24/-1/-1 [2] 24/-1/-1->27->26|26->27->24/-1/-1 [3] 26/-1/-1->27->24|24->27->26/-1/-1 [4] 26/16/32->27->24|24->27->26/16/32 [5] 24/-1/-1->27->26|26->27->24/-1/-1 [6] 24/-1/-1->27->26|26->27->24/-1/-1 [7] 26/-1/-1->27->24|24->27->26/-1/-1
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 00 : 61[1b0] -> 62[1c0] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Trees [0] 29/-1/-1->25->26|26->25->29/-1/-1 [1] 26/-1/-1->25->18|18->25->26/-1/-1 [2] 26/-1/-1->25->29|29->25->26/-1/-1 [3] -1/-1/-1->25->26|26->25->-1/-1/-1 [4] 29/-1/-1->25->26|26->25->29/-1/-1 [5] 26/-1/-1->25->42|42->25->26/-1/-1 [6] 26/-1/-1->25->29|29->25->26/-1/-1 [7] -1/-1/-1->25->26|26->25->-1/-1/-1
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Trees [0] -1/-1/-1->28->31|31->28->-1/-1/-1 [1] 31/-1/-1->28->24|24->28->31/-1/-1 [2] 31/-1/-1->28->23|23->28->31/-1/-1 [3] 24/-1/-1->28->31|31->28->24/-1/-1 [4] -1/-1/-1->28->31|31->28->-1/-1/-1 [5] 31/-1/-1->28->24|24->28->31/-1/-1 [6] 31/-1/-1->28->47|47->28->31/-1/-1 [7] 24/-1/-1->28->31|31->28->24/-1/-1
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Trees [0] 27/-1/-1->24->19|19->24->27/-1/-1 [1] 28/-1/-1->24->27|27->24->28/-1/-1 [2] -1/-1/-1->24->27|27->24->-1/-1/-1 [3] 27/-1/-1->24->28|28->24->27/-1/-1 [4] 27/-1/-1->24->43|43->24->27/-1/-1 [5] 28/-1/-1->24->27|27->24->28/-1/-1 [6] -1/-1/-1->24->27|27->24->-1/-1/-1 [7] 27/-1/-1->24->28|28->24->27/-1/-1
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Trees [0] 30/-1/-1->29->25|25->29->30/-1/-1 [1] -1/-1/-1->29->30|30->29->-1/-1/-1 [2] 25/-1/-1->29->30|30->29->25/-1/-1 [3] 30/-1/-1->29->22|22->29->30/-1/-1 [4] 30/-1/-1->29->25|25->29->30/-1/-1 [5] -1/-1/-1->29->30|30->29->-1/-1/-1 [6] 25/-1/-1->29->30|30->29->25/-1/-1 [7] 30/-1/-1->29->46|46->29->30/-1/-1
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Trees [0] 28/-1/-1->31->30|30->31->28/-1/-1 [1] 30/-1/-1->31->28|28->31->30/-1/-1 [2] 30/-1/-1->31->28|28->31->30/-1/-1 [3] 28/-1/-1->31->30|30->31->28/-1/-1 [4] 28/-1/-1->31->30|30->31->28/-1/-1 [5] 30/-1/-1->31->28|28->31->30/-1/-1 [6] 30/20/36->31->28|28->31->30/20/36 [7] 28/-1/-1->31->30|30->31->28/-1/-1
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Trees [0] 31/-1/-1->30->29|29->30->31/-1/-1 [1] 29/-1/-1->30->31|31->30->29/-1/-1 [2] 29/-1/-1->30->31|31->30->29/-1/-1 [3] 31/-1/-1->30->29|29->30->31/-1/-1 [4] 31/-1/-1->30->29|29->30->31/-1/-1 [5] 29/-1/-1->30->31|31->30->29/-1/-1 [6] 29/-1/-1->30->31|31->30->29/-1/-1 [7] 31/21/37->30->29|29->30->31/21/37
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 00 : 62[1c0] -> 63[1d0] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Trees [0] 37/-1/-1->33->34|34->33->37/-1/-1 [1] 34/-1/-1->33->2|2->33->34/-1/-1 [2] 34/-1/-1->33->37|37->33->34/-1/-1 [3] -1/-1/-1->33->34|34->33->-1/-1/-1 [4] 37/-1/-1->33->34|34->33->37/-1/-1 [5] 34/-1/-1->33->26|26->33->34/-1/-1 [6] 34/-1/-1->33->37|37->33->34/-1/-1 [7] -1/-1/-1->33->34|34->33->-1/-1/-1
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Trees [0] 35/-1/-1->32->3|3->32->35/-1/-1 [1] 36/-1/-1->32->35|35->32->36/-1/-1 [2] -1/-1/-1->32->35|35->32->-1/-1/-1 [3] 35/-1/-1->32->36|36->32->35/-1/-1 [4] 35/-1/-1->32->27|27->32->35/-1/-1 [5] 36/-1/-1->32->35|35->32->36/-1/-1 [6] -1/-1/-1->32->35|35->32->-1/-1/-1 [7] 35/-1/-1->32->36|36->32->35/-1/-1
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Trees [0] 33/-1/-1->34->35|35->34->33/-1/-1 [1] 35/17/49->34->33|33->34->35/17/49 [2] 35/-1/-1->34->33|33->34->35/-1/-1 [3] 33/-1/-1->34->35|35->34->33/-1/-1 [4] 33/-1/-1->34->35|35->34->33/-1/-1 [5] 35/-1/-1->34->33|33->34->35/-1/-1 [6] 35/-1/-1->34->33|33->34->35/-1/-1 [7] 33/-1/-1->34->35|35->34->33/-1/-1
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Trees [0] 34/16/48->35->32|32->35->34/16/48 [1] 32/-1/-1->35->34|34->35->32/-1/-1 [2] 32/-1/-1->35->34|34->35->32/-1/-1 [3] 34/-1/-1->35->32|32->35->34/-1/-1 [4] 34/-1/-1->35->32|32->35->34/-1/-1 [5] 32/-1/-1->35->34|34->35->32/-1/-1 [6] 32/-1/-1->35->34|34->35->32/-1/-1 [7] 34/-1/-1->35->32|32->35->34/-1/-1
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Trees [0] -1/-1/-1->36->39|39->36->-1/-1/-1 [1] 39/-1/-1->36->32|32->36->39/-1/-1 [2] 39/-1/-1->36->7|7->36->39/-1/-1 [3] 32/-1/-1->36->39|39->36->32/-1/-1 [4] -1/-1/-1->36->39|39->36->-1/-1/-1 [5] 39/-1/-1->36->32|32->36->39/-1/-1 [6] 39/-1/-1->36->31|31->36->39/-1/-1 [7] 32/-1/-1->36->39|39->36->32/-1/-1
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Trees [0] 38/-1/-1->37->33|33->37->38/-1/-1 [1] -1/-1/-1->37->38|38->37->-1/-1/-1 [2] 33/-1/-1->37->38|38->37->33/-1/-1 [3] 38/-1/-1->37->6|6->37->38/-1/-1 [4] 38/-1/-1->37->33|33->37->38/-1/-1 [5] -1/-1/-1->37->38|38->37->-1/-1/-1 [6] 33/-1/-1->37->38|38->37->33/-1/-1 [7] 38/-1/-1->37->30|30->37->38/-1/-1
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Trees [0] 39/-1/-1->38->37|37->38->39/-1/-1 [1] 37/-1/-1->38->39|39->38->37/-1/-1 [2] 37/-1/-1->38->39|39->38->37/-1/-1 [3] 39/21/53->38->37|37->38->39/21/53 [4] 39/-1/-1->38->37|37->38->39/-1/-1 [5] 37/-1/-1->38->39|39->38->37/-1/-1 [6] 37/-1/-1->38->39|39->38->37/-1/-1 [7] 39/-1/-1->38->37|37->38->39/-1/-1
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Trees [0] 36/-1/-1->39->38|38->39->36/-1/-1 [1] 38/-1/-1->39->36|36->39->38/-1/-1 [2] 38/20/52->39->36|36->39->38/20/52 [3] 36/-1/-1->39->38|38->39->36/-1/-1 [4] 36/-1/-1->39->38|38->39->36/-1/-1 [5] 38/-1/-1->39->36|36->39->38/-1/-1 [6] 38/-1/-1->39->36|36->39->38/-1/-1 [7] 36/-1/-1->39->38|38->39->36/-1/-1
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 00 : 63[1d0] -> 60[1a0] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Trees [0] 51/-1/-1->48->35|35->48->51/-1/-1 [1] 52/-1/-1->48->51|51->48->52/-1/-1 [2] -1/-1/-1->48->51|51->48->-1/-1/-1 [3] 51/-1/-1->48->52|52->48->51/-1/-1 [4] 51/-1/-1->48->59|59->48->51/-1/-1 [5] 52/-1/-1->48->51|51->48->52/-1/-1 [6] -1/-1/-1->48->51|51->48->-1/-1/-1 [7] 51/-1/-1->48->52|52->48->51/-1/-1
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Trees [0] 53/-1/-1->49->50|50->49->53/-1/-1 [1] 50/-1/-1->49->34|34->49->50/-1/-1 [2] 50/-1/-1->49->53|53->49->50/-1/-1 [3] -1/-1/-1->49->50|50->49->-1/-1/-1 [4] 53/-1/-1->49->50|50->49->53/-1/-1 [5] 50/-1/-1->49->58|58->49->50/-1/-1 [6] 50/-1/-1->49->53|53->49->50/-1/-1 [7] -1/-1/-1->49->50|50->49->-1/-1/-1
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Trees [0] 41/-1/-1->42->43|43->42->41/-1/-1 [1] 43/-1/-1->42->41|41->42->43/-1/-1 [2] 43/-1/-1->42->41|41->42->43/-1/-1 [3] 41/-1/-1->42->43|43->42->41/-1/-1 [4] 41/-1/-1->42->43|43->42->41/-1/-1 [5] 43/25/57->42->41|41->42->43/25/57 [6] 43/-1/-1->42->41|41->42->43/-1/-1 [7] 41/-1/-1->42->43|43->42->41/-1/-1
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Trees [0] 45/-1/-1->41->42|42->41->45/-1/-1 [1] 42/-1/-1->41->50|50->41->42/-1/-1 [2] 42/-1/-1->41->45|45->41->42/-1/-1 [3] -1/-1/-1->41->42|42->41->-1/-1/-1 [4] 45/-1/-1->41->42|42->41->45/-1/-1 [5] 42/-1/-1->41->10|10->41->42/-1/-1 [6] 42/-1/-1->41->45|45->41->42/-1/-1 [7] -1/-1/-1->41->42|42->41->-1/-1/-1
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Trees [0] 50/40/56->51->48|48->51->50/40/56 [1] 48/-1/-1->51->50|50->51->48/-1/-1 [2] 48/-1/-1->51->50|50->51->48/-1/-1 [3] 50/-1/-1->51->48|48->51->50/-1/-1 [4] 50/-1/-1->51->48|48->51->50/-1/-1 [5] 48/-1/-1->51->50|50->51->48/-1/-1 [6] 48/-1/-1->51->50|50->51->48/-1/-1 [7] 50/-1/-1->51->48|48->51->50/-1/-1
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Trees [0] 43/-1/-1->40->51|51->40->43/-1/-1 [1] 44/-1/-1->40->43|43->40->44/-1/-1 [2] -1/-1/-1->40->43|43->40->-1/-1/-1 [3] 43/-1/-1->40->44|44->40->43/-1/-1 [4] 43/-1/-1->40->11|11->40->43/-1/-1 [5] 44/-1/-1->40->43|43->40->44/-1/-1 [6] -1/-1/-1->40->43|43->40->-1/-1/-1 [7] 43/-1/-1->40->44|44->40->43/-1/-1
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Trees [0] -1/-1/-1->44->47|47->44->-1/-1/-1 [1] 47/-1/-1->44->40|40->44->47/-1/-1 [2] 47/-1/-1->44->55|55->44->47/-1/-1 [3] 40/-1/-1->44->47|47->44->40/-1/-1 [4] -1/-1/-1->44->47|47->44->-1/-1/-1 [5] 47/-1/-1->44->40|40->44->47/-1/-1 [6] 47/-1/-1->44->15|15->44->47/-1/-1 [7] 40/-1/-1->44->47|47->44->40/-1/-1
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Trees [0] 49/-1/-1->50->51|51->50->49/-1/-1 [1] 51/41/57->50->49|49->50->51/41/57 [2] 51/-1/-1->50->49|49->50->51/-1/-1 [3] 49/-1/-1->50->51|51->50->49/-1/-1 [4] 49/-1/-1->50->51|51->50->49/-1/-1 [5] 51/-1/-1->50->49|49->50->51/-1/-1 [6] 51/-1/-1->50->49|49->50->51/-1/-1 [7] 49/-1/-1->50->51|51->50->49/-1/-1
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Trees [0] 46/-1/-1->45->41|41->45->46/-1/-1 [1] -1/-1/-1->45->46|46->45->-1/-1/-1 [2] 41/-1/-1->45->46|46->45->41/-1/-1 [3] 46/-1/-1->45->54|54->45->46/-1/-1 [4] 46/-1/-1->45->41|41->45->46/-1/-1 [5] -1/-1/-1->45->46|46->45->-1/-1/-1 [6] 41/-1/-1->45->46|46->45->41/-1/-1 [7] 46/-1/-1->45->14|14->45->46/-1/-1
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Trees [0] 44/-1/-1->47->46|46->47->44/-1/-1 [1] 46/-1/-1->47->44|44->47->46/-1/-1 [2] 46/-1/-1->47->44|44->47->46/-1/-1 [3] 44/-1/-1->47->46|46->47->44/-1/-1 [4] 44/-1/-1->47->46|46->47->44/-1/-1 [5] 46/-1/-1->47->44|44->47->46/-1/-1 [6] 46/28/60->47->44|44->47->46/28/60 [7] 44/-1/-1->47->46|46->47->44/-1/-1
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Trees [0] 54/-1/-1->53->49|49->53->54/-1/-1 [1] -1/-1/-1->53->54|54->53->-1/-1/-1 [2] 49/-1/-1->53->54|54->53->49/-1/-1 [3] 54/-1/-1->53->38|38->53->54/-1/-1 [4] 54/-1/-1->53->49|49->53->54/-1/-1 [5] -1/-1/-1->53->54|54->53->-1/-1/-1 [6] 49/-1/-1->53->54|54->53->49/-1/-1 [7] 54/-1/-1->53->62|62->53->54/-1/-1
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Trees [0] 59/-1/-1->56->51|51->56->59/-1/-1 [1] 60/-1/-1->56->59|59->56->60/-1/-1 [2] -1/-1/-1->56->59|59->56->-1/-1/-1 [3] 59/-1/-1->56->60|60->56->59/-1/-1 [4] 59/-1/-1->56->43|43->56->59/-1/-1 [5] 60/-1/-1->56->59|59->56->60/-1/-1 [6] -1/-1/-1->56->59|59->56->-1/-1/-1 [7] 59/-1/-1->56->60|60->56->59/-1/-1
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Trees [0] 42/-1/-1->43->40|40->43->42/-1/-1 [1] 40/-1/-1->43->42|42->43->40/-1/-1 [2] 40/-1/-1->43->42|42->43->40/-1/-1 [3] 42/-1/-1->43->40|40->43->42/-1/-1 [4] 42/24/56->43->40|40->43->42/24/56 [5] 40/-1/-1->43->42|42->43->40/-1/-1 [6] 40/-1/-1->43->42|42->43->40/-1/-1 [7] 42/-1/-1->43->40|40->43->42/-1/-1
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Trees [0] -1/-1/-1->52->55|55->52->-1/-1/-1 [1] 55/-1/-1->52->48|48->52->55/-1/-1 [2] 55/-1/-1->52->39|39->52->55/-1/-1 [3] 48/-1/-1->52->55|55->52->48/-1/-1 [4] -1/-1/-1->52->55|55->52->-1/-1/-1 [5] 55/-1/-1->52->48|48->52->55/-1/-1 [6] 55/-1/-1->52->63|63->52->55/-1/-1 [7] 48/-1/-1->52->55|55->52->48/-1/-1
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Trees [0] 47/-1/-1->46->45|45->46->47/-1/-1 [1] 45/-1/-1->46->47|47->46->45/-1/-1 [2] 45/-1/-1->46->47|47->46->45/-1/-1 [3] 47/-1/-1->46->45|45->46->47/-1/-1 [4] 47/-1/-1->46->45|45->46->47/-1/-1 [5] 45/-1/-1->46->47|47->46->45/-1/-1 [6] 45/-1/-1->46->47|47->46->45/-1/-1 [7] 47/29/61->46->45|45->46->47/29/61
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Trees [0] 55/-1/-1->54->53|53->54->55/-1/-1 [1] 53/-1/-1->54->55|55->54->53/-1/-1 [2] 53/-1/-1->54->55|55->54->53/-1/-1 [3] 55/45/61->54->53|53->54->55/45/61 [4] 55/-1/-1->54->53|53->54->55/-1/-1 [5] 53/-1/-1->54->55|55->54->53/-1/-1 [6] 53/-1/-1->54->55|55->54->53/-1/-1 [7] 55/-1/-1->54->53|53->54->55/-1/-1
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Trees [0] 52/-1/-1->55->54|54->55->52/-1/-1 [1] 54/-1/-1->55->52|52->55->54/-1/-1 [2] 54/44/60->55->52|52->55->54/44/60 [3] 52/-1/-1->55->54|54->55->52/-1/-1 [4] 52/-1/-1->55->54|54->55->52/-1/-1 [5] 54/-1/-1->55->52|52->55->54/-1/-1 [6] 54/-1/-1->55->52|52->55->54/-1/-1 [7] 52/-1/-1->55->54|54->55->52/-1/-1
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Trees [0] 61/-1/-1->57->58|58->57->61/-1/-1 [1] 58/-1/-1->57->50|50->57->58/-1/-1 [2] 58/-1/-1->57->61|61->57->58/-1/-1 [3] -1/-1/-1->57->58|58->57->-1/-1/-1 [4] 61/-1/-1->57->58|58->57->61/-1/-1 [5] 58/-1/-1->57->42|42->57->58/-1/-1 [6] 58/-1/-1->57->61|61->57->58/-1/-1 [7] -1/-1/-1->57->58|58->57->-1/-1/-1
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Trees [0] 57/-1/-1->58->59|59->58->57/-1/-1 [1] 59/-1/-1->58->57|57->58->59/-1/-1 [2] 59/-1/-1->58->57|57->58->59/-1/-1 [3] 57/-1/-1->58->59|59->58->57/-1/-1 [4] 57/-1/-1->58->59|59->58->57/-1/-1 [5] 59/49/1->58->57|57->58->59/49/1 [6] 59/-1/-1->58->57|57->58->59/-1/-1 [7] 57/-1/-1->58->59|59->58->57/-1/-1
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Trees [0] -1/-1/-1->60->63|63->60->-1/-1/-1 [1] 63/-1/-1->60->56|56->60->63/-1/-1 [2] 63/-1/-1->60->55|55->60->63/-1/-1 [3] 56/-1/-1->60->63|63->60->56/-1/-1 [4] -1/-1/-1->60->63|63->60->-1/-1/-1 [5] 63/-1/-1->60->56|56->60->63/-1/-1 [6] 63/-1/-1->60->47|47->60->63/-1/-1 [7] 56/-1/-1->60->63|63->60->56/-1/-1
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO threadThresholds 8/8/64 | 512/8/64 | 8/8/64
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Trees [0] 58/-1/-1->59->56|56->59->58/-1/-1 [1] 56/-1/-1->59->58|58->59->56/-1/-1 [2] 56/-1/-1->59->58|58->59->56/-1/-1 [3] 58/-1/-1->59->56|56->59->58/-1/-1 [4] 58/48/0->59->56|56->59->58/48/0 [5] 56/-1/-1->59->58|58->59->56/-1/-1 [6] 56/-1/-1->59->58|58->59->56/-1/-1 [7] 58/-1/-1->59->56|56->59->58/-1/-1
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 00 : 18[180] -> 17[170] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 00 : 1[170] -> 5[1b0] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 00 : 9[170] -> 13[1b0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 00 : 10[180] -> 9[170] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 00 : 3[190] -> 2[180] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 00 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 00 : 13[1b0] -> 14[1c0] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 00 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 00 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 00 : 25[170] -> 29[1b0] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 00 : 14[1c0] -> 15[1d0] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 00 : 17[170] -> 21[1b0] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 00 : 26[180] -> 25[170] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 00 : 19[190] -> 18[180] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 00 : 2[180] -> 1[170] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 00 : 27[190] -> 26[180] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 00 : 21[1b0] -> 22[1c0] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 00 : 11[190] -> 10[180] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 00 : 15[1d0] -> 12[1a0] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 00 : 33[170] -> 37[1b0] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 00 : 29[1b0] -> 30[1c0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 00 : 34[180] -> 33[170] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 00 : 35[190] -> 34[180] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 00 : 22[1c0] -> 23[1d0] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 00 : 41[170] -> 45[1b0] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 00 : 50[180] -> 49[170] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 00 : 49[170] -> 53[1b0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 00 : 51[190] -> 50[180] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 00 : 57[170] -> 61[1b0] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 00 : 23[1d0] -> 20[1a0] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 00 : 46[1c0] -> 47[1d0] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 00 : 58[180] -> 57[170] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 00 : 43[190] -> 42[180] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 00 : 31[1d0] -> 28[1a0] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 00 : 62[1c0] -> 61[1b0] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 00 : 37[1b0] -> 38[1c0] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 00 : 42[180] -> 41[170] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 00 : 38[1c0] -> 39[1d0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 00 : 30[1c0] -> 31[1d0] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 00 : 47[1d0] -> 44[1a0] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 00 : 39[1d0] -> 36[1a0] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 00 : 4[1a0] -> 8[160] [receive] via NET/AWS Libfabric/0
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 00 : 45[1b0] -> 46[1c0] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 00 : 53[1b0] -> 54[1c0] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 00 : 59[190] -> 58[180] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 00 : 12[1a0] -> 16[160] [receive] via NET/AWS Libfabric/0
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 00 : 54[1c0] -> 55[1d0] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 00 : 55[1d0] -> 52[1a0] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 00 : 20[1a0] -> 24[160] [receive] via NET/AWS Libfabric/0
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 00 : 28[1a0] -> 32[160] [receive] via NET/AWS Libfabric/0
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 00 : 44[1a0] -> 48[160] [receive] via NET/AWS Libfabric/0
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 00 : 52[1a0] -> 56[160] [receive] via NET/AWS Libfabric/0
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 00 : 20[1a0] -> 24[160] [send] via NET/AWS Libfabric/0
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 00 : 12[1a0] -> 16[160] [send] via NET/AWS Libfabric/0
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 00 : 60[1a0] -> 0[160] [receive] via NET/AWS Libfabric/0
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 00 : 4[1a0] -> 8[160] [send] via NET/AWS Libfabric/0
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 00 : 28[1a0] -> 32[160] [send] via NET/AWS Libfabric/0
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 00 : 36[1a0] -> 40[160] [receive] via NET/AWS Libfabric/0
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 00 : 36[1a0] -> 40[160] [send] via NET/AWS Libfabric/0
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 00 : 44[1a0] -> 48[160] [send] via NET/AWS Libfabric/0
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 00 : 60[1a0] -> 0[160] [send] via NET/AWS Libfabric/0
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 00 : 52[1a0] -> 56[160] [send] via NET/AWS Libfabric/0
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 00 : 63[1d0] -> 62[1c0] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 00 : 18[180] -> 19[190] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 00 : 1[170] -> 2[180] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 00 : 61[1b0] -> 57[170] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 00 : 9[170] -> 10[180] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 00 : 10[180] -> 11[190] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 00 : 13[1b0] -> 9[170] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 00 : 17[170] -> 18[180] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 00 : 5[1b0] -> 1[170] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 00 : 21[1b0] -> 17[170] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 00 : 14[1c0] -> 13[1b0] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 00 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 00 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 00 : 15[1d0] -> 14[1c0] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 00 : 25[170] -> 26[180] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 00 : 2[180] -> 3[190] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 00 : 22[1c0] -> 21[1b0] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 00 : 26[180] -> 27[190] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 00 : 23[1d0] -> 22[1c0] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 00 : 29[1b0] -> 25[170] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 00 : 33[170] -> 34[180] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 00 : 57[170] -> 58[180] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 00 : 34[180] -> 35[190] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 00 : 58[180] -> 59[190] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 00 : 31[1d0] -> 30[1c0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 00 : 30[1c0] -> 29[1b0] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 00 : 50[180] -> 51[190] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 00 : 41[170] -> 42[180] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 00 : 46[1c0] -> 45[1b0] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 00 : 49[170] -> 50[180] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 00 : 37[1b0] -> 33[170] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 00 : 38[1c0] -> 37[1b0] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 00 : 39[1d0] -> 38[1c0] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 00 : 53[1b0] -> 49[170] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 00 : 42[180] -> 43[190] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 00 : 54[1c0] -> 53[1b0] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 00 : 55[1d0] -> 54[1c0] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 00 : 47[1d0] -> 46[1c0] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 00 : 45[1b0] -> 41[170] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 01 : 62[1c0] -> 61[1b0] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 01 : 14[1c0] -> 13[1b0] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 01 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 01 : 22[1c0] -> 21[1b0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 01 : 30[1c0] -> 29[1b0] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 01 : 38[1c0] -> 37[1b0] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 01 : 46[1c0] -> 45[1b0] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 01 : 54[1c0] -> 53[1b0] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 01 : 5[1b0] -> 9[170] [receive] via NET/AWS Libfabric/1
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 01 : 61[1b0] -> 1[170] [receive] via NET/AWS Libfabric/1
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 01 : 13[1b0] -> 17[170] [receive] via NET/AWS Libfabric/1
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 01 : 53[1b0] -> 57[170] [receive] via NET/AWS Libfabric/1
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 01 : 21[1b0] -> 25[170] [receive] via NET/AWS Libfabric/1
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 01 : 13[1b0] -> 17[170] [send] via NET/AWS Libfabric/1
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 01 : 61[1b0] -> 1[170] [send] via NET/AWS Libfabric/1
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 01 : 5[1b0] -> 9[170] [send] via NET/AWS Libfabric/1
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 01 : 21[1b0] -> 25[170] [send] via NET/AWS Libfabric/1
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 01 : 29[1b0] -> 33[170] [receive] via NET/AWS Libfabric/1
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 01 : 29[1b0] -> 33[170] [send] via NET/AWS Libfabric/1
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 01 : 37[1b0] -> 41[170] [receive] via NET/AWS Libfabric/1
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 01 : 45[1b0] -> 49[170] [receive] via NET/AWS Libfabric/1
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 01 : 37[1b0] -> 41[170] [send] via NET/AWS Libfabric/1
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 01 : 53[1b0] -> 57[170] [send] via NET/AWS Libfabric/1
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 01 : 45[1b0] -> 49[170] [send] via NET/AWS Libfabric/1
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 00 : 8[160] -> 11[190] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 00 : 48[160] -> 51[190] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 00 : 11[190] -> 8[160] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 00 : 56[160] -> 59[190] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 01 : 10[180] -> 11[190] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 01 : 50[180] -> 51[190] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 00 : 59[190] -> 56[160] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 00 : 16[160] -> 19[190] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 01 : 58[180] -> 59[190] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 00 : 24[160] -> 27[190] via P2P/IPC
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 00 : 32[160] -> 35[190] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 00 : 40[160] -> 51[190] [receive] via NET/AWS Libfabric/0
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 00 : 27[190] -> 24[160] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 01 : 18[180] -> 19[190] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 00 : 40[160] -> 43[190] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 01 : 34[180] -> 35[190] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 01 : 26[180] -> 27[190] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 00 : 8[160] -> 19[190] [receive] via NET/AWS Libfabric/0
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 00 : 43[190] -> 40[160] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 01 : 1[170] -> 2[180] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 00 : 16[160] -> 35[190] [receive] via NET/AWS Libfabric/0
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 01 : 42[180] -> 43[190] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 00 : 0[160] -> 3[190] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 01 : 41[170] -> 42[180] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 01 : 49[170] -> 50[180] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 01 : 2[180] -> 3[190] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 01 : 9[170] -> 10[180] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 01 : 17[170] -> 18[180] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 01 : 25[170] -> 26[180] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 01 : 57[170] -> 58[180] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 01 : 33[170] -> 34[180] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 00 : 32[160] -> 3[190] [receive] via NET/AWS Libfabric/0
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 00 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 01 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 01 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 01 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 01 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 00 : 28[1a0] -> 31[1d0] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 00 : 44[1a0] -> 47[1d0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 00 : 56[160] -> 51[190] [receive] via NET/AWS Libfabric/0
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 00 : 20[1a0] -> 23[1d0] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 00 : 52[1a0] -> 55[1d0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 00 : 51[190] -> 48[160] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 01 : 28[1a0] -> 31[1d0] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 01 : 44[1a0] -> 47[1d0] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 01 : 31[1d0] -> 30[1c0] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 01 : 47[1d0] -> 46[1c0] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 01 : 20[1a0] -> 23[1d0] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 01 : 52[1a0] -> 55[1d0] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 01 : 11[190] -> 8[160] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 00 : 12[1a0] -> 15[1d0] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 01 : 55[1d0] -> 54[1c0] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 01 : 23[1d0] -> 22[1c0] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 00 : 24[160] -> 19[190] [receive] via NET/AWS Libfabric/0
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 01 : 30[1c0] -> 31[1d0] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 01 : 31[1d0] -> 28[1a0] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 01 : 46[1c0] -> 47[1d0] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 01 : 47[1d0] -> 44[1a0] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 00 : 48[160] -> 35[190] [receive] via NET/AWS Libfabric/0
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 00 : 19[190] -> 16[160] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 00 : 35[190] -> 32[160] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 00 : 8[160] -> 19[190] [send] via NET/AWS Libfabric/0
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 01 : 54[1c0] -> 55[1d0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 01 : 22[1c0] -> 23[1d0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 01 : 10[180] -> 9[170] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 01 : 55[1d0] -> 52[1a0] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 00 : 60[1a0] -> 63[1d0] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 01 : 12[1a0] -> 15[1d0] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 01 : 23[1d0] -> 20[1a0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 01 : 15[1d0] -> 14[1c0] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 00 : 3[190] -> 0[160] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 01 : 60[1a0] -> 63[1d0] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 00 : 36[1a0] -> 39[1d0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 01 : 63[1d0] -> 62[1c0] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 01 : 14[1c0] -> 15[1d0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 01 : 15[1d0] -> 12[1a0] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 01 : 13[1b0] -> 14[1c0] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 01 : 27[190] -> 24[160] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 01 : 36[1a0] -> 39[1d0] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 01 : 39[1d0] -> 38[1c0] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 01 : 21[1b0] -> 22[1c0] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 00 : 48[160] -> 35[190] [send] via NET/AWS Libfabric/0
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 01 : 61[1b0] -> 62[1c0] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 02 : 13[1b0] -> 14[1c0] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 01 : 62[1c0] -> 63[1d0] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 01 : 29[1b0] -> 30[1c0] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 01 : 45[1b0] -> 46[1c0] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 00 : 19[190] -> 8[160] [receive] via NET/AWS Libfabric/0
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 01 : 26[180] -> 25[170] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 00 : 24[160] -> 19[190] [send] via NET/AWS Libfabric/0
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 01 : 37[1b0] -> 38[1c0] via P2P/IPC
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 00 : 32[160] -> 3[190] [send] via NET/AWS Libfabric/0
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 02 : 21[1b0] -> 22[1c0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 01 : 63[1d0] -> 60[1a0] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 02 : 29[1b0] -> 30[1c0] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 01 : 38[1c0] -> 39[1d0] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 02 : 45[1b0] -> 46[1c0] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 00 : 56[160] -> 51[190] [send] via NET/AWS Libfabric/0
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 01 : 39[1d0] -> 36[1a0] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 00 : 16[160] -> 35[190] [send] via NET/AWS Libfabric/0
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 01 : 59[190] -> 56[160] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 01 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 02 : 61[1b0] -> 62[1c0] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 01 : 53[1b0] -> 54[1c0] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 02 : 14[1c0] -> 18[180] [send] via NET/AWS Libfabric/2
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 02 : 37[1b0] -> 38[1c0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 02 : 22[1c0] -> 26[180] [send] via NET/AWS Libfabric/2
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 01 : 58[180] -> 57[170] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 01 : 43[190] -> 40[160] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 02 : 53[1b0] -> 54[1c0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 02 : 30[1c0] -> 34[180] [send] via NET/AWS Libfabric/2
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 00 : 35[190] -> 48[160] [receive] via NET/AWS Libfabric/0
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 02 : 46[1c0] -> 50[180] [send] via NET/AWS Libfabric/2
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 01 : 0[160] -> 4[1a0] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 02 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 00 : 19[190] -> 24[160] [receive] via NET/AWS Libfabric/0
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 01 : 42[180] -> 41[170] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 00 : 40[160] -> 51[190] [send] via NET/AWS Libfabric/0
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 00 : 3[190] -> 32[160] [receive] via NET/AWS Libfabric/0
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 02 : 62[1c0] -> 2[180] [send] via NET/AWS Libfabric/2
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 02 : 38[1c0] -> 42[180] [send] via NET/AWS Libfabric/2
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 01 : 4[1a0] -> 0[160] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 00 : 51[190] -> 56[160] [receive] via NET/AWS Libfabric/0
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 00 : 35[190] -> 16[160] [receive] via NET/AWS Libfabric/0
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 01 : 17[170] -> 34[180] [send] via NET/AWS Libfabric/1
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 02 : 54[1c0] -> 58[180] [send] via NET/AWS Libfabric/2
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 01 : 25[170] -> 18[180] [send] via NET/AWS Libfabric/1
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 02 : 6[1c0] -> 10[180] [send] via NET/AWS Libfabric/2
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 02 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 01 : 41[170] -> 50[180] [send] via NET/AWS Libfabric/1
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 01 : 33[170] -> 2[180] [send] via NET/AWS Libfabric/1
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 01 : 49[170] -> 34[180] [send] via NET/AWS Libfabric/1
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 00 : 51[190] -> 40[160] [receive] via NET/AWS Libfabric/0
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 01 : 9[170] -> 18[180] [send] via NET/AWS Libfabric/1
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 01 : 57[170] -> 50[180] [send] via NET/AWS Libfabric/1
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 00 : 3[190] -> 32[160] [send] via NET/AWS Libfabric/0
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 01 : 32[160] -> 36[1a0] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 01 : 3[190] -> 0[160] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 01 : 36[1a0] -> 32[160] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 02 : 39[1d0] -> 36[1a0] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 01 : 0[160] -> 3[190] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 01 : 3[190] -> 2[180] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 02 : 4[1a0] -> 0[160] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 01 : 33[170] -> 2[180] [receive] via NET/AWS Libfabric/1
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 02 : 0[160] -> 1[170] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 02 : 3[190] -> 7[1d0] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 02 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 02 : 36[1a0] -> 7[1d0] [receive] via NET/AWS Libfabric/2
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 00 : 19[190] -> 8[160] [send] via NET/AWS Libfabric/0
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 00 : 35[190] -> 16[160] [send] via NET/AWS Libfabric/0
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 00 : 19[190] -> 24[160] [send] via NET/AWS Libfabric/0
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 00 : 35[190] -> 48[160] [send] via NET/AWS Libfabric/0
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 01 : 8[160] -> 12[1a0] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 01 : 19[190] -> 16[160] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 01 : 24[160] -> 28[1a0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 00 : 51[190] -> 40[160] [send] via NET/AWS Libfabric/0
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 01 : 2[180] -> 1[170] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 01 : 48[160] -> 52[1a0] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 01 : 35[190] -> 32[160] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 01 : 16[160] -> 20[1a0] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 01 : 27[190] -> 26[180] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 01 : 12[1a0] -> 8[160] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 01 : 11[190] -> 10[180] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 01 : 28[1a0] -> 24[160] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 01 : 8[160] -> 11[190] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 02 : 1[170] -> 5[1b0] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 01 : 52[1a0] -> 48[160] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 01 : 24[160] -> 27[190] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 01 : 9[170] -> 18[180] [receive] via NET/AWS Libfabric/1
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 01 : 32[160] -> 35[190] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 01 : 19[190] -> 18[180] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 00 : 51[190] -> 56[160] [send] via NET/AWS Libfabric/0
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 02 : 0[160] -> 3[190] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 02 : 55[1d0] -> 52[1a0] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 01 : 35[190] -> 34[180] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 01 : 20[1a0] -> 16[160] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 02 : 5[1b0] -> 1[170] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 02 : 15[1d0] -> 12[1a0] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 01 : 16[160] -> 19[190] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 02 : 31[1d0] -> 28[1a0] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 02 : 27[190] -> 31[1d0] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 02 : 12[1a0] -> 8[160] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 02 : 11[190] -> 15[1d0] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 02 : 8[160] -> 9[170] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 01 : 56[160] -> 60[1a0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 01 : 51[190] -> 48[160] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 02 : 28[1a0] -> 24[160] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 01 : 40[160] -> 44[1a0] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 02 : 36[1a0] -> 32[160] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 02 : 22[1c0] -> 26[180] [receive] via NET/AWS Libfabric/2
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 02 : 24[160] -> 25[170] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 01 : 17[170] -> 34[180] [receive] via NET/AWS Libfabric/1
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 02 : 6[1c0] -> 10[180] [receive] via NET/AWS Libfabric/2
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 02 : 32[160] -> 33[170] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 02 : 23[1d0] -> 20[1a0] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 02 : 35[190] -> 39[1d0] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 02 : 19[190] -> 23[1d0] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 02 : 20[1a0] -> 16[160] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 01 : 43[190] -> 42[180] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 01 : 48[160] -> 51[190] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 01 : 60[1a0] -> 56[160] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 01 : 59[190] -> 58[180] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 02 : 16[160] -> 17[170] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 01 : 44[1a0] -> 40[160] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 01 : 51[190] -> 50[180] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 01 : 56[160] -> 59[190] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 01 : 40[160] -> 43[190] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 02 : 12[1a0] -> 23[1d0] [send] via NET/AWS Libfabric/2
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 02 : 36[1a0] -> 7[1d0] [send] via NET/AWS Libfabric/2
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 02 : 28[1a0] -> 23[1d0] [send] via NET/AWS Libfabric/2
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 02 : 52[1a0] -> 48[160] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 01 : 41[170] -> 50[180] [receive] via NET/AWS Libfabric/1
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 02 : 20[1a0] -> 39[1d0] [receive] via NET/AWS Libfabric/2
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 02 : 48[160] -> 49[170] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 02 : 47[1d0] -> 44[1a0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 02 : 63[1d0] -> 60[1a0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 02 : 51[190] -> 55[1d0] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 02 : 43[190] -> 47[1d0] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 02 : 60[1a0] -> 56[160] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 02 : 12[1a0] -> 23[1d0] [receive] via NET/AWS Libfabric/2
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 02 : 59[190] -> 63[1d0] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 02 : 20[1a0] -> 39[1d0] [send] via NET/AWS Libfabric/2
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 02 : 44[1a0] -> 40[160] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 02 : 38[1c0] -> 42[180] [receive] via NET/AWS Libfabric/2
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 02 : 56[160] -> 57[170] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 02 : 40[160] -> 41[170] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 02 : 54[1c0] -> 58[180] [receive] via NET/AWS Libfabric/2
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 01 : 2[180] -> 33[170] [send] via NET/AWS Libfabric/1
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 02 : 52[1a0] -> 39[1d0] [send] via NET/AWS Libfabric/2
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 02 : 44[1a0] -> 55[1d0] [receive] via NET/AWS Libfabric/2
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 02 : 44[1a0] -> 55[1d0] [send] via NET/AWS Libfabric/2
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 02 : 60[1a0] -> 55[1d0] [send] via NET/AWS Libfabric/2
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 02 : 10[180] -> 11[190] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 02 : 11[190] -> 10[180] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 01 : 49[170] -> 34[180] [receive] via NET/AWS Libfabric/1
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 01 : 25[170] -> 18[180] [receive] via NET/AWS Libfabric/1
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 01 : 34[180] -> 33[170] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 02 : 26[180] -> 27[190] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 01 : 18[180] -> 17[170] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 02 : 27[190] -> 26[180] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 01 : 18[180] -> 9[170] [receive] via NET/AWS Libfabric/1
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 02 : 52[1a0] -> 39[1d0] [receive] via NET/AWS Libfabric/2
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 01 : 18[180] -> 25[170] [receive] via NET/AWS Libfabric/1
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 01 : 2[180] -> 33[170] [receive] via NET/AWS Libfabric/1
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 01 : 57[170] -> 50[180] [receive] via NET/AWS Libfabric/1
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 01 : 50[180] -> 49[170] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 01 : 34[180] -> 17[170] [receive] via NET/AWS Libfabric/1
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 01 : 50[180] -> 41[170] [receive] via NET/AWS Libfabric/1
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 02 : 42[180] -> 43[190] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 02 : 33[170] -> 37[1b0] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 02 : 58[180] -> 59[190] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 02 : 43[190] -> 42[180] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 02 : 59[190] -> 58[180] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 01 : 34[180] -> 49[170] [receive] via NET/AWS Libfabric/1
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 02 : 32[160] -> 35[190] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 02 : 37[1b0] -> 33[170] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 01 : 50[180] -> 57[170] [receive] via NET/AWS Libfabric/1
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 02 : 28[1a0] -> 23[1d0] [receive] via NET/AWS Libfabric/2
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 02 : 62[1c0] -> 2[180] [receive] via NET/AWS Libfabric/2
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 02 : 7[1d0] -> 36[1a0] [receive] via NET/AWS Libfabric/2
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 02 : 36[1a0] -> 39[1d0] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 02 : 60[1a0] -> 55[1d0] [receive] via NET/AWS Libfabric/2
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 02 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 02 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 02 : 22[1c0] -> 23[1d0] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 02 : 2[180] -> 3[190] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 02 : 39[1d0] -> 20[1a0] [receive] via NET/AWS Libfabric/2
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 02 : 22[1c0] -> 21[1b0] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 02 : 20[1a0] -> 23[1d0] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 02 : 3[190] -> 2[180] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 02 : 38[1c0] -> 39[1d0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 02 : 10[180] -> 9[170] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 02 : 38[1c0] -> 37[1b0] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 02 : 39[1d0] -> 52[1a0] [receive] via NET/AWS Libfabric/2
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 02 : 52[1a0] -> 55[1d0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 01 : 34[180] -> 17[170] [send] via NET/AWS Libfabric/1
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 01 : 18[180] -> 9[170] [send] via NET/AWS Libfabric/1
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 02 : 26[180] -> 25[170] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 02 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 02 : 23[1d0] -> 12[1a0] [receive] via NET/AWS Libfabric/2
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 02 : 12[1a0] -> 15[1d0] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 02 : 54[1c0] -> 55[1d0] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 02 : 54[1c0] -> 53[1b0] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 03 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 03 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 01 : 34[180] -> 49[170] [send] via NET/AWS Libfabric/1
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 02 : 55[1d0] -> 44[1a0] [receive] via NET/AWS Libfabric/2
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 01 : 18[180] -> 25[170] [send] via NET/AWS Libfabric/1
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 02 : 42[180] -> 41[170] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 02 : 44[1a0] -> 47[1d0] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 02 : 7[1d0] -> 36[1a0] [send] via NET/AWS Libfabric/2
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 02 : 23[1d0] -> 28[1a0] [receive] via NET/AWS Libfabric/2
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 02 : 28[1a0] -> 31[1d0] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 01 : 50[180] -> 41[170] [send] via NET/AWS Libfabric/1
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 02 : 49[170] -> 53[1b0] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 02 : 17[170] -> 21[1b0] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 02 : 25[170] -> 29[1b0] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 02 : 9[170] -> 13[1b0] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 02 : 55[1d0] -> 60[1a0] [receive] via NET/AWS Libfabric/2
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 02 : 60[1a0] -> 63[1d0] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 02 : 48[160] -> 51[190] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 02 : 16[160] -> 19[190] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 02 : 30[1c0] -> 34[180] [receive] via NET/AWS Libfabric/2
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 02 : 24[160] -> 27[190] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 02 : 8[160] -> 11[190] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 02 : 53[1b0] -> 49[170] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 02 : 29[1b0] -> 25[170] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 01 : 50[180] -> 57[170] [send] via NET/AWS Libfabric/1
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 02 : 21[1b0] -> 17[170] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 02 : 14[1c0] -> 18[180] [receive] via NET/AWS Libfabric/2
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 02 : 13[1b0] -> 9[170] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 02 : 27[190] -> 24[160] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 02 : 11[190] -> 8[160] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 03 : 7[1d0] -> 11[190] [send] via NET/AWS Libfabric/3
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 02 : 41[170] -> 45[1b0] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 02 : 25[170] -> 26[180] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 02 : 57[170] -> 61[1b0] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 02 : 9[170] -> 10[180] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 02 : 40[160] -> 43[190] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 03 : 24[160] -> 25[170] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 02 : 56[160] -> 59[190] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 03 : 8[160] -> 9[170] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 02 : 45[1b0] -> 41[170] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 03 : 26[180] -> 30[1c0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 03 : 10[180] -> 14[1c0] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 02 : 46[1c0] -> 50[180] [receive] via NET/AWS Libfabric/2
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 03 : 25[170] -> 26[180] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 02 : 58[180] -> 57[170] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 02 : 61[1b0] -> 57[170] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 02 : 43[190] -> 40[160] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 03 : 9[170] -> 10[180] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 03 : 23[1d0] -> 27[190] [receive] via NET/AWS Libfabric/3
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 03 : 7[1d0] -> 11[190] [receive] via NET/AWS Libfabric/3
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 02 : 59[190] -> 56[160] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 02 : 41[170] -> 42[180] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 02 : 57[170] -> 58[180] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 03 : 40[160] -> 41[170] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 03 : 42[180] -> 46[1c0] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 03 : 56[160] -> 57[170] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 03 : 41[170] -> 42[180] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 03 : 39[1d0] -> 43[190] [receive] via NET/AWS Libfabric/3
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 03 : 58[180] -> 62[1c0] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 03 : 57[170] -> 58[180] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 03 : 55[1d0] -> 59[190] [receive] via NET/AWS Libfabric/3
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 02 : 34[180] -> 35[190] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 02 : 35[190] -> 34[180] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 02 : 18[180] -> 19[190] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 02 : 19[190] -> 18[180] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 02 : 23[1d0] -> 22[1c0] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 02 : 39[1d0] -> 38[1c0] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 02 : 62[1c0] -> 63[1d0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 03 : 22[1c0] -> 21[1b0] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 03 : 38[1c0] -> 37[1b0] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 02 : 62[1c0] -> 61[1b0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 02 : 63[1d0] -> 62[1c0] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 02 : 23[1d0] -> 12[1a0] [send] via NET/AWS Libfabric/2
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 03 : 27[190] -> 24[160] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 02 : 39[1d0] -> 20[1a0] [send] via NET/AWS Libfabric/2
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 03 : 11[190] -> 8[160] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 03 : 36[1a0] -> 39[1d0] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 03 : 24[160] -> 28[1a0] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 03 : 8[160] -> 12[1a0] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 03 : 61[1b0] -> 60[1a0] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 02 : 55[1d0] -> 54[1c0] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 03 : 62[1c0] -> 61[1b0] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 02 : 23[1d0] -> 28[1a0] [send] via NET/AWS Libfabric/2
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 02 : 50[180] -> 51[190] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 03 : 58[180] -> 59[190] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 02 : 39[1d0] -> 52[1a0] [send] via NET/AWS Libfabric/2
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 02 : 2[180] -> 1[170] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 02 : 3[190] -> 0[160] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 02 : 51[190] -> 50[180] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 03 : 54[1c0] -> 53[1b0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 03 : 63[1d0] -> 3[190] [send] via NET/AWS Libfabric/3
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 02 : 55[1d0] -> 44[1a0] [send] via NET/AWS Libfabric/2
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 02 : 1[170] -> 2[180] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 03 : 20[1a0] -> 23[1d0] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 03 : 52[1a0] -> 55[1d0] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 03 : 43[190] -> 40[160] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 02 : 55[1d0] -> 60[1a0] [send] via NET/AWS Libfabric/2
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 03 : 23[1d0] -> 27[190] [send] via NET/AWS Libfabric/3
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 03 : 0[160] -> 1[170] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 03 : 40[160] -> 44[1a0] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 03 : 39[1d0] -> 43[190] [send] via NET/AWS Libfabric/3
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 03 : 59[190] -> 56[160] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 03 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 03 : 2[180] -> 6[1c0] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 03 : 56[160] -> 60[1a0] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 03 : 1[170] -> 2[180] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 03 : 60[1a0] -> 63[1d0] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 03 : 63[1d0] -> 3[190] [receive] via NET/AWS Libfabric/3
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 03 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 03 : 2[180] -> 3[190] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 03 : 60[1a0] -> 56[160] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 03 : 55[1d0] -> 59[190] [send] via NET/AWS Libfabric/3
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 03 : 56[160] -> 59[190] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 03 : 61[1b0] -> 54[1c0] [send] via NET/AWS Libfabric/3
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 03 : 37[1b0] -> 6[1c0] [receive] via NET/AWS Libfabric/3
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 02 : 30[1c0] -> 31[1d0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 02 : 30[1c0] -> 29[1b0] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 02 : 31[1d0] -> 30[1c0] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 03 : 29[1b0] -> 28[1a0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 03 : 30[1c0] -> 29[1b0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 02 : 34[180] -> 33[170] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 03 : 28[1a0] -> 31[1d0] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 03 : 26[180] -> 27[190] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 02 : 14[1c0] -> 15[1d0] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 02 : 35[190] -> 32[160] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 02 : 33[170] -> 34[180] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 03 : 31[1d0] -> 35[190] [send] via NET/AWS Libfabric/3
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 02 : 14[1c0] -> 13[1b0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 02 : 15[1d0] -> 14[1c0] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 03 : 28[1a0] -> 24[160] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 03 : 24[160] -> 27[190] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 03 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 03 : 29[1b0] -> 22[1c0] [send] via NET/AWS Libfabric/3
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 03 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 03 : 13[1b0] -> 12[1a0] via P2P/IPC
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 03 : 32[160] -> 33[170] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 03 : 34[180] -> 38[1c0] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 03 : 37[1b0] -> 36[1a0] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 03 : 14[1c0] -> 13[1b0] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 02 : 46[1c0] -> 47[1d0] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 03 : 33[170] -> 34[180] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 03 : 12[1a0] -> 15[1d0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 03 : 10[180] -> 11[190] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 03 : 31[1d0] -> 35[190] [receive] via NET/AWS Libfabric/3
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 02 : 18[180] -> 17[170] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 02 : 46[1c0] -> 45[1b0] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 02 : 47[1d0] -> 46[1c0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 03 : 34[180] -> 35[190] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 03 : 15[1d0] -> 19[190] [send] via NET/AWS Libfabric/3
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 02 : 19[190] -> 16[160] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 03 : 45[1b0] -> 44[1a0] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 02 : 17[170] -> 18[180] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 03 : 46[1c0] -> 45[1b0] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 03 : 13[1b0] -> 22[1c0] [send] via NET/AWS Libfabric/3
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 03 : 21[1b0] -> 38[1c0] [receive] via NET/AWS Libfabric/3
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 03 : 37[1b0] -> 6[1c0] [send] via NET/AWS Libfabric/3
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 03 : 11[190] -> 10[180] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 03 : 10[180] -> 9[170] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 03 : 12[1a0] -> 8[160] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 03 : 8[160] -> 11[190] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 02 : 50[180] -> 49[170] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 03 : 44[1a0] -> 47[1d0] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 03 : 42[180] -> 43[190] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 03 : 39[1d0] -> 38[1c0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 02 : 51[190] -> 48[160] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 03 : 3[190] -> 0[160] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 03 : 39[1d0] -> 36[1a0] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 03 : 16[160] -> 17[170] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 03 : 47[1d0] -> 51[190] [send] via NET/AWS Libfabric/3
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 03 : 0[160] -> 4[1a0] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 03 : 23[1d0] -> 22[1c0] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 03 : 21[1b0] -> 20[1a0] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 02 : 49[170] -> 50[180] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 04 : 9[170] -> 13[1b0] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 04 : 11[190] -> 10[180] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 03 : 15[1d0] -> 19[190] [receive] via NET/AWS Libfabric/3
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 04 : 10[180] -> 9[170] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 03 : 18[180] -> 22[1c0] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 03 : 44[1a0] -> 40[160] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 03 : 40[160] -> 43[190] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 03 : 0[160] -> 3[190] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 03 : 4[1a0] -> 0[160] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 04 : 10[180] -> 11[190] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 03 : 17[170] -> 18[180] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 03 : 45[1b0] -> 54[1c0] [send] via NET/AWS Libfabric/3
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 03 : 48[160] -> 49[170] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 04 : 4[1a0] -> 8[160] [receive] via NET/AWS Libfabric/0
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 04 : 8[160] -> 11[190] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 03 : 53[1b0] -> 52[1a0] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 03 : 50[180] -> 54[1c0] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 03 : 18[180] -> 19[190] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 03 : 47[1d0] -> 51[190] [receive] via NET/AWS Libfabric/3
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 03 : 27[190] -> 26[180] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 04 : 4[1a0] -> 8[160] [send] via NET/AWS Libfabric/0
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 03 : 23[1d0] -> 20[1a0] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 03 : 26[180] -> 25[170] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 03 : 21[1b0] -> 38[1c0] [send] via NET/AWS Libfabric/3
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 03 : 42[180] -> 41[170] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 03 : 43[190] -> 42[180] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 03 : 49[170] -> 50[180] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 03 : 13[1b0] -> 22[1c0] [receive] via NET/AWS Libfabric/3
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 03 : 55[1d0] -> 54[1c0] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 04 : 40[160] -> 11[190] [receive] via NET/AWS Libfabric/0
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 03 : 50[180] -> 51[190] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 04 : 25[170] -> 29[1b0] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 04 : 27[190] -> 26[180] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 04 : 26[180] -> 25[170] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 04 : 41[170] -> 45[1b0] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 04 : 42[180] -> 41[170] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 04 : 43[190] -> 42[180] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 03 : 55[1d0] -> 52[1a0] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 04 : 20[1a0] -> 24[160] [receive] via NET/AWS Libfabric/0
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 04 : 24[160] -> 27[190] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 03 : 53[1b0] -> 38[1c0] [send] via NET/AWS Libfabric/3
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 04 : 26[180] -> 27[190] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 04 : 36[1a0] -> 40[160] [receive] via NET/AWS Libfabric/0
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 04 : 42[180] -> 43[190] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 03 : 45[1b0] -> 54[1c0] [receive] via NET/AWS Libfabric/3
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 04 : 40[160] -> 43[190] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 03 : 59[190] -> 58[180] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 03 : 58[180] -> 57[170] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 04 : 16[160] -> 27[190] [receive] via NET/AWS Libfabric/0
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 04 : 24[160] -> 43[190] [receive] via NET/AWS Libfabric/0
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 04 : 57[170] -> 61[1b0] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 04 : 59[190] -> 58[180] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 04 : 58[180] -> 57[170] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 04 : 52[1a0] -> 56[160] [receive] via NET/AWS Libfabric/0
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 04 : 58[180] -> 59[190] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 04 : 56[160] -> 59[190] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 03 : 35[190] -> 32[160] via P2P/IPC
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 03 : 32[160] -> 36[1a0] via P2P/IPC
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 03 : 32[160] -> 35[190] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 03 : 36[1a0] -> 32[160] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 04 : 48[160] -> 59[190] [receive] via NET/AWS Libfabric/0
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 03 : 53[1b0] -> 38[1c0] [receive] via NET/AWS Libfabric/3
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 04 : 36[1a0] -> 40[160] [send] via NET/AWS Libfabric/0
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 03 : 19[190] -> 16[160] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 03 : 16[160] -> 20[1a0] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 03 : 16[160] -> 19[190] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 04 : 40[160] -> 11[190] [send] via NET/AWS Libfabric/0
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 03 : 20[1a0] -> 16[160] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 03 : 51[190] -> 48[160] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 03 : 48[160] -> 52[1a0] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 04 : 11[190] -> 8[160] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 03 : 6[1c0] -> 37[1b0] [receive] via NET/AWS Libfabric/3
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 03 : 48[160] -> 51[190] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 03 : 52[1a0] -> 48[160] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 03 : 37[1b0] -> 38[1c0] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 04 : 20[1a0] -> 24[160] [send] via NET/AWS Libfabric/0
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 05 : 8[160] -> 12[1a0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 03 : 63[1d0] -> 62[1c0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 03 : 29[1b0] -> 22[1c0] [receive] via NET/AWS Libfabric/3
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 03 : 63[1d0] -> 60[1a0] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 03 : 62[1c0] -> 63[1d0] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 03 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 04 : 24[160] -> 43[190] [send] via NET/AWS Libfabric/0
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 04 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 04 : 52[1a0] -> 56[160] [send] via NET/AWS Libfabric/0
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 04 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 04 : 63[1d0] -> 60[1a0] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 04 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 03 : 61[1b0] -> 54[1c0] [receive] via NET/AWS Libfabric/3
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 03 : 6[1c0] -> 37[1b0] [send] via NET/AWS Libfabric/3
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 04 : 60[1a0] -> 0[160] [send] via NET/AWS Libfabric/0
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 04 : 56[160] -> 43[190] [send] via NET/AWS Libfabric/0
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 04 : 32[160] -> 27[190] [receive] via NET/AWS Libfabric/0
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 04 : 27[190] -> 24[160] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 03 : 3[190] -> 2[180] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 03 : 2[180] -> 1[170] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 04 : 56[160] -> 43[190] [receive] via NET/AWS Libfabric/0
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 04 : 43[190] -> 40[160] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 04 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 04 : 11[190] -> 40[160] [send] via NET/AWS Libfabric/0
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 04 : 43[190] -> 24[160] [receive] via NET/AWS Libfabric/0
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 04 : 11[190] -> 40[160] [receive] via NET/AWS Libfabric/0
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 04 : 1[170] -> 5[1b0] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 04 : 60[1a0] -> 0[160] [receive] via NET/AWS Libfabric/0
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 04 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 04 : 60[1a0] -> 63[1d0] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 04 : 3[190] -> 2[180] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 04 : 2[180] -> 1[170] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 03 : 31[1d0] -> 30[1c0] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 05 : 40[160] -> 44[1a0] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 05 : 11[190] -> 8[160] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 04 : 0[160] -> 59[190] [receive] via NET/AWS Libfabric/0
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 04 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 04 : 0[160] -> 3[190] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 04 : 59[190] -> 56[160] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 03 : 31[1d0] -> 28[1a0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 03 : 30[1c0] -> 31[1d0] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 05 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 04 : 31[1d0] -> 28[1a0] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 04 : 5[1b0] -> 1[170] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 04 : 43[190] -> 56[160] [receive] via NET/AWS Libfabric/0
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 04 : 1[170] -> 2[180] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 05 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 04 : 28[1a0] -> 32[160] [send] via NET/AWS Libfabric/0
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 04 : 3[190] -> 0[160] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 03 : 38[1c0] -> 21[1b0] [receive] via NET/AWS Libfabric/3
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 04 : 2[180] -> 3[190] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 03 : 21[1b0] -> 22[1c0] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 03 : 35[190] -> 34[180] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 03 : 34[180] -> 33[170] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 03 : 15[1d0] -> 14[1c0] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 04 : 0[160] -> 59[190] [send] via NET/AWS Libfabric/0
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 05 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 03 : 15[1d0] -> 12[1a0] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 03 : 14[1c0] -> 15[1d0] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 03 : 38[1c0] -> 53[1b0] [receive] via NET/AWS Libfabric/3
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 04 : 33[170] -> 37[1b0] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 04 : 35[190] -> 34[180] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 04 : 34[180] -> 33[170] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 03 : 53[1b0] -> 54[1c0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 04 : 15[1d0] -> 12[1a0] via P2P/IPC
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 04 : 28[1a0] -> 32[160] [receive] via NET/AWS Libfabric/0
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 05 : 3[190] -> 0[160] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 05 : 2[180] -> 3[190] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 04 : 34[180] -> 35[190] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 05 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 05 : 61[1b0] -> 1[170] [receive] via NET/AWS Libfabric/1
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 04 : 32[160] -> 35[190] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 05 : 5[1b0] -> 9[170] [send] via NET/AWS Libfabric/1
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 04 : 28[1a0] -> 31[1d0] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 05 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 05 : 1[170] -> 2[180] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 04 : 35[190] -> 32[160] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 04 : 12[1a0] -> 16[160] [send] via NET/AWS Libfabric/0
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 04 : 59[190] -> 0[160] [receive] via NET/AWS Libfabric/0
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 05 : 2[180] -> 1[170] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 05 : 35[190] -> 32[160] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 03 : 47[1d0] -> 46[1c0] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 03 : 19[190] -> 18[180] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 03 : 18[180] -> 17[170] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 03 : 22[1c0] -> 13[1b0] [receive] via NET/AWS Libfabric/3
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 04 : 32[160] -> 27[190] [send] via NET/AWS Libfabric/0
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 03 : 13[1b0] -> 14[1c0] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 03 : 47[1d0] -> 44[1a0] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 03 : 46[1c0] -> 47[1d0] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 04 : 14[1c0] -> 15[1d0] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 04 : 17[170] -> 21[1b0] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 04 : 19[190] -> 18[180] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 04 : 18[180] -> 17[170] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 04 : 47[1d0] -> 44[1a0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 04 : 15[1d0] -> 14[1c0] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 03 : 22[1c0] -> 29[1b0] [receive] via NET/AWS Libfabric/3
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 04 : 12[1a0] -> 16[160] [receive] via NET/AWS Libfabric/0
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 04 : 27[190] -> 32[160] [receive] via NET/AWS Libfabric/0
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 03 : 54[1c0] -> 45[1b0] [receive] via NET/AWS Libfabric/3
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 03 : 29[1b0] -> 30[1c0] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 04 : 16[160] -> 19[190] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 04 : 18[180] -> 19[190] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 03 : 45[1b0] -> 46[1c0] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 04 : 12[1a0] -> 15[1d0] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 04 : 44[1a0] -> 48[160] [send] via NET/AWS Libfabric/0
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 04 : 30[1c0] -> 31[1d0] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 05 : 12[1a0] -> 15[1d0] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 04 : 46[1c0] -> 47[1d0] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 04 : 19[190] -> 16[160] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 05 : 8[160] -> 11[190] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 03 : 51[190] -> 50[180] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 03 : 50[180] -> 49[170] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 04 : 31[1d0] -> 30[1c0] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 04 : 47[1d0] -> 46[1c0] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 05 : 19[190] -> 16[160] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 03 : 54[1c0] -> 61[1b0] [receive] via NET/AWS Libfabric/3
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 05 : 28[1a0] -> 31[1d0] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 03 : 61[1b0] -> 62[1c0] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 04 : 16[160] -> 27[190] [send] via NET/AWS Libfabric/0
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 04 : 62[1c0] -> 63[1d0] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 04 : 49[170] -> 53[1b0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 04 : 51[190] -> 50[180] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 04 : 50[180] -> 49[170] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 04 : 63[1d0] -> 62[1c0] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 04 : 44[1a0] -> 48[160] [receive] via NET/AWS Libfabric/0
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 05 : 60[1a0] -> 63[1d0] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 04 : 48[160] -> 51[190] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 04 : 44[1a0] -> 47[1d0] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 04 : 50[180] -> 51[190] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 04 : 27[190] -> 16[160] [receive] via NET/AWS Libfabric/0
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 05 : 44[1a0] -> 47[1d0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 04 : 51[190] -> 48[160] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 05 : 51[190] -> 48[160] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 04 : 48[160] -> 59[190] [send] via NET/AWS Libfabric/0
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 04 : 43[190] -> 24[160] [send] via NET/AWS Libfabric/0
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 04 : 59[190] -> 48[160] [receive] via NET/AWS Libfabric/0
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 04 : 43[190] -> 56[160] [send] via NET/AWS Libfabric/0
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 03 : 38[1c0] -> 39[1d0] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 04 : 39[1d0] -> 36[1a0] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 05 : 24[160] -> 28[1a0] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 05 : 56[160] -> 60[1a0] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 05 : 43[190] -> 40[160] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 04 : 36[1a0] -> 39[1d0] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 04 : 37[1b0] -> 38[1c0] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 03 : 38[1c0] -> 21[1b0] [send] via NET/AWS Libfabric/3
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 05 : 40[160] -> 43[190] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 04 : 33[170] -> 34[180] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 05 : 34[180] -> 35[190] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 03 : 38[1c0] -> 53[1b0] [send] via NET/AWS Libfabric/3
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 04 : 38[1c0] -> 39[1d0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 03 : 22[1c0] -> 23[1d0] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 04 : 23[1d0] -> 20[1a0] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 04 : 39[1d0] -> 38[1c0] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 04 : 37[1b0] -> 33[170] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 04 : 20[1a0] -> 23[1d0] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 04 : 38[1c0] -> 37[1b0] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 04 : 21[1b0] -> 22[1c0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 03 : 22[1c0] -> 13[1b0] [send] via NET/AWS Libfabric/3
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 03 : 54[1c0] -> 55[1d0] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 04 : 17[170] -> 18[180] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 05 : 36[1a0] -> 39[1d0] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 04 : 55[1d0] -> 52[1a0] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 05 : 18[180] -> 19[190] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 05 : 39[1d0] -> 38[1c0] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 04 : 52[1a0] -> 55[1d0] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 05 : 38[1c0] -> 37[1b0] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 05 : 29[1b0] -> 33[170] [receive] via NET/AWS Libfabric/1
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 03 : 22[1c0] -> 29[1b0] [send] via NET/AWS Libfabric/3
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 04 : 53[1b0] -> 54[1c0] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 03 : 54[1c0] -> 45[1b0] [send] via NET/AWS Libfabric/3
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 05 : 33[170] -> 34[180] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 04 : 49[170] -> 50[180] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 05 : 37[1b0] -> 41[170] [send] via NET/AWS Libfabric/1
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 05 : 39[1d0] -> 36[1a0] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 05 : 50[180] -> 51[190] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 05 : 38[1c0] -> 39[1d0] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 04 : 13[1b0] -> 14[1c0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 05 : 34[180] -> 33[170] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 04 : 22[1c0] -> 23[1d0] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 03 : 54[1c0] -> 61[1b0] [send] via NET/AWS Libfabric/3
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 04 : 29[1b0] -> 30[1c0] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 04 : 21[1b0] -> 17[170] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 04 : 14[1c0] -> 13[1b0] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 04 : 9[170] -> 10[180] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 04 : 23[1d0] -> 22[1c0] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 04 : 13[1b0] -> 9[170] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 04 : 45[1b0] -> 46[1c0] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 04 : 22[1c0] -> 21[1b0] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 04 : 54[1c0] -> 55[1d0] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 04 : 61[1b0] -> 62[1c0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 04 : 30[1c0] -> 29[1b0] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 04 : 25[170] -> 26[180] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 04 : 29[1b0] -> 25[170] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 05 : 20[1a0] -> 23[1d0] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 04 : 53[1b0] -> 49[170] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 04 : 46[1c0] -> 45[1b0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 05 : 15[1d0] -> 14[1c0] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 04 : 41[170] -> 42[180] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 04 : 45[1b0] -> 41[170] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 05 : 23[1d0] -> 22[1c0] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 04 : 55[1d0] -> 54[1c0] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 04 : 62[1c0] -> 61[1b0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 05 : 10[180] -> 11[190] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 04 : 57[170] -> 58[180] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 05 : 22[1c0] -> 21[1b0] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 05 : 13[1b0] -> 17[170] [receive] via NET/AWS Libfabric/1
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 04 : 61[1b0] -> 57[170] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 04 : 54[1c0] -> 53[1b0] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 05 : 14[1c0] -> 13[1b0] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 05 : 17[170] -> 18[180] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 05 : 31[1d0] -> 30[1c0] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 05 : 26[180] -> 27[190] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 05 : 52[1a0] -> 55[1d0] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 04 : 27[190] -> 16[160] [send] via NET/AWS Libfabric/0
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 05 : 30[1c0] -> 29[1b0] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 05 : 21[1b0] -> 25[170] [send] via NET/AWS Libfabric/1
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 05 : 47[1d0] -> 46[1c0] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 05 : 12[1a0] -> 8[160] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 05 : 23[1d0] -> 20[1a0] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 05 : 5[1b0] -> 9[170] [receive] via NET/AWS Libfabric/1
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 05 : 22[1c0] -> 23[1d0] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 05 : 42[180] -> 43[190] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 05 : 55[1d0] -> 54[1c0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 05 : 63[1d0] -> 62[1c0] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 05 : 58[180] -> 59[190] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 05 : 18[180] -> 17[170] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 05 : 54[1c0] -> 53[1b0] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 05 : 45[1b0] -> 49[170] [receive] via NET/AWS Libfabric/1
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 05 : 21[1b0] -> 25[170] [receive] via NET/AWS Libfabric/1
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 05 : 46[1c0] -> 45[1b0] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 05 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 05 : 28[1a0] -> 24[160] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 05 : 13[1b0] -> 17[170] [send] via NET/AWS Libfabric/1
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 05 : 62[1c0] -> 61[1b0] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 05 : 11[190] -> 10[180] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 05 : 15[1d0] -> 12[1a0] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 05 : 9[170] -> 10[180] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 05 : 21[1b0] -> 22[1c0] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 05 : 49[170] -> 50[180] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 05 : 25[170] -> 26[180] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 05 : 31[1d0] -> 28[1a0] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 06 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 05 : 37[1b0] -> 41[170] [receive] via NET/AWS Libfabric/1
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 05 : 53[1b0] -> 57[170] [receive] via NET/AWS Libfabric/1
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 05 : 60[1a0] -> 56[160] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 05 : 29[1b0] -> 33[170] [send] via NET/AWS Libfabric/1
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 05 : 53[1b0] -> 57[170] [send] via NET/AWS Libfabric/1
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 05 : 30[1c0] -> 31[1d0] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 05 : 37[1b0] -> 38[1c0] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 06 : 21[1b0] -> 22[1c0] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 05 : 55[1d0] -> 52[1a0] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 05 : 44[1a0] -> 40[160] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 05 : 63[1d0] -> 60[1a0] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 04 : 27[190] -> 32[160] [send] via NET/AWS Libfabric/0
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 05 : 14[1c0] -> 15[1d0] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 05 : 54[1c0] -> 55[1d0] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 05 : 57[170] -> 58[180] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 05 : 45[1b0] -> 49[170] [send] via NET/AWS Libfabric/1
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 05 : 41[170] -> 42[180] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 05 : 43[190] -> 42[180] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 05 : 13[1b0] -> 14[1c0] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 05 : 50[180] -> 49[170] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 05 : 61[1b0] -> 1[170] [send] via NET/AWS Libfabric/1
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 05 : 62[1c0] -> 63[1d0] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 05 : 53[1b0] -> 54[1c0] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 05 : 29[1b0] -> 30[1c0] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 05 : 47[1d0] -> 44[1a0] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 06 : 31[1d0] -> 28[1a0] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 05 : 17[170] -> 26[180] [send] via NET/AWS Libfabric/1
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 06 : 6[1c0] -> 10[180] [send] via NET/AWS Libfabric/2
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 06 : 37[1b0] -> 38[1c0] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 06 : 8[160] -> 9[170] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 04 : 59[190] -> 48[160] [send] via NET/AWS Libfabric/0
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 05 : 32[160] -> 36[1a0] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 06 : 12[1a0] -> 8[160] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 06 : 22[1c0] -> 26[180] [send] via NET/AWS Libfabric/2
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 06 : 53[1b0] -> 54[1c0] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 05 : 61[1b0] -> 62[1c0] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 05 : 16[160] -> 20[1a0] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 05 : 46[1c0] -> 47[1d0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 06 : 63[1d0] -> 60[1a0] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 05 : 27[190] -> 24[160] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 06 : 29[1b0] -> 30[1c0] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 05 : 25[170] -> 42[180] [send] via NET/AWS Libfabric/1
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 05 : 45[1b0] -> 46[1c0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 06 : 15[1d0] -> 12[1a0] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 06 : 61[1b0] -> 62[1c0] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 05 : 33[170] -> 26[180] [send] via NET/AWS Libfabric/1
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 05 : 19[190] -> 18[180] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 06 : 13[1b0] -> 14[1c0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 05 : 41[170] -> 10[180] [receive] via NET/AWS Libfabric/1
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 06 : 38[1c0] -> 42[180] [send] via NET/AWS Libfabric/2
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 05 : 49[170] -> 58[180] [send] via NET/AWS Libfabric/1
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 06 : 40[160] -> 41[170] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 05 : 1[170] -> 58[180] [send] via NET/AWS Libfabric/1
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 05 : 36[1a0] -> 32[160] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 06 : 54[1c0] -> 58[180] [send] via NET/AWS Libfabric/2
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 05 : 20[1a0] -> 16[160] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 06 : 11[190] -> 15[1d0] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 05 : 35[190] -> 34[180] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 05 : 57[170] -> 42[180] [send] via NET/AWS Libfabric/1
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 06 : 12[1a0] -> 15[1d0] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 04 : 59[190] -> 0[160] [send] via NET/AWS Libfabric/0
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 06 : 30[1c0] -> 34[180] [send] via NET/AWS Libfabric/2
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 05 : 16[160] -> 19[190] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 06 : 44[1a0] -> 40[160] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 05 : 24[160] -> 27[190] via P2P/IPC
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 05 : 32[160] -> 35[190] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 05 : 27[190] -> 26[180] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 06 : 62[1c0] -> 2[180] [send] via NET/AWS Libfabric/2
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 06 : 14[1c0] -> 18[180] [send] via NET/AWS Libfabric/2
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 06 : 47[1d0] -> 44[1a0] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 05 : 25[170] -> 42[180] [receive] via NET/AWS Libfabric/1
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 05 : 41[170] -> 10[180] [send] via NET/AWS Libfabric/1
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 05 : 48[160] -> 52[1a0] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 06 : 45[1b0] -> 46[1c0] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 05 : 0[160] -> 4[1a0] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 05 : 59[190] -> 56[160] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 06 : 23[1d0] -> 20[1a0] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 06 : 39[1d0] -> 36[1a0] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 06 : 19[190] -> 23[1d0] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 05 : 17[170] -> 26[180] [receive] via NET/AWS Libfabric/1
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 06 : 28[1a0] -> 24[160] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 06 : 43[190] -> 47[1d0] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 06 : 24[160] -> 25[170] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 06 : 20[1a0] -> 16[160] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 06 : 36[1a0] -> 32[160] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 06 : 44[1a0] -> 15[1d0] [receive] via NET/AWS Libfabric/2
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 06 : 27[190] -> 31[1d0] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 06 : 35[190] -> 39[1d0] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 06 : 16[160] -> 17[170] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 06 : 14[1c0] -> 18[180] [receive] via NET/AWS Libfabric/2
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 06 : 30[1c0] -> 34[180] [receive] via NET/AWS Libfabric/2
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 06 : 32[160] -> 33[170] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 05 : 56[160] -> 59[190] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 06 : 46[1c0] -> 50[180] [send] via NET/AWS Libfabric/2
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 05 : 3[190] -> 2[180] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 05 : 52[1a0] -> 48[160] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 05 : 51[190] -> 50[180] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 05 : 4[1a0] -> 0[160] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 05 : 59[190] -> 58[180] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 06 : 14[1c0] -> 15[1d0] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 06 : 18[180] -> 19[190] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 06 : 30[1c0] -> 31[1d0] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 06 : 34[180] -> 35[190] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 05 : 48[160] -> 51[190] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 06 : 44[1a0] -> 15[1d0] [send] via NET/AWS Libfabric/2
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 06 : 14[1c0] -> 13[1b0] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 05 : 0[160] -> 3[190] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 06 : 30[1c0] -> 29[1b0] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 06 : 19[190] -> 18[180] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 06 : 60[1a0] -> 56[160] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 06 : 35[190] -> 34[180] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 06 : 18[180] -> 17[170] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 06 : 34[180] -> 33[170] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 06 : 28[1a0] -> 47[1d0] [receive] via NET/AWS Libfabric/2
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 06 : 20[1a0] -> 31[1d0] [receive] via NET/AWS Libfabric/2
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 06 : 55[1d0] -> 52[1a0] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 06 : 56[160] -> 57[170] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 06 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 05 : 49[170] -> 58[180] [receive] via NET/AWS Libfabric/1
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 06 : 20[1a0] -> 31[1d0] [send] via NET/AWS Libfabric/2
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 06 : 36[1a0] -> 31[1d0] [send] via NET/AWS Libfabric/2
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 06 : 28[1a0] -> 47[1d0] [send] via NET/AWS Libfabric/2
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 06 : 59[190] -> 63[1d0] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 06 : 52[1a0] -> 48[160] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 06 : 51[190] -> 55[1d0] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 06 : 3[190] -> 7[1d0] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 06 : 4[1a0] -> 0[160] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 06 : 62[1c0] -> 2[180] [receive] via NET/AWS Libfabric/2
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 06 : 46[1c0] -> 50[180] [receive] via NET/AWS Libfabric/2
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 06 : 48[160] -> 49[170] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 06 : 0[160] -> 1[170] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 06 : 62[1c0] -> 63[1d0] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 06 : 2[180] -> 3[190] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 06 : 46[1c0] -> 47[1d0] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 06 : 50[180] -> 51[190] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 06 : 62[1c0] -> 61[1b0] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 06 : 60[1a0] -> 47[1d0] [send] via NET/AWS Libfabric/2
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 06 : 46[1c0] -> 45[1b0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 06 : 52[1a0] -> 63[1d0] [receive] via NET/AWS Libfabric/2
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 06 : 51[190] -> 50[180] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 06 : 50[180] -> 49[170] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 06 : 2[180] -> 1[170] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 06 : 3[190] -> 2[180] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 06 : 52[1a0] -> 63[1d0] [send] via NET/AWS Libfabric/2
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 06 : 4[1a0] -> 63[1d0] [send] via NET/AWS Libfabric/2
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 05 : 10[180] -> 9[170] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 06 : 9[170] -> 13[1b0] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 06 : 8[160] -> 11[190] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 06 : 13[1b0] -> 9[170] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 05 : 57[170] -> 42[180] [receive] via NET/AWS Libfabric/1
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 05 : 42[180] -> 41[170] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 06 : 15[1d0] -> 44[1a0] [receive] via NET/AWS Libfabric/2
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 05 : 33[170] -> 26[180] [receive] via NET/AWS Libfabric/1
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 05 : 26[180] -> 17[170] [receive] via NET/AWS Libfabric/1
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 06 : 44[1a0] -> 47[1d0] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 05 : 26[180] -> 25[170] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 06 : 60[1a0] -> 47[1d0] [receive] via NET/AWS Libfabric/2
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 05 : 10[180] -> 41[170] [receive] via NET/AWS Libfabric/1
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 06 : 47[1d0] -> 28[1a0] [receive] via NET/AWS Libfabric/2
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 06 : 31[1d0] -> 20[1a0] [receive] via NET/AWS Libfabric/2
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 06 : 36[1a0] -> 31[1d0] [receive] via NET/AWS Libfabric/2
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 06 : 28[1a0] -> 31[1d0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 05 : 10[180] -> 41[170] [send] via NET/AWS Libfabric/1
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 06 : 20[1a0] -> 23[1d0] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 05 : 26[180] -> 33[170] [receive] via NET/AWS Libfabric/1
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 05 : 1[170] -> 58[180] [receive] via NET/AWS Libfabric/1
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 05 : 58[180] -> 49[170] [receive] via NET/AWS Libfabric/1
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 05 : 42[180] -> 25[170] [receive] via NET/AWS Libfabric/1
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 05 : 58[180] -> 57[170] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 06 : 15[1d0] -> 14[1c0] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 06 : 41[170] -> 45[1b0] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 07 : 12[1a0] -> 15[1d0] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 07 : 14[1c0] -> 13[1b0] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 06 : 47[1d0] -> 60[1a0] [receive] via NET/AWS Libfabric/2
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 06 : 31[1d0] -> 36[1a0] [receive] via NET/AWS Libfabric/2
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 06 : 60[1a0] -> 63[1d0] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 06 : 36[1a0] -> 39[1d0] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 06 : 40[160] -> 43[190] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 06 : 4[1a0] -> 63[1d0] [receive] via NET/AWS Libfabric/2
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 06 : 63[1d0] -> 52[1a0] [receive] via NET/AWS Libfabric/2
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 06 : 15[1d0] -> 44[1a0] [send] via NET/AWS Libfabric/2
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 06 : 45[1b0] -> 41[170] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 06 : 6[1c0] -> 10[180] [receive] via NET/AWS Libfabric/2
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 06 : 52[1a0] -> 55[1d0] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 05 : 42[180] -> 57[170] [receive] via NET/AWS Libfabric/1
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 06 : 10[180] -> 11[190] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 06 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 05 : 58[180] -> 1[170] [receive] via NET/AWS Libfabric/1
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 06 : 10[180] -> 9[170] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 06 : 11[190] -> 10[180] via P2P/IPC
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 06 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 06 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 06 : 11[190] -> 8[160] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 06 : 9[170] -> 10[180] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 07 : 15[1d0] -> 19[190] [send] via NET/AWS Libfabric/3
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 07 : 8[160] -> 9[170] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 07 : 13[1b0] -> 12[1a0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 07 : 10[180] -> 14[1c0] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 07 : 7[1d0] -> 11[190] [receive] via NET/AWS Libfabric/3
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO Ring 07 : 9[170] -> 10[180] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 07 : 11[190] -> 8[160] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO Ring 07 : 13[1b0] -> 14[1c0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 07 : 10[180] -> 11[190] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 07 : 8[160] -> 12[1a0] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO Ring 07 : 12[1a0] -> 8[160] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO Ring 07 : 8[160] -> 11[190] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 07 : 45[1b0] -> 14[1c0] [receive] via NET/AWS Libfabric/3
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 06 : 63[1d0] -> 62[1c0] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 05 : 42[180] -> 25[170] [send] via NET/AWS Libfabric/1
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 06 : 47[1d0] -> 46[1c0] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 06 : 31[1d0] -> 30[1c0] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 05 : 26[180] -> 17[170] [send] via NET/AWS Libfabric/1
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 06 : 63[1d0] -> 4[1a0] [receive] via NET/AWS Libfabric/2
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 07 : 44[1a0] -> 47[1d0] via P2P/IPC
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 07 : 46[1c0] -> 45[1b0] via P2P/IPC
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 06 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 06 : 63[1d0] -> 52[1a0] [send] via NET/AWS Libfabric/2
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 05 : 42[180] -> 57[170] [send] via NET/AWS Libfabric/1
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 06 : 47[1d0] -> 28[1a0] [send] via NET/AWS Libfabric/2
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 06 : 31[1d0] -> 20[1a0] [send] via NET/AWS Libfabric/2
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 05 : 26[180] -> 33[170] [send] via NET/AWS Libfabric/1
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 05 : 58[180] -> 49[170] [send] via NET/AWS Libfabric/1
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 06 : 63[1d0] -> 4[1a0] [send] via NET/AWS Libfabric/2
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 07 : 7[1d0] -> 11[190] [send] via NET/AWS Libfabric/3
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 06 : 25[170] -> 29[1b0] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 06 : 57[170] -> 61[1b0] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 06 : 47[1d0] -> 60[1a0] [send] via NET/AWS Libfabric/2
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 06 : 17[170] -> 21[1b0] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 06 : 33[170] -> 37[1b0] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 06 : 56[160] -> 59[190] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 06 : 24[160] -> 27[190] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO Ring 07 : 11[190] -> 10[180] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 06 : 31[1d0] -> 36[1a0] [send] via NET/AWS Libfabric/2
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 07 : 4[1a0] -> 7[1d0] via P2P/IPC
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO Ring 07 : 10[180] -> 9[170] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 06 : 38[1c0] -> 42[180] [receive] via NET/AWS Libfabric/2
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 06 : 32[160] -> 35[190] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 06 : 29[1b0] -> 25[170] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 06 : 42[180] -> 43[190] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 06 : 16[160] -> 19[190] via P2P/IPC
[1,16]<stdout>:ip-192-168-71-105:27897:27897 [0] NCCL INFO comm 0x5581c5229f70 rank 8 nranks 64 cudaDev 0 busId 160 - Init COMPLETE
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 05 : 58[180] -> 1[170] [send] via NET/AWS Libfabric/1
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 07 : 7[1d0] -> 6[1c0] via P2P/IPC
[1,17]<stdout>:ip-192-168-71-105:27896:27896 [1] NCCL INFO comm 0x55e31453cb20 rank 9 nranks 64 cudaDev 1 busId 170 - Init COMPLETE
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 06 : 61[1b0] -> 57[170] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 06 : 21[1b0] -> 17[170] via P2P/IPC
[1,19]<stdout>:ip-192-168-71-105:27895:27895 [3] NCCL INFO comm 0x55964db25d10 rank 11 nranks 64 cudaDev 3 busId 190 - Init COMPLETE
[1,18]<stdout>:ip-192-168-71-105:27904:27904 [2] NCCL INFO comm 0x556ecb9777d0 rank 10 nranks 64 cudaDev 2 busId 180 - Init COMPLETE
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 07 : 60[1a0] -> 63[1d0] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 07 : 28[1a0] -> 31[1d0] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 06 : 22[1c0] -> 26[180] [receive] via NET/AWS Libfabric/2
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 07 : 30[1c0] -> 29[1b0] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 06 : 37[1b0] -> 33[170] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 07 : 62[1c0] -> 61[1b0] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 06 : 19[190] -> 16[160] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 06 : 35[190] -> 32[160] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 06 : 38[1c0] -> 39[1d0] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 06 : 42[180] -> 41[170] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 06 : 26[180] -> 27[190] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 06 : 49[170] -> 53[1b0] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 06 : 43[190] -> 42[180] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 06 : 1[170] -> 5[1b0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 07 : 63[1d0] -> 3[190] [send] via NET/AWS Libfabric/3
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 06 : 17[170] -> 18[180] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 06 : 0[160] -> 3[190] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 06 : 48[160] -> 51[190] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 06 : 26[180] -> 25[170] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 06 : 22[1c0] -> 23[1d0] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 06 : 27[190] -> 26[180] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 06 : 54[1c0] -> 58[180] [receive] via NET/AWS Libfabric/2
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 07 : 47[1d0] -> 51[190] [send] via NET/AWS Libfabric/3
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 06 : 53[1b0] -> 49[170] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 06 : 58[180] -> 59[190] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 06 : 33[170] -> 34[180] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 06 : 43[190] -> 40[160] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 06 : 41[170] -> 42[180] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 07 : 16[160] -> 17[170] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 06 : 5[1b0] -> 1[170] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 07 : 31[1d0] -> 35[190] [send] via NET/AWS Libfabric/3
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 06 : 38[1c0] -> 37[1b0] via P2P/IPC
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 07 : 32[160] -> 33[170] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 06 : 39[1d0] -> 38[1c0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 06 : 51[190] -> 48[160] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 06 : 58[180] -> 57[170] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 06 : 3[190] -> 0[160] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 07 : 15[1d0] -> 19[190] [receive] via NET/AWS Libfabric/3
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 06 : 59[190] -> 58[180] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 06 : 27[190] -> 24[160] via P2P/IPC
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 06 : 25[170] -> 26[180] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 06 : 54[1c0] -> 55[1d0] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 07 : 18[180] -> 22[1c0] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 07 : 31[1d0] -> 35[190] [receive] via NET/AWS Libfabric/3
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 06 : 22[1c0] -> 21[1b0] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 06 : 23[1d0] -> 22[1c0] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 07 : 15[1d0] -> 14[1c0] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 07 : 45[1b0] -> 44[1a0] via P2P/IPC
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 06 : 49[170] -> 50[180] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 07 : 40[160] -> 41[170] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 07 : 42[180] -> 46[1c0] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 07 : 19[190] -> 16[160] via P2P/IPC
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO Ring 07 : 17[170] -> 18[180] via P2P/IPC
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO Ring 07 : 15[1d0] -> 12[1a0] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 07 : 6[1c0] -> 5[1b0] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 06 : 1[170] -> 2[180] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 06 : 57[170] -> 58[180] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 06 : 59[190] -> 56[160] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 07 : 35[190] -> 32[160] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 07 : 36[1a0] -> 39[1d0] via P2P/IPC
[1,20]<stdout>:ip-192-168-71-105:27909:27909 [4] NCCL INFO comm 0x55b3e5ca3520 rank 12 nranks 64 cudaDev 4 busId 1a0 - Init COMPLETE
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 07 : 34[180] -> 38[1c0] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 07 : 0[160] -> 1[170] via P2P/IPC
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO Ring 07 : 41[170] -> 42[180] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 07 : 31[1d0] -> 30[1c0] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 07 : 39[1d0] -> 43[190] [receive] via NET/AWS Libfabric/3
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 07 : 29[1b0] -> 28[1a0] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 07 : 26[180] -> 30[1c0] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 07 : 48[160] -> 49[170] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 06 : 54[1c0] -> 53[1b0] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 07 : 24[160] -> 25[170] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 07 : 37[1b0] -> 36[1a0] via P2P/IPC
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO Ring 07 : 33[170] -> 34[180] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 07 : 20[1a0] -> 23[1d0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 07 : 47[1d0] -> 51[190] [receive] via NET/AWS Libfabric/3
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 06 : 55[1d0] -> 54[1c0] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 07 : 43[190] -> 40[160] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 07 : 16[160] -> 20[1a0] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 07 : 50[180] -> 54[1c0] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 07 : 23[1d0] -> 27[190] [receive] via NET/AWS Libfabric/3
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO Ring 07 : 25[170] -> 26[180] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 07 : 61[1b0] -> 60[1a0] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 07 : 42[180] -> 43[190] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 07 : 63[1d0] -> 3[190] [receive] via NET/AWS Libfabric/3
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 07 : 21[1b0] -> 20[1a0] via P2P/IPC
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 07 : 5[1b0] -> 4[1a0] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 07 : 38[1c0] -> 37[1b0] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 07 : 58[180] -> 62[1c0] via P2P/IPC
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 07 : 2[180] -> 6[1c0] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 07 : 56[160] -> 57[170] via P2P/IPC
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 07 : 22[1c0] -> 21[1b0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 07 : 51[190] -> 48[160] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 07 : 47[1d0] -> 46[1c0] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 07 : 40[160] -> 44[1a0] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 07 : 45[1b0] -> 14[1c0] [send] via NET/AWS Libfabric/3
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO Ring 07 : 49[170] -> 50[180] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 07 : 27[190] -> 24[160] via P2P/IPC
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 07 : 32[160] -> 36[1a0] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 07 : 3[190] -> 0[160] via P2P/IPC
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO Ring 07 : 1[170] -> 2[180] via P2P/IPC
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO Ring 07 : 57[170] -> 58[180] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 07 : 39[1d0] -> 43[190] [send] via NET/AWS Libfabric/3
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 07 : 26[180] -> 27[190] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 07 : 34[180] -> 35[190] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 07 : 18[180] -> 19[190] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 07 : 55[1d0] -> 59[190] [receive] via NET/AWS Libfabric/3
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 07 : 29[1b0] -> 46[1c0] [receive] via NET/AWS Libfabric/3
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 07 : 52[1a0] -> 55[1d0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 07 : 63[1d0] -> 62[1c0] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 07 : 23[1d0] -> 27[190] [send] via NET/AWS Libfabric/3
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 07 : 24[160] -> 28[1a0] via P2P/IPC
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO Ring 07 : 40[160] -> 43[190] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 07 : 53[1b0] -> 52[1a0] via P2P/IPC
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO Ring 07 : 44[1a0] -> 40[160] via P2P/IPC
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO Ring 07 : 47[1d0] -> 44[1a0] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 07 : 59[190] -> 56[160] via P2P/IPC
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 07 : 29[1b0] -> 46[1c0] [send] via NET/AWS Libfabric/3
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 07 : 48[160] -> 52[1a0] via P2P/IPC
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 07 : 58[180] -> 59[190] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO Ring 07 : 31[1d0] -> 28[1a0] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 07 : 54[1c0] -> 53[1b0] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 07 : 0[160] -> 4[1a0] via P2P/IPC
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 07 : 21[1b0] -> 30[1c0] [receive] via NET/AWS Libfabric/3
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 07 : 2[180] -> 3[190] via P2P/IPC
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 07 : 39[1d0] -> 38[1c0] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 07 : 37[1b0] -> 30[1c0] [send] via NET/AWS Libfabric/3
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 07 : 14[1c0] -> 45[1b0] [receive] via NET/AWS Libfabric/3
[1,84]<stdout>:ip-192-168-87-97:23441:23441 [4] NCCL INFO comm 0x56032b69ef20 rank 44 nranks 64 cudaDev 4 busId 1a0 - Init COMPLETE
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 07 : 21[1b0] -> 30[1c0] [send] via NET/AWS Libfabric/3
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 07 : 56[160] -> 60[1a0] via P2P/IPC
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 07 : 61[1b0] -> 46[1c0] [send] via NET/AWS Libfabric/3
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 07 : 23[1d0] -> 22[1c0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO Ring 07 : 63[1d0] -> 60[1a0] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO Ring 07 : 42[180] -> 41[170] via P2P/IPC
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO Ring 07 : 18[180] -> 17[170] via P2P/IPC
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO Ring 07 : 19[190] -> 18[180] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO Ring 07 : 20[1a0] -> 16[160] via P2P/IPC
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO Ring 07 : 43[190] -> 42[180] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO Ring 07 : 45[1b0] -> 46[1c0] via P2P/IPC
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO Ring 07 : 16[160] -> 19[190] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 07 : 50[180] -> 51[190] via P2P/IPC
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO Ring 07 : 24[160] -> 27[190] via P2P/IPC
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO Ring 07 : 28[1a0] -> 24[160] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO Ring 07 : 34[180] -> 33[170] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 07 : 53[1b0] -> 62[1c0] [receive] via NET/AWS Libfabric/3
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO Ring 07 : 35[190] -> 34[180] via P2P/IPC
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO Ring 07 : 32[160] -> 35[190] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO Ring 07 : 36[1a0] -> 32[160] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 07 : 55[1d0] -> 59[190] [send] via NET/AWS Libfabric/3
[1,81]<stdout>:ip-192-168-87-97:23447:23447 [1] NCCL INFO comm 0x555aa0e9a050 rank 41 nranks 64 cudaDev 1 busId 170 - Init COMPLETE
[1,80]<stdout>:ip-192-168-87-97:23446:23446 [0] NCCL INFO comm 0x561921ab6ab0 rank 40 nranks 64 cudaDev 0 busId 160 - Init COMPLETE
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 07 : 5[1b0] -> 62[1c0] [send] via NET/AWS Libfabric/3
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO Ring 07 : 60[1a0] -> 56[160] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO Ring 07 : 56[160] -> 59[190] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO Ring 07 : 27[190] -> 26[180] via P2P/IPC
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO Ring 07 : 26[180] -> 25[170] via P2P/IPC
[1,82]<stdout>:ip-192-168-87-97:23448:23448 [2] NCCL INFO comm 0x55d863d77bc0 rank 42 nranks 64 cudaDev 2 busId 180 - Init COMPLETE
[1,33]<stdout>:ip-192-168-72-95:25421:25421 [1] NCCL INFO comm 0x555c20df3dd0 rank 17 nranks 64 cudaDev 1 busId 170 - Init COMPLETE
[1,83]<stdout>:ip-192-168-87-97:23440:23440 [3] NCCL INFO comm 0x562d08ea7a20 rank 43 nranks 64 cudaDev 3 busId 190 - Init COMPLETE
[1,65]<stdout>:ip-192-168-83-55:53977:53977 [1] NCCL INFO comm 0x556462ade2e0 rank 33 nranks 64 cudaDev 1 busId 170 - Init COMPLETE
[1,52]<stdout>:ip-192-168-95-203:24939:24939 [4] NCCL INFO comm 0x562fbc5ce390 rank 28 nranks 64 cudaDev 4 busId 1a0 - Init COMPLETE
[1,48]<stdout>:ip-192-168-95-203:24938:24938 [0] NCCL INFO comm 0x55e0816b5a70 rank 24 nranks 64 cudaDev 0 busId 160 - Init COMPLETE
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO Ring 07 : 7[1d0] -> 4[1a0] via P2P/IPC
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO Ring 07 : 6[1c0] -> 7[1d0] via P2P/IPC
[1,116]<stdout>:ip-192-168-90-179:25776:25776 [4] NCCL INFO comm 0x55852672d090 rank 60 nranks 64 cudaDev 4 busId 1a0 - Init COMPLETE
[1,34]<stdout>:ip-192-168-72-95:25425:25425 [2] NCCL INFO comm 0x5618567ae320 rank 18 nranks 64 cudaDev 2 busId 180 - Init COMPLETE
[1,49]<stdout>:ip-192-168-95-203:24931:24931 [1] NCCL INFO comm 0x56165e7f3190 rank 25 nranks 64 cudaDev 1 busId 170 - Init COMPLETE
[1,35]<stdout>:ip-192-168-72-95:25427:25427 [3] NCCL INFO comm 0x55981cdd6150 rank 19 nranks 64 cudaDev 3 busId 190 - Init COMPLETE
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO Ring 07 : 38[1c0] -> 39[1d0] via P2P/IPC
[1,67]<stdout>:ip-192-168-83-55:53976:53976 [3] NCCL INFO comm 0x556fb18ac3e0 rank 35 nranks 64 cudaDev 3 busId 190 - Init COMPLETE
[1,32]<stdout>:ip-192-168-72-95:25431:25431 [0] NCCL INFO comm 0x55ba99af2fc0 rank 16 nranks 64 cudaDev 0 busId 160 - Init COMPLETE
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO Ring 07 : 4[1a0] -> 0[160] via P2P/IPC
[1,66]<stdout>:ip-192-168-83-55:53981:53981 [2] NCCL INFO comm 0x56419c9a1ec0 rank 34 nranks 64 cudaDev 2 busId 180 - Init COMPLETE
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO Ring 07 : 39[1d0] -> 36[1a0] via P2P/IPC
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO Ring 07 : 0[160] -> 3[190] via P2P/IPC
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO Ring 07 : 3[190] -> 2[180] via P2P/IPC
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 07 : 53[1b0] -> 62[1c0] [send] via NET/AWS Libfabric/3
[1,64]<stdout>:ip-192-168-83-55:53989:53989 [0] NCCL INFO comm 0x55d5890b8db0 rank 32 nranks 64 cudaDev 0 busId 160 - Init COMPLETE
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO Ring 07 : 2[180] -> 1[170] via P2P/IPC
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 07 : 55[1d0] -> 54[1c0] via P2P/IPC
[1,51]<stdout>:ip-192-168-95-203:24929:24929 [3] NCCL INFO comm 0x5563e2b260c0 rank 27 nranks 64 cudaDev 3 busId 190 - Init COMPLETE
[1,50]<stdout>:ip-192-168-95-203:24934:24934 [2] NCCL INFO comm 0x556cf2916b20 rank 26 nranks 64 cudaDev 2 busId 180 - Init COMPLETE
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO Ring 07 : 22[1c0] -> 23[1d0] via P2P/IPC
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 07 : 14[1c0] -> 15[1d0] via P2P/IPC
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO Ring 07 : 51[190] -> 50[180] via P2P/IPC
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO Ring 07 : 59[190] -> 58[180] via P2P/IPC
[1,21]<stdout>:ip-192-168-71-105:27900:27900 [5] NCCL INFO comm 0x558de62ce220 rank 13 nranks 64 cudaDev 5 busId 1b0 - Init COMPLETE
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO Ring 07 : 58[180] -> 57[170] via P2P/IPC
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO Ring 07 : 23[1d0] -> 20[1a0] via P2P/IPC
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO Ring 07 : 50[180] -> 49[170] via P2P/IPC
[1,112]<stdout>:ip-192-168-90-179:25775:25775 [0] NCCL INFO comm 0x563cfd5ebbe0 rank 56 nranks 64 cudaDev 0 busId 160 - Init COMPLETE
[1,23]<stdout>:ip-192-168-71-105:27906:27906 [7] NCCL INFO comm 0x55c704ff5f10 rank 15 nranks 64 cudaDev 7 busId 1d0 - Init COMPLETE
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO Ring 07 : 52[1a0] -> 48[160] via P2P/IPC
[1,36]<stdout>:ip-192-168-72-95:25434:25434 [4] NCCL INFO comm 0x5648c9240120 rank 20 nranks 64 cudaDev 4 busId 1a0 - Init COMPLETE
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO Ring 07 : 48[160] -> 51[190] via P2P/IPC
[1,68]<stdout>:ip-192-168-83-55:53974:53974 [4] NCCL INFO comm 0x55588522ca20 rank 36 nranks 64 cudaDev 4 busId 1a0 - Init COMPLETE
[1,71]<stdout>:ip-192-168-83-55:53985:53985 [7] NCCL INFO comm 0x560bfdfc3280 rank 39 nranks 64 cudaDev 7 busId 1d0 - Init COMPLETE
[1,113]<stdout>:ip-192-168-90-179:25769:25769 [1] NCCL INFO comm 0x5644cca68750 rank 57 nranks 64 cudaDev 1 busId 170 - Init COMPLETE
[1,39]<stdout>:ip-192-168-72-95:25422:25422 [7] NCCL INFO comm 0x56498effd760 rank 23 nranks 64 cudaDev 7 busId 1d0 - Init COMPLETE
[1,1]<stdout>:ip-192-168-64-81:24883:24883 [1] NCCL INFO comm 0x56242b9ec350 rank 1 nranks 64 cudaDev 1 busId 170 - Init COMPLETE
[1,7]<stdout>:ip-192-168-64-81:24893:24893 [7] NCCL INFO comm 0x5572fa69f1f0 rank 7 nranks 64 cudaDev 7 busId 1d0 - Init COMPLETE
[1,115]<stdout>:ip-192-168-90-179:25772:25772 [3] NCCL INFO comm 0x556cbd86d360 rank 59 nranks 64 cudaDev 3 busId 190 - Init COMPLETE
[1,114]<stdout>:ip-192-168-90-179:25778:25778 [2] NCCL INFO comm 0x563d24571640 rank 58 nranks 64 cudaDev 2 busId 180 - Init COMPLETE
[1,97]<stdout>:ip-192-168-64-19:28231:28231 [1] NCCL INFO comm 0x555628479f80 rank 49 nranks 64 cudaDev 1 busId 170 - Init COMPLETE
[1,4]<stdout>:ip-192-168-64-81:24885:24885 [4] NCCL INFO comm 0x5575c92c8c10 rank 4 nranks 64 cudaDev 4 busId 1a0 - Init COMPLETE
[1,0]<stdout>:ip-192-168-64-81:24882:24882 [0] NCCL INFO comm 0x55c1f0b4e0e0 rank 0 nranks 64 cudaDev 0 busId 160 - Init COMPLETE
[1,3]<stdout>:ip-192-168-64-81:24880:24880 [3] NCCL INFO comm 0x55bda2c198d0 rank 3 nranks 64 cudaDev 3 busId 190 - Init COMPLETE
[1,2]<stdout>:ip-192-168-64-81:24881:24881 [2] NCCL INFO comm 0x55a70ca0ee70 rank 2 nranks 64 cudaDev 2 busId 180 - Init COMPLETE
[1,99]<stdout>:ip-192-168-64-19:28227:28227 [3] NCCL INFO comm 0x556516afd190 rank 51 nranks 64 cudaDev 3 busId 190 - Init COMPLETE
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO Ring 07 : 14[1c0] -> 45[1b0] [send] via NET/AWS Libfabric/3
[1,98]<stdout>:ip-192-168-64-19:28226:28226 [2] NCCL INFO comm 0x5594f8a2cdc0 rank 50 nranks 64 cudaDev 2 busId 180 - Init COMPLETE
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO Ring 07 : 54[1c0] -> 55[1d0] via P2P/IPC
[1,96]<stdout>:ip-192-168-64-19:28228:28228 [0] NCCL INFO comm 0x559d0f6c8560 rank 48 nranks 64 cudaDev 0 busId 160 - Init COMPLETE
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO Ring 07 : 55[1d0] -> 52[1a0] via P2P/IPC
[1,100]<stdout>:ip-192-168-64-19:28229:28229 [4] NCCL INFO comm 0x559684967400 rank 52 nranks 64 cudaDev 4 busId 1a0 - Init COMPLETE
[1,103]<stdout>:ip-192-168-64-19:28235:28235 [7] NCCL INFO comm 0x5607d6cdeb20 rank 55 nranks 64 cudaDev 7 busId 1d0 - Init COMPLETE
[1,22]<stdout>:ip-192-168-71-105:27903:27903 [6] NCCL INFO comm 0x56164679ceb0 rank 14 nranks 64 cudaDev 6 busId 1c0 - Init COMPLETE
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 07 : 46[1c0] -> 29[1b0] [receive] via NET/AWS Libfabric/3
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 07 : 37[1b0] -> 30[1c0] [receive] via NET/AWS Libfabric/3
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 07 : 30[1c0] -> 21[1b0] [receive] via NET/AWS Libfabric/3
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 07 : 61[1b0] -> 46[1c0] [receive] via NET/AWS Libfabric/3
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO Ring 07 : 29[1b0] -> 30[1c0] via P2P/IPC
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO Ring 07 : 21[1b0] -> 22[1c0] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 07 : 5[1b0] -> 62[1c0] [receive] via NET/AWS Libfabric/3
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 07 : 62[1c0] -> 53[1b0] [receive] via NET/AWS Libfabric/3
[1,38]<stdout>:ip-192-168-72-95:25432:25432 [6] NCCL INFO comm 0x55ec2a410dd0 rank 22 nranks 64 cudaDev 6 busId 1c0 - Init COMPLETE
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO Ring 07 : 53[1b0] -> 54[1c0] via P2P/IPC
[1,102]<stdout>:ip-192-168-64-19:28239:28239 [6] NCCL INFO comm 0x555de844fb40 rank 54 nranks 64 cudaDev 6 busId 1c0 - Init COMPLETE
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 07 : 30[1c0] -> 37[1b0] [receive] via NET/AWS Libfabric/3
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 07 : 46[1c0] -> 61[1b0] [receive] via NET/AWS Libfabric/3
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO Ring 07 : 61[1b0] -> 62[1c0] via P2P/IPC
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO Ring 07 : 37[1b0] -> 38[1c0] via P2P/IPC
[1,70]<stdout>:ip-192-168-83-55:53990:53990 [6] NCCL INFO comm 0x559f2beb4140 rank 38 nranks 64 cudaDev 6 busId 1c0 - Init COMPLETE
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 07 : 62[1c0] -> 63[1d0] via P2P/IPC
[1,119]<stdout>:ip-192-168-90-179:25770:25770 [7] NCCL INFO comm 0x562ffc0af120 rank 63 nranks 64 cudaDev 7 busId 1d0 - Init COMPLETE
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 07 : 62[1c0] -> 5[1b0] [receive] via NET/AWS Libfabric/3
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO Ring 07 : 5[1b0] -> 6[1c0] via P2P/IPC
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 07 : 62[1c0] -> 53[1b0] [send] via NET/AWS Libfabric/3
[1,6]<stdout>:ip-192-168-64-81:24886:24886 [6] NCCL INFO comm 0x5631c7b4d950 rank 6 nranks 64 cudaDev 6 busId 1c0 - Init COMPLETE
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 07 : 30[1c0] -> 31[1d0] via P2P/IPC
[1,55]<stdout>:ip-192-168-95-203:24933:24933 [7] NCCL INFO comm 0x55bf57c76f90 rank 31 nranks 64 cudaDev 7 busId 1d0 - Init COMPLETE
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO Ring 07 : 62[1c0] -> 5[1b0] [send] via NET/AWS Libfabric/3
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 07 : 30[1c0] -> 21[1b0] [send] via NET/AWS Libfabric/3
[1,101]<stdout>:ip-192-168-64-19:28232:28232 [5] NCCL INFO comm 0x5635e0855c50 rank 53 nranks 64 cudaDev 5 busId 1b0 - Init COMPLETE
[1,118]<stdout>:ip-192-168-90-179:25780:25780 [6] NCCL INFO comm 0x55b2e8dfbea0 rank 62 nranks 64 cudaDev 6 busId 1c0 - Init COMPLETE
[1,5]<stdout>:ip-192-168-64-81:24890:24890 [5] NCCL INFO comm 0x55f8521119c0 rank 5 nranks 64 cudaDev 5 busId 1b0 - Init COMPLETE
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 07 : 46[1c0] -> 47[1d0] via P2P/IPC
[1,85]<stdout>:ip-192-168-87-97:23445:23445 [5] NCCL INFO comm 0x5603e42e2280 rank 45 nranks 64 cudaDev 5 busId 1b0 - Init COMPLETE
[1,87]<stdout>:ip-192-168-87-97:23444:23444 [7] NCCL INFO comm 0x564f44f50c90 rank 47 nranks 64 cudaDev 7 busId 1d0 - Init COMPLETE
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO Ring 07 : 30[1c0] -> 37[1b0] [send] via NET/AWS Libfabric/3
[1,37]<stdout>:ip-192-168-72-95:25426:25426 [5] NCCL INFO comm 0x55a6cefc7220 rank 21 nranks 64 cudaDev 5 busId 1b0 - Init COMPLETE
[1,69]<stdout>:ip-192-168-83-55:53975:53975 [5] NCCL INFO comm 0x55d5755127b0 rank 37 nranks 64 cudaDev 5 busId 1b0 - Init COMPLETE
[1,54]<stdout>:ip-192-168-95-203:24940:24940 [6] NCCL INFO comm 0x55b7a43b3e70 rank 30 nranks 64 cudaDev 6 busId 1c0 - Init COMPLETE
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 07 : 46[1c0] -> 29[1b0] [send] via NET/AWS Libfabric/3
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO Ring 07 : 46[1c0] -> 61[1b0] [send] via NET/AWS Libfabric/3
[1,117]<stdout>:ip-192-168-90-179:25774:25774 [5] NCCL INFO comm 0x55d20474fbb0 rank 61 nranks 64 cudaDev 5 busId 1b0 - Init COMPLETE
[1,53]<stdout>:ip-192-168-95-203:24935:24935 [5] NCCL INFO comm 0x55adaa6bcb60 rank 29 nranks 64 cudaDev 5 busId 1b0 - Init COMPLETE
[1,86]<stdout>:ip-192-168-87-97:23442:23442 [6] NCCL INFO comm 0x55700d0761d0 rank 46 nranks 64 cudaDev 6 busId 1c0 - Init COMPLETE
[1,17]<stderr>:2020-09-18 19:25:49.994925: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,17]<stderr>:2020-09-18 19:25:49.995143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:49.996843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,17]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,17]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,17]<stderr>:2020-09-18 19:25:49.996917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:49.998453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,17]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,17]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,17]<stderr>:2020-09-18 19:25:49.998499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.000101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,17]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,17]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,17]<stderr>:2020-09-18 19:25:50.000154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.001696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,17]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,17]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,17]<stderr>:2020-09-18 19:25:50.001743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.002721: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,23]<stderr>:2020-09-18 19:25:50.002883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.003786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,17]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,17]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,17]<stderr>:2020-09-18 19:25:50.003843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.005376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,23]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,23]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,23]<stderr>:2020-09-18 19:25:50.005462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.006948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,17]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,17]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,17]<stderr>:2020-09-18 19:25:50.007002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.008508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,23]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,23]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,23]<stderr>:2020-09-18 19:25:50.008561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.010069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,17]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,17]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,17]<stderr>:2020-09-18 19:25:50.010121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.011681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,23]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,23]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,23]<stderr>:2020-09-18 19:25:50.011730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.013222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,17]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,17]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,17]<stderr>:2020-09-18 19:25:50.013244: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,23]<stderr>:2020-09-18 19:25:50.014402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,23]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,23]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,23]<stderr>:2020-09-18 19:25:50.014445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.016034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,23]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,23]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,23]<stderr>:2020-09-18 19:25:50.016086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.017616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,23]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,23]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,23]<stderr>:2020-09-18 19:25:50.017655: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.018358: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,21]<stderr>:2020-09-18 19:25:50.018511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.019698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,23]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,23]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,23]<stderr>:2020-09-18 19:25:50.019746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.020421: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,21]<stderr>:2020-09-18 19:25:50.021290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,21]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,21]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,21]<stderr>:2020-09-18 19:25:50.021368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.022833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,23]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,23]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,23]<stderr>:2020-09-18 19:25:50.022857: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,21]<stderr>:2020-09-18 19:25:50.023977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,21]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,21]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,21]<stderr>:2020-09-18 19:25:50.024042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.024741: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,21]<stderr>:2020-09-18 19:25:50.025625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,21]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,21]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,21]<stderr>:2020-09-18 19:25:50.025676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.026912: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,21]<stderr>:2020-09-18 19:25:50.027236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,21]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,21]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,21]<stderr>:2020-09-18 19:25:50.027282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.028271: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,21]<stderr>:2020-09-18 19:25:50.028811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,21]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,21]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,21]<stderr>:2020-09-18 19:25:50.028861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.030381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,21]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,21]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,21]<stderr>:2020-09-18 19:25:50.030421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.031029: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,21]<stderr>:2020-09-18 19:25:50.031978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,21]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,21]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,21]<stderr>:2020-09-18 19:25:50.032032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.032449: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,17]<stderr>:2020-09-18 19:25:50.032923: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,21]<stderr>:2020-09-18 19:25:50.033546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,21]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,21]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,21]<stderr>:2020-09-18 19:25:50.033566: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,18]<stderr>:2020-09-18 19:25:50.036239: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,23]<stderr>:2020-09-18 19:25:50.036367: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,18]<stderr>:2020-09-18 19:25:50.036461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.037096: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,18]<stderr>:2020-09-18 19:25:50.038121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,18]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,18]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,18]<stderr>:2020-09-18 19:25:50.038204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.038383: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,23]<stderr>:2020-09-18 19:25:50.038818: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,18]<stderr>:2020-09-18 19:25:50.039766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,18]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,18]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,18]<stderr>:2020-09-18 19:25:50.039831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.041157: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,17]<stderr>:2020-09-18 19:25:50.041268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.041373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,18]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,18]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,18]<stderr>:2020-09-18 19:25:50.041427: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.041526: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,20]<stderr>:2020-09-18 19:25:50.041808: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,20]<stderr>:2020-09-18 19:25:50.041965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.042502: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,23]<stderr>:2020-09-18 19:25:50.042607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.042523: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,19]<stderr>:2020-09-18 19:25:50.042681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.044473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,16]<stderr>:2020-09-18 19:25:50.046804: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,16]<stderr>:2020-09-18 19:25:50.046967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.047007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.047077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,18]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,18]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,18]<stderr>:2020-09-18 19:25:50.047184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.048731: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,20]<stderr>:2020-09-18 19:25:50.049746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,20]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,20]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,20]<stderr>:2020-09-18 19:25:50.049831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.050614: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,23]<stderr>:2020-09-18 19:25:50.051329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.051375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,19]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,19]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,19]<stderr>:2020-09-18 19:25:50.051465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.054251: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,21]<stderr>:2020-09-18 19:25:50.054349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.056996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,16]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,16]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,16]<stderr>:2020-09-18 19:25:50.057093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.057109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.057325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,18]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,18]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,18]<stderr>:2020-09-18 19:25:50.057416: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.058434: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,22]<stderr>:2020-09-18 19:25:50.058578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.060099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,20]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,20]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,20]<stderr>:2020-09-18 19:25:50.060167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.062942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.063078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,19]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,19]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,19]<stderr>:2020-09-18 19:25:50.063138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.067062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.069851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,16]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,16]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,16]<stderr>:2020-09-18 19:25:50.069918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.070084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.070383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,18]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,18]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,18]<stderr>:2020-09-18 19:25:50.070475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.071439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,22]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,22]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,22]<stderr>:2020-09-18 19:25:50.071525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.073296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,20]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,20]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,20]<stderr>:2020-09-18 19:25:50.073350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.076233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.076359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,19]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,19]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,19]<stderr>:2020-09-18 19:25:50.076412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.080222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.083014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,16]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,16]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,16]<stderr>:2020-09-18 19:25:50.083094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.083256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.083543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,18]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,18]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,18]<stderr>:2020-09-18 19:25:50.083631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.083950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,22]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,22]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,22]<stderr>:2020-09-18 19:25:50.084011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.086322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,20]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,20]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,20]<stderr>:2020-09-18 19:25:50.086400: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.089336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.089372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,19]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,19]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,19]<stderr>:2020-09-18 19:25:50.089424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.093266: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.096119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,16]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,16]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,16]<stderr>:2020-09-18 19:25:50.096183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.096425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.096656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,18]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,18]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,18]<stderr>:2020-09-18 19:25:50.096690: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,22]<stderr>:2020-09-18 19:25:50.096987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,22]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,22]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,22]<stderr>:2020-09-18 19:25:50.097047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.099210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,20]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,20]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,20]<stderr>:2020-09-18 19:25:50.099266: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.100470: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,19]<stderr>:2020-09-18 19:25:50.101999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,19]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,19]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,19]<stderr>:2020-09-18 19:25:50.102079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.101978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.104292: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,21]<stderr>:2020-09-18 19:25:50.105012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.106903: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,16]<stderr>:2020-09-18 19:25:50.107661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,16]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,16]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,16]<stderr>:2020-09-18 19:25:50.107721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.107865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.108423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,22]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,22]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,22]<stderr>:2020-09-18 19:25:50.108486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.110559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,20]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,20]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,20]<stderr>:2020-09-18 19:25:50.110613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.111470: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,23]<stderr>:2020-09-18 19:25:50.113313: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.113348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,19]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,19]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,19]<stderr>:2020-09-18 19:25:50.113407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.113896: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,21]<stderr>:2020-09-18 19:25:50.116427: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.118023: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,18]<stderr>:2020-09-18 19:25:50.118127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.119106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,16]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,16]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,16]<stderr>:2020-09-18 19:25:50.119179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.119392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.120039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,22]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,22]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,22]<stderr>:2020-09-18 19:25:50.120096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.122334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,20]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,20]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,20]<stderr>:2020-09-18 19:25:50.122386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.125895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.125936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,19]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,19]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,19]<stderr>:2020-09-18 19:25:50.125998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.129004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.131097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.132142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,16]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,16]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,16]<stderr>:2020-09-18 19:25:50.132214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.132260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.132974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,22]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,22]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,22]<stderr>:2020-09-18 19:25:50.133031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.135293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,20]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,20]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,20]<stderr>:2020-09-18 19:25:50.135317: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,23]<stderr>:2020-09-18 19:25:50.138559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.138681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,19]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,19]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,19]<stderr>:2020-09-18 19:25:50.138710: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,20]<stderr>:2020-09-18 19:25:50.140724: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,21]<stderr>:2020-09-18 19:25:50.141571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.142818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.143074: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,16]<stderr>:2020-09-18 19:25:50.143449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,16]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,16]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,16]<stderr>:2020-09-18 19:25:50.143482: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,17]<stderr>:2020-09-18 19:25:50.143679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.143954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,22]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,22]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,22]<stderr>:2020-09-18 19:25:50.144009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.144286: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,20]<stderr>:2020-09-18 19:25:50.146018: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,19]<stderr>:2020-09-18 19:25:50.146820: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,19]<stderr>:2020-09-18 19:25:50.148094: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,23]<stderr>:2020-09-18 19:25:50.148591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.148594: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,20]<stderr>:2020-09-18 19:25:50.149982: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,21]<stderr>:2020-09-18 19:25:50.150529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.151821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.152477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.152698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,22]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,22]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,22]<stderr>:2020-09-18 19:25:50.152724: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,20]<stderr>:2020-09-18 19:25:50.152690: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,16]<stderr>:2020-09-18 19:25:50.152755: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,19]<stderr>:2020-09-18 19:25:50.152897: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,16]<stderr>:2020-09-18 19:25:50.154092: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,19]<stderr>:2020-09-18 19:25:50.154931: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,20]<stderr>:2020-09-18 19:25:50.156554: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,20]<stderr>:2020-09-18 19:25:50.156648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.156979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.157211: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,16]<stderr>:2020-09-18 19:25:50.157766: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,21]<stderr>:2020-09-18 19:25:50.158291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.158879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,19]<stderr>:2020-09-18 19:25:50.158973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.159703: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.160088: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,17]<stderr>:2020-09-18 19:25:50.160279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.160441: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,22]<stderr>:2020-09-18 19:25:50.161514: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,16]<stderr>:2020-09-18 19:25:50.164110: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,16]<stderr>:2020-09-18 19:25:50.164206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.165281: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,20]<stderr>:2020-09-18 19:25:50.166422: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.166832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.167970: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,21]<stderr>:2020-09-18 19:25:50.168426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.169432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.170119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.171587: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,22]<stderr>:2020-09-18 19:25:50.171680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.171839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.176461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.177883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.178901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.181451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.182614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.183464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.184805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.184747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.189920: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,103]<stderr>:2020-09-18 19:25:50.190108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.189710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.191173: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,101]<stderr>:2020-09-18 19:25:50.191353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.192065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,103]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,103]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,103]<stderr>:2020-09-18 19:25:50.192138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.191099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.191904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.193801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,101]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,101]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,101]<stderr>:2020-09-18 19:25:50.193911: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.195339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,103]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,103]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,103]<stderr>:2020-09-18 19:25:50.195399: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.194645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.195865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.196968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,101]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,101]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,101]<stderr>:2020-09-18 19:25:50.197052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.197487: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,99]<stderr>:2020-09-18 19:25:50.197645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.196622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.197737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.197877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.199167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,103]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,103]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,103]<stderr>:2020-09-18 19:25:50.199225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.201939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,101]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,101]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,101]<stderr>:2020-09-18 19:25:50.202021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.202027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,99]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,99]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,99]<stderr>:2020-09-18 19:25:50.202103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.202691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.203997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,103]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,103]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,103]<stderr>:2020-09-18 19:25:50.204049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.204064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.204897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.206751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,101]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,101]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,99]<stderr>:2020-09-18 19:25:50.206826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,99]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,99]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,101]<stderr>:2020-09-18 19:25:50.206834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.206883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.207716: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,97]<stderr>:2020-09-18 19:25:50.207865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.207676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.209137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,103]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,103]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,103]<stderr>:2020-09-18 19:25:50.209191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.208979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.209661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.210757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.211681: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,96]<stderr>:2020-09-18 19:25:50.211872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.210950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.212462: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,100]<stderr>:2020-09-18 19:25:50.212623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.213271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,101]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,101]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,101]<stderr>:2020-09-18 19:25:50.213343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.213444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,99]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,99]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,99]<stderr>:2020-09-18 19:25:50.213498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.214906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,97]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,97]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,97]<stderr>:2020-09-18 19:25:50.214991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.215824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.218112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,103]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,103]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,103]<stderr>:2020-09-18 19:25:50.218167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.217286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.218088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.221532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,96]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,96]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,96]<stderr>:2020-09-18 19:25:50.221649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.220901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.222468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,100]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,100]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,100]<stderr>:2020-09-18 19:25:50.222552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.222874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,101]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,101]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,101]<stderr>:2020-09-18 19:25:50.222941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.222057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.223209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,99]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,99]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,99]<stderr>:2020-09-18 19:25:50.223260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.222930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.223816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.224735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,97]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,97]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,97]<stderr>:2020-09-18 19:25:50.224806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.224211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,103]<stderr>:2020-09-18 19:25:50.227906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,103]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,103]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,103]<stderr>:2020-09-18 19:25:50.227961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.228575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.229946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.231383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,96]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,96]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,96]<stderr>:2020-09-18 19:25:50.231447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.230650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,100]<stderr>:2020-09-18 19:25:50.232293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,100]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,100]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,100]<stderr>:2020-09-18 19:25:50.232350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.232630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,101]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,101]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,101]<stderr>:2020-09-18 19:25:50.232696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.232804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,99]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,99]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,99]<stderr>:2020-09-18 19:25:50.232858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.232622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.233437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.234703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,97]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,97]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,97]<stderr>:2020-09-18 19:25:50.234789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.234043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.234106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.237790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,103]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,103]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,103]<stderr>:2020-09-18 19:25:50.237816: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,16]<stderr>:2020-09-18 19:25:50.238512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.239697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.241139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,96]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,96]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,96]<stderr>:2020-09-18 19:25:50.241199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.241857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,100]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,100]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,100]<stderr>:2020-09-18 19:25:50.241920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.242128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,101]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,101]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,101]<stderr>:2020-09-18 19:25:50.242155: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,99]<stderr>:2020-09-18 19:25:50.242285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,99]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,99]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,99]<stderr>:2020-09-18 19:25:50.242353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.243220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,97]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,97]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,97]<stderr>:2020-09-18 19:25:50.243281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.242243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,7]<stderr>:2020-09-18 19:25:50.242963: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,7]<stderr>:2020-09-18 19:25:50.243166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.243921: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,19]<stderr>:2020-09-18 19:25:50.243022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.243484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.243546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.244872: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,67]<stderr>:2020-09-18 19:25:50.245065: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.244814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,7]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,7]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,7]<stderr>:2020-09-18 19:25:50.244899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.246736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,67]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,67]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,67]<stderr>:2020-09-18 19:25:50.246824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.246491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,7]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,7]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,7]<stderr>:2020-09-18 19:25:50.246545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.247800: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,65]<stderr>:2020-09-18 19:25:50.247964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.247890: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,96]<stderr>:2020-09-18 19:25:50.248008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,96]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,96]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,16]<stderr>:2020-09-18 19:25:50.246960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.248062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.248587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,100]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,100]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,67]<stderr>:2020-09-18 19:25:50.248832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,67]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,67]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,100]<stderr>:2020-09-18 19:25:50.248641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.248893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.248170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,7]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,7]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,7]<stderr>:2020-09-18 19:25:50.248237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.248748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,99]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,99]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,99]<stderr>:2020-09-18 19:25:50.248807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.248857: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,20]<stderr>:2020-09-18 19:25:50.248001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.249566: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,71]<stderr>:2020-09-18 19:25:50.249720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.249831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,97]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,97]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,97]<stderr>:2020-09-18 19:25:50.249896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.250336: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,7]<stderr>:2020-09-18 19:25:50.249781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,7]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,7]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,7]<stderr>:2020-09-18 19:25:50.249832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.250813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,65]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,65]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,2]<stderr>:2020-09-18 19:25:50.249915: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,65]<stderr>:2020-09-18 19:25:50.250900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.250112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.250955: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,101]<stderr>:2020-09-18 19:25:50.251482: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,19]<stderr>:2020-09-18 19:25:50.251068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.251592: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.251529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.253416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,67]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,67]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,67]<stderr>:2020-09-18 19:25:50.253482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.252674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,7]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,7]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,7]<stderr>:2020-09-18 19:25:50.252738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.253798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,96]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,96]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,96]<stderr>:2020-09-18 19:25:50.253854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.253349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,2]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,2]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,2]<stderr>:2020-09-18 19:25:50.253437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.254472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,71]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,71]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,71]<stderr>:2020-09-18 19:25:50.254583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.253804: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,17]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,100]<stderr>:2020-09-18 19:25:50.254990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,100]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,100]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,100]<stderr>:2020-09-18 19:25:50.255042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.255227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,99]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,99]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,99]<stderr>:2020-09-18 19:25:50.255252: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,65]<stderr>:2020-09-18 19:25:50.255593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,65]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,65]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,103]<stderr>:2020-09-18 19:25:50.255312: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,65]<stderr>:2020-09-18 19:25:50.255658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.254945: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.256149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,97]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,97]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,97]<stderr>:2020-09-18 19:25:50.256207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.256418: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,7]<stderr>:2020-09-18 19:25:50.255928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,7]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,7]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,7]<stderr>:2020-09-18 19:25:50.255995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.256056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.256601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,2]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,2]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,2]<stderr>:2020-09-18 19:25:50.256664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.257968: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,67]<stderr>:2020-09-18 19:25:50.258268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,67]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,67]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,67]<stderr>:2020-09-18 19:25:50.258331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.258841: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,71]<stderr>:2020-09-18 19:25:50.259246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,71]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,71]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,96]<stderr>:2020-09-18 19:25:50.258970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,96]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,96]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,96]<stderr>:2020-09-18 19:25:50.259029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.259312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.258325: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,23]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,99]<stderr>:2020-09-18 19:25:50.259427: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,7]<stderr>:2020-09-18 19:25:50.259274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,7]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,7]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,7]<stderr>:2020-09-18 19:25:50.259356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.259986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,100]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,100]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,100]<stderr>:2020-09-18 19:25:50.260042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.260339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,65]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,65]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,19]<stderr>:2020-09-18 19:25:50.259136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.260398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.259956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,2]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,2]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,2]<stderr>:2020-09-18 19:25:50.260033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.259575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.259636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.261071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,97]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,97]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,97]<stderr>:2020-09-18 19:25:50.261134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.262016: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,103]<stderr>:2020-09-18 19:25:50.262118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.262652: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,101]<stderr>:2020-09-18 19:25:50.262706: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,101]<stderr>:2020-09-18 19:25:50.262808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.263093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,67]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,67]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,67]<stderr>:2020-09-18 19:25:50.263162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.262551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,7]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,7]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,7]<stderr>:2020-09-18 19:25:50.262581: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,3]<stderr>:2020-09-18 19:25:50.262856: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,2]<stderr>:2020-09-18 19:25:50.262935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,2]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,2]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,2]<stderr>:2020-09-18 19:25:50.263000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.263018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.263930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,71]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,71]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,71]<stderr>:2020-09-18 19:25:50.263991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.263321: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,99]<stderr>:2020-09-18 19:25:50.264041: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,0]<stderr>:2020-09-18 19:25:50.263488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.263083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.264513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,96]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,96]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,96]<stderr>:2020-09-18 19:25:50.264569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.265186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,65]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,65]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,65]<stderr>:2020-09-18 19:25:50.265249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.264121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.265734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,100]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,100]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,100]<stderr>:2020-09-18 19:25:50.265796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.266215: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,21]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,23]<stderr>:2020-09-18 19:25:50.266299: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,23]<stderr>:2020-09-18 19:25:50.266420: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c70eb19ef0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,23]<stderr>:2020-09-18 19:25:50.266439: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,67]<stderr>:2020-09-18 19:25:50.267847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,67]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,67]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,67]<stderr>:2020-09-18 19:25:50.267909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.268009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,71]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,71]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,71]<stderr>:2020-09-18 19:25:50.268070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.267567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,2]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,2]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,2]<stderr>:2020-09-18 19:25:50.267628: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.268154: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,19]<stderr>:2020-09-18 19:25:50.267299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.267744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,3]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,3]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,3]<stderr>:2020-09-18 19:25:50.267844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.268690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,97]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,97]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,97]<stderr>:2020-09-18 19:25:50.268716: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,7]<stderr>:2020-09-18 19:25:50.268144: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,22]<stderr>:2020-09-18 19:25:50.267808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.268246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,0]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,0]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,18]<stderr>:2020-09-18 19:25:50.267742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.268329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.269968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,65]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,65]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,65]<stderr>:2020-09-18 19:25:50.270051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.268713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.270135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.270213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.270020: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,4]<stderr>:2020-09-18 19:25:50.270170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.270782: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,96]<stderr>:2020-09-18 19:25:50.272395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,96]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,96]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,96]<stderr>:2020-09-18 19:25:50.272421: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,67]<stderr>:2020-09-18 19:25:50.272743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,67]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,67]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,67]<stderr>:2020-09-18 19:25:50.272812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.272823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,71]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,71]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,71]<stderr>:2020-09-18 19:25:50.272881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.272010: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,100]<stderr>:2020-09-18 19:25:50.272824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,100]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,100]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,100]<stderr>:2020-09-18 19:25:50.272846: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,97]<stderr>:2020-09-18 19:25:50.272872: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,16]<stderr>:2020-09-18 19:25:50.271752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.272960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,2]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,2]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,2]<stderr>:2020-09-18 19:25:50.273018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.273057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,3]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,3]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,20]<stderr>:2020-09-18 19:25:50.272769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.273118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.274449: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,99]<stderr>:2020-09-18 19:25:50.274547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.274817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,65]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,65]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,65]<stderr>:2020-09-18 19:25:50.274881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.274127: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,0]<stderr>:2020-09-18 19:25:50.274248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,0]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,0]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,0]<stderr>:2020-09-18 19:25:50.274307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.275385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.275474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.276264: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,6]<stderr>:2020-09-18 19:25:50.275676: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,6]<stderr>:2020-09-18 19:25:50.275830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.276543: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,64]<stderr>:2020-09-18 19:25:50.276731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.275458: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,21]<stderr>:2020-09-18 19:25:50.275579: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558deae77e80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,21]<stderr>:2020-09-18 19:25:50.275599: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,4]<stderr>:2020-09-18 19:25:50.276480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,4]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,4]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,4]<stderr>:2020-09-18 19:25:50.276558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.277156: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,96]<stderr>:2020-09-18 19:25:50.277262: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,67]<stderr>:2020-09-18 19:25:50.277775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,67]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,67]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,67]<stderr>:2020-09-18 19:25:50.277802: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,71]<stderr>:2020-09-18 19:25:50.277852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,71]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,71]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,71]<stderr>:2020-09-18 19:25:50.277903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.277762: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,7]<stderr>:2020-09-18 19:25:50.277668: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,19]<stderr>:2020-09-18 19:25:50.277339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.277864: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.277888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.277946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.279429: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,66]<stderr>:2020-09-18 19:25:50.279590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.279402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.280171: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.280117: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,101]<stderr>:2020-09-18 19:25:50.280255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.280562: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,2]<stderr>:2020-09-18 19:25:50.279892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,2]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,2]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,7]<stderr>:2020-09-18 19:25:50.279846: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,2]<stderr>:2020-09-18 19:25:50.279951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.279556: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c70e9d3b10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,23]<stderr>:2020-09-18 19:25:50.279577: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,3]<stderr>:2020-09-18 19:25:50.280066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,3]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,3]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,3]<stderr>:2020-09-18 19:25:50.280137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.279778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.281039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,65]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,65]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,65]<stderr>:2020-09-18 19:25:50.281140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.281029: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,100]<stderr>:2020-09-18 19:25:50.281290: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,35]<stderr>:2020-09-18 19:25:50.281320: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,35]<stderr>:2020-09-18 19:25:50.281537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.281575: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,0]<stderr>:2020-09-18 19:25:50.281115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,0]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,0]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,0]<stderr>:2020-09-18 19:25:50.281175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.282551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,64]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,64]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,64]<stderr>:2020-09-18 19:25:50.282637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.283269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,35]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,35]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,35]<stderr>:2020-09-18 19:25:50.283361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.283643: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,37]<stderr>:2020-09-18 19:25:50.283561: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,16]<stderr>:2020-09-18 19:25:50.282393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.283546: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,37]<stderr>:2020-09-18 19:25:50.283726: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.283199: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,7]<stderr>:2020-09-18 19:25:50.283304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.284233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,71]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,71]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,71]<stderr>:2020-09-18 19:25:50.284323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.284107: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.283228: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,17]<stderr>:2020-09-18 19:25:50.283397: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e317340fe0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,17]<stderr>:2020-09-18 19:25:50.283418: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,6]<stderr>:2020-09-18 19:25:50.283922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,6]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,6]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,6]<stderr>:2020-09-18 19:25:50.284004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.283544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.284894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.284982: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.284775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,4]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,4]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,4]<stderr>:2020-09-18 19:25:50.284835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.285329: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,100]<stderr>:2020-09-18 19:25:50.285330: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,66]<stderr>:2020-09-18 19:25:50.285934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,66]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,66]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,66]<stderr>:2020-09-18 19:25:50.286041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.285530: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,84]<stderr>:2020-09-18 19:25:50.285723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.286012: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,33]<stderr>:2020-09-18 19:25:50.286169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.286221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,35]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,35]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,35]<stderr>:2020-09-18 19:25:50.286289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.285740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,83]<stderr>:2020-09-18 19:25:50.286703: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,83]<stderr>:2020-09-18 19:25:50.286909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.287173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,37]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,37]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,37]<stderr>:2020-09-18 19:25:50.287252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.287210: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,97]<stderr>:2020-09-18 19:25:50.287306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.287482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,65]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,65]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,65]<stderr>:2020-09-18 19:25:50.287513: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,67]<stderr>:2020-09-18 19:25:50.287563: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,100]<stderr>:2020-09-18 19:25:50.287711: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,96]<stderr>:2020-09-18 19:25:50.287692: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,84]<stderr>:2020-09-18 19:25:50.287906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,84]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,84]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,49]<stderr>:2020-09-18 19:25:50.288366: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,84]<stderr>:2020-09-18 19:25:50.288000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.288570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.288909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,64]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,64]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,64]<stderr>:2020-09-18 19:25:50.288967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.289061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.289734: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,2]<stderr>:2020-09-18 19:25:50.289196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,2]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,2]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,83]<stderr>:2020-09-18 19:25:50.289594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,83]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,83]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,2]<stderr>:2020-09-18 19:25:50.289222: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,83]<stderr>:2020-09-18 19:25:50.289692: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.290204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,49]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,49]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,3]<stderr>:2020-09-18 19:25:50.289290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,3]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,3]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,3]<stderr>:2020-09-18 19:25:50.289357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.290283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.288995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.290102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.290369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,71]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,71]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,101]<stderr>:2020-09-18 19:25:50.290188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.290393: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,0]<stderr>:2020-09-18 19:25:50.289732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,0]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,0]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,0]<stderr>:2020-09-18 19:25:50.289808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.290885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,66]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,66]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,66]<stderr>:2020-09-18 19:25:50.290950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.289794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,33]<stderr>:2020-09-18 19:25:50.290878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,33]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,33]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,22]<stderr>:2020-09-18 19:25:50.289931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.290946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,35]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,35]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,33]<stderr>:2020-09-18 19:25:50.290955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.291002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.290063: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558dead1f800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,21]<stderr>:2020-09-18 19:25:50.290088: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,21]<stderr>:2020-09-18 19:25:50.290267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.291279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,84]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,84]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,49]<stderr>:2020-09-18 19:25:50.291882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,49]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,49]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,84]<stderr>:2020-09-18 19:25:50.291363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.291940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.291736: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,100]<stderr>:2020-09-18 19:25:50.291819: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,96]<stderr>:2020-09-18 19:25:50.291843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.292103: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,100]<stderr>:2020-09-18 19:25:50.291914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.291961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,37]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,37]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,37]<stderr>:2020-09-18 19:25:50.292016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.292465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,64]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,64]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,64]<stderr>:2020-09-18 19:25:50.292523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.291584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,23]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,23]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,23]<stderr>:2020-09-18 19:25:50.291617: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,23]<stderr>:2020-09-18 19:25:50.291683: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,23]<stderr>:2020-09-18 19:25:50.291701: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,23]<stderr>:2020-09-18 19:25:50.291718: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,23]<stderr>:2020-09-18 19:25:50.291733: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,23]<stderr>:2020-09-18 19:25:50.291749: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,23]<stderr>:2020-09-18 19:25:50.291765: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,23]<stderr>:2020-09-18 19:25:50.291818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.293492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,49]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,49]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,7]<stderr>:2020-09-18 19:25:50.292479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.293539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,83]<stderr>:2020-09-18 19:25:50.293003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,83]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,83]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,83]<stderr>:2020-09-18 19:25:50.293089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.293604: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,66]<stderr>:2020-09-18 19:25:50.294034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,66]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,66]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,97]<stderr>:2020-09-18 19:25:50.293833: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.294090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.293265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,6]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,6]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,6]<stderr>:2020-09-18 19:25:50.293326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.293341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,4]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,4]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,4]<stderr>:2020-09-18 19:25:50.293392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.293541: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,71]<stderr>:2020-09-18 19:25:50.294373: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,68]<stderr>:2020-09-18 19:25:50.294478: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,68]<stderr>:2020-09-18 19:25:50.294635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.295141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,49]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,49]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,49]<stderr>:2020-09-18 19:25:50.295193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.294649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,84]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,84]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,84]<stderr>:2020-09-18 19:25:50.294708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.295186: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,33]<stderr>:2020-09-18 19:25:50.295656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,33]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,33]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,33]<stderr>:2020-09-18 19:25:50.295712: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.295993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,64]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,64]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,64]<stderr>:2020-09-18 19:25:50.296045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.295735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,35]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,35]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,35]<stderr>:2020-09-18 19:25:50.295799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.296257: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,65]<stderr>:2020-09-18 19:25:50.296550: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,16]<stderr>:2020-09-18 19:25:50.295390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,83]<stderr>:2020-09-18 19:25:50.296318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,83]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,83]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,49]<stderr>:2020-09-18 19:25:50.296745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,49]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,49]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,49]<stderr>:2020-09-18 19:25:50.296786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,83]<stderr>:2020-09-18 19:25:50.296395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.296462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.296817: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,37]<stderr>:2020-09-18 19:25:50.296669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,37]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,37]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,37]<stderr>:2020-09-18 19:25:50.296724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.296601: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,20]<stderr>:2020-09-18 19:25:50.296737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.298270: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,3]<stderr>:2020-09-18 19:25:50.297413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,3]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,3]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,3]<stderr>:2020-09-18 19:25:50.297479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.298339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,49]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,49]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,49]<stderr>:2020-09-18 19:25:50.298394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.297575: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,84]<stderr>:2020-09-18 19:25:50.297980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,84]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,84]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,84]<stderr>:2020-09-18 19:25:50.298035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.297855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,0]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,0]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,66]<stderr>:2020-09-18 19:25:50.298660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,66]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,66]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,66]<stderr>:2020-09-18 19:25:50.298716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.298755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,68]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,68]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,0]<stderr>:2020-09-18 19:25:50.297927: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.298832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.299750: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,113]<stderr>:2020-09-18 19:25:50.299949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.299436: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,51]<stderr>:2020-09-18 19:25:50.299602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.299187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.299273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.298549: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e3171be230 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,17]<stderr>:2020-09-18 19:25:50.298569: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,17]<stderr>:2020-09-18 19:25:50.298728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.300013: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,83]<stderr>:2020-09-18 19:25:50.299681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,83]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,83]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,83]<stderr>:2020-09-18 19:25:50.299745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.300346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,49]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,49]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,67]<stderr>:2020-09-18 19:25:50.300312: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,49]<stderr>:2020-09-18 19:25:50.300405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.300415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.300348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,33]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,33]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,113]<stderr>:2020-09-18 19:25:50.301601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,113]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,113]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,113]<stderr>:2020-09-18 19:25:50.301680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.300398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.301769: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,35]<stderr>:2020-09-18 19:25:50.300513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,35]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,35]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,64]<stderr>:2020-09-18 19:25:50.300828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,64]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,64]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,35]<stderr>:2020-09-18 19:25:50.300576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.300890: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.301935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.300578: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,39]<stderr>:2020-09-18 19:25:50.300726: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.300605: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.301583: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,37]<stderr>:2020-09-18 19:25:50.301557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,37]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,37]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,2]<stderr>:2020-09-18 19:25:50.300854: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,37]<stderr>:2020-09-18 19:25:50.301608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.301393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,84]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,84]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,85]<stderr>:2020-09-18 19:25:50.301428: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,84]<stderr>:2020-09-18 19:25:50.301454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.301719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.301797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.301593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.301413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,6]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,6]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,6]<stderr>:2020-09-18 19:25:50.301469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.302295: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,4]<stderr>:2020-09-18 19:25:50.301491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,4]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,4]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,114]<stderr>:2020-09-18 19:25:50.303177: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,4]<stderr>:2020-09-18 19:25:50.301544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.303352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.301324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.302819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,51]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,51]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,51]<stderr>:2020-09-18 19:25:50.302908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.304121: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,115]<stderr>:2020-09-18 19:25:50.304285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.303429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,49]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,49]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,49]<stderr>:2020-09-18 19:25:50.303453: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,22]<stderr>:2020-09-18 19:25:50.301984: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.302029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,21]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,21]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,21]<stderr>:2020-09-18 19:25:50.302061: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,21]<stderr>:2020-09-18 19:25:50.302106: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,21]<stderr>:2020-09-18 19:25:50.302119: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,21]<stderr>:2020-09-18 19:25:50.302132: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,21]<stderr>:2020-09-18 19:25:50.302144: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,21]<stderr>:2020-09-18 19:25:50.302157: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,21]<stderr>:2020-09-18 19:25:50.302170: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,21]<stderr>:2020-09-18 19:25:50.302226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.302733: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,71]<stderr>:2020-09-18 19:25:50.303564: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,69]<stderr>:2020-09-18 19:25:50.303954: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,83]<stderr>:2020-09-18 19:25:50.303534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,83]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,83]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,97]<stderr>:2020-09-18 19:25:50.303717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,83]<stderr>:2020-09-18 19:25:50.303602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.305006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,113]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,113]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,113]<stderr>:2020-09-18 19:25:50.305069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.304105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.304766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,51]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,51]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,51]<stderr>:2020-09-18 19:25:50.304822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.303539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.304807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,66]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,66]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,66]<stderr>:2020-09-18 19:25:50.304868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.304886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,68]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,68]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,68]<stderr>:2020-09-18 19:25:50.304943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.306085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,119]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,119]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,119]<stderr>:2020-09-18 19:25:50.306165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.306671: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,117]<stderr>:2020-09-18 19:25:50.306828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.306951: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,65]<stderr>:2020-09-18 19:25:50.306074: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,118]<stderr>:2020-09-18 19:25:50.307125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.306171: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,65]<stderr>:2020-09-18 19:25:50.306178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.306356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.306412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,51]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,51]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,51]<stderr>:2020-09-18 19:25:50.306472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.306159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.306498: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,3]<stderr>:2020-09-18 19:25:50.305555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,3]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,3]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,3]<stderr>:2020-09-18 19:25:50.305624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.306683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.305828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,0]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,0]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,0]<stderr>:2020-09-18 19:25:50.305887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.306444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,33]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,33]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,33]<stderr>:2020-09-18 19:25:50.306500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.306296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,84]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,84]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,84]<stderr>:2020-09-18 19:25:50.306350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.306404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,85]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,85]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,85]<stderr>:2020-09-18 19:25:50.306481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.306918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,35]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,35]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,35]<stderr>:2020-09-18 19:25:50.306985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.307313: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,39]<stderr>:2020-09-18 19:25:50.307157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,39]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,39]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,71]<stderr>:2020-09-18 19:25:50.307412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.307235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.306680: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,67]<stderr>:2020-09-18 19:25:50.307524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.306776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.307763: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,48]<stderr>:2020-09-18 19:25:50.307935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.307772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,37]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,37]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,37]<stderr>:2020-09-18 19:25:50.307823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.308155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,64]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,64]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,64]<stderr>:2020-09-18 19:25:50.308212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,70]<stderr>:2020-09-18 19:25:50.308288: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,49]<stderr>:2020-09-18 19:25:50.308342: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,70]<stderr>:2020-09-18 19:25:50.308439: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.308099: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,32]<stderr>:2020-09-18 19:25:50.308281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.307320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,83]<stderr>:2020-09-18 19:25:50.308474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,83]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,83]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,38]<stderr>:2020-09-18 19:25:50.308718: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,83]<stderr>:2020-09-18 19:25:50.308541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.308818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.308896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.308903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.308720: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,80]<stderr>:2020-09-18 19:25:50.308897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.308995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.310823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,114]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,114]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,114]<stderr>:2020-09-18 19:25:50.310910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.308617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.310020: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,82]<stderr>:2020-09-18 19:25:50.310168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.309977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,6]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,6]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,115]<stderr>:2020-09-18 19:25:50.311770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,115]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,115]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,6]<stderr>:2020-09-18 19:25:50.310035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.311865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.310061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,4]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,4]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,4]<stderr>:2020-09-18 19:25:50.310111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.311410: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,87]<stderr>:2020-09-18 19:25:50.310880: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,87]<stderr>:2020-09-18 19:25:50.311040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.311624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,50]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,50]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,51]<stderr>:2020-09-18 19:25:50.311691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,51]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,51]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,96]<stderr>:2020-09-18 19:25:50.311330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.311718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.311405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.311746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.311316: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,36]<stderr>:2020-09-18 19:25:50.311476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.310557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,17]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,17]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,17]<stderr>:2020-09-18 19:25:50.310591: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,17]<stderr>:2020-09-18 19:25:50.310640: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,17]<stderr>:2020-09-18 19:25:50.310653: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,17]<stderr>:2020-09-18 19:25:50.310665: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,17]<stderr>:2020-09-18 19:25:50.310677: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,17]<stderr>:2020-09-18 19:25:50.310689: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,17]<stderr>:2020-09-18 19:25:50.310701: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,53]<stderr>:2020-09-18 19:25:50.312042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,53]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,53]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,17]<stderr>:2020-09-18 19:25:50.310755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.312123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.313005: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,116]<stderr>:2020-09-18 19:25:50.313166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.312442: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,52]<stderr>:2020-09-18 19:25:50.312609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.312639: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,84]<stderr>:2020-09-18 19:25:50.312218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,84]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,84]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,84]<stderr>:2020-09-18 19:25:50.312300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.312486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,85]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,85]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,85]<stderr>:2020-09-18 19:25:50.312549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.312813: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,113]<stderr>:2020-09-18 19:25:50.314058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,113]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,113]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,113]<stderr>:2020-09-18 19:25:50.314120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.312958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.313332: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,55]<stderr>:2020-09-18 19:25:50.313503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.313364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.313143: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,86]<stderr>:2020-09-18 19:25:50.313292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.312611: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,18]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,19]<stderr>:2020-09-18 19:25:50.313086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.314216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,33]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,33]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,33]<stderr>:2020-09-18 19:25:50.314281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.314593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,69]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,69]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,69]<stderr>:2020-09-18 19:25:50.314687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.316109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,119]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,119]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,22]<stderr>:2020-09-18 19:25:50.313837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.316188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.313921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.316492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,117]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,117]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,117]<stderr>:2020-09-18 19:25:50.316605: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.315914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,48]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,48]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,48]<stderr>:2020-09-18 19:25:50.316003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.315816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.315992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,66]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,66]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,66]<stderr>:2020-09-18 19:25:50.316064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.316049: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,68]<stderr>:2020-09-18 19:25:50.316079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,68]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,68]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,3]<stderr>:2020-09-18 19:25:50.315278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,3]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,3]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,3]<stderr>:2020-09-18 19:25:50.315350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.316155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.315922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,35]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,35]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,35]<stderr>:2020-09-18 19:25:50.315987: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.315563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,0]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,0]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,0]<stderr>:2020-09-18 19:25:50.315637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.317441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,118]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,118]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,118]<stderr>:2020-09-18 19:25:50.317534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.315783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,81]<stderr>:2020-09-18 19:25:50.316424: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,23]<stderr>:2020-09-18 19:25:50.315708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 7
[1,81]<stderr>:2020-09-18 19:25:50.316578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.315759: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,39]<stderr>:2020-09-18 19:25:50.317046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,39]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,39]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,54]<stderr>:2020-09-18 19:25:50.317305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,39]<stderr>:2020-09-18 19:25:50.317117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,54]<stderr>:2020-09-18 19:25:50.317470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.317906: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,37]<stderr>:2020-09-18 19:25:50.318062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,37]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,37]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,5]<stderr>:2020-09-18 19:25:50.317449: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,112]<stderr>:2020-09-18 19:25:50.319226: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,37]<stderr>:2020-09-18 19:25:50.318123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.318347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.319372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.317619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.318523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.318611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,83]<stderr>:2020-09-18 19:25:50.318505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,83]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,83]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,83]<stderr>:2020-09-18 19:25:50.318570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.318680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,80]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,80]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,80]<stderr>:2020-09-18 19:25:50.318769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.318929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.319736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,82]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,82]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,71]<stderr>:2020-09-18 19:25:50.320180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.319819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.320342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.319668: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,16]<stderr>:2020-09-18 19:25:50.319163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.319826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.320380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,32]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,32]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,32]<stderr>:2020-09-18 19:25:50.320476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.320064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,6]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,6]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,6]<stderr>:2020-09-18 19:25:50.320120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.320141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,4]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,4]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,4]<stderr>:2020-09-18 19:25:50.320191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.321024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,64]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,64]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,64]<stderr>:2020-09-18 19:25:50.321113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.321311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,50]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,50]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,50]<stderr>:2020-09-18 19:25:50.321372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.321408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,51]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,51]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,114]<stderr>:2020-09-18 19:25:50.322256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,114]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,114]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,114]<stderr>:2020-09-18 19:25:50.322318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.321488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.321148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.321242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.321338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,38]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,38]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,38]<stderr>:2020-09-18 19:25:50.321427: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.321801: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,20]<stderr>:2020-09-18 19:25:50.320392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.321897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,70]<stderr>:2020-09-18 19:25:50.321827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,70]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,70]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,115]<stderr>:2020-09-18 19:25:50.322778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,115]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,115]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,115]<stderr>:2020-09-18 19:25:50.322857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.322025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,53]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,53]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,70]<stderr>:2020-09-18 19:25:50.321916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.322084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.322132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,52]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,52]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,52]<stderr>:2020-09-18 19:25:50.322224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.322707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,87]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,87]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,87]<stderr>:2020-09-18 19:25:50.322816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.323194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.322390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.324897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,116]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,116]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,116]<stderr>:2020-09-18 19:25:50.324985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.324154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,36]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,36]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,55]<stderr>:2020-09-18 19:25:50.324669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,55]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,55]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,36]<stderr>:2020-09-18 19:25:50.324251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.324770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.325830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,113]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,113]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,113]<stderr>:2020-09-18 19:25:50.325908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.323691: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,18]<stderr>:2020-09-18 19:25:50.323824: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556ed0becd60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,18]<stderr>:2020-09-18 19:25:50.323843: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,19]<stderr>:2020-09-18 19:25:50.324027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.324943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,84]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,84]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,84]<stderr>:2020-09-18 19:25:50.324969: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,85]<stderr>:2020-09-18 19:25:50.325301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,85]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,85]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,85]<stderr>:2020-09-18 19:25:50.325358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.324592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 5
[1,21]<stderr>:2020-09-18 19:25:50.324646: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,99]<stderr>:2020-09-18 19:25:50.325671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.324562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.325492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,86]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,86]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,86]<stderr>:2020-09-18 19:25:50.325591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.325795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,34]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,34]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,34]<stderr>:2020-09-18 19:25:50.325879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.326841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,69]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,69]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,48]<stderr>:2020-09-18 19:25:50.326988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,48]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,48]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,69]<stderr>:2020-09-18 19:25:50.326906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.327064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.326785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,3]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,3]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,3]<stderr>:2020-09-18 19:25:50.326823: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,33]<stderr>:2020-09-18 19:25:50.327444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,33]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,33]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,33]<stderr>:2020-09-18 19:25:50.327530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.326604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.329070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,119]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,119]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,119]<stderr>:2020-09-18 19:25:50.329137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.329249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,117]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,117]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,117]<stderr>:2020-09-18 19:25:50.329345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.328344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.328433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.327989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,0]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,0]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,0]<stderr>:2020-09-18 19:25:50.328045: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,2]<stderr>:2020-09-18 19:25:50.328113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.328881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,66]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,66]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,66]<stderr>:2020-09-18 19:25:50.328943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.328962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,68]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,68]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,68]<stderr>:2020-09-18 19:25:50.329026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.328486: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,35]<stderr>:2020-09-18 19:25:50.328990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,35]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,35]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,35]<stderr>:2020-09-18 19:25:50.329025: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,54]<stderr>:2020-09-18 19:25:50.329517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,54]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,54]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,54]<stderr>:2020-09-18 19:25:50.329616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.330563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,118]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,118]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,118]<stderr>:2020-09-18 19:25:50.330626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,81]<stderr>:2020-09-18 19:25:50.330137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,81]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,81]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,39]<stderr>:2020-09-18 19:25:50.330389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,39]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,39]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,39]<stderr>:2020-09-18 19:25:50.330471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,81]<stderr>:2020-09-18 19:25:50.330239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.330006: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,16]<stderr>:2020-09-18 19:25:50.329605: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.330214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,5]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,5]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,112]<stderr>:2020-09-18 19:25:50.331946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,112]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,112]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,112]<stderr>:2020-09-18 19:25:50.332045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.330301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.330885: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.330963: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.331135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,37]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,37]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,65]<stderr>:2020-09-18 19:25:50.331364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.331187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.331190: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,83]<stderr>:2020-09-18 19:25:50.331350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,83]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,83]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,83]<stderr>:2020-09-18 19:25:50.331374: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,80]<stderr>:2020-09-18 19:25:50.331519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,80]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,80]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,7]<stderr>:2020-09-18 19:25:50.331141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.331590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.331177: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,20]<stderr>:2020-09-18 19:25:50.330755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,82]<stderr>:2020-09-18 19:25:50.331798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,82]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,82]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,82]<stderr>:2020-09-18 19:25:50.331861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.332235: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,1]<stderr>:2020-09-18 19:25:50.332053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,1]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,1]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,1]<stderr>:2020-09-18 19:25:50.332155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.332295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,6]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,6]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,97]<stderr>:2020-09-18 19:25:50.332820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.333067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.332857: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,4]<stderr>:2020-09-18 19:25:50.332363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,4]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,4]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,17]<stderr>:2020-09-18 19:25:50.331879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 1
[1,17]<stderr>:2020-09-18 19:25:50.331925: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,67]<stderr>:2020-09-18 19:25:50.333243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.332379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.332413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.332928: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,32]<stderr>:2020-09-18 19:25:50.333517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,32]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,32]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,32]<stderr>:2020-09-18 19:25:50.333597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.333984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,64]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,64]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,64]<stderr>:2020-09-18 19:25:50.334011: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,50]<stderr>:2020-09-18 19:25:50.334231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,50]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,50]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,50]<stderr>:2020-09-18 19:25:50.334288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.334195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,38]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,38]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,114]<stderr>:2020-09-18 19:25:50.335364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,114]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,114]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,114]<stderr>:2020-09-18 19:25:50.335424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.334258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.334398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,51]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,51]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,51]<stderr>:2020-09-18 19:25:50.334476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.333783: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,87]<stderr>:2020-09-18 19:25:50.334228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,87]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,87]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,87]<stderr>:2020-09-18 19:25:50.334318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.333884: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,70]<stderr>:2020-09-18 19:25:50.334835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,70]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,70]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,19]<stderr>:2020-09-18 19:25:50.333569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,70]<stderr>:2020-09-18 19:25:50.334899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.335031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,83]<stderr>:2020-09-18 19:25:50.334583: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,53]<stderr>:2020-09-18 19:25:50.335159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,53]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,53]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,53]<stderr>:2020-09-18 19:25:50.335219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.335254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,52]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,52]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,115]<stderr>:2020-09-18 19:25:50.336067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,115]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,115]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,115]<stderr>:2020-09-18 19:25:50.336163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.335327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.333933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.334954: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,102]<stderr>:2020-09-18 19:25:50.335150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.334642: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,99]<stderr>:2020-09-18 19:25:50.335434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.335442: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
[1,98]<stderr>:2020-09-18 19:25:50.335621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.335463: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,35]<stderr>:2020-09-18 19:25:50.335768: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,36]<stderr>:2020-09-18 19:25:50.336136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,36]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,36]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,36]<stderr>:2020-09-18 19:25:50.336224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.335287: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556ed0bd51c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,18]<stderr>:2020-09-18 19:25:50.335304: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,18]<stderr>:2020-09-18 19:25:50.335493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.336685: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,85]<stderr>:2020-09-18 19:25:50.336485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,85]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,85]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,85]<stderr>:2020-09-18 19:25:50.336543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.335790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,86]<stderr>:2020-09-18 19:25:50.336668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,86]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,86]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,116]<stderr>:2020-09-18 19:25:50.338126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,116]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,116]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,86]<stderr>:2020-09-18 19:25:50.336768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.338216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.337279: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,3]<stderr>:2020-09-18 19:25:50.336699: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,55]<stderr>:2020-09-18 19:25:50.337754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,55]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,55]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,55]<stderr>:2020-09-18 19:25:50.337822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.337313: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,83]<stderr>:2020-09-18 19:25:50.337329: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,34]<stderr>:2020-09-18 19:25:50.337573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,34]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,34]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,34]<stderr>:2020-09-18 19:25:50.337632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.337093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.339097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,113]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,113]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,113]<stderr>:2020-09-18 19:25:50.339181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.337537: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,83]<stderr>:2020-09-18 19:25:50.338079: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,103]<stderr>:2020-09-18 19:25:50.338503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.338754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.338365: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,22]<stderr>:2020-09-18 19:25:50.338042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,69]<stderr>:2020-09-18 19:25:50.339390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,69]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,69]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,69]<stderr>:2020-09-18 19:25:50.339453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.339184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,33]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,33]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,33]<stderr>:2020-09-18 19:25:50.339250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.338413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,18]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,18]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,18]<stderr>:2020-09-18 19:25:50.338435: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,18]<stderr>:2020-09-18 19:25:50.338482: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,18]<stderr>:2020-09-18 19:25:50.338496: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,18]<stderr>:2020-09-18 19:25:50.338509: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,18]<stderr>:2020-09-18 19:25:50.338522: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,18]<stderr>:2020-09-18 19:25:50.338534: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,18]<stderr>:2020-09-18 19:25:50.338547: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,18]<stderr>:2020-09-18 19:25:50.338595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.340049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,48]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,48]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,35]<stderr>:2020-09-18 19:25:50.339774: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,48]<stderr>:2020-09-18 19:25:50.340120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.339092: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,64]<stderr>:2020-09-18 19:25:50.340171: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,81]<stderr>:2020-09-18 19:25:50.340232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,81]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,81]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,81]<stderr>:2020-09-18 19:25:50.340316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.340085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,5]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,5]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,5]<stderr>:2020-09-18 19:25:50.340154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.341126: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,119]<stderr>:2020-09-18 19:25:50.342222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,119]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,119]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,119]<stderr>:2020-09-18 19:25:50.342302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,83]<stderr>:2020-09-18 19:25:50.340876: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,117]<stderr>:2020-09-18 19:25:50.342392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,117]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,117]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,117]<stderr>:2020-09-18 19:25:50.342474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.341494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,66]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,66]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,66]<stderr>:2020-09-18 19:25:50.341518: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,68]<stderr>:2020-09-18 19:25:50.341583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,68]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,68]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,18]<stderr>:2020-09-18 19:25:50.340260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.341684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.340884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,54]<stderr>:2020-09-18 19:25:50.341862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,54]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,54]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,54]<stderr>:2020-09-18 19:25:50.341934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.341396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,80]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,80]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,35]<stderr>:2020-09-18 19:25:50.341575: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,80]<stderr>:2020-09-18 19:25:50.341466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.341481: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,39]<stderr>:2020-09-18 19:25:50.341769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,39]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,39]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,82]<stderr>:2020-09-18 19:25:50.341572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,82]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,82]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,39]<stderr>:2020-09-18 19:25:50.341827: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.341572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.341631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.342199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.342287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.342446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,37]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,37]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,37]<stderr>:2020-09-18 19:25:50.342470: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,1]<stderr>:2020-09-18 19:25:50.341952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,1]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,1]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,1]<stderr>:2020-09-18 19:25:50.342013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.342036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,6]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,6]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,6]<stderr>:2020-09-18 19:25:50.342092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.343775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,118]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,118]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,118]<stderr>:2020-09-18 19:25:50.343858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,83]<stderr>:2020-09-18 19:25:50.342497: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,18]<stderr>:2020-09-18 19:25:50.341788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 2
[1,4]<stderr>:2020-09-18 19:25:50.342202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,4]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,4]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,4]<stderr>:2020-09-18 19:25:50.342232: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,18]<stderr>:2020-09-18 19:25:50.341825: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,65]<stderr>:2020-09-18 19:25:50.343159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.342389: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,3]<stderr>:2020-09-18 19:25:50.342491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.342913: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,0]<stderr>:2020-09-18 19:25:50.343004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.343995: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,112]<stderr>:2020-09-18 19:25:50.345083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,112]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,112]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,112]<stderr>:2020-09-18 19:25:50.345164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.344321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.344486: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,67]<stderr>:2020-09-18 19:25:50.344506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.344368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,87]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,87]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,87]<stderr>:2020-09-18 19:25:50.344430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.344712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,32]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,32]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,32]<stderr>:2020-09-18 19:25:50.344779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.345295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.345395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,38]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,38]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,38]<stderr>:2020-09-18 19:25:50.345454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.345724: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,70]<stderr>:2020-09-18 19:25:50.345851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,70]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,70]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,37]<stderr>:2020-09-18 19:25:50.345625: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,70]<stderr>:2020-09-18 19:25:50.345905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.345665: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,35]<stderr>:2020-09-18 19:25:50.345767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.345476: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,83]<stderr>:2020-09-18 19:25:50.346425: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,83]<stderr>:2020-09-18 19:25:50.346515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.347056: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,85]<stderr>:2020-09-18 19:25:50.346769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,85]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,85]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,85]<stderr>:2020-09-18 19:25:50.346826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.347484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,50]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,50]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,50]<stderr>:2020-09-18 19:25:50.347568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.348480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,114]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,114]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,114]<stderr>:2020-09-18 19:25:50.348538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.347236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,36]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,36]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,36]<stderr>:2020-09-18 19:25:50.347300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.347125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,86]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,86]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,86]<stderr>:2020-09-18 19:25:50.347223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.347723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,51]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,51]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,51]<stderr>:2020-09-18 19:25:50.347788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.347985: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,49]<stderr>:2020-09-18 19:25:50.348231: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.348246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,53]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,53]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,53]<stderr>:2020-09-18 19:25:50.348300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.349105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,115]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,115]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,2]<stderr>:2020-09-18 19:25:50.347373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.349189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.348419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,52]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,52]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,52]<stderr>:2020-09-18 19:25:50.348481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.348095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,102]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,102]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,102]<stderr>:2020-09-18 19:25:50.348219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.348261: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,99]<stderr>:2020-09-18 19:25:50.348405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.348609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,98]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,98]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,4]<stderr>:2020-09-18 19:25:50.348119: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,98]<stderr>:2020-09-18 19:25:50.348724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.348669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,34]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,34]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,34]<stderr>:2020-09-18 19:25:50.348726: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.349223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,69]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,69]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,37]<stderr>:2020-09-18 19:25:50.349059: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,69]<stderr>:2020-09-18 19:25:50.349309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.348973: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,64]<stderr>:2020-09-18 19:25:50.349701: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,64]<stderr>:2020-09-18 19:25:50.349799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.349802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,33]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,33]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,33]<stderr>:2020-09-18 19:25:50.349827: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,20]<stderr>:2020-09-18 19:25:50.348982: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,20]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,116]<stderr>:2020-09-18 19:25:50.351198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,116]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,116]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,116]<stderr>:2020-09-18 19:25:50.351261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.350779: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,55]<stderr>:2020-09-18 19:25:50.350899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,55]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,55]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,55]<stderr>:2020-09-18 19:25:50.350959: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.352135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,113]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,113]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,113]<stderr>:2020-09-18 19:25:50.352202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.351600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,68]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,68]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,68]<stderr>:2020-09-18 19:25:50.351673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.351638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.351847: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,101]<stderr>:2020-09-18 19:25:50.351882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.351404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,5]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,5]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,5]<stderr>:2020-09-18 19:25:50.351466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.352391: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,81]<stderr>:2020-09-18 19:25:50.352052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,81]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,81]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,4]<stderr>:2020-09-18 19:25:50.351707: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,81]<stderr>:2020-09-18 19:25:50.352131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.352691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,39]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,39]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,7]<stderr>:2020-09-18 19:25:50.352030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.352755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.352812: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,48]<stderr>:2020-09-18 19:25:50.353145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,48]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,48]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,48]<stderr>:2020-09-18 19:25:50.353228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.353244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.352095: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,19]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,37]<stderr>:2020-09-18 19:25:50.353464: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,80]<stderr>:2020-09-18 19:25:50.353268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,80]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,80]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,80]<stderr>:2020-09-18 19:25:50.353332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.353493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.353523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,82]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,82]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,82]<stderr>:2020-09-18 19:25:50.353576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.353276: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,1]<stderr>:2020-09-18 19:25:50.353398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,1]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,1]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,6]<stderr>:2020-09-18 19:25:50.353473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,6]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,6]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,1]<stderr>:2020-09-18 19:25:50.353479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.355217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,119]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,119]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,119]<stderr>:2020-09-18 19:25:50.355288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.353498: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,117]<stderr>:2020-09-18 19:25:50.355393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,117]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,117]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,117]<stderr>:2020-09-18 19:25:50.355450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,54]<stderr>:2020-09-18 19:25:50.354840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,54]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,54]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,71]<stderr>:2020-09-18 19:25:50.354693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,54]<stderr>:2020-09-18 19:25:50.354922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.354739: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.354042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.353598: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,16]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,0]<stderr>:2020-09-18 19:25:50.354306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.355191: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,96]<stderr>:2020-09-18 19:25:50.355233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.355401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.355543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,32]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,32]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,32]<stderr>:2020-09-18 19:25:50.355609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.356793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,118]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,118]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,118]<stderr>:2020-09-18 19:25:50.356853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.355900: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,66]<stderr>:2020-09-18 19:25:50.356236: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,66]<stderr>:2020-09-18 19:25:50.356335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,70]<stderr>:2020-09-18 19:25:50.356656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,70]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,70]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,70]<stderr>:2020-09-18 19:25:50.356709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.356366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,38]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,38]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,38]<stderr>:2020-09-18 19:25:50.356427: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.356503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.358105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,112]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,112]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,112]<stderr>:2020-09-18 19:25:50.358164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.355947: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,22]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,37]<stderr>:2020-09-18 19:25:50.357234: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,37]<stderr>:2020-09-18 19:25:50.357334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.356634: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,36]<stderr>:2020-09-18 19:25:50.357377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,36]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,36]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,36]<stderr>:2020-09-18 19:25:50.357439: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.357164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,87]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,87]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,87]<stderr>:2020-09-18 19:25:50.357248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.356984: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,4]<stderr>:2020-09-18 19:25:50.357082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.358453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.358604: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,34]<stderr>:2020-09-18 19:25:50.358813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,34]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,34]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,34]<stderr>:2020-09-18 19:25:50.358871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.358832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.359159: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,83]<stderr>:2020-09-18 19:25:50.359712: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.359913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,85]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,85]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,85]<stderr>:2020-09-18 19:25:50.359965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.360469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,50]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,50]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,50]<stderr>:2020-09-18 19:25:50.360538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.360147: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,114]<stderr>:2020-09-18 19:25:50.361511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,114]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,114]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,114]<stderr>:2020-09-18 19:25:50.361568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.360194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,86]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,86]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,86]<stderr>:2020-09-18 19:25:50.360276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.359974: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,51]<stderr>:2020-09-18 19:25:50.360796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,51]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,51]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,51]<stderr>:2020-09-18 19:25:50.360833: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,49]<stderr>:2020-09-18 19:25:50.361016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.360951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,69]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,69]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,53]<stderr>:2020-09-18 19:25:50.361139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,53]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,53]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,69]<stderr>:2020-09-18 19:25:50.361031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.361194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.361088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.359894: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,115]<stderr>:2020-09-18 19:25:50.362117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,115]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,115]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,115]<stderr>:2020-09-18 19:25:50.362186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.361310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,52]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,52]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,52]<stderr>:2020-09-18 19:25:50.361381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.360020: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b3ea809690 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,20]<stderr>:2020-09-18 19:25:50.360039: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,102]<stderr>:2020-09-18 19:25:50.361095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,102]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,102]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,102]<stderr>:2020-09-18 19:25:50.361184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.360373: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,19]<stderr>:2020-09-18 19:25:50.360509: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559652a07140 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,19]<stderr>:2020-09-18 19:25:50.360530: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,99]<stderr>:2020-09-18 19:25:50.361531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.361806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
[1,98]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,98]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,98]<stderr>:2020-09-18 19:25:50.361880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.362010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,5]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,5]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,5]<stderr>:2020-09-18 19:25:50.362072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.361713: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,16]<stderr>:2020-09-18 19:25:50.361841: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5581c8818870 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,16]<stderr>:2020-09-18 19:25:50.361861: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,39]<stderr>:2020-09-18 19:25:50.362913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,39]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,39]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,39]<stderr>:2020-09-18 19:25:50.362971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.362464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.364257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,116]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,116]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,116]<stderr>:2020-09-18 19:25:50.364317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.362633: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,55]<stderr>:2020-09-18 19:25:50.363537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,55]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,55]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,55]<stderr>:2020-09-18 19:25:50.363606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.363809: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,20]<stderr>:2020-09-18 19:25:50.362462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.363877: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,68]<stderr>:2020-09-18 19:25:50.364043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,68]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,68]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,68]<stderr>:2020-09-18 19:25:50.364099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.363966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.365100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,113]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,113]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,113]<stderr>:2020-09-18 19:25:50.365163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.363122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.364660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.364913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.364321: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,22]<stderr>:2020-09-18 19:25:50.363890: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,1]<stderr>:2020-09-18 19:25:50.364360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,1]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,1]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,22]<stderr>:2020-09-18 19:25:50.364010: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56164b24f170 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,22]<stderr>:2020-09-18 19:25:50.364040: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,1]<stderr>:2020-09-18 19:25:50.364421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.364201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,81]<stderr>:2020-09-18 19:25:50.365161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,81]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,81]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,81]<stderr>:2020-09-18 19:25:50.365225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.365727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,48]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,48]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,48]<stderr>:2020-09-18 19:25:50.365797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.364909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.365654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.365341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.366367: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,54]<stderr>:2020-09-18 19:25:50.366715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,54]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,54]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,54]<stderr>:2020-09-18 19:25:50.366789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.366384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,80]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,80]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,80]<stderr>:2020-09-18 19:25:50.366470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.366522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.366644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,82]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,82]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,51]<stderr>:2020-09-18 19:25:50.367188: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,82]<stderr>:2020-09-18 19:25:50.366727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.366809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,32]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,32]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,32]<stderr>:2020-09-18 19:25:50.366873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.367308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.367384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.368432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,119]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,119]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,117]<stderr>:2020-09-18 19:25:50.368504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,117]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,117]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,119]<stderr>:2020-09-18 19:25:50.368513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.366369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.368560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.366637: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b3ea814840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,20]<stderr>:2020-09-18 19:25:50.366655: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,38]<stderr>:2020-09-18 19:25:50.367794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,38]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,38]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,38]<stderr>:2020-09-18 19:25:50.367852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.366830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.368066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.367949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.368310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.368470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.367942: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,6]<stderr>:2020-09-18 19:25:50.368045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.369932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,118]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,118]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,118]<stderr>:2020-09-18 19:25:50.370015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.368349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,70]<stderr>:2020-09-18 19:25:50.369467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,70]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,70]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,70]<stderr>:2020-09-18 19:25:50.369519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.369195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.369246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,36]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,36]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,36]<stderr>:2020-09-18 19:25:50.369332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.369906: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,112]<stderr>:2020-09-18 19:25:50.371240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,112]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,112]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,112]<stderr>:2020-09-18 19:25:50.371319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.370525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,87]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,87]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,87]<stderr>:2020-09-18 19:25:50.370612: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.370751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,34]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,34]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,34]<stderr>:2020-09-18 19:25:50.370804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.370321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.371592: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,19]<stderr>:2020-09-18 19:25:50.370335: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5596529e2ad0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,19]<stderr>:2020-09-18 19:25:50.370358: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,16]<stderr>:2020-09-18 19:25:50.370355: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5581c8778330 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,16]<stderr>:2020-09-18 19:25:50.370373: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,97]<stderr>:2020-09-18 19:25:50.371478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.370548: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.370574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.372096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,50]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,50]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,50]<stderr>:2020-09-18 19:25:50.372156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.372490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.372629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,53]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,53]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,53]<stderr>:2020-09-18 19:25:50.372680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.372740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,52]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,52]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,52]<stderr>:2020-09-18 19:25:50.372803: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,83]<stderr>:2020-09-18 19:25:50.373002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.373208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,85]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,85]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,85]<stderr>:2020-09-18 19:25:50.373264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.374585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,114]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,114]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,114]<stderr>:2020-09-18 19:25:50.374665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.373877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,69]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,69]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,69]<stderr>:2020-09-18 19:25:50.373937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.373480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,86]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,86]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,86]<stderr>:2020-09-18 19:25:50.373550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.374042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.375352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,115]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,115]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,115]<stderr>:2020-09-18 19:25:50.375421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.374219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,102]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,102]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,102]<stderr>:2020-09-18 19:25:50.374299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.373810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,5]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,5]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,5]<stderr>:2020-09-18 19:25:50.373899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.374609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.375126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,55]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,55]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,7]<stderr>:2020-09-18 19:25:50.374281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.375195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.374909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 2 with properties: 
[1,98]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,98]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,98]<stderr>:2020-09-18 19:25:50.374980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.375536: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,51]<stderr>:2020-09-18 19:25:50.375643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.374237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,20]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,20]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,20]<stderr>:2020-09-18 19:25:50.374289: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,20]<stderr>:2020-09-18 19:25:50.374358: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,20]<stderr>:2020-09-18 19:25:50.374373: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,20]<stderr>:2020-09-18 19:25:50.374386: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,20]<stderr>:2020-09-18 19:25:50.374398: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,20]<stderr>:2020-09-18 19:25:50.374411: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,20]<stderr>:2020-09-18 19:25:50.374424: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,22]<stderr>:2020-09-18 19:25:50.374453: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56164b2e5ba0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,22]<stderr>:2020-09-18 19:25:50.374471: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,20]<stderr>:2020-09-18 19:25:50.374490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.374648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.375886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,39]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,39]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,39]<stderr>:2020-09-18 19:25:50.375944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.377442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,116]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,116]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,116]<stderr>:2020-09-18 19:25:50.377528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.377594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,113]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,113]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,113]<stderr>:2020-09-18 19:25:50.377623: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,33]<stderr>:2020-09-18 19:25:50.376642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.376946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,68]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,68]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,68]<stderr>:2020-09-18 19:25:50.376981: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,48]<stderr>:2020-09-18 19:25:50.377604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,48]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,48]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,48]<stderr>:2020-09-18 19:25:50.377677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.377142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,1]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,1]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,1]<stderr>:2020-09-18 19:25:50.377198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.377746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.377933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.377700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,54]<stderr>:2020-09-18 19:25:50.378588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,54]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,54]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,54]<stderr>:2020-09-18 19:25:50.378657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.378572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,81]<stderr>:2020-09-18 19:25:50.378335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,81]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,81]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,81]<stderr>:2020-09-18 19:25:50.378395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.378078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.378255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,16]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,16]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,16]<stderr>:2020-09-18 19:25:50.378287: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,19]<stderr>:2020-09-18 19:25:50.378342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,19]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,19]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,19]<stderr>:2020-09-18 19:25:50.378376: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,16]<stderr>:2020-09-18 19:25:50.378344: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,16]<stderr>:2020-09-18 19:25:50.378357: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,16]<stderr>:2020-09-18 19:25:50.378369: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,16]<stderr>:2020-09-18 19:25:50.378381: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,16]<stderr>:2020-09-18 19:25:50.378393: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,16]<stderr>:2020-09-18 19:25:50.378405: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,19]<stderr>:2020-09-18 19:25:50.378439: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,19]<stderr>:2020-09-18 19:25:50.378454: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,16]<stderr>:2020-09-18 19:25:50.378466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.378468: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,19]<stderr>:2020-09-18 19:25:50.378481: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,19]<stderr>:2020-09-18 19:25:50.378493: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,19]<stderr>:2020-09-18 19:25:50.378506: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,19]<stderr>:2020-09-18 19:25:50.378576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.379509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,80]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,80]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,80]<stderr>:2020-09-18 19:25:50.379570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.379630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.379986: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.379665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,82]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,82]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,67]<stderr>:2020-09-18 19:25:50.380068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.379720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.381170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,119]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,119]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,119]<stderr>:2020-09-18 19:25:50.381244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.381169: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,32]<stderr>:2020-09-18 19:25:50.379991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,32]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,32]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,32]<stderr>:2020-09-18 19:25:50.380079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.380318: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,117]<stderr>:2020-09-18 19:25:50.381351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,117]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,117]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,117]<stderr>:2020-09-18 19:25:50.381436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.380715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.380669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.380355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.381025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,38]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,38]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,38]<stderr>:2020-09-18 19:25:50.381109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.381171: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.381508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.382622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,118]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,118]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,118]<stderr>:2020-09-18 19:25:50.382686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,70]<stderr>:2020-09-18 19:25:50.382148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,70]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,70]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,70]<stderr>:2020-09-18 19:25:50.382201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.381445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.382414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.382437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,36]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,36]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,36]<stderr>:2020-09-18 19:25:50.382498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.382946: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,112]<stderr>:2020-09-18 19:25:50.383916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,112]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,112]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,112]<stderr>:2020-09-18 19:25:50.383999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.383979: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,68]<stderr>:2020-09-18 19:25:50.383891: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,20]<stderr>:2020-09-18 19:25:50.382657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.382679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,22]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,22]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,22]<stderr>:2020-09-18 19:25:50.382707: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,22]<stderr>:2020-09-18 19:25:50.382766: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,22]<stderr>:2020-09-18 19:25:50.382779: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,87]<stderr>:2020-09-18 19:25:50.383557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,87]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,87]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,87]<stderr>:2020-09-18 19:25:50.383620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.382791: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,22]<stderr>:2020-09-18 19:25:50.382804: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,22]<stderr>:2020-09-18 19:25:50.382816: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,22]<stderr>:2020-09-18 19:25:50.382828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,113]<stderr>:2020-09-18 19:25:50.384964: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,22]<stderr>:2020-09-18 19:25:50.382889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.383964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,34]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,34]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,34]<stderr>:2020-09-18 19:25:50.384042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.383518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.384479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.384883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,50]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,50]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,50]<stderr>:2020-09-18 19:25:50.384944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.385358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.385498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,53]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,53]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,53]<stderr>:2020-09-18 19:25:50.385552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.386358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,114]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,114]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,114]<stderr>:2020-09-18 19:25:50.386433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.385552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,69]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,69]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,69]<stderr>:2020-09-18 19:25:50.385636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.385681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,52]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,52]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,52]<stderr>:2020-09-18 19:25:50.385745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.385667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.386951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,115]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,115]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,115]<stderr>:2020-09-18 19:25:50.387019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,83]<stderr>:2020-09-18 19:25:50.385784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.386086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,85]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,85]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,85]<stderr>:2020-09-18 19:25:50.386110: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,68]<stderr>:2020-09-18 19:25:50.386566: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,86]<stderr>:2020-09-18 19:25:50.386423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,86]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,86]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,86]<stderr>:2020-09-18 19:25:50.386493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.388051: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,102]<stderr>:2020-09-18 19:25:50.387302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,102]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,102]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,102]<stderr>:2020-09-18 19:25:50.387378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.387120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,5]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,5]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,99]<stderr>:2020-09-18 19:25:50.387703: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.387204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.389000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,116]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,116]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,116]<stderr>:2020-09-18 19:25:50.389062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.388207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,55]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,55]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,55]<stderr>:2020-09-18 19:25:50.388291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.387999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 3 with properties: 
[1,98]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,98]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,16]<stderr>:2020-09-18 19:25:50.386940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.388069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.388278: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,19]<stderr>:2020-09-18 19:25:50.387059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.387505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.388816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.389844: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,39]<stderr>:2020-09-18 19:25:50.389031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,39]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,39]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,39]<stderr>:2020-09-18 19:25:50.389060: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,85]<stderr>:2020-09-18 19:25:50.389038: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,33]<stderr>:2020-09-18 19:25:50.389707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.389894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.390734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,48]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,48]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,48]<stderr>:2020-09-18 19:25:50.390803: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.390760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.390939: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.390319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,1]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,1]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,1]<stderr>:2020-09-18 19:25:50.390373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.391355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.391437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,81]<stderr>:2020-09-18 19:25:50.390897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,81]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,81]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,81]<stderr>:2020-09-18 19:25:50.390971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.390771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.392532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,119]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,119]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,119]<stderr>:2020-09-18 19:25:50.392555: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,54]<stderr>:2020-09-18 19:25:50.391700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,54]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,54]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,54]<stderr>:2020-09-18 19:25:50.391767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.392717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,117]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,117]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,117]<stderr>:2020-09-18 19:25:50.392788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.391614: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,68]<stderr>:2020-09-18 19:25:50.391956: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,68]<stderr>:2020-09-18 19:25:50.392050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.392077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,70]<stderr>:2020-09-18 19:25:50.392084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,70]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,70]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,70]<stderr>:2020-09-18 19:25:50.392133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.391309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.390927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 4
[1,20]<stderr>:2020-09-18 19:25:50.390971: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,22]<stderr>:2020-09-18 19:25:50.391167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.392107: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,80]<stderr>:2020-09-18 19:25:50.392047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,80]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,80]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,80]<stderr>:2020-09-18 19:25:50.392135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.392159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.392197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,82]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,82]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,82]<stderr>:2020-09-18 19:25:50.392254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.392373: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,32]<stderr>:2020-09-18 19:25:50.392778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,32]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,32]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,113]<stderr>:2020-09-18 19:25:50.393992: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,32]<stderr>:2020-09-18 19:25:50.392847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.394080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.394125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,118]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,118]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,118]<stderr>:2020-09-18 19:25:50.394186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.393522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,38]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,38]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,38]<stderr>:2020-09-18 19:25:50.393585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.393690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.393856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.393750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.393488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.395443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,112]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,112]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,112]<stderr>:2020-09-18 19:25:50.395501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.395685: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,39]<stderr>:2020-09-18 19:25:50.394649: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,37]<stderr>:2020-09-18 19:25:50.394959: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.395005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,36]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,36]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,36]<stderr>:2020-09-18 19:25:50.395070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.394594: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.395060: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,87]<stderr>:2020-09-18 19:25:50.395263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,87]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,87]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,39]<stderr>:2020-09-18 19:25:50.395468: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,87]<stderr>:2020-09-18 19:25:50.395319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.395660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,34]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,34]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,34]<stderr>:2020-09-18 19:25:50.395724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.394732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
[1,16]<stderr>:2020-09-18 19:25:50.394774: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,19]<stderr>:2020-09-18 19:25:50.394818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 3
[1,19]<stderr>:2020-09-18 19:25:50.394870: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,114]<stderr>:2020-09-18 19:25:50.397917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,114]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,114]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,114]<stderr>:2020-09-18 19:25:50.397944: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,85]<stderr>:2020-09-18 19:25:50.396687: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,22]<stderr>:2020-09-18 19:25:50.396029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 6
[1,22]<stderr>:2020-09-18 19:25:50.396074: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,69]<stderr>:2020-09-18 19:25:50.397232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,69]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,69]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,69]<stderr>:2020-09-18 19:25:50.397260: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,64]<stderr>:2020-09-18 19:25:50.397351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.398488: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,115]<stderr>:2020-09-18 19:25:50.398540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,115]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,115]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,115]<stderr>:2020-09-18 19:25:50.398566: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,83]<stderr>:2020-09-18 19:25:50.397175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.396708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.397499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.398070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,50]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,50]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,50]<stderr>:2020-09-18 19:25:50.398104: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,86]<stderr>:2020-09-18 19:25:50.397654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,86]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,86]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,86]<stderr>:2020-09-18 19:25:50.397722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.399329: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,39]<stderr>:2020-09-18 19:25:50.398177: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,53]<stderr>:2020-09-18 19:25:50.398613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,53]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,53]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,53]<stderr>:2020-09-18 19:25:50.398649: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,49]<stderr>:2020-09-18 19:25:50.398579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.398787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,52]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,52]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,116]<stderr>:2020-09-18 19:25:50.399614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,116]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,116]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,116]<stderr>:2020-09-18 19:25:50.399674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.398849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.399804: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,114]<stderr>:2020-09-18 19:25:50.401317: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,69]<stderr>:2020-09-18 19:25:50.400603: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,102]<stderr>:2020-09-18 19:25:50.400462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,102]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,102]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,102]<stderr>:2020-09-18 19:25:50.400551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.401678: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,55]<stderr>:2020-09-18 19:25:50.401052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,55]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,55]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,55]<stderr>:2020-09-18 19:25:50.401123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.400764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.400586: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,85]<stderr>:2020-09-18 19:25:50.400679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.402255: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,5]<stderr>:2020-09-18 19:25:50.400358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,5]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,5]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,5]<stderr>:2020-09-18 19:25:50.400441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.401439: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.401028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.401150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 4 with properties: 
[1,98]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,98]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,7]<stderr>:2020-09-18 19:25:50.400644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.401229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.401511: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,53]<stderr>:2020-09-18 19:25:50.401743: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,65]<stderr>:2020-09-18 19:25:50.402193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.403347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,117]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,117]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,117]<stderr>:2020-09-18 19:25:50.403373: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,113]<stderr>:2020-09-18 19:25:50.403818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.403838: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,118]<stderr>:2020-09-18 19:25:50.403855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,118]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,118]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,81]<stderr>:2020-09-18 19:25:50.402415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,81]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,81]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,81]<stderr>:2020-09-18 19:25:50.402483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.403877: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,48]<stderr>:2020-09-18 19:25:50.403119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,48]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,48]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,48]<stderr>:2020-09-18 19:25:50.403151: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,69]<stderr>:2020-09-18 19:25:50.403125: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,115]<stderr>:2020-09-18 19:25:50.404181: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,54]<stderr>:2020-09-18 19:25:50.403397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,54]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,54]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,114]<stderr>:2020-09-18 19:25:50.404102: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,54]<stderr>:2020-09-18 19:25:50.403488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.404124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,112]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,112]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,112]<stderr>:2020-09-18 19:25:50.404183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.403649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.403741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.403416: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,39]<stderr>:2020-09-18 19:25:50.403505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.404908: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,69]<stderr>:2020-09-18 19:25:50.404048: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,115]<stderr>:2020-09-18 19:25:50.405011: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,80]<stderr>:2020-09-18 19:25:50.403768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,80]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,80]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,80]<stderr>:2020-09-18 19:25:50.403793: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,103]<stderr>:2020-09-18 19:25:50.403934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.404086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.403415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,1]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,1]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,1]<stderr>:2020-09-18 19:25:50.403469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.403899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.404403: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,82]<stderr>:2020-09-18 19:25:50.403923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,82]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,82]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,82]<stderr>:2020-09-18 19:25:50.403947: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,32]<stderr>:2020-09-18 19:25:50.404092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,32]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,32]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,32]<stderr>:2020-09-18 19:25:50.404117: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,50]<stderr>:2020-09-18 19:25:50.404518: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,68]<stderr>:2020-09-18 19:25:50.404403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,70]<stderr>:2020-09-18 19:25:50.404510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,70]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,70]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,70]<stderr>:2020-09-18 19:25:50.404534: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,66]<stderr>:2020-09-18 19:25:50.404485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.403792: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.404832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,38]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,38]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,38]<stderr>:2020-09-18 19:25:50.404853: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,116]<stderr>:2020-09-18 19:25:50.406049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,116]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,116]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,116]<stderr>:2020-09-18 19:25:50.406072: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,0]<stderr>:2020-09-18 19:25:50.404483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.405531: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,50]<stderr>:2020-09-18 19:25:50.405573: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,35]<stderr>:2020-09-18 19:25:50.405167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.406603: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,118]<stderr>:2020-09-18 19:25:50.407115: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,48]<stderr>:2020-09-18 19:25:50.406358: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,37]<stderr>:2020-09-18 19:25:50.406264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.406309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,36]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,36]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,36]<stderr>:2020-09-18 19:25:50.406338: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,119]<stderr>:2020-09-18 19:25:50.407792: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,119]<stderr>:2020-09-18 19:25:50.407888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.407912: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,114]<stderr>:2020-09-18 19:25:50.407949: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,34]<stderr>:2020-09-18 19:25:50.406757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,34]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,34]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,34]<stderr>:2020-09-18 19:25:50.406788: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,96]<stderr>:2020-09-18 19:25:50.406811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.406575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,87]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,87]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,87]<stderr>:2020-09-18 19:25:50.406601: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,100]<stderr>:2020-09-18 19:25:50.407030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.407242: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,6]<stderr>:2020-09-18 19:25:50.406547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.408526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,70]<stderr>:2020-09-18 19:25:50.407839: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,112]<stderr>:2020-09-18 19:25:50.408842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,112]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,112]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,112]<stderr>:2020-09-18 19:25:50.408867: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,32]<stderr>:2020-09-18 19:25:50.407772: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,82]<stderr>:2020-09-18 19:25:50.407586: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,80]<stderr>:2020-09-18 19:25:50.407606: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,64]<stderr>:2020-09-18 19:25:50.408169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.408317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,52]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,52]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,52]<stderr>:2020-09-18 19:25:50.408339: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,49]<stderr>:2020-09-18 19:25:50.408277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.409256: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,53]<stderr>:2020-09-18 19:25:50.408407: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,116]<stderr>:2020-09-18 19:25:50.409327: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,38]<stderr>:2020-09-18 19:25:50.408223: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,4]<stderr>:2020-09-18 19:25:50.407720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.409553: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,50]<stderr>:2020-09-18 19:25:50.408642: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,114]<stderr>:2020-09-18 19:25:50.409657: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,118]<stderr>:2020-09-18 19:25:50.409775: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,48]<stderr>:2020-09-18 19:25:50.409057: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,117]<stderr>:2020-09-18 19:25:50.410107: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,69]<stderr>:2020-09-18 19:25:50.409078: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,83]<stderr>:2020-09-18 19:25:50.408896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.410541: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,55]<stderr>:2020-09-18 19:25:50.409670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,55]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,55]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,55]<stderr>:2020-09-18 19:25:50.409700: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,48]<stderr>:2020-09-18 19:25:50.409813: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,36]<stderr>:2020-09-18 19:25:50.409424: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,86]<stderr>:2020-09-18 19:25:50.409280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,86]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,86]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,86]<stderr>:2020-09-18 19:25:50.409308: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,51]<stderr>:2020-09-18 19:25:50.409974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.410096: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,34]<stderr>:2020-09-18 19:25:50.409862: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,50]<stderr>:2020-09-18 19:25:50.410347: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,87]<stderr>:2020-09-18 19:25:50.409835: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,70]<stderr>:2020-09-18 19:25:50.410324: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,119]<stderr>:2020-09-18 19:25:50.411459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.410316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.409813: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.411746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,54]<stderr>:2020-09-18 19:25:50.410860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,54]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,54]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,32]<stderr>:2020-09-18 19:25:50.410499: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,54]<stderr>:2020-09-18 19:25:50.410887: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,116]<stderr>:2020-09-18 19:25:50.411801: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,112]<stderr>:2020-09-18 19:25:50.411879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,38]<stderr>:2020-09-18 19:25:50.410763: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,80]<stderr>:2020-09-18 19:25:50.410544: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,82]<stderr>:2020-09-18 19:25:50.410540: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,97]<stderr>:2020-09-18 19:25:50.410798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,70]<stderr>:2020-09-18 19:25:50.411208: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,85]<stderr>:2020-09-18 19:25:50.410745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.411306: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,52]<stderr>:2020-09-18 19:25:50.411673: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,116]<stderr>:2020-09-18 19:25:50.412628: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,39]<stderr>:2020-09-18 19:25:50.411369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,81]<stderr>:2020-09-18 19:25:50.411322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,81]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,81]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,81]<stderr>:2020-09-18 19:25:50.411352: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,82]<stderr>:2020-09-18 19:25:50.411400: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,38]<stderr>:2020-09-18 19:25:50.411575: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,80]<stderr>:2020-09-18 19:25:50.411468: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,36]<stderr>:2020-09-18 19:25:50.411819: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,117]<stderr>:2020-09-18 19:25:50.413000: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,65]<stderr>:2020-09-18 19:25:50.412218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.412063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.413353: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,84]<stderr>:2020-09-18 19:25:50.411925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.412635: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,34]<stderr>:2020-09-18 19:25:50.412200: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,118]<stderr>:2020-09-18 19:25:50.413425: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,115]<stderr>:2020-09-18 19:25:50.413444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.412276: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,114]<stderr>:2020-09-18 19:25:50.413730: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,114]<stderr>:2020-09-18 19:25:50.413824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.412583: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,69]<stderr>:2020-09-18 19:25:50.412905: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,49]<stderr>:2020-09-18 19:25:50.412973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.412937: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,69]<stderr>:2020-09-18 19:25:50.412993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.412495: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,37]<stderr>:2020-09-18 19:25:50.412801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.414208: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,34]<stderr>:2020-09-18 19:25:50.412979: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,51]<stderr>:2020-09-18 19:25:50.413509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.413461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.413621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.413768: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,117]<stderr>:2020-09-18 19:25:50.414597: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,53]<stderr>:2020-09-18 19:25:50.413860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.413349: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,54]<stderr>:2020-09-18 19:25:50.414048: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,102]<stderr>:2020-09-18 19:25:50.413804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,102]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,102]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,70]<stderr>:2020-09-18 19:25:50.413946: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,112]<stderr>:2020-09-18 19:25:50.414951: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,48]<stderr>:2020-09-18 19:25:50.414209: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,102]<stderr>:2020-09-18 19:25:50.413888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.415075: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,52]<stderr>:2020-09-18 19:25:50.414284: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,99]<stderr>:2020-09-18 19:25:50.414029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.414298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.414343: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,66]<stderr>:2020-09-18 19:25:50.414371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.415394: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,50]<stderr>:2020-09-18 19:25:50.414466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.413585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,5]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,5]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,5]<stderr>:2020-09-18 19:25:50.413621: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,119]<stderr>:2020-09-18 19:25:50.415351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.413709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.414294: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,38]<stderr>:2020-09-18 19:25:50.414496: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,98]<stderr>:2020-09-18 19:25:50.414484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 5 with properties: 
[1,98]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,98]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,98]<stderr>:2020-09-18 19:25:50.414564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.415779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,83]<stderr>:2020-09-18 19:25:50.414470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.415149: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,80]<stderr>:2020-09-18 19:25:50.414456: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,82]<stderr>:2020-09-18 19:25:50.414460: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,81]<stderr>:2020-09-18 19:25:50.414601: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,86]<stderr>:2020-09-18 19:25:50.414788: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,55]<stderr>:2020-09-18 19:25:50.415596: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,36]<stderr>:2020-09-18 19:25:50.415413: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,70]<stderr>:2020-09-18 19:25:50.415776: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,34]<stderr>:2020-09-18 19:25:50.415745: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,86]<stderr>:2020-09-18 19:25:50.415634: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,116]<stderr>:2020-09-18 19:25:50.416990: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,32]<stderr>:2020-09-18 19:25:50.415964: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,55]<stderr>:2020-09-18 19:25:50.416341: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,38]<stderr>:2020-09-18 19:25:50.416093: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,85]<stderr>:2020-09-18 19:25:50.415830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,54]<stderr>:2020-09-18 19:25:50.416557: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,80]<stderr>:2020-09-18 19:25:50.416187: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,82]<stderr>:2020-09-18 19:25:50.416188: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,87]<stderr>:2020-09-18 19:25:50.416237: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,112]<stderr>:2020-09-18 19:25:50.417751: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,33]<stderr>:2020-09-18 19:25:50.416590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.417039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.416260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,1]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,1]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,1]<stderr>:2020-09-18 19:25:50.416288: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,84]<stderr>:2020-09-18 19:25:50.416761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.416990: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,54]<stderr>:2020-09-18 19:25:50.417426: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,103]<stderr>:2020-09-18 19:25:50.417158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,3]<stderr>:2020-09-18 19:25:50.416666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.418415: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,117]<stderr>:2020-09-18 19:25:50.418518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.417310: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,101]<stderr>:2020-09-18 19:25:50.417325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,81]<stderr>:2020-09-18 19:25:50.417015: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,5]<stderr>:2020-09-18 19:25:50.416922: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,48]<stderr>:2020-09-18 19:25:50.417938: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,52]<stderr>:2020-09-18 19:25:50.418038: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,48]<stderr>:2020-09-18 19:25:50.418048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.417668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.417127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.419002: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,118]<stderr>:2020-09-18 19:25:50.419102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,81]<stderr>:2020-09-18 19:25:50.417790: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,87]<stderr>:2020-09-18 19:25:50.417913: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,112]<stderr>:2020-09-18 19:25:50.419373: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,35]<stderr>:2020-09-18 19:25:50.418364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.418447: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,64]<stderr>:2020-09-18 19:25:50.418927: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.419877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.420052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.419223: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,51]<stderr>:2020-09-18 19:25:50.419337: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.419062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,70]<stderr>:2020-09-18 19:25:50.419491: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,70]<stderr>:2020-09-18 19:25:50.419579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.419686: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,83]<stderr>:2020-09-18 19:25:50.419331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.418979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.419537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.419610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.420779: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,116]<stderr>:2020-09-18 19:25:50.420878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,54]<stderr>:2020-09-18 19:25:50.420046: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,4]<stderr>:2020-09-18 19:25:50.419319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.419894: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,32]<stderr>:2020-09-18 19:25:50.419899: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,38]<stderr>:2020-09-18 19:25:50.420012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.420011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.419502: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,5]<stderr>:2020-09-18 19:25:50.419622: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,82]<stderr>:2020-09-18 19:25:50.420116: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,82]<stderr>:2020-09-18 19:25:50.420206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.420103: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,80]<stderr>:2020-09-18 19:25:50.420196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.420205: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,53]<stderr>:2020-09-18 19:25:50.420739: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.420908: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,50]<stderr>:2020-09-18 19:25:50.420930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.420614: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,36]<stderr>:2020-09-18 19:25:50.420711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.420867: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,81]<stderr>:2020-09-18 19:25:50.420632: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,5]<stderr>:2020-09-18 19:25:50.420371: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,34]<stderr>:2020-09-18 19:25:50.420971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.420866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,54]<stderr>:2020-09-18 19:25:50.421331: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,2]<stderr>:2020-09-18 19:25:50.421128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.423030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.423050: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,87]<stderr>:2020-09-18 19:25:50.421745: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,112]<stderr>:2020-09-18 19:25:50.423145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.421835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,81]<stderr>:2020-09-18 19:25:50.422337: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,1]<stderr>:2020-09-18 19:25:50.421991: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,84]<stderr>:2020-09-18 19:25:50.422723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.422966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.423383: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,52]<stderr>:2020-09-18 19:25:50.423482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.424455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.423569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.422877: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,5]<stderr>:2020-09-18 19:25:50.423160: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,54]<stderr>:2020-09-18 19:25:50.424458: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,54]<stderr>:2020-09-18 19:25:50.424574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.423801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.424140: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,86]<stderr>:2020-09-18 19:25:50.424229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.424344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,102]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,102]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,102]<stderr>:2020-09-18 19:25:50.424417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.424741: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,99]<stderr>:2020-09-18 19:25:50.424469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.424731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.424839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.424486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.424876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 6 with properties: 
[1,98]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,98]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,71]<stderr>:2020-09-18 19:25:50.425129: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.425231: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.424947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.425302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.424716: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,39]<stderr>:2020-09-18 19:25:50.425789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.425990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.426054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.425546: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,48]<stderr>:2020-09-18 19:25:50.426845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,81]<stderr>:2020-09-18 19:25:50.426223: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,81]<stderr>:2020-09-18 19:25:50.426321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.426554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.426920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.427315: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,51]<stderr>:2020-09-18 19:25:50.428627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.430096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,83]<stderr>:2020-09-18 19:25:50.428775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.428652: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,118]<stderr>:2020-09-18 19:25:50.430353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.428751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.428803: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.429316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.429449: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.429392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.429139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.429607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.429686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.431004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.432495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.431701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.431229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.430918: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,114]<stderr>:2020-09-18 19:25:50.432656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.431010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.431844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,70]<stderr>:2020-09-18 19:25:50.431930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.431173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.431948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.432029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.433607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.432750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.432706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.433503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.433584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.434103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,102]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,102]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,102]<stderr>:2020-09-18 19:25:50.434134: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,99]<stderr>:2020-09-18 19:25:50.434184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,87]<stderr>:2020-09-18 19:25:50.434146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.434264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.436063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.435172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 7 with properties: 
[1,98]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,98]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,98]<stderr>:2020-09-18 19:25:50.435201: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,112]<stderr>:2020-09-18 19:25:50.436311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.435263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.436073: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.436560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.437519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.436659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.436913: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,103]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,101]<stderr>:2020-09-18 19:25:50.437158: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,101]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,54]<stderr>:2020-09-18 19:25:50.437503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.437716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.437467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.438032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.437820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.438159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.437898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.438238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.438374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.438246: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,68]<stderr>:2020-09-18 19:25:50.438925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.438728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.439064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.438745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.438215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.439072: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,81]<stderr>:2020-09-18 19:25:50.438923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.440037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.439319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.441556: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,51]<stderr>:2020-09-18 19:25:50.441821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.442031: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,83]<stderr>:2020-09-18 19:25:50.441836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.443202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.441498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.441638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.443498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.442423: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,4]<stderr>:2020-09-18 19:25:50.441897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.442462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.442663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.442747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.442827: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,80]<stderr>:2020-09-18 19:25:50.442691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.442770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.443583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.444171: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.444844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.445683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.443993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.444759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.444332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,70]<stderr>:2020-09-18 19:25:50.444866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.445871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.444242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.445049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.445218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.446630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.445916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.446322: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,98]<stderr>:2020-09-18 19:25:50.446500: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,36]<stderr>:2020-09-18 19:25:50.446667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.446828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.447082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.447648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.447734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.447347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.449347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.448080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.449527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.448462: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,98]<stderr>:2020-09-18 19:25:50.448503: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,97]<stderr>:2020-09-18 19:25:50.448530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,52]<stderr>:2020-09-18 19:25:50.449075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.449412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.450753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.449535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,54]<stderr>:2020-09-18 19:25:50.450538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.450572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.451018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.450718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.451181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.451136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.451137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,100]<stderr>:2020-09-18 19:25:50.451212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,49]<stderr>:2020-09-18 19:25:50.451552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.451861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.451930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.451155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.451977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,81]<stderr>:2020-09-18 19:25:50.451850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.452702: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,99]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,48]<stderr>:2020-09-18 19:25:50.453093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.452295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.453998: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,98]<stderr>:2020-09-18 19:25:50.454027: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,102]<stderr>:2020-09-18 19:25:50.454116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.454125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.454908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,83]<stderr>:2020-09-18 19:25:50.454698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.456341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.454575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.454655: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.456617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.455103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.455537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.455614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.455735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.457287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.457372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.457601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.458628: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.457157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,70]<stderr>:2020-09-18 19:25:50.457672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.457382: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.456948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.457926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.458874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.457349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.458170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.458318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.459736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.457386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,23]<stderr>:2020-09-18 19:25:50.457437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      7 
[1,23]<stderr>:2020-09-18 19:25:50.457444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 7:   N 
[1,23]<stderr>:2020-09-18 19:25:50.457661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.458968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.459575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.459844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.459979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.460461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.459620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.460544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.460498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,84]<stderr>:2020-09-18 19:25:50.460898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.462409: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.462654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.462201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.462076: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz
[1,99]<stderr>:2020-09-18 19:25:50.462231: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55651c10f830 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,99]<stderr>:2020-09-18 19:25:50.462250: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,65]<stderr>:2020-09-18 19:25:50.462426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.463807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.462412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,23]<stderr>:2020-09-18 19:25:50.462015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29600 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1d.0, compute capability: 7.0)
[1,69]<stderr>:2020-09-18 19:25:50.463562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,54]<stderr>:2020-09-18 19:25:50.463644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.463675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.463758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.464022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.464158: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.463784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.464388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.464763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.464580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.463983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.464845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.464934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,81]<stderr>:2020-09-18 19:25:50.464705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.464970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.465530: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz
[1,101]<stderr>:2020-09-18 19:25:50.465599: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz
[1,0]<stderr>:2020-09-18 19:25:50.464994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.465679: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5607dc1117a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,103]<stderr>:2020-09-18 19:25:50.465701: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,101]<stderr>:2020-09-18 19:25:50.465731: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5635e60ec4e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,101]<stderr>:2020-09-18 19:25:50.465749: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,48]<stderr>:2020-09-18 19:25:50.466197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.467099: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,97]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,83]<stderr>:2020-09-18 19:25:50.466846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.467367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.467450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.467000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.467237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.466740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,21]<stderr>:2020-09-18 19:25:50.466768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      5 
[1,21]<stderr>:2020-09-18 19:25:50.466774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 5:   N 
[1,21]<stderr>:2020-09-18 19:25:50.466981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.468249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.468189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.468225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.469420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.467751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.469612: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.468341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.468419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.468795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.469321: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,96]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,1]<stderr>:2020-09-18 19:25:50.468740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.469461: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,100]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,2]<stderr>:2020-09-18 19:25:50.468977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.469931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.470573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.471560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,70]<stderr>:2020-09-18 19:25:50.470685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.470464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.471793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.471127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.470904: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55651b88c170 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,99]<stderr>:2020-09-18 19:25:50.470927: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,99]<stderr>:2020-09-18 19:25:50.471094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.471234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.471395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.472723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.470415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.472089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.472696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.472971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.471964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,17]<stderr>:2020-09-18 19:25:50.471991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      1 
[1,17]<stderr>:2020-09-18 19:25:50.471998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N 
[1,87]<stderr>:2020-09-18 19:25:50.472841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.472800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.473755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.475331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.475505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.475369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.475249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,21]<stderr>:2020-09-18 19:25:50.474209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29660 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1b.0, compute capability: 7.0)
[1,86]<stderr>:2020-09-18 19:25:50.475213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.476679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.475243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.475903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.476223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.476184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,54]<stderr>:2020-09-18 19:25:50.476815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.476895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.476971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.476705: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5607db84b9e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,103]<stderr>:2020-09-18 19:25:50.476726: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,101]<stderr>:2020-09-18 19:25:50.476768: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5635e57c11d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,101]<stderr>:2020-09-18 19:25:50.476787: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,97]<stderr>:2020-09-18 19:25:50.476794: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz
[1,0]<stderr>:2020-09-18 19:25:50.476268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.476895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.476934: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55562c052d20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,97]<stderr>:2020-09-18 19:25:50.476952: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,101]<stderr>:2020-09-18 19:25:50.476951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.477502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.477314: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz
[1,33]<stderr>:2020-09-18 19:25:50.477200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.477479: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559d13799cf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,96]<stderr>:2020-09-18 19:25:50.477502: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,68]<stderr>:2020-09-18 19:25:50.477649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.477848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.477537: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz
[1,66]<stderr>:2020-09-18 19:25:50.477729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.477671: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559689e62440 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,100]<stderr>:2020-09-18 19:25:50.477690: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,81]<stderr>:2020-09-18 19:25:50.477586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.477350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.478474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.478287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.479321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.478525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.479283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.479004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.479600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,99]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,99]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,18]<stderr>:2020-09-18 19:25:50.478443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,18]<stderr>:2020-09-18 19:25:50.478482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      2 
[1,18]<stderr>:2020-09-18 19:25:50.478490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 2:   N 
[1,99]<stderr>:2020-09-18 19:25:50.479629: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,99]<stderr>:2020-09-18 19:25:50.479677: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,99]<stderr>:2020-09-18 19:25:50.479690: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,99]<stderr>:2020-09-18 19:25:50.479702: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,99]<stderr>:2020-09-18 19:25:50.479713: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,99]<stderr>:2020-09-18 19:25:50.479724: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,99]<stderr>:2020-09-18 19:25:50.479736: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,99]<stderr>:2020-09-18 19:25:50.479786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.478896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.479824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.479986: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,83]<stderr>:2020-09-18 19:25:50.479715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.480000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.480216: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,7]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,2]<stderr>:2020-09-18 19:25:50.480239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.481343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.482342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.482532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.481295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.481346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.482290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.482941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.484496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.483684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.484731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,70]<stderr>:2020-09-18 19:25:50.483857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,17]<stderr>:2020-09-18 19:25:50.482800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29645 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:17.0, compute capability: 7.0)
[1,53]<stderr>:2020-09-18 19:25:50.484210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.483957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.485697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.485192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.484729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.484829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.484568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.485936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.485792: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.486219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.486444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.486922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.486709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.487061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,103]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,103]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,103]<stderr>:2020-09-18 19:25:50.487101: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,101]<stderr>:2020-09-18 19:25:50.487138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,101]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,101]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,119]<stderr>:2020-09-18 19:25:50.488385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.486681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.487170: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,103]<stderr>:2020-09-18 19:25:50.487188: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,112]<stderr>:2020-09-18 19:25:50.488563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.487172: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,103]<stderr>:2020-09-18 19:25:50.487204: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,103]<stderr>:2020-09-18 19:25:50.487220: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,103]<stderr>:2020-09-18 19:25:50.487236: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,101]<stderr>:2020-09-18 19:25:50.487238: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,101]<stderr>:2020-09-18 19:25:50.487255: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,103]<stderr>:2020-09-18 19:25:50.487252: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,101]<stderr>:2020-09-18 19:25:50.487271: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,101]<stderr>:2020-09-18 19:25:50.487287: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,101]<stderr>:2020-09-18 19:25:50.487302: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,103]<stderr>:2020-09-18 19:25:50.487309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.487318: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,101]<stderr>:2020-09-18 19:25:50.487375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.488514: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.488407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.487747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.488161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.489724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.489413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,54]<stderr>:2020-09-18 19:25:50.490000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.490126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.490144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,5]<stderr>:2020-09-18 19:25:50.489676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.490695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.490335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.490767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.490939: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,81]<stderr>:2020-09-18 19:25:50.490335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.489994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.490941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.490478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,18]<stderr>:2020-09-18 19:25:50.490066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29633 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:18.0, compute capability: 7.0)
[1,39]<stderr>:2020-09-18 19:25:50.491607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.491472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.492485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.491685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,83]<stderr>:2020-09-18 19:25:50.492628: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.492896: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55562c0348a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,97]<stderr>:2020-09-18 19:25:50.492915: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,97]<stderr>:2020-09-18 19:25:50.493068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.493163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.493608: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559d13772980 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,96]<stderr>:2020-09-18 19:25:50.493630: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,100]<stderr>:2020-09-18 19:25:50.493737: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559689510c60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,100]<stderr>:2020-09-18 19:25:50.493759: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,96]<stderr>:2020-09-18 19:25:50.493801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.493931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.495399: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.494568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.494149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.494218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.495623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.495453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.495761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.496325: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,70]<stderr>:2020-09-18 19:25:50.496429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.497402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.497901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.497017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.497514: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.498949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.497791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.497961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.498348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.497670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.498649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.498613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.499230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.499473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.499450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.499714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.499491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.499899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.500054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,101]<stderr>:2020-09-18 19:25:50.499990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.499680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.501490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.501670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.499992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.500979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.500393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.501444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,86]<stderr>:2020-09-18 19:25:50.500957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.501586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.501924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.502892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.501873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.501216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,54]<stderr>:2020-09-18 19:25:50.502941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.503704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.503841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,81]<stderr>:2020-09-18 19:25:50.503233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.503496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.504726: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.505452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,83]<stderr>:2020-09-18 19:25:50.505523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.505973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,70]<stderr>:2020-09-18 19:25:50.506068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.506269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,97]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,97]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,97]<stderr>:2020-09-18 19:25:50.506308: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,99]<stderr>:2020-09-18 19:25:50.506342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 3
[1,97]<stderr>:2020-09-18 19:25:50.506366: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,97]<stderr>:2020-09-18 19:25:50.506383: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,99]<stderr>:2020-09-18 19:25:50.506393: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,97]<stderr>:2020-09-18 19:25:50.506399: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,97]<stderr>:2020-09-18 19:25:50.506415: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,97]<stderr>:2020-09-18 19:25:50.506430: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,96]<stderr>:2020-09-18 19:25:50.506433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,96]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,96]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,96]<stderr>:2020-09-18 19:25:50.506459: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,97]<stderr>:2020-09-18 19:25:50.506446: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,97]<stderr>:2020-09-18 19:25:50.506519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.506525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,100]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,100]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,96]<stderr>:2020-09-18 19:25:50.506522: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,96]<stderr>:2020-09-18 19:25:50.506538: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,96]<stderr>:2020-09-18 19:25:50.506551: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,100]<stderr>:2020-09-18 19:25:50.506562: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,96]<stderr>:2020-09-18 19:25:50.506563: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,96]<stderr>:2020-09-18 19:25:50.506576: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,96]<stderr>:2020-09-18 19:25:50.506589: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,100]<stderr>:2020-09-18 19:25:50.506629: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,96]<stderr>:2020-09-18 19:25:50.506644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.506646: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,100]<stderr>:2020-09-18 19:25:50.506662: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,100]<stderr>:2020-09-18 19:25:50.506678: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,100]<stderr>:2020-09-18 19:25:50.506693: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,100]<stderr>:2020-09-18 19:25:50.506709: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,100]<stderr>:2020-09-18 19:25:50.506764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.507350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.507016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.507087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.508576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.508901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.507285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.507434: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz
[1,7]<stderr>:2020-09-18 19:25:50.507591: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5572fb841d00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,7]<stderr>:2020-09-18 19:25:50.507612: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,35]<stderr>:2020-09-18 19:25:50.508663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.508616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.508260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.509229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.509515: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,67]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,115]<stderr>:2020-09-18 19:25:50.510581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.509847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.509923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.510124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.510985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.509318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.509629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.510307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.509983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.510038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.511914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.510912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.511085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.511224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.510958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.511569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.512238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.512467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.512546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 7
[1,103]<stderr>:2020-09-18 19:25:50.512602: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,36]<stderr>:2020-09-18 19:25:50.512524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.512717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.512715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 5
[1,84]<stderr>:2020-09-18 19:25:50.512401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.512770: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,2]<stderr>:2020-09-18 19:25:50.512154: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,2]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,52]<stderr>:2020-09-18 19:25:50.513148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,54]<stderr>:2020-09-18 19:25:50.513703: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.514558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.514733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.514021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,70]<stderr>:2020-09-18 19:25:50.514108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.514018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.515889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.515099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,81]<stderr>:2020-09-18 19:25:50.516133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.516724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.516656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.516969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.517049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.517278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.517129: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.517790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.517997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.517969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.518562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,83]<stderr>:2020-09-18 19:25:50.518466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.518165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.519496: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,71]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,0]<stderr>:2020-09-18 19:25:50.519158: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.520098: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,65]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,80]<stderr>:2020-09-18 19:25:50.519972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.521646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.520694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.520786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.522017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.520768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.520406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.521352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.520794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.521525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.521543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.521285: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz
[1,4]<stderr>:2020-09-18 19:25:50.521302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.522136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.522149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.521413: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a71185b340 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,2]<stderr>:2020-09-18 19:25:50.521432: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,70]<stderr>:2020-09-18 19:25:50.522238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.521483: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5572f9ddb7b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,7]<stderr>:2020-09-18 19:25:50.521505: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,7]<stderr>:2020-09-18 19:25:50.521675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.523635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.522148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.524066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.523255: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,49]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,116]<stderr>:2020-09-18 19:25:50.524305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.523262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.524291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,20]<stderr>:2020-09-18 19:25:50.522834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,20]<stderr>:2020-09-18 19:25:50.522876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      4 
[1,20]<stderr>:2020-09-18 19:25:50.522883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 4:   N 
[1,20]<stderr>:2020-09-18 19:25:50.523120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.524128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.524198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.523736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,54]<stderr>:2020-09-18 19:25:50.524966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.524776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.524951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 1
[1,97]<stderr>:2020-09-18 19:25:50.525007: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,96]<stderr>:2020-09-18 19:25:50.525028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
[1,96]<stderr>:2020-09-18 19:25:50.525067: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,100]<stderr>:2020-09-18 19:25:50.525113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 4
[1,100]<stderr>:2020-09-18 19:25:50.525154: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,69]<stderr>:2020-09-18 19:25:50.525475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.525504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.525751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.525897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.525980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.525509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,20]<stderr>:2020-09-18 19:25:50.524763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.526349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.527726: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.527934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.526950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.527471: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,102]<stderr>:2020-09-18 19:25:50.527411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.527597: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560c02a54a70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,71]<stderr>:2020-09-18 19:25:50.527614: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,20]<stderr>:2020-09-18 19:25:50.526382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29679 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1a.0, compute capability: 7.0)
[1,98]<stderr>:2020-09-18 19:25:50.527488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.527995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.529139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.528458: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,65]<stderr>:2020-09-18 19:25:50.528567: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5564658f0fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,65]<stderr>:2020-09-18 19:25:50.528579: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,81]<stderr>:2020-09-18 19:25:50.529092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.529816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.528419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,19]<stderr>:2020-09-18 19:25:50.528459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      3 
[1,19]<stderr>:2020-09-18 19:25:50.528466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 3:   N 
[1,19]<stderr>:2020-09-18 19:25:50.528765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.529999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.529642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.530066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,70]<stderr>:2020-09-18 19:25:50.530182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.529672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,16]<stderr>:2020-09-18 19:25:50.529341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,16]<stderr>:2020-09-18 19:25:50.529369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
[1,16]<stderr>:2020-09-18 19:25:50.529375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
[1,102]<stderr>:2020-09-18 19:25:50.530529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.530604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.530904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.529720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.530834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,83]<stderr>:2020-09-18 19:25:50.531067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,0]<stderr>:2020-09-18 19:25:50.530766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,22]<stderr>:2020-09-18 19:25:50.531113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,22]<stderr>:2020-09-18 19:25:50.531139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      6 
[1,22]<stderr>:2020-09-18 19:25:50.531145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 6:   N 
[1,53]<stderr>:2020-09-18 19:25:50.532544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.531641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.532724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.532819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.532429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.533530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.532825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.534686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.533333: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.533635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.533712: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.533232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.534031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.535041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.533516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,7]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,7]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,7]<stderr>:2020-09-18 19:25:50.533546: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,7]<stderr>:2020-09-18 19:25:50.533596: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,7]<stderr>:2020-09-18 19:25:50.533610: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,7]<stderr>:2020-09-18 19:25:50.533622: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,7]<stderr>:2020-09-18 19:25:50.533634: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,7]<stderr>:2020-09-18 19:25:50.533646: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,7]<stderr>:2020-09-18 19:25:50.533658: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,7]<stderr>:2020-09-18 19:25:50.533712: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.534490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.533222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.534530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,1]<stderr>:2020-09-18 19:25:50.533879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.534570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,115]<stderr>:2020-09-18 19:25:50.535975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.535615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,54]<stderr>:2020-09-18 19:25:50.536256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.537121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.535359: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a7111bbf60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,2]<stderr>:2020-09-18 19:25:50.535381: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,116]<stderr>:2020-09-18 19:25:50.537294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.535584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.536126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.535982: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.535372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.536756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.536831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.536854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.536930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.537671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.537271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.538150: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,67]<stderr>:2020-09-18 19:25:50.538314: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556fb6eceaf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,67]<stderr>:2020-09-18 19:25:50.538335: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,36]<stderr>:2020-09-18 19:25:50.538047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.538348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.537782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.539349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.539396: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560c02925950 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,71]<stderr>:2020-09-18 19:25:50.539419: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,71]<stderr>:2020-09-18 19:25:50.539600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,81]<stderr>:2020-09-18 19:25:50.539098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.540730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.540937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,70]<stderr>:2020-09-18 19:25:50.540018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.539892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.539966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,19]<stderr>:2020-09-18 19:25:50.539182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29652 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:19.0, compute capability: 7.0)
[1,65]<stderr>:2020-09-18 19:25:50.540692: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55646578d080 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,65]<stderr>:2020-09-18 19:25:50.540719: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,65]<stderr>:2020-09-18 19:25:50.540913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.540926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.541170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.542075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,16]<stderr>:2020-09-18 19:25:50.540289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29660 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:16.0, compute capability: 7.0)
[1,33]<stderr>:2020-09-18 19:25:50.541398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.541753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.542489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.541999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.542535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.542607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.543028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.543222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.543116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.543142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.542892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,68]<stderr>:2020-09-18 19:25:50.543660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.543805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,22]<stderr>:2020-09-18 19:25:50.542868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29600 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1c.0, compute capability: 7.0)
[1,7]<stderr>:2020-09-18 19:25:50.543467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.543720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.544856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.545081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,2]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,2]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,2]<stderr>:2020-09-18 19:25:50.545110: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,2]<stderr>:2020-09-18 19:25:50.545170: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,2]<stderr>:2020-09-18 19:25:50.545187: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,2]<stderr>:2020-09-18 19:25:50.545202: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,2]<stderr>:2020-09-18 19:25:50.545218: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,2]<stderr>:2020-09-18 19:25:50.545234: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,2]<stderr>:2020-09-18 19:25:50.545250: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,2]<stderr>:2020-09-18 19:25:50.545303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.545677: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,84]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,87]<stderr>:2020-09-18 19:25:50.545870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.546807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.546476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,117]<stderr>:2020-09-18 19:25:50.547745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.546572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,118]<stderr>:2020-09-18 19:25:50.548121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.548207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,54]<stderr>:2020-09-18 19:25:50.547460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.547065: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.547416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,0]<stderr>:2020-09-18 19:25:50,546 - INFO - Distributed training: True
[1,0]<stderr>:2020-09-18 19:25:50,547 - INFO - AWSDet Version: 0.0.1.1
[1,0]<stderr>:2020-09-18 19:25:50,547 - INFO - Config:
[1,0]<stderr>:/shared/deep-learning-models/models/vision/detection/configs/common/datasets/coco.py
[1,0]<stderr>:# dataset settings
[1,0]<stderr>:dataset_type = 'CocoDataset'
[1,0]<stderr>:data_root = '/shared/awsdet/data/coco/coco/'
[1,0]<stderr>:preproc_mode = 'rgb'
[1,0]<stderr>:image_mean = (123.68, 116.78, 103.94)
[1,0]<stderr>:image_std = (58.393, 57.12, 57.375)
[1,0]<stderr>:data = dict(
[1,0]<stderr>:    imgs_per_gpu=4,
[1,0]<stderr>:    train=dict(
[1,0]<stderr>:        type=dataset_type,
[1,0]<stderr>:        train=True,
[1,0]<stderr>:        dataset_dir=data_root,
[1,0]<stderr>:        subset='train',
[1,0]<stderr>:        flip_ratio=0.5,
[1,0]<stderr>:        pad_mode='fixed',
[1,0]<stderr>:        preproc_mode=preproc_mode,
[1,0]<stderr>:        mean=image_mean,
[1,0]<stderr>:        std=image_std,
[1,0]<stderr>:        scale=(800, 1333)),
[1,0]<stderr>:    val=dict(
[1,0]<stderr>:        type=dataset_type,
[1,0]<stderr>:        train=False,
[1,0]<stderr>:        dataset_dir=data_root,
[1,0]<stderr>:        subset='val',
[1,0]<stderr>:        flip_ratio=0,
[1,0]<stderr>:        pad_mode='fixed',
[1,0]<stderr>:        preproc_mode=preproc_mode,
[1,0]<stderr>:        mean=image_mean,
[1,0]<stderr>:        std=image_std,
[1,0]<stderr>:        scale=(800, 1333)),
[1,0]<stderr>:    test=dict(
[1,0]<stderr>:        type=dataset_type,
[1,0]<stderr>:        train=False,
[1,0]<stderr>:        dataset_dir=data_root,
[1,0]<stderr>:        subset='val',
[1,0]<stderr>:        flip_ratio=0,
[1,0]<stderr>:        pad_mode='fixed',
[1,0]<stderr>:        preproc_mode=preproc_mode,
[1,0]<stderr>:        mean=image_mean,
[1,0]<stderr>:        std=image_std,
[1,0]<stderr>:        scale=(800, 1333)),
[1,0]<stderr>:)
[1,0]<stderr>:
[1,0]<stderr>:
[1,0]<stderr>:/shared/deep-learning-models/models/vision/detection/configs/common/lr_policy.py
[1,0]<stderr>:# optimizer
[1,0]<stderr>:optimizer = dict(
[1,0]<stderr>:    type='MomentumOptimizer',
[1,0]<stderr>:    learning_rate=1e-2,
[1,0]<stderr>:    momentum=0.9,
[1,0]<stderr>:    nesterov=False,
[1,0]<stderr>:)
[1,0]<stderr>:
[1,0]<stderr>:# extra options related to optimizers
[1,0]<stderr>:optimizer_config = dict(
[1,0]<stderr>:    amp_enabled=True,
[1,0]<stderr>:)
[1,0]<stderr>:
[1,0]<stderr>:# learning policy
[1,0]<stderr>:lr_config = dict(
[1,0]<stderr>:    policy='step',
[1,0]<stderr>:    warmup='linear',
[1,0]<stderr>:    warmup_iters=500,
[1,0]<stderr>:    warmup_ratio=0.001,
[1,0]<stderr>:    step=[8, 11]
[1,0]<stderr>:)
[1,0]<stderr>:
[1,0]<stderr>:
[1,0]<stderr>:/shared/deep-learning-models/models/vision/detection/configs/common/runtime.py
[1,0]<stderr>:# model training and testing settings
[1,0]<stderr>:train_cfg = dict(
[1,0]<stderr>:    freeze_patterns=['^conv[12]_*', '_bn$'],
[1,0]<stderr>:    weight_decay=1e-4,
[1,0]<stderr>:)
[1,0]<stderr>:test_cfg = dict(
[1,0]<stderr>:)
[1,0]<stderr>:
[1,0]<stderr>:# run eval on validation with interval specified below
[1,0]<stderr>:evaluation = dict(interval=12)
[1,0]<stderr>:
[1,0]<stderr>:
[1,0]<stderr>:checkpoint_config = dict(interval=1, outdir='checkpoints')
[1,0]<stderr>:
[1,0]<stderr>:# logging and viz options
[1,0]<stderr>:log_config = dict(
[1,0]<stderr>:    interval=50,
[1,0]<stderr>:    hooks=[
[1,0]<stderr>:        dict(type='TextLoggerHook'),
[1,0]<stderr>:        dict(type='TensorboardLoggerHook', log_dir='/tmp/tensorboard')
[1,0]<stderr>:    ])
[1,0]<stderr>:
[1,0]<stderr>:# runtime settings
[1,0]<stderr>:total_epochs = 12
[1,0]<stderr>:log_level = 'INFO'
[1,0]<stderr>:load_from = None
[1,0]<stderr>:resume_from = None
[1,0]<stderr>:workflow = [('train', 1)]
[1,0]<stderr>:
[1,0]<stderr>:
[1,0]<stderr>:/shared/deep-learning-models/models/vision/detection/configs/mask_rcnn/EC2/CI/8/mask_rcnn_r50v1_d_fpn_1x_coco.py
[1,0]<stderr>:# -*- coding: utf-8 -*-
[1,0]<stderr>:base_files = ['../../../../common/datasets/coco.py',
[1,0]<stderr>:              '../../../../common/lr_policy.py',
[1,0]<stderr>:              '../../../../common/runtime.py',]
[1,0]<stderr>:# model settings
[1,0]<stderr>:model = dict(
[1,0]<stderr>:    type='FasterRCNN',
[1,0]<stderr>:    backbone=dict(
[1,0]<stderr>:        type='KerasBackbone',
[1,0]<stderr>:        model_name='ResNet50V1_d',
[1,0]<stderr>:        weights_path='/shared/awsdet/data/weights/resnet50v1_d',
[1,0]<stderr>:        weight_decay=1e-4
[1,0]<stderr>:    ),
[1,0]<stderr>:    neck=dict(
[1,0]<stderr>:        type='FPN',
[1,0]<stderr>:        in_channels=[('C2', 256), ('C3', 512), ('C4', 1024), ('C5', 2048)],
[1,0]<stderr>:        out_channels=256,
[1,0]<stderr>:        num_outs=5,
[1,0]<stderr>:        interpolation_method='bilinear',
[1,0]<stderr>:        weight_decay=1e-4,
[1,0]<stderr>:    ),
[1,0]<stderr>:    rpn_head=dict(
[1,0]<stderr>:        type='RPNHead',
[1,0]<stderr>:        anchor_scales=[8.],
[1,0]<stderr>:        anchor_ratios=[0.5, 1.0, 2.0],
[1,0]<stderr>:        anchor_strides=[4, 8, 16, 32, 64],
[1,0]<stderr>:        target_means=[.0, .0, .0, .0],
[1,0]<stderr>:        target_stds= [1.0, 1.0, 1.0, 1.0],
[1,0]<stderr>:        feat_channels=512,
[1,0]<stderr>:        num_samples=256,
[1,0]<stderr>:        positive_fraction=0.5,
[1,0]<stderr>:        pos_iou_thr=0.7,
[1,0]<stderr>:        neg_iou_thr=0.3,
[1,0]<stderr>:        num_pre_nms_train=6000,
[1,0]<stderr>:        num_post_nms_train=2000,
[1,0]<stderr>:        num_pre_nms_test=2000,
[1,0]<stderr>:        num_post_nms_test=1000,
[1,0]<stderr>:        weight_decay=1e-4,
[1,0]<stderr>:    ),
[1,0]<stderr>:    bbox_roi_extractor=dict(
[1,0]<stderr>:        type='PyramidROIAlign',
[1,0]<stderr>:        pool_shape=[7, 7],
[1,0]<stderr>:        pool_type='avg',
[1,0]<stderr>:    ),
[1,0]<stderr>:    bbox_head=dict(
[1,0]<stderr>:        type='BBoxHead',
[1,0]<stderr>:        num_classes=81,
[1,0]<stderr>:        pool_size=[7, 7],
[1,0]<stderr>:        target_means=[0., 0., 0., 0.],
[1,0]<stderr>:        target_stds=[0.1, 0.1, 0.2, 0.2],
[1,0]<stderr>:        min_confidence=0.005, 
[1,0]<stderr>:        nms_threshold=0.75,
[1,0]<stderr>:        max_instances=100,
[1,0]<stderr>:        weight_decay=1e-4,
[1,0]<stderr>:        use_conv=False,
[1,0]<stderr>:        use_bn=False,
[1,0]<stderr>:        soft_nms_sigma=0.5
[1,0]<stderr>:    ),
[1,0]<stderr>:    mask_head=dict(
[1,0]<stderr>:   [1,0]<stderr>:     type='MaskHead',
[1,0]<stderr>:        num_classes=81,
[1,0]<stderr>:        weight_decay=1e-5,
[1,0]<stderr>:        use_bn=False,
[1,0]<stderr>:    ),
[1,0]<stderr>:    mask_roi_extractor=dict(
[1,0]<stderr>:        type='PyramidROIAlign',
[1,0]<stderr>:        pool_shape=[14, 14],
[1,0]<stderr>:        pool_type='avg',
[1,0]<stderr>:    ),
[1,0]<stderr>:)
[1,0]<stderr>:
[1,0]<stderr>:# dataset settings
[1,0]<stderr>:dataset_type = 'CocoDataset'
[1,0]<stderr>:data_root = '/shared/awsdet/data/coco/coco/'
[1,0]<stderr>:preproc_mode = 'rgb'
[1,0]<stderr>:image_mean = (123.68, 116.78, 103.94)
[1,0]<stderr>:image_std = (58.393, 57.12, 57.375)
[1,0]<stderr>:
[1,0]<stderr>:data = dict(
[1,0]<stderr>:    _overwrite_=True,
[1,0]<stderr>:    imgs_per_gpu=4,
[1,0]<stderr>:    train=dict(
[1,0]<stderr>:        type=dataset_type,
[1,0]<stderr>:        train=True,
[1,0]<stderr>:        dataset_dir=data_root,
[1,0]<stderr>:        subset='train',
[1,0]<stderr>:        flip_ratio=0.5,
[1,0]<stderr>:        pad_mode='fixed',
[1,0]<stderr>:        preproc_mode=preproc_mode,
[1,0]<stderr>:        mean=image_mean,
[1,0]<stderr>:        std=image_std,
[1,0]<stderr>:        scale=(800, 1333),
[1,0]<stderr>:        mask=True),
[1,0]<stderr>:    val=dict(
[1,0]<stderr>:        type=dataset_type,
[1,0]<stderr>:        train=False,
[1,0]<stderr>:        dataset_dir=data_root,
[1,0]<stderr>:        subset='val',
[1,0]<stderr>:        flip_ratio=0,
[1,0]<stderr>:        pad_mode='fixed',
[1,0]<stderr>:        preproc_mode=preproc_mode,
[1,0]<stderr>:        mean=image_mean,
[1,0]<stderr>:        std=image_std,
[1,0]<stderr>:        scale=(800, 1333),
[1,0]<stderr>:        mask=True),
[1,0]<stderr>:    test=dict(
[1,0]<stderr>:        type=dataset_type,
[1,0]<stderr>:        train=False,
[1,0]<stderr>:        dataset_dir=data_root,
[1,0]<stderr>:        subset='val',
[1,0]<stderr>:        flip_ratio=0,
[1,0]<stderr>:        pad_mode='fixed',
[1,0]<stderr>:        preproc_mode=preproc_mode,
[1,0]<stderr>:        mean=image_mean,
[1,0]<stderr>:        std=image_std,
[1,0]<stderr>:        scale=(800, 1333),
[1,0]<stderr>:        mask=True),
[1,0]<stderr>:)
[1,0]<stderr>:
[1,0]<stderr>:
[1,0]<stderr>:# optimizer
[1,0]<stderr>:optimizer = dict(
[1,0]<stderr>:    _overwrite_=True,
[1,0]<stderr>:    type='MomentumOptimizer',
[1,0]<stderr>:    learning_rate=5e-3,
[1,0]<stderr>:    momentum=0.9,
[1,0]<stderr>:    nesterov=False,
[1,0]<stderr>:)
[1,0]<stderr>:
[1,0]<stderr>:# extra options related to optimizers
[1,0]<stderr>:optimizer_config = dict(
[1,0]<stderr>:    _overwrite_=True,
[1,0]<stderr>:    amp_enabled=True,
[1,0]<stderr>:    gradient_clip=5.0,
[1,0]<stderr>:)
[1,0]<stderr>:
[1,0]<stderr>:# overwrite lr policy
[1,0]<stderr>:# learning policy
[1,0]<stderr>:lr_config = dict(
[1,0]<stderr>:    _overwrite_=True,
[1,0]<stderr>:    policy='step',
[1,0]<stderr>:    warmup='linear',
[1,0]<stderr>:    warmup_iters=1500,
[1,0]<stderr>:    warmup_ratio=0.001,
[1,0]<stderr>:    step=[8, 11]
[1,0]<stderr>:)
[1,0]<stderr>:
[1,0]<stderr>:
[1,0]<stderr>:
[1,0]<stderr>:work_dir = './work_dirs/mask_rcnn_r50v1_d_fpn_1x_coco'
[1,0]<stderr>:
[1,0]<stderr>:2020-09-18 19:25:50,547 - INFO - Tensorflow version: 2.3.0
[1,0]<stderr>:2020-09-18 19:25:50,547 - INFO - Set random seed to 17, deterministic: True
[1,38]<stderr>:2020-09-18 19:25:50.548049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.548130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.548791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,71]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,71]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,71]<stderr>:2020-09-18 19:25:50.548823: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,55]<stderr>:2020-09-18 19:25:50.548870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.548873: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,71]<stderr>:2020-09-18 19:25:50.548887: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,71]<stderr>:2020-09-18 19:25:50.548899: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,71]<stderr>:2020-09-18 19:25:50.548912: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,71]<stderr>:2020-09-18 19:25:50.548924: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,71]<stderr>:2020-09-18 19:25:50.548937: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,71]<stderr>:2020-09-18 19:25:50.548992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.550350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.549235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,81]<stderr>:2020-09-18 19:25:50.548967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.548606: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,3]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,116]<stderr>:2020-09-18 19:25:50.550493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.549393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.549701: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,64]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,70]<stderr>:2020-09-18 19:25:50.549761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.550003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,65]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,65]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,65]<stderr>:2020-09-18 19:25:50.550040: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,65]<stderr>:2020-09-18 19:25:50.550100: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,65]<stderr>:2020-09-18 19:25:50.550118: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,65]<stderr>:2020-09-18 19:25:50.550134: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,65]<stderr>:2020-09-18 19:25:50.550150: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,65]<stderr>:2020-09-18 19:25:50.550167: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,65]<stderr>:2020-09-18 19:25:50.550183: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,65]<stderr>:2020-09-18 19:25:50.550241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.550391: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556fb66a6680 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,67]<stderr>:2020-09-18 19:25:50.550412: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,67]<stderr>:2020-09-18 19:25:50.550581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.550560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.550813: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,49]<stderr>:2020-09-18 19:25:50.550972: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5616615b8d00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,49]<stderr>:2020-09-18 19:25:50.550992: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,83]<stderr>:2020-09-18 19:25:50.550354: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,83]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,5]<stderr>:2020-09-18 19:25:50.550094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.550207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,7]<stderr>:2020-09-18 19:25:50.551313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 7
[1,7]<stderr>:2020-09-18 19:25:50.551354: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,51]<stderr>:2020-09-18 19:25:50.552354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,1]<stderr>:2020-09-18 19:25:50.551634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.552183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,39]<stderr>:2020-09-18 19:25:50.552500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.552258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.552331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.553867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.552999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.554022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.553225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.552856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.553444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.552653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.553908: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,66]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,113]<stderr>:2020-09-18 19:25:50.555189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.553577: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,0]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,35]<stderr>:2020-09-18 19:25:50.554493: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,35]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,53]<stderr>:2020-09-18 19:25:50.555113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.556156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.555736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.555321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.556538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.556988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.557278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.557360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.557760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.558105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.557832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.557280: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz
[1,3]<stderr>:2020-09-18 19:25:50.557407: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bda7a87670 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,3]<stderr>:2020-09-18 19:25:50.557426: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,2]<stderr>:2020-09-18 19:25:50.557568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 2
[1,2]<stderr>:2020-09-18 19:25:50.557614: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,64]<stderr>:2020-09-18 19:25:50.558535: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,71]<stderr>:2020-09-18 19:25:50.558592: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.558659: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d58c5fcd10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,64]<stderr>:2020-09-18 19:25:50.558678: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,54]<stderr>:2020-09-18 19:25:50.558770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,83]<stderr>:2020-09-18 19:25:50.558424: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,83]<stderr>:2020-09-18 19:25:50.558544: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562d0dc687d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,83]<stderr>:2020-09-18 19:25:50.558561: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,81]<stderr>:2020-09-18 19:25:50.558843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,70]<stderr>:2020-09-18 19:25:50.559529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.559780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.559813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,67]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,67]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,67]<stderr>:2020-09-18 19:25:50.559838: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,67]<stderr>:2020-09-18 19:25:50.559893: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,67]<stderr>:2020-09-18 19:25:50.559905: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,67]<stderr>:2020-09-18 19:25:50.559917: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,67]<stderr>:2020-09-18 19:25:50.559928: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,117]<stderr>:2020-09-18 19:25:50.560893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.559939: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,67]<stderr>:2020-09-18 19:25:50.559951: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,67]<stderr>:2020-09-18 19:25:50.560003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.560197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.561186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.561269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.559742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.559918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.560507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.561157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,83]<stderr>:2020-09-18 19:25:50.560797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.560635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.561910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.562043: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,66]<stderr>:2020-09-18 19:25:50.562209: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5641a3387780 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,66]<stderr>:2020-09-18 19:25:50.562226: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,114]<stderr>:2020-09-18 19:25:50.563275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.563425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.561608: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz
[1,0]<stderr>:2020-09-18 19:25:50.561718: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c1f4064420 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,0]<stderr>:2020-09-18 19:25:50.561736: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,80]<stderr>:2020-09-18 19:25:50.562245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.561936: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,4]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,82]<stderr>:2020-09-18 19:25:50.562343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.563075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.562921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.563689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,66]<stderr>:2020-09-18 19:25:50.564582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.564050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.565063: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5616614aa360 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,49]<stderr>:2020-09-18 19:25:50.565083: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,49]<stderr>:2020-09-18 19:25:50.565252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.565330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.564830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.565406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.564989: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bda797ad90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,3]<stderr>:2020-09-18 19:25:50.565011: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,119]<stderr>:2020-09-18 19:25:50.566759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.565180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.566930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.565821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.565897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.565853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.566588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.565781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.566376: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,37]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,113]<stderr>:2020-09-18 19:25:50.568074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,102]<stderr>:2020-09-18 19:25:50.567274: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,102]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,50]<stderr>:2020-09-18 19:25:50.567652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.567668: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,98]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,86]<stderr>:2020-09-18 19:25:50.567816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.568623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.569616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.569872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 7
[1,71]<stderr>:2020-09-18 19:25:50.569914: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,54]<stderr>:2020-09-18 19:25:50.570354: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,81]<stderr>:2020-09-18 19:25:50.569818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.569579: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,6]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,70]<stderr>:2020-09-18 19:25:50.570937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.571098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.571137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 1
[1,65]<stderr>:2020-09-18 19:25:50.571183: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,67]<stderr>:2020-09-18 19:25:50.571293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.570717: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c1f37e11b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,0]<stderr>:2020-09-18 19:25:50.570735: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,33]<stderr>:2020-09-18 19:25:50.571340: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,33]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,0]<stderr>:2020-09-18 19:25:50.570917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.572007: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,51]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,5]<stderr>:2020-09-18 19:25:50.571035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.571517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,3]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,3]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,4]<stderr>:2020-09-18 19:25:50.571526: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz
[1,3]<stderr>:2020-09-18 19:25:50.571544: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,3]<stderr>:2020-09-18 19:25:50.571596: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,3]<stderr>:2020-09-18 19:25:50.571610: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,117]<stderr>:2020-09-18 19:25:50.573443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.571622: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,3]<stderr>:2020-09-18 19:25:50.571635: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,3]<stderr>:2020-09-18 19:25:50.571647: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,3]<stderr>:2020-09-18 19:25:50.571660: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,4]<stderr>:2020-09-18 19:25:50.571660: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5575ad7d3220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,4]<stderr>:2020-09-18 19:25:50.571678: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,3]<stderr>:2020-09-18 19:25:50.571714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.573700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.573794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.572772: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d58bda9330 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,64]<stderr>:2020-09-18 19:25:50.572793: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,83]<stderr>:2020-09-18 19:25:50.572430: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562d0e5b0e50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,83]<stderr>:2020-09-18 19:25:50.572451: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,1]<stderr>:2020-09-18 19:25:50.572149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.572962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,83]<stderr>:2020-09-18 19:25:50.572610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.573405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.573346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.573423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.573757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.573534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.573615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.573839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.573915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.574174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,4]<stderr>:2020-09-18 19:25:50.573976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.575835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.575991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.575318: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,84]<stderr>:2020-09-18 19:25:50.575464: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5603303713b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,84]<stderr>:2020-09-18 19:25:50.575487: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,49]<stderr>:2020-09-18 19:25:50.576691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,49]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,49]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,49]<stderr>:2020-09-18 19:25:50.576722: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,49]<stderr>:2020-09-18 19:25:50.576780: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,49]<stderr>:2020-09-18 19:25:50.576797: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,49]<stderr>:2020-09-18 19:25:50.576813: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,49]<stderr>:2020-09-18 19:25:50.576828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,49]<stderr>:2020-09-18 19:25:50.576843: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,49]<stderr>:2020-09-18 19:25:50.576859: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,49]<stderr>:2020-09-18 19:25:50.576910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.576611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,102]<stderr>:2020-09-18 19:25:50.576762: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz
[1,98]<stderr>:2020-09-18 19:25:50.576762: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz
[1,102]<stderr>:2020-09-18 19:25:50.576899: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555ded8855f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,102]<stderr>:2020-09-18 19:25:50.576916: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,98]<stderr>:2020-09-18 19:25:50.576902: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5594fd7a1350 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,98]<stderr>:2020-09-18 19:25:50.576920: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,37]<stderr>:2020-09-18 19:25:50.577115: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,119]<stderr>:2020-09-18 19:25:50.578306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.577254: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a6d429cf20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,37]<stderr>:2020-09-18 19:25:50.577274: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,87]<stderr>:2020-09-18 19:25:50.576989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.578421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.577835: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5641a2a2e540 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,66]<stderr>:2020-09-18 19:25:50.577859: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,53]<stderr>:2020-09-18 19:25:50.578096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.578137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.577748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.577521: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz
[1,6]<stderr>:2020-09-18 19:25:50.577635: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5631cc7fc900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,6]<stderr>:2020-09-18 19:25:50.577654: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,0]<stderr>:2020-09-18 19:25:50.577772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,0]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,0]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,0]<stderr>:2020-09-18 19:25:50.577809: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,5]<stderr>:2020-09-18 19:25:50.577862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,0]<stderr>:2020-09-18 19:25:50.577882: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,0]<stderr>:2020-09-18 19:25:50.577901: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,0]<stderr>:2020-09-18 19:25:50.577918: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,0]<stderr>:2020-09-18 19:25:50.577934: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,0]<stderr>:2020-09-18 19:25:50.577950: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,0]<stderr>:2020-09-18 19:25:50.577979: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,70]<stderr>:2020-09-18 19:25:50.578809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.578033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.579168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.579196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 3
[1,67]<stderr>:2020-09-18 19:25:50.579244: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,86]<stderr>:2020-09-18 19:25:50.578888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.579363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.579467: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,33]<stderr>:2020-09-18 19:25:50.579580: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555c24898880 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,33]<stderr>:2020-09-18 19:25:50.579616: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,37]<stderr>:2020-09-18 19:25:50.579649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.579111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.580183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,64]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,64]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,64]<stderr>:2020-09-18 19:25:50.580215: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,64]<stderr>:2020-09-18 19:25:50.580279: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,64]<stderr>:2020-09-18 19:25:50.580295: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,64]<stderr>:2020-09-18 19:25:50.580311: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,64]<stderr>:2020-09-18 19:25:50.580326: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,64]<stderr>:2020-09-18 19:25:50.580342: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,64]<stderr>:2020-09-18 19:25:50.580357: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,1]<stderr>:2020-09-18 19:25:50.579540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,64]<stderr>:2020-09-18 19:25:50.580408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.580739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,6]<stderr>:2020-09-18 19:25:50.579948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.581105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.581174: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,81]<stderr>:2020-09-18 19:25:50.581001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.581296: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555ded15f2e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,102]<stderr>:2020-09-18 19:25:50.581313: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,38]<stderr>:2020-09-18 19:25:50.581303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.581331: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598223138d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,35]<stderr>:2020-09-18 19:25:50.581351: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,32]<stderr>:2020-09-18 19:25:50.581488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.581534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,54]<stderr>:2020-09-18 19:25:50.582027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.581087: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5575ad6dffd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,4]<stderr>:2020-09-18 19:25:50.581106: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,98]<stderr>:2020-09-18 19:25:50.581773: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.581285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.581943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.582002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.582077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.582713: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,55]<stderr>:2020-09-18 19:25:50.582841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.582835: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5563e7bad380 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,51]<stderr>:2020-09-18 19:25:50.582854: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,68]<stderr>:2020-09-18 19:25:50.583094: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,68]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,83]<stderr>:2020-09-18 19:25:50.582731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,83]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,83]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,83]<stderr>:2020-09-18 19:25:50.582757: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,83]<stderr>:2020-09-18 19:25:50.582801: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,83]<stderr>:2020-09-18 19:25:50.582818: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,83]<stderr>:2020-09-18 19:25:50.582830: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,83]<stderr>:2020-09-18 19:25:50.582842: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,83]<stderr>:2020-09-18 19:25:50.582853: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,83]<stderr>:2020-09-18 19:25:50.582865: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,83]<stderr>:2020-09-18 19:25:50.582915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.584695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.584868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.584115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,66]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,66]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,66]<stderr>:2020-09-18 19:25:50.584140: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,115]<stderr>:2020-09-18 19:25:50.585043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.584191: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,66]<stderr>:2020-09-18 19:25:50.584206: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,66]<stderr>:2020-09-18 19:25:50.584218: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,35]<stderr>:2020-09-18 19:25:50.583875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.584230: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,66]<stderr>:2020-09-18 19:25:50.584241: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,66]<stderr>:2020-09-18 19:25:50.584254: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,70]<stderr>:2020-09-18 19:25:50.584274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,66]<stderr>:2020-09-18 19:25:50.584305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.584100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.584187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.585001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.585110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.585156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.584533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.584906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 3
[1,3]<stderr>:2020-09-18 19:25:50.584957: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,114]<stderr>:2020-09-18 19:25:50.587053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.587286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.586808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,102]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,102]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,102]<stderr>:2020-09-18 19:25:50.586839: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,102]<stderr>:2020-09-18 19:25:50.586908: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,102]<stderr>:2020-09-18 19:25:50.586922: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,102]<stderr>:2020-09-18 19:25:50.586935: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,113]<stderr>:2020-09-18 19:25:50.588080: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,113]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,102]<stderr>:2020-09-18 19:25:50.586948: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,102]<stderr>:2020-09-18 19:25:50.586961: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,102]<stderr>:2020-09-18 19:25:50.586974: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,102]<stderr>:2020-09-18 19:25:50.587042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.587403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.586553: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5631cc848460 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,6]<stderr>:2020-09-18 19:25:50.586575: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,4]<stderr>:2020-09-18 19:25:50.586630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,4]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,4]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,4]<stderr>:2020-09-18 19:25:50.586655: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,4]<stderr>:2020-09-18 19:25:50.586712: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,4]<stderr>:2020-09-18 19:25:50.586728: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,4]<stderr>:2020-09-18 19:25:50.586740: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,98]<stderr>:2020-09-18 19:25:50.587357: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5594fd68dfa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,98]<stderr>:2020-09-18 19:25:50.587378: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,6]<stderr>:2020-09-18 19:25:50.586751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.586752: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,4]<stderr>:2020-09-18 19:25:50.586764: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,4]<stderr>:2020-09-18 19:25:50.586776: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,4]<stderr>:2020-09-18 19:25:50.586834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.587606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.588045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
[1,64]<stderr>:2020-09-18 19:25:50.588086: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,119]<stderr>:2020-09-18 19:25:50.589513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,49]<stderr>:2020-09-18 19:25:50.588821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.589726: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.588414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,66]<stderr>:2020-09-18 19:25:50.589238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 2
[1,66]<stderr>:2020-09-18 19:25:50.589274: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,0]<stderr>:2020-09-18 19:25:50.588775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
[1,0]<stderr>:2020-09-18 19:25:50.588828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,84]<stderr>:2020-09-18 19:25:50.589539: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5603302421d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,84]<stderr>:2020-09-18 19:25:50.589560: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,84]<stderr>:2020-09-18 19:25:50.589709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.590346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.590350: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a6d3a3fbb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,37]<stderr>:2020-09-18 19:25:50.590369: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,37]<stderr>:2020-09-18 19:25:50.590531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.590492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.591274: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,68]<stderr>:2020-09-18 19:25:50.591393: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555889efc910 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,68]<stderr>:2020-09-18 19:25:50.591412: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,102]<stderr>:2020-09-18 19:25:50.591126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.591426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.591377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,6]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,6]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,6]<stderr>:2020-09-18 19:25:50.591409: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,6]<stderr>:2020-09-18 19:25:50.591482: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,4]<stderr>:2020-09-18 19:25:50.591502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.592116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,98]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,98]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,6]<stderr>:2020-09-18 19:25:50.591501: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,6]<stderr>:2020-09-18 19:25:50.591518: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,6]<stderr>:2020-09-18 19:25:50.591534: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,98]<stderr>:2020-09-18 19:25:50.592149: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,6]<stderr>:2020-09-18 19:25:50.591550: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,6]<stderr>:2020-09-18 19:25:50.591566: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,98]<stderr>:2020-09-18 19:25:50.592229: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,6]<stderr>:2020-09-18 19:25:50.591628: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.592247: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,98]<stderr>:2020-09-18 19:25:50.592262: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,98]<stderr>:2020-09-18 19:25:50.592277: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,98]<stderr>:2020-09-18 19:25:50.592293: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,98]<stderr>:2020-09-18 19:25:50.592309: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,98]<stderr>:2020-09-18 19:25:50.592374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,81]<stderr>:2020-09-18 19:25:50.592617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.593051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.593243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.593265: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,85]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,68]<stderr>:2020-09-18 19:25:50.593730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.594007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.594091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 6
[1,36]<stderr>:2020-09-18 19:25:50.594113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.594130: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,34]<stderr>:2020-09-18 19:25:50.594193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.595461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.594283: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555c24015130 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,33]<stderr>:2020-09-18 19:25:50.594306: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,33]<stderr>:2020-09-18 19:25:50.594471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,83]<stderr>:2020-09-18 19:25:50.594257: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.595614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.595795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,54]<stderr>:2020-09-18 19:25:50.595079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.594779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 4
[1,4]<stderr>:2020-09-18 19:25:50.594821: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,68]<stderr>:2020-09-18 19:25:50.595681: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555889dfab40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,68]<stderr>:2020-09-18 19:25:50.595699: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,6]<stderr>:2020-09-18 19:25:50.594980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.595870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.595930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.595531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.595740: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559821b8f7e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,35]<stderr>:2020-09-18 19:25:50.595759: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,39]<stderr>:2020-09-18 19:25:50.595786: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,39]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,82]<stderr>:2020-09-18 19:25:50.595613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.595942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.595846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.597133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.597364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.597413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,68]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,68]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,6]<stderr>:2020-09-18 19:25:50.596673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 6
[1,68]<stderr>:2020-09-18 19:25:50.597436: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,6]<stderr>:2020-09-18 19:25:50.596716: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,68]<stderr>:2020-09-18 19:25:50.597488: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,68]<stderr>:2020-09-18 19:25:50.597504: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,68]<stderr>:2020-09-18 19:25:50.597515: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,68]<stderr>:2020-09-18 19:25:50.597527: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,68]<stderr>:2020-09-18 19:25:50.597539: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,68]<stderr>:2020-09-18 19:25:50.597550: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,68]<stderr>:2020-09-18 19:25:50.597598: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.597415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 2
[1,98]<stderr>:2020-09-18 19:25:50.597473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,5]<stderr>:2020-09-18 19:25:50.596967: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,5]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,48]<stderr>:2020-09-18 19:25:50.598401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.599376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.598625: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5563e728b610 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,51]<stderr>:2020-09-18 19:25:50.598648: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,51]<stderr>:2020-09-18 19:25:50.598807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.598198: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,1]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,68]<stderr>:2020-09-18 19:25:50.599244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.599707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.600324: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,69]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,68]<stderr>:2020-09-18 19:25:50.600788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 4
[1,68]<stderr>:2020-09-18 19:25:50.600827: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,84]<stderr>:2020-09-18 19:25:50.600344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,84]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,84]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,84]<stderr>:2020-09-18 19:25:50.600374: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,84]<stderr>:2020-09-18 19:25:50.600431: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,84]<stderr>:2020-09-18 19:25:50.600448: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,84]<stderr>:2020-09-18 19:25:50.600463: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,84]<stderr>:2020-09-18 19:25:50.600478: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,84]<stderr>:2020-09-18 19:25:50.600493: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,84]<stderr>:2020-09-18 19:25:50.600509: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,84]<stderr>:2020-09-18 19:25:50.600561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.601885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 1
[1,49]<stderr>:2020-09-18 19:25:50.601928: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,85]<stderr>:2020-09-18 19:25:50.601696: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,86]<stderr>:2020-09-18 19:25:50.601796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.601815: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5603e8ebc500 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,85]<stderr>:2020-09-18 19:25:50.601833: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,37]<stderr>:2020-09-18 19:25:50.602396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,37]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,37]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,37]<stderr>:2020-09-18 19:25:50.602427: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,37]<stderr>:2020-09-18 19:25:50.602483: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,37]<stderr>:2020-09-18 19:25:50.602495: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,37]<stderr>:2020-09-18 19:25:50.602507: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,37]<stderr>:2020-09-18 19:25:50.602518: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,37]<stderr>:2020-09-18 19:25:50.602529: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,37]<stderr>:2020-09-18 19:25:50.602542: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,37]<stderr>:2020-09-18 19:25:50.602622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.603363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,70]<stderr>:2020-09-18 19:25:50.603552: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,70]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,117]<stderr>:2020-09-18 19:25:50.605135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.604316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,81]<stderr>:2020-09-18 19:25:50.603877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.605302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.605427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,85]<stderr>:2020-09-18 19:25:50.604184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.604406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,32]<stderr>:2020-09-18 19:25:50.604492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,36]<stderr>:2020-09-18 19:25:50.605195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,34]<stderr>:2020-09-18 19:25:50.605274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,33]<stderr>:2020-09-18 19:25:50.605443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,33]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,33]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,33]<stderr>:2020-09-18 19:25:50.605470: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,114]<stderr>:2020-09-18 19:25:50.606601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,33]<stderr>:2020-09-18 19:25:50.605516: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,33]<stderr>:2020-09-18 19:25:50.605529: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,116]<stderr>:2020-09-18 19:25:50.606874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.605541: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,33]<stderr>:2020-09-18 19:25:50.605553: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,33]<stderr>:2020-09-18 19:25:50.605565: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,33]<stderr>:2020-09-18 19:25:50.605577: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,33]<stderr>:2020-09-18 19:25:50.605632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.605900: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,83]<stderr>:2020-09-18 19:25:50.605698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 3
[1,39]<stderr>:2020-09-18 19:25:50.606018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56499451c170 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,39]<stderr>:2020-09-18 19:25:50.606037: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,83]<stderr>:2020-09-18 19:25:50.605744: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,35]<stderr>:2020-09-18 19:25:50.606030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,35]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,35]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,35]<stderr>:2020-09-18 19:25:50.606072: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,35]<stderr>:2020-09-18 19:25:50.606174: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,35]<stderr>:2020-09-18 19:25:50.606203: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,35]<stderr>:2020-09-18 19:25:50.606228: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,35]<stderr>:2020-09-18 19:25:50.606253: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,35]<stderr>:2020-09-18 19:25:50.606277: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,52]<stderr>:2020-09-18 19:25:50.606491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.606302: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,35]<stderr>:2020-09-18 19:25:50.606383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.607976: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,119]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,54]<stderr>:2020-09-18 19:25:50.607299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.608174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.607097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,82]<stderr>:2020-09-18 19:25:50.607187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,55]<stderr>:2020-09-18 19:25:50.607893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.607131: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz
[1,1]<stderr>:2020-09-18 19:25:50.607164: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz
[1,5]<stderr>:2020-09-18 19:25:50.607269: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f856c91160 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,5]<stderr>:2020-09-18 19:25:50.607306: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,1]<stderr>:2020-09-18 19:25:50.607331: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562411d2f270 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,1]<stderr>:2020-09-18 19:25:50.607352: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,39]<stderr>:2020-09-18 19:25:50.608372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.608652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,51]<stderr>:2020-09-18 19:25:50.608822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,51]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,51]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,51]<stderr>:2020-09-18 19:25:50.608858: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,51]<stderr>:2020-09-18 19:25:50.608907: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,51]<stderr>:2020-09-18 19:25:50.608920: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,51]<stderr>:2020-09-18 19:25:50.608933: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,51]<stderr>:2020-09-18 19:25:50.608944: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,51]<stderr>:2020-09-18 19:25:50.608956: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,51]<stderr>:2020-09-18 19:25:50.608968: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,51]<stderr>:2020-09-18 19:25:50.609029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.608742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.610337: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,69]<stderr>:2020-09-18 19:25:50.610486: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d57a22d670 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,69]<stderr>:2020-09-18 19:25:50.610507: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,1]<stderr>:2020-09-18 19:25:50.609932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.609943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.611900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,118]<stderr>:2020-09-18 19:25:50.611983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,33]<stderr>:2020-09-18 19:25:50.611076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.611295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,70]<stderr>:2020-09-18 19:25:50.611820: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,70]<stderr>:2020-09-18 19:25:50.611949: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559f30e47740 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,70]<stderr>:2020-09-18 19:25:50.611969: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,116]<stderr>:2020-09-18 19:25:50.613005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,112]<stderr>:2020-09-18 19:25:50.613391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,84]<stderr>:2020-09-18 19:25:50.611936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.612803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,86]<stderr>:2020-09-18 19:25:50.612412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,35]<stderr>:2020-09-18 19:25:50.612647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.613052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,81]<stderr>:2020-09-18 19:25:50.612929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,54]<stderr>:2020-09-18 19:25:50.613895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,85]<stderr>:2020-09-18 19:25:50.613345: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5603e8e92fb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,85]<stderr>:2020-09-18 19:25:50.613366: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,85]<stderr>:2020-09-18 19:25:50.613541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.614136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
[1,70]<stderr>:2020-09-18 19:25:50.614374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.614528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.616198: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz
[1,84]<stderr>:2020-09-18 19:25:50.614814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 4
[1,84]<stderr>:2020-09-18 19:25:50.614856: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,113]<stderr>:2020-09-18 19:25:50.616459: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5644cf91bcd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,113]<stderr>:2020-09-18 19:25:50.616480: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,39]<stderr>:2020-09-18 19:25:50.615279: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564993b7f3e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,39]<stderr>:2020-09-18 19:25:50.615302: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,39]<stderr>:2020-09-18 19:25:50.615475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.616865: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz
[1,37]<stderr>:2020-09-18 19:25:50.615702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 5
[1,51]<stderr>:2020-09-18 19:25:50.616085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 3
[1,37]<stderr>:2020-09-18 19:25:50.615747: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,119]<stderr>:2020-09-18 19:25:50.616988: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563000d6d720 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,119]<stderr>:2020-09-18 19:25:50.617007: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,51]<stderr>:2020-09-18 19:25:50.616123: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,1]<stderr>:2020-09-18 19:25:50.615320: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56242c0c8470 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,1]<stderr>:2020-09-18 19:25:50.615343: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,5]<stderr>:2020-09-18 19:25:50.615417: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f856c88970 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,5]<stderr>:2020-09-18 19:25:50.615441: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,1]<stderr>:2020-09-18 19:25:50.615576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.615657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.616042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,85]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,85]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,85]<stderr>:2020-09-18 19:25:50.616072: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,85]<stderr>:2020-09-18 19:25:50.616121: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,85]<stderr>:2020-09-18 19:25:50.616135: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,85]<stderr>:2020-09-18 19:25:50.616147: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,85]<stderr>:2020-09-18 19:25:50.616159: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,85]<stderr>:2020-09-18 19:25:50.616171: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,85]<stderr>:2020-09-18 19:25:50.616184: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,85]<stderr>:2020-09-18 19:25:50.616235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.616622: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d57a0dbfd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,69]<stderr>:2020-09-18 19:25:50.616645: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,69]<stderr>:2020-09-18 19:25:50.616854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.618961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.617794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.618024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 1
[1,33]<stderr>:2020-09-18 19:25:50.618064: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,119]<stderr>:2020-09-18 19:25:50.619418: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.619029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 3
[1,35]<stderr>:2020-09-18 19:25:50.619100: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,70]<stderr>:2020-09-18 19:25:50.619598: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559f30cfc2c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,70]<stderr>:2020-09-18 19:25:50.619620: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,39]<stderr>:2020-09-18 19:25:50.619470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,39]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,39]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,39]<stderr>:2020-09-18 19:25:50.619496: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,39]<stderr>:2020-09-18 19:25:50.619542: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,39]<stderr>:2020-09-18 19:25:50.619555: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,39]<stderr>:2020-09-18 19:25:50.619567: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,85]<stderr>:2020-09-18 19:25:50.619409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 5
[1,70]<stderr>:2020-09-18 19:25:50.619847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.619578: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,85]<stderr>:2020-09-18 19:25:50.619445: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,39]<stderr>:2020-09-18 19:25:50.619590: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,39]<stderr>:2020-09-18 19:25:50.619602: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,39]<stderr>:2020-09-18 19:25:50.619657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.619259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,1]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,1]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,1]<stderr>:2020-09-18 19:25:50.619310: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,5]<stderr>:2020-09-18 19:25:50.619379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,5]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,5]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,1]<stderr>:2020-09-18 19:25:50.619395: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,1]<stderr>:2020-09-18 19:25:50.619413: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,5]<stderr>:2020-09-18 19:25:50.619416: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,1]<stderr>:2020-09-18 19:25:50.619426: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,1]<stderr>:2020-09-18 19:25:50.619438: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,1]<stderr>:2020-09-18 19:25:50.619450: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,1]<stderr>:2020-09-18 19:25:50.619463: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,5]<stderr>:2020-09-18 19:25:50.619495: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,5]<stderr>:2020-09-18 19:25:50.619512: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,1]<stderr>:2020-09-18 19:25:50.619527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.619528: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,5]<stderr>:2020-09-18 19:25:50.619544: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,5]<stderr>:2020-09-18 19:25:50.619560: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,5]<stderr>:2020-09-18 19:25:50.619576: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,5]<stderr>:2020-09-18 19:25:50.619643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.621152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,69]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,69]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,69]<stderr>:2020-09-18 19:25:50.621194: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,69]<stderr>:2020-09-18 19:25:50.621276: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,69]<stderr>:2020-09-18 19:25:50.621296: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,69]<stderr>:2020-09-18 19:25:50.621312: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,69]<stderr>:2020-09-18 19:25:50.621327: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,69]<stderr>:2020-09-18 19:25:50.621342: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,69]<stderr>:2020-09-18 19:25:50.621358: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,69]<stderr>:2020-09-18 19:25:50.621428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.621280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.621764: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,34]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,32]<stderr>:2020-09-18 19:25:50.622054: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,32]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,113]<stderr>:2020-09-18 19:25:50.623237: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5644cf719780 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,113]<stderr>:2020-09-18 19:25:50.623256: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,113]<stderr>:2020-09-18 19:25:50.623446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.623689: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562fe05cc690 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,119]<stderr>:2020-09-18 19:25:50.623706: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,119]<stderr>:2020-09-18 19:25:50.623873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.623091: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,53]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,39]<stderr>:2020-09-18 19:25:50.622860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 7
[1,39]<stderr>:2020-09-18 19:25:50.622899: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,70]<stderr>:2020-09-18 19:25:50.623352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,70]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,70]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,70]<stderr>:2020-09-18 19:25:50.623397: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,70]<stderr>:2020-09-18 19:25:50.623464: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,70]<stderr>:2020-09-18 19:25:50.623478: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,70]<stderr>:2020-09-18 19:25:50.623490: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,70]<stderr>:2020-09-18 19:25:50.623503: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,70]<stderr>:2020-09-18 19:25:50.623515: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,70]<stderr>:2020-09-18 19:25:50.623529: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,70]<stderr>:2020-09-18 19:25:50.623602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.622830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.623367: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,38]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,115]<stderr>:2020-09-18 19:25:50.624649: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,115]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,36]<stderr>:2020-09-18 19:25:50.623360: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,36]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,50]<stderr>:2020-09-18 19:25:50.623866: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,50]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,5]<stderr>:2020-09-18 19:25:50.623221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.625488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,113]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,113]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,113]<stderr>:2020-09-18 19:25:50.625515: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,113]<stderr>:2020-09-18 19:25:50.625580: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,113]<stderr>:2020-09-18 19:25:50.625600: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,113]<stderr>:2020-09-18 19:25:50.625615: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,113]<stderr>:2020-09-18 19:25:50.625630: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,113]<stderr>:2020-09-18 19:25:50.625646: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,113]<stderr>:2020-09-18 19:25:50.625661: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,113]<stderr>:2020-09-18 19:25:50.625710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.626079: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,114]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,69]<stderr>:2020-09-18 19:25:50.625318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.627033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,119]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,119]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,119]<stderr>:2020-09-18 19:25:50.627059: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,119]<stderr>:2020-09-18 19:25:50.627106: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,119]<stderr>:2020-09-18 19:25:50.627119: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,119]<stderr>:2020-09-18 19:25:50.627131: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,119]<stderr>:2020-09-18 19:25:50.627142: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,119]<stderr>:2020-09-18 19:25:50.627154: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,119]<stderr>:2020-09-18 19:25:50.627165: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,119]<stderr>:2020-09-18 19:25:50.627216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.626212: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,82]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,1]<stderr>:2020-09-18 19:25:50.626708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 1
[1,1]<stderr>:2020-09-18 19:25:50.626753: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,113]<stderr>:2020-09-18 19:25:50.628666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.627329: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,80]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,5]<stderr>:2020-09-18 19:25:50.627051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 5
[1,5]<stderr>:2020-09-18 19:25:50.627098: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,70]<stderr>:2020-09-18 19:25:50.627768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.628199: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,48]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,119]<stderr>:2020-09-18 19:25:50.630215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.630789: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,112]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,117]<stderr>:2020-09-18 19:25:50.631047: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,117]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,118]<stderr>:2020-09-18 19:25:50.631140: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,118]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,69]<stderr>:2020-09-18 19:25:50.630354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 5
[1,69]<stderr>:2020-09-18 19:25:50.630408: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,113]<stderr>:2020-09-18 19:25:50.631691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 1
[1,113]<stderr>:2020-09-18 19:25:50.631732: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,54]<stderr>:2020-09-18 19:25:50.631824: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,54]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,119]<stderr>:2020-09-18 19:25:50.632876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 7
[1,55]<stderr>:2020-09-18 19:25:50.631834: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,55]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,87]<stderr>:2020-09-18 19:25:50.631501: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,87]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,119]<stderr>:2020-09-18 19:25:50.632923: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,52]<stderr>:2020-09-18 19:25:50.632251: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,52]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,116]<stderr>:2020-09-18 19:25:50.633090: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,116]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,70]<stderr>:2020-09-18 19:25:50.632089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 6
[1,70]<stderr>:2020-09-18 19:25:50.632147: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,50]<stderr>:2020-09-18 19:25:50.632400: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,53]<stderr>:2020-09-18 19:25:50.632407: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,50]<stderr>:2020-09-18 19:25:50.632523: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556cf7f35510 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,50]<stderr>:2020-09-18 19:25:50.632543: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,53]<stderr>:2020-09-18 19:25:50.632542: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55adaf527120 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,53]<stderr>:2020-09-18 19:25:50.632560: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,86]<stderr>:2020-09-18 19:25:50.632006: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,86]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,32]<stderr>:2020-09-18 19:25:50.632559: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,115]<stderr>:2020-09-18 19:25:50.633899: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz
[1,34]<stderr>:2020-09-18 19:25:50.632560: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,114]<stderr>:2020-09-18 19:25:50.634030: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz
[1,36]<stderr>:2020-09-18 19:25:50.632560: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,115]<stderr>:2020-09-18 19:25:50.634040: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556cc262acf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,115]<stderr>:2020-09-18 19:25:50.634059: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,38]<stderr>:2020-09-18 19:25:50.632584: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,114]<stderr>:2020-09-18 19:25:50.634160: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563d29497ce0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,114]<stderr>:2020-09-18 19:25:50.634179: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,34]<stderr>:2020-09-18 19:25:50.632795: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56185b6af6f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,34]<stderr>:2020-09-18 19:25:50.632814: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,32]<stderr>:2020-09-18 19:25:50.632799: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ba9d037da0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,32]<stderr>:2020-09-18 19:25:50.632817: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,36]<stderr>:2020-09-18 19:25:50.632801: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5648d0ff0bb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,36]<stderr>:2020-09-18 19:25:50.632820: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,38]<stderr>:2020-09-18 19:25:50.632800: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ec2f93ae50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,38]<stderr>:2020-09-18 19:25:50.632819: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,81]<stderr>:2020-09-18 19:25:50.633252: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
[1,81]<stderr>:To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[1,50]<stderr>:2020-09-18 19:25:50.634978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.635085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.635212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.636508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.635234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.635286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.635377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.636612: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.636362: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,48]<stderr>:2020-09-18 19:25:50.636493: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e084c1fc70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,48]<stderr>:2020-09-18 19:25:50.636510: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,80]<stderr>:2020-09-18 19:25:50.635931: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,82]<stderr>:2020-09-18 19:25:50.635929: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,80]<stderr>:2020-09-18 19:25:50.636052: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5619248a1340 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,82]<stderr>:2020-09-18 19:25:50.636053: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d868b2c6d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,82]<stderr>:2020-09-18 19:25:50.636070: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,80]<stderr>:2020-09-18 19:25:50.636070: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,112]<stderr>:2020-09-18 19:25:50.638842: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz
[1,112]<stderr>:2020-09-18 19:25:50.638961: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563d00fb0250 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,112]<stderr>:2020-09-18 19:25:50.638978: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,118]<stderr>:2020-09-18 19:25:50.639139: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz
[1,117]<stderr>:2020-09-18 19:25:50.639216: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz
[1,118]<stderr>:2020-09-18 19:25:50.639262: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b2ee253e50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,118]<stderr>:2020-09-18 19:25:50.639279: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,117]<stderr>:2020-09-18 19:25:50.639351: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d209b7a9d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,117]<stderr>:2020-09-18 19:25:50.639369: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,48]<stderr>:2020-09-18 19:25:50.638840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.638573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.638640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,54]<stderr>:2020-09-18 19:25:50.639768: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,50]<stderr>:2020-09-18 19:25:50.639836: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556cf76afd70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,50]<stderr>:2020-09-18 19:25:50.639856: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,115]<stderr>:2020-09-18 19:25:50.640738: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556cc25960b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,115]<stderr>:2020-09-18 19:25:50.640758: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,54]<stderr>:2020-09-18 19:25:50.639889: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b7a1e1c780 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,54]<stderr>:2020-09-18 19:25:50.639909: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,50]<stderr>:2020-09-18 19:25:50.640024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.640941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.640964: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563d29330b90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,114]<stderr>:2020-09-18 19:25:50.640981: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,55]<stderr>:2020-09-18 19:25:50.640067: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,87]<stderr>:2020-09-18 19:25:50.639588: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,53]<stderr>:2020-09-18 19:25:50.640205: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55adaf3253e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,53]<stderr>:2020-09-18 19:25:50.640224: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,55]<stderr>:2020-09-18 19:25:50.640210: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bf5db9f1f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,55]<stderr>:2020-09-18 19:25:50.640227: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,87]<stderr>:2020-09-18 19:25:50.639717: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564f4a2ecf40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,87]<stderr>:2020-09-18 19:25:50.639737: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,52]<stderr>:2020-09-18 19:25:50.640334: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,99]<stderr>:2020-09-18 19:25:50.639852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,99]<stderr>:2020-09-18 19:25:50.639903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      3 
[1,99]<stderr>:2020-09-18 19:25:50.639910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 3:   N 
[1,53]<stderr>:2020-09-18 19:25:50.640428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.640470: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562fc0d871f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,52]<stderr>:2020-09-18 19:25:50.640493: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,99]<stderr>:2020-09-18 19:25:50.640151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.641257: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz
[1,114]<stderr>:2020-09-18 19:25:50.641176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.641441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.641519: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55852c230970 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,116]<stderr>:2020-09-18 19:25:50.641540: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,86]<stderr>:2020-09-18 19:25:50.640038: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,86]<stderr>:2020-09-18 19:25:50.640156: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557010bff8d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,86]<stderr>:2020-09-18 19:25:50.640173: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,118]<stderr>:2020-09-18 19:25:50.641735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.641811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,81]<stderr>:2020-09-18 19:25:50.641385: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz
[1,81]<stderr>:2020-09-18 19:25:50.641529: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555aa3f5fe40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
[1,81]<stderr>:2020-09-18 19:25:50.641550: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[1,54]<stderr>:2020-09-18 19:25:50.642176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.642197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.642187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.642783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.642844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.642835: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e08439d5b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,48]<stderr>:2020-09-18 19:25:50.642854: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,48]<stderr>:2020-09-18 19:25:50.643027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.643929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.642852: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ba9c79cbe0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,32]<stderr>:2020-09-18 19:25:50.642873: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,34]<stderr>:2020-09-18 19:25:50.642912: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56185b53dae0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,34]<stderr>:2020-09-18 19:25:50.642929: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,86]<stderr>:2020-09-18 19:25:50.642747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.643054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.643091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.643096: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ec2f1201d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,38]<stderr>:2020-09-18 19:25:50.643115: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,36]<stderr>:2020-09-18 19:25:50.643173: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5648d0793db0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,36]<stderr>:2020-09-18 19:25:50.643194: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,38]<stderr>:2020-09-18 19:25:50.643305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.643105: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56192479b070 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,80]<stderr>:2020-09-18 19:25:50.643127: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,36]<stderr>:2020-09-18 19:25:50.643390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.643287: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d868b33710 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,82]<stderr>:2020-09-18 19:25:50.643307: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,80]<stderr>:2020-09-18 19:25:50.643367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.643504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,81]<stderr>:2020-09-18 19:25:50.644024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,99]<stderr>:2020-09-18 19:25:50.644216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29652 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:19.0, compute capability: 7.0)
[1,101]<stderr>:2020-09-18 19:25:50.644461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,101]<stderr>:2020-09-18 19:25:50.644490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      5 
[1,101]<stderr>:2020-09-18 19:25:50.644496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 5:   N 
[1,103]<stderr>:2020-09-18 19:25:50.644681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,101]<stderr>:2020-09-18 19:25:50.644683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.644702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      7 
[1,103]<stderr>:2020-09-18 19:25:50.644708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 7:   N 
[1,103]<stderr>:2020-09-18 19:25:50.644951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.647214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,115]<stderr>:pciBusID: 0000:00:19.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,115]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,115]<stderr>:2020-09-18 19:25:50.647246: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,115]<stderr>:2020-09-18 19:25:50.647301: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,115]<stderr>:2020-09-18 19:25:50.647315: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,115]<stderr>:2020-09-18 19:25:50.647327: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,115]<stderr>:2020-09-18 19:25:50.647339: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,115]<stderr>:2020-09-18 19:25:50.647351: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,115]<stderr>:2020-09-18 19:25:50.647363: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,115]<stderr>:2020-09-18 19:25:50.647422: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.648277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,50]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,50]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,50]<stderr>:2020-09-18 19:25:50.648311: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,53]<stderr>:2020-09-18 19:25:50.648361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,53]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,53]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,50]<stderr>:2020-09-18 19:25:50.648364: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,50]<stderr>:2020-09-18 19:25:50.648378: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,50]<stderr>:2020-09-18 19:25:50.648391: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,50]<stderr>:2020-09-18 19:25:50.648403: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,53]<stderr>:2020-09-18 19:25:50.648395: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,50]<stderr>:2020-09-18 19:25:50.648415: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,50]<stderr>:2020-09-18 19:25:50.648427: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,53]<stderr>:2020-09-18 19:25:50.648463: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,53]<stderr>:2020-09-18 19:25:50.648477: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,50]<stderr>:2020-09-18 19:25:50.648481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.648489: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,53]<stderr>:2020-09-18 19:25:50.648502: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,53]<stderr>:2020-09-18 19:25:50.648514: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,53]<stderr>:2020-09-18 19:25:50.648527: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,53]<stderr>:2020-09-18 19:25:50.648596: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.649650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,114]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,114]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,114]<stderr>:2020-09-18 19:25:50.649683: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,114]<stderr>:2020-09-18 19:25:50.649750: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,114]<stderr>:2020-09-18 19:25:50.649768: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,114]<stderr>:2020-09-18 19:25:50.649783: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,114]<stderr>:2020-09-18 19:25:50.649799: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,114]<stderr>:2020-09-18 19:25:50.649814: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,114]<stderr>:2020-09-18 19:25:50.649830: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,114]<stderr>:2020-09-18 19:25:50.649882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.648905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,32]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,32]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,32]<stderr>:2020-09-18 19:25:50.648931: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,32]<stderr>:2020-09-18 19:25:50.648986: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,32]<stderr>:2020-09-18 19:25:50.649017: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,32]<stderr>:2020-09-18 19:25:50.649032: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,32]<stderr>:2020-09-18 19:25:50.649044: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,32]<stderr>:2020-09-18 19:25:50.649057: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,32]<stderr>:2020-09-18 19:25:50.649069: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,34]<stderr>:2020-09-18 19:25:50.649070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,34]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,34]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,101]<stderr>:2020-09-18 19:25:50.649001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.649114: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,32]<stderr>:2020-09-18 19:25:50.649145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.649174: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,34]<stderr>:2020-09-18 19:25:50.649191: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,34]<stderr>:2020-09-18 19:25:50.649207: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,34]<stderr>:2020-09-18 19:25:50.649223: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,34]<stderr>:2020-09-18 19:25:50.649238: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,34]<stderr>:2020-09-18 19:25:50.649255: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,34]<stderr>:2020-09-18 19:25:50.649310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.649491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,38]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,38]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,38]<stderr>:2020-09-18 19:25:50.649518: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,112]<stderr>:2020-09-18 19:25:50.650709: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563d010372d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,112]<stderr>:2020-09-18 19:25:50.650730: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,38]<stderr>:2020-09-18 19:25:50.649564: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,36]<stderr>:2020-09-18 19:25:50.649572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,36]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,36]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,36]<stderr>:2020-09-18 19:25:50.649595: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,38]<stderr>:2020-09-18 19:25:50.649579: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,38]<stderr>:2020-09-18 19:25:50.649591: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,38]<stderr>:2020-09-18 19:25:50.649603: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,38]<stderr>:2020-09-18 19:25:50.649615: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,38]<stderr>:2020-09-18 19:25:50.649627: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,36]<stderr>:2020-09-18 19:25:50.649642: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,36]<stderr>:2020-09-18 19:25:50.649656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,112]<stderr>:2020-09-18 19:25:50.650891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.649669: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,36]<stderr>:2020-09-18 19:25:50.649681: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,38]<stderr>:2020-09-18 19:25:50.649680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.649693: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,36]<stderr>:2020-09-18 19:25:50.649706: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,36]<stderr>:2020-09-18 19:25:50.649762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,103]<stderr>:2020-09-18 19:25:50.649989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.651976: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b2edab8f30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,118]<stderr>:2020-09-18 19:25:50.651998: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,117]<stderr>:2020-09-18 19:25:50.652188: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d2092f8f00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,117]<stderr>:2020-09-18 19:25:50.652215: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,118]<stderr>:2020-09-18 19:25:50.652200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.650795: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564f49a61270 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,87]<stderr>:2020-09-18 19:25:50.650816: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,117]<stderr>:2020-09-18 19:25:50.652438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.651029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.651945: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557010bf64e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,86]<stderr>:2020-09-18 19:25:50.651966: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,86]<stderr>:2020-09-18 19:25:50.652158: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,54]<stderr>:2020-09-18 19:25:50.653047: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b7a2dc29a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,54]<stderr>:2020-09-18 19:25:50.653069: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,54]<stderr>:2020-09-18 19:25:50.653240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.652957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,80]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,80]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,80]<stderr>:2020-09-18 19:25:50.652993: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,80]<stderr>:2020-09-18 19:25:50.653055: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,80]<stderr>:2020-09-18 19:25:50.653069: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,80]<stderr>:2020-09-18 19:25:50.653081: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,80]<stderr>:2020-09-18 19:25:50.653093: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,80]<stderr>:2020-09-18 19:25:50.653104: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,116]<stderr>:2020-09-18 19:25:50.654459: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55852c26a430 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,116]<stderr>:2020-09-18 19:25:50.654483: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,80]<stderr>:2020-09-18 19:25:50.653117: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,80]<stderr>:2020-09-18 19:25:50.653179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.654677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.653802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,48]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,48]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,48]<stderr>:2020-09-18 19:25:50.653847: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,82]<stderr>:2020-09-18 19:25:50.653293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,82]<stderr>:pciBusID: 0000:00:18.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,82]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,82]<stderr>:2020-09-18 19:25:50.653325: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,48]<stderr>:2020-09-18 19:25:50.653905: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,48]<stderr>:2020-09-18 19:25:50.653920: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,48]<stderr>:2020-09-18 19:25:50.653932: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,82]<stderr>:2020-09-18 19:25:50.653383: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,55]<stderr>:2020-09-18 19:25:50.653929: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bf5d3dcc00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,55]<stderr>:2020-09-18 19:25:50.653949: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,82]<stderr>:2020-09-18 19:25:50.653397: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,82]<stderr>:2020-09-18 19:25:50.653409: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,48]<stderr>:2020-09-18 19:25:50.653945: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,48]<stderr>:2020-09-18 19:25:50.653957: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,82]<stderr>:2020-09-18 19:25:50.653421: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,48]<stderr>:2020-09-18 19:25:50.653970: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,82]<stderr>:2020-09-18 19:25:50.653433: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,82]<stderr>:2020-09-18 19:25:50.653445: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,48]<stderr>:2020-09-18 19:25:50.654028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.653503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.654028: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562fc0d6cc60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,52]<stderr>:2020-09-18 19:25:50.654050: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,55]<stderr>:2020-09-18 19:25:50.654164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.654239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,101]<stderr>:2020-09-18 19:25:50.654202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29660 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1b.0, compute capability: 7.0)
[1,103]<stderr>:2020-09-18 19:25:50.654917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29600 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1d.0, compute capability: 7.0)
[1,81]<stderr>:2020-09-18 19:25:50.654598: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555aa3f2abe0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
[1,81]<stderr>:2020-09-18 19:25:50.654624: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
[1,81]<stderr>:2020-09-18 19:25:50.654835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.655404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.655558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.656751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.655957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.656114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.659473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.659927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,112]<stderr>:pciBusID: 0000:00:16.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,112]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,112]<stderr>:2020-09-18 19:25:50.659961: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,112]<stderr>:2020-09-18 19:25:50.660017: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,112]<stderr>:2020-09-18 19:25:50.660062: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,50]<stderr>:2020-09-18 19:25:50.659156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.660099: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,112]<stderr>:2020-09-18 19:25:50.660116: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,112]<stderr>:2020-09-18 19:25:50.660132: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,112]<stderr>:2020-09-18 19:25:50.660148: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,112]<stderr>:2020-09-18 19:25:50.660204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.659258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.659899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,96]<stderr>:2020-09-18 19:25:50.659943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
[1,96]<stderr>:2020-09-18 19:25:50.659950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
[1,97]<stderr>:2020-09-18 19:25:50.660077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,97]<stderr>:2020-09-18 19:25:50.660098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      1 
[1,97]<stderr>:2020-09-18 19:25:50.660104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N 
[1,87]<stderr>:2020-09-18 19:25:50.659960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,87]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,87]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,87]<stderr>:2020-09-18 19:25:50.659996: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,87]<stderr>:2020-09-18 19:25:50.660060: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,87]<stderr>:2020-09-18 19:25:50.660074: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,87]<stderr>:2020-09-18 19:25:50.660086: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,87]<stderr>:2020-09-18 19:25:50.660098: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,87]<stderr>:2020-09-18 19:25:50.660110: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,87]<stderr>:2020-09-18 19:25:50.660123: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,87]<stderr>:2020-09-18 19:25:50.660190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.660559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,97]<stderr>:2020-09-18 19:25:50.660646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.661958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,118]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,118]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,118]<stderr>:2020-09-18 19:25:50.661986: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,118]<stderr>:2020-09-18 19:25:50.662036: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,118]<stderr>:2020-09-18 19:25:50.662050: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,118]<stderr>:2020-09-18 19:25:50.662062: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,118]<stderr>:2020-09-18 19:25:50.662074: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,117]<stderr>:2020-09-18 19:25:50.662050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,117]<stderr>:pciBusID: 0000:00:1b.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,117]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,117]<stderr>:2020-09-18 19:25:50.662087: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,118]<stderr>:2020-09-18 19:25:50.662086: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,118]<stderr>:2020-09-18 19:25:50.662098: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,117]<stderr>:2020-09-18 19:25:50.662150: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,117]<stderr>:2020-09-18 19:25:50.662169: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,117]<stderr>:2020-09-18 19:25:50.662183: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,117]<stderr>:2020-09-18 19:25:50.662195: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,117]<stderr>:2020-09-18 19:25:50.662207: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,117]<stderr>:2020-09-18 19:25:50.662219: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,118]<stderr>:2020-09-18 19:25:50.662154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.662288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.661522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,100]<stderr>:2020-09-18 19:25:50.661552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      4 
[1,100]<stderr>:2020-09-18 19:25:50.661558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 4:   N 
[1,86]<stderr>:2020-09-18 19:25:50.661804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,86]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,86]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,86]<stderr>:2020-09-18 19:25:50.661836: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,86]<stderr>:2020-09-18 19:25:50.661894: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,100]<stderr>:2020-09-18 19:25:50.662108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.661908: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,86]<stderr>:2020-09-18 19:25:50.661920: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,86]<stderr>:2020-09-18 19:25:50.661932: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,86]<stderr>:2020-09-18 19:25:50.661945: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,86]<stderr>:2020-09-18 19:25:50.661957: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,86]<stderr>:2020-09-18 19:25:50.662019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.662391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
[1,32]<stderr>:2020-09-18 19:25:50.662429: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,34]<stderr>:2020-09-18 19:25:50.662695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 2
[1,34]<stderr>:2020-09-18 19:25:50.662737: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,38]<stderr>:2020-09-18 19:25:50.663031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 6
[1,38]<stderr>:2020-09-18 19:25:50.663071: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,36]<stderr>:2020-09-18 19:25:50.663107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 4
[1,36]<stderr>:2020-09-18 19:25:50.663147: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,116]<stderr>:2020-09-18 19:25:50.664350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,116]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,116]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,116]<stderr>:2020-09-18 19:25:50.664377: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,80]<stderr>:2020-09-18 19:25:50.662999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.664426: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,116]<stderr>:2020-09-18 19:25:50.664440: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,116]<stderr>:2020-09-18 19:25:50.664453: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,116]<stderr>:2020-09-18 19:25:50.664466: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,116]<stderr>:2020-09-18 19:25:50.664478: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,116]<stderr>:2020-09-18 19:25:50.664492: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,116]<stderr>:2020-09-18 19:25:50.664550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.663238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,54]<stderr>:2020-09-18 19:25:50.663948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,54]<stderr>:pciBusID: 0000:00:1c.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,54]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,54]<stderr>:2020-09-18 19:25:50.663974: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,54]<stderr>:2020-09-18 19:25:50.664018: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,54]<stderr>:2020-09-18 19:25:50.664037: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,54]<stderr>:2020-09-18 19:25:50.664049: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,54]<stderr>:2020-09-18 19:25:50.664061: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,54]<stderr>:2020-09-18 19:25:50.664072: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,54]<stderr>:2020-09-18 19:25:50.664083: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,54]<stderr>:2020-09-18 19:25:50.664137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.664795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.664931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,55]<stderr>:pciBusID: 0000:00:1d.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,55]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,55]<stderr>:2020-09-18 19:25:50.664969: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,52]<stderr>:2020-09-18 19:25:50.665012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,52]<stderr>:pciBusID: 0000:00:1a.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,52]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,52]<stderr>:2020-09-18 19:25:50.665039: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,55]<stderr>:2020-09-18 19:25:50.665028: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,55]<stderr>:2020-09-18 19:25:50.665042: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,55]<stderr>:2020-09-18 19:25:50.665055: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,55]<stderr>:2020-09-18 19:25:50.665067: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,55]<stderr>:2020-09-18 19:25:50.665080: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,52]<stderr>:2020-09-18 19:25:50.665097: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,55]<stderr>:2020-09-18 19:25:50.665092: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,52]<stderr>:2020-09-18 19:25:50.665117: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,52]<stderr>:2020-09-18 19:25:50.665134: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,81]<stderr>:2020-09-18 19:25:50.664484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
[1,81]<stderr>:pciBusID: 0000:00:17.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
[1,81]<stderr>:coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
[1,81]<stderr>:2020-09-18 19:25:50.664522: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,81]<stderr>:2020-09-18 19:25:50.664598: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,81]<stderr>:2020-09-18 19:25:50.664616: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
[1,81]<stderr>:2020-09-18 19:25:50.664632: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
[1,52]<stderr>:2020-09-18 19:25:50.665147: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,52]<stderr>:2020-09-18 19:25:50.665165: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,81]<stderr>:2020-09-18 19:25:50.664648: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
[1,81]<stderr>:2020-09-18 19:25:50.664663: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
[1,55]<stderr>:2020-09-18 19:25:50.665154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.665184: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,81]<stderr>:2020-09-18 19:25:50.664679: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,81]<stderr>:2020-09-18 19:25:50.664746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.665272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.666924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 3
[1,115]<stderr>:2020-09-18 19:25:50.666989: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,114]<stderr>:2020-09-18 19:25:50.669388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 2
[1,114]<stderr>:2020-09-18 19:25:50.669431: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,112]<stderr>:2020-09-18 19:25:50.669791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,96]<stderr>:2020-09-18 19:25:50.669696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.670092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 2
[1,50]<stderr>:2020-09-18 19:25:50.670134: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,53]<stderr>:2020-09-18 19:25:50.670176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 5
[1,53]<stderr>:2020-09-18 19:25:50.670223: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,97]<stderr>:2020-09-18 19:25:50.669867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.669877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.671559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.671742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.671599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,100]<stderr>:2020-09-18 19:25:50.671780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.673151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.672727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
[1,80]<stderr>:2020-09-18 19:25:50.672783: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,82]<stderr>:2020-09-18 19:25:50.672801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 2
[1,82]<stderr>:2020-09-18 19:25:50.672841: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,54]<stderr>:2020-09-18 19:25:50.674237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,81]<stderr>:2020-09-18 19:25:50.673873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.674906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
[1,48]<stderr>:2020-09-18 19:25:50.674949: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,55]<stderr>:2020-09-18 19:25:50.675126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.675212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.677297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
[1,112]<stderr>:2020-09-18 19:25:50.677341: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,87]<stderr>:2020-09-18 19:25:50.677077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 7
[1,87]<stderr>:2020-09-18 19:25:50.677128: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,86]<stderr>:2020-09-18 19:25:50.677246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 6
[1,86]<stderr>:2020-09-18 19:25:50.677289: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,118]<stderr>:2020-09-18 19:25:50.678795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 6
[1,118]<stderr>:2020-09-18 19:25:50.678835: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,117]<stderr>:2020-09-18 19:25:50.678881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 5
[1,117]<stderr>:2020-09-18 19:25:50.678935: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,116]<stderr>:2020-09-18 19:25:50.679183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 4
[1,116]<stderr>:2020-09-18 19:25:50.679225: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,81]<stderr>:2020-09-18 19:25:50.678622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 1
[1,81]<stderr>:2020-09-18 19:25:50.678669: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,96]<stderr>:2020-09-18 19:25:50.679075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29660 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:16.0, compute capability: 7.0)
[1,97]<stderr>:2020-09-18 19:25:50.679292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29645 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:17.0, compute capability: 7.0)
[1,54]<stderr>:2020-09-18 19:25:50.679842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 6
[1,54]<stderr>:2020-09-18 19:25:50.679882: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,55]<stderr>:2020-09-18 19:25:50.680267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 7
[1,55]<stderr>:2020-09-18 19:25:50.680313: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,52]<stderr>:2020-09-18 19:25:50.680348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 4
[1,52]<stderr>:2020-09-18 19:25:50.680387: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
[1,100]<stderr>:2020-09-18 19:25:50.680637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29679 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1a.0, compute capability: 7.0)
[1,7]<stderr>:2020-09-18 19:25:50.688510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,7]<stderr>:2020-09-18 19:25:50.688559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      7 
[1,7]<stderr>:2020-09-18 19:25:50.688566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 7:   N 
[1,7]<stderr>:2020-09-18 19:25:50.688794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.690709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-09-18 19:25:50.692307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29600 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1d.0, compute capability: 7.0)
[1,2]<stderr>:2020-09-18 19:25:50.695920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,2]<stderr>:2020-09-18 19:25:50.695969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      2 
[1,2]<stderr>:2020-09-18 19:25:50.695976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 2:   N 
[1,2]<stderr>:2020-09-18 19:25:50.696272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.699872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-09-18 19:25:50.703070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29633 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:18.0, compute capability: 7.0)
[1,71]<stderr>:2020-09-18 19:25:50.705459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,71]<stderr>:2020-09-18 19:25:50.705513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      7 
[1,71]<stderr>:2020-09-18 19:25:50.705520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 7:   N 
[1,71]<stderr>:2020-09-18 19:25:50.705741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.707398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,65]<stderr>:2020-09-18 19:25:50.708139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,65]<stderr>:2020-09-18 19:25:50.708168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      1 
[1,65]<stderr>:2020-09-18 19:25:50.708174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N 
[1,65]<stderr>:2020-09-18 19:25:50.708868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,71]<stderr>:2020-09-18 19:25:50.709751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29600 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1d.0, compute capability: 7.0)
[1,65]<stderr>:2020-09-18 19:25:50.711075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.714043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,67]<stderr>:2020-09-18 19:25:50.714067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      3 
[1,67]<stderr>:2020-09-18 19:25:50.714073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 3:   N 
[1,65]<stderr>:2020-09-18 19:25:50.714206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29645 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:17.0, compute capability: 7.0)
[1,67]<stderr>:2020-09-18 19:25:50.714409: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.716044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,3]<stderr>:2020-09-18 19:25:50.716082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      3 
[1,3]<stderr>:2020-09-18 19:25:50.716088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 3:   N 
[1,3]<stderr>:2020-09-18 19:25:50.716284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.717858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-09-18 19:25:50.717990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.719045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,4]<stderr>:2020-09-18 19:25:50.719079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      4 
[1,4]<stderr>:2020-09-18 19:25:50.719085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 4:   N 
[1,4]<stderr>:2020-09-18 19:25:50.719344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.719863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,0]<stderr>:2020-09-18 19:25:50.719888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
[1,0]<stderr>:2020-09-18 19:25:50.719894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
[1,3]<stderr>:2020-09-18 19:25:50.720241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29652 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:19.0, compute capability: 7.0)
[1,0]<stderr>:2020-09-18 19:25:50.720249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.721348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,64]<stderr>:2020-09-18 19:25:50.721396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
[1,64]<stderr>:2020-09-18 19:25:50.721403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
[1,64]<stderr>:2020-09-18 19:25:50.721871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,67]<stderr>:2020-09-18 19:25:50.722161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29652 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:19.0, compute capability: 7.0)
[1,66]<stderr>:2020-09-18 19:25:50.723022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,66]<stderr>:2020-09-18 19:25:50.723054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      2 
[1,66]<stderr>:2020-09-18 19:25:50.723061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 2:   N 
[1,66]<stderr>:2020-09-18 19:25:50.723435: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.723675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.724411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-09-18 19:25:50.724835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,6]<stderr>:2020-09-18 19:25:50.724858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      6 
[1,6]<stderr>:2020-09-18 19:25:50.724865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 6:   N 
[1,6]<stderr>:2020-09-18 19:25:50.725241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.728201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-09-18 19:25:50.728619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29679 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1a.0, compute capability: 7.0)
[1,66]<stderr>:2020-09-18 19:25:50.730618: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-09-18 19:25:50.730149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29660 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:16.0, compute capability: 7.0)
[1,6]<stderr>:2020-09-18 19:25:50.731095: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,68]<stderr>:2020-09-18 19:25:50.733253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,68]<stderr>:2020-09-18 19:25:50.733278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      4 
[1,68]<stderr>:2020-09-18 19:25:50.733284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 4:   N 
[1,68]<stderr>:2020-09-18 19:25:50.733795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.733513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,102]<stderr>:2020-09-18 19:25:50.733551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      6 
[1,102]<stderr>:2020-09-18 19:25:50.733557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 6:   N 
[1,102]<stderr>:2020-09-18 19:25:50.733781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,102]<stderr>:2020-09-18 19:25:50.735419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,64]<stderr>:2020-09-18 19:25:50.735571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29660 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:16.0, compute capability: 7.0)
[1,102]<stderr>:2020-09-18 19:25:50.737007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29600 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1c.0, compute capability: 7.0)
[1,6]<stderr>:2020-09-18 19:25:50.736448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29600 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1c.0, compute capability: 7.0)
[1,66]<stderr>:2020-09-18 19:25:50.737827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29633 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:18.0, compute capability: 7.0)
[1,68]<stderr>:2020-09-18 19:25:50.741970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.742063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,98]<stderr>:2020-09-18 19:25:50.742089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      2 
[1,98]<stderr>:2020-09-18 19:25:50.742095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 2:   N 
[1,98]<stderr>:2020-09-18 19:25:50.742327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.745141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,98]<stderr>:2020-09-18 19:25:50.747949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29633 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:18.0, compute capability: 7.0)
[1,68]<stderr>:2020-09-18 19:25:50.749697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29679 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1a.0, compute capability: 7.0)
[1,49]<stderr>:2020-09-18 19:25:50.751145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,49]<stderr>:2020-09-18 19:25:50.751202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      1 
[1,49]<stderr>:2020-09-18 19:25:50.751208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N 
[1,49]<stderr>:2020-09-18 19:25:50.751453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.752477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,33]<stderr>:2020-09-18 19:25:50.752521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      1 
[1,33]<stderr>:2020-09-18 19:25:50.752528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N 
[1,49]<stderr>:2020-09-18 19:25:50.753085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.752783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,83]<stderr>:2020-09-18 19:25:50.752755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,83]<stderr>:2020-09-18 19:25:50.752798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      3 
[1,83]<stderr>:2020-09-18 19:25:50.752805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 3:   N 
[1,83]<stderr>:2020-09-18 19:25:50.753025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.754393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,84]<stderr>:2020-09-18 19:25:50.754437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      4 
[1,84]<stderr>:2020-09-18 19:25:50.754443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 4:   N 
[1,84]<stderr>:2020-09-18 19:25:50.754806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.755205: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,49]<stderr>:2020-09-18 19:25:50.755778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29645 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:17.0, compute capability: 7.0)
[1,83]<stderr>:2020-09-18 19:25:50.755711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.756453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,39]<stderr>:2020-09-18 19:25:50.756484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      7 
[1,39]<stderr>:2020-09-18 19:25:50.756490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 7:   N 
[1,39]<stderr>:2020-09-18 19:25:50.756685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,33]<stderr>:2020-09-18 19:25:50.756818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29645 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:17.0, compute capability: 7.0)
[1,39]<stderr>:2020-09-18 19:25:50.758673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,84]<stderr>:2020-09-18 19:25:50.758652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,69]<stderr>:2020-09-18 19:25:50.759463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,69]<stderr>:2020-09-18 19:25:50.759502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      5 
[1,69]<stderr>:2020-09-18 19:25:50.759507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 5:   N 
[1,83]<stderr>:2020-09-18 19:25:50.759301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29652 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:19.0, compute capability: 7.0)
[1,69]<stderr>:2020-09-18 19:25:50.759954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.759956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,51]<stderr>:2020-09-18 19:25:50.759984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      3 
[1,51]<stderr>:2020-09-18 19:25:50.759991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 3:   N 
[1,85]<stderr>:2020-09-18 19:25:50.759543: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,85]<stderr>:2020-09-18 19:25:50.759574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      5 
[1,85]<stderr>:2020-09-18 19:25:50.759580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 5:   N 
[1,51]<stderr>:2020-09-18 19:25:50.760347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.760264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.760371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,1]<stderr>:2020-09-18 19:25:50.760409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      1 
[1,1]<stderr>:2020-09-18 19:25:50.760415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N 
[1,84]<stderr>:2020-09-18 19:25:50.761000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29679 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1a.0, compute capability: 7.0)
[1,1]<stderr>:2020-09-18 19:25:50.760823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,39]<stderr>:2020-09-18 19:25:50.761484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29600 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1d.0, compute capability: 7.0)
[1,5]<stderr>:2020-09-18 19:25:50.761180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,5]<stderr>:2020-09-18 19:25:50.761210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      5 
[1,5]<stderr>:2020-09-18 19:25:50.761216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 5:   N 
[1,5]<stderr>:2020-09-18 19:25:50.761803: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.763467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.764039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,113]<stderr>:2020-09-18 19:25:50.766708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,113]<stderr>:2020-09-18 19:25:50.766759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      1 
[1,113]<stderr>:2020-09-18 19:25:50.766766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N 
[1,113]<stderr>:2020-09-18 19:25:50.766985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.766999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,119]<stderr>:2020-09-18 19:25:50.767027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      7 
[1,119]<stderr>:2020-09-18 19:25:50.767033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 7:   N 
[1,119]<stderr>:2020-09-18 19:25:50.767268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,51]<stderr>:2020-09-18 19:25:50.766274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29652 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:19.0, compute capability: 7.0)
[1,69]<stderr>:2020-09-18 19:25:50.766805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.766155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.766824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,85]<stderr>:2020-09-18 19:25:50.769061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29660 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1b.0, compute capability: 7.0)
[1,70]<stderr>:2020-09-18 19:25:50.769814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,70]<stderr>:2020-09-18 19:25:50.769842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      6 
[1,70]<stderr>:2020-09-18 19:25:50.769848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 6:   N 
[1,113]<stderr>:2020-09-18 19:25:50.770921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,119]<stderr>:2020-09-18 19:25:50.771727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-09-18 19:25:50.770355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29645 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:17.0, compute capability: 7.0)
[1,70]<stderr>:2020-09-18 19:25:50.771195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-09-18 19:25:50.770582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29660 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1b.0, compute capability: 7.0)
[1,113]<stderr>:2020-09-18 19:25:50.774306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29645 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:17.0, compute capability: 7.0)
[1,69]<stderr>:2020-09-18 19:25:50.773437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29660 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1b.0, compute capability: 7.0)
[1,119]<stderr>:2020-09-18 19:25:50.774592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29600 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1d.0, compute capability: 7.0)
[1,70]<stderr>:2020-09-18 19:25:50.777558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.778798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,37]<stderr>:2020-09-18 19:25:50.778828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      5 
[1,37]<stderr>:2020-09-18 19:25:50.778834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 5:   N 
[1,37]<stderr>:2020-09-18 19:25:50.779029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.780868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.781755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,35]<stderr>:2020-09-18 19:25:50.781782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      3 
[1,35]<stderr>:2020-09-18 19:25:50.781789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 3:   N 
[1,35]<stderr>:2020-09-18 19:25:50.782133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,37]<stderr>:2020-09-18 19:25:50.782756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29660 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1b.0, compute capability: 7.0)
[1,70]<stderr>:2020-09-18 19:25:50.783928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29600 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1c.0, compute capability: 7.0)
[1,35]<stderr>:2020-09-18 19:25:50.784388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,35]<stderr>:2020-09-18 19:25:50.787143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29652 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:19.0, compute capability: 7.0)
[1,32]<stderr>:2020-09-18 19:25:50.791044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,32]<stderr>:2020-09-18 19:25:50.791085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
[1,32]<stderr>:2020-09-18 19:25:50.791092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
[1,32]<stderr>:2020-09-18 19:25:50.791429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.792281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,34]<stderr>:2020-09-18 19:25:50.792312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      2 
[1,34]<stderr>:2020-09-18 19:25:50.792318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 2:   N 
[1,34]<stderr>:2020-09-18 19:25:50.792786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.795770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,36]<stderr>:2020-09-18 19:25:50.795795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      4 
[1,36]<stderr>:2020-09-18 19:25:50.795801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 4:   N 
[1,38]<stderr>:2020-09-18 19:25:50.795918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,38]<stderr>:2020-09-18 19:25:50.795942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      6 
[1,38]<stderr>:2020-09-18 19:25:50.795948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 6:   N 
[1,36]<stderr>:2020-09-18 19:25:50.796830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,38]<stderr>:2020-09-18 19:25:50.796860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,32]<stderr>:2020-09-18 19:25:50.796986: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.799218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,114]<stderr>:2020-09-18 19:25:50.799262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      2 
[1,114]<stderr>:2020-09-18 19:25:50.799270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 2:   N 
[1,114]<stderr>:2020-09-18 19:25:50.799496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.799064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,53]<stderr>:2020-09-18 19:25:50.799111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      5 
[1,53]<stderr>:2020-09-18 19:25:50.799118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 5:   N 
[1,53]<stderr>:2020-09-18 19:25:50.799344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.800113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,115]<stderr>:2020-09-18 19:25:50.800149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      3 
[1,115]<stderr>:2020-09-18 19:25:50.800155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 3:   N 
[1,34]<stderr>:2020-09-18 19:25:50.799280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.800826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.801543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,53]<stderr>:2020-09-18 19:25:50.800983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,50]<stderr>:2020-09-18 19:25:50.802440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,50]<stderr>:2020-09-18 19:25:50.802483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      2 
[1,50]<stderr>:2020-09-18 19:25:50.802490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 2:   N 
[1,53]<stderr>:2020-09-18 19:25:50.802559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29660 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1b.0, compute capability: 7.0)
[1,50]<stderr>:2020-09-18 19:25:50.802726: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.804154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,114]<stderr>:2020-09-18 19:25:50.804781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29633 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:18.0, compute capability: 7.0)
[1,50]<stderr>:2020-09-18 19:25:50.805053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,115]<stderr>:2020-09-18 19:25:50.806064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29652 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:19.0, compute capability: 7.0)
[1,82]<stderr>:2020-09-18 19:25:50.804662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,82]<stderr>:2020-09-18 19:25:50.804711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      2 
[1,82]<stderr>:2020-09-18 19:25:50.804717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 2:   N 
[1,82]<stderr>:2020-09-18 19:25:50.804951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.805814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.805702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,80]<stderr>:2020-09-18 19:25:50.805730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
[1,38]<stderr>:2020-09-18 19:25:50.805970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.805736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
[1,32]<stderr>:2020-09-18 19:25:50.806090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29660 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:16.0, compute capability: 7.0)
[1,80]<stderr>:2020-09-18 19:25:50.806269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.807001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,48]<stderr>:2020-09-18 19:25:50.807031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
[1,48]<stderr>:2020-09-18 19:25:50.807038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
[1,48]<stderr>:2020-09-18 19:25:50.807397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.806919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.808885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,118]<stderr>:2020-09-18 19:25:50.808916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      6 
[1,118]<stderr>:2020-09-18 19:25:50.808923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 6:   N 
[1,50]<stderr>:2020-09-18 19:25:50.808324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29633 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:18.0, compute capability: 7.0)
[1,118]<stderr>:2020-09-18 19:25:50.809321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,34]<stderr>:2020-09-18 19:25:50.808002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29633 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:18.0, compute capability: 7.0)
[1,112]<stderr>:2020-09-18 19:25:50.809336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,112]<stderr>:2020-09-18 19:25:50.809360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
[1,112]<stderr>:2020-09-18 19:25:50.809366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
[1,86]<stderr>:2020-09-18 19:25:50.808127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,86]<stderr>:2020-09-18 19:25:50.808153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      6 
[1,86]<stderr>:2020-09-18 19:25:50.808160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 6:   N 
[1,112]<stderr>:2020-09-18 19:25:50.809800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.808444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.808636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,87]<stderr>:2020-09-18 19:25:50.808674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      7 
[1,87]<stderr>:2020-09-18 19:25:50.808681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 7:   N 
[1,117]<stderr>:2020-09-18 19:25:50.810456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,117]<stderr>:2020-09-18 19:25:50.810486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      5 
[1,117]<stderr>:2020-09-18 19:25:50.810492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 5:   N 
[1,87]<stderr>:2020-09-18 19:25:50.809519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.810995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.809699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,54]<stderr>:2020-09-18 19:25:50.810567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,54]<stderr>:2020-09-18 19:25:50.810592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      6 
[1,54]<stderr>:2020-09-18 19:25:50.810598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 6:   N 
[1,55]<stderr>:2020-09-18 19:25:50.810952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,55]<stderr>:2020-09-18 19:25:50.810983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      7 
[1,55]<stderr>:2020-09-18 19:25:50.810990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 7:   N 
[1,54]<stderr>:2020-09-18 19:25:50.810997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.811218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,55]<stderr>:2020-09-18 19:25:50.811473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,82]<stderr>:2020-09-18 19:25:50.810896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29633 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:18.0, compute capability: 7.0)
[1,116]<stderr>:2020-09-18 19:25:50.812845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,116]<stderr>:2020-09-18 19:25:50.812872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      4 
[1,116]<stderr>:2020-09-18 19:25:50.812878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 4:   N 
[1,81]<stderr>:2020-09-18 19:25:50.812171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,81]<stderr>:2020-09-18 19:25:50.812204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      1 
[1,81]<stderr>:2020-09-18 19:25:50.812210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N 
[1,116]<stderr>:2020-09-18 19:25:50.814051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,36]<stderr>:2020-09-18 19:25:50.813447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29679 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1a.0, compute capability: 7.0)
[1,52]<stderr>:2020-09-18 19:25:50.813815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,52]<stderr>:2020-09-18 19:25:50.813842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      4 
[1,52]<stderr>:2020-09-18 19:25:50.813848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 4:   N 
[1,38]<stderr>:2020-09-18 19:25:50.813699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29600 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1c.0, compute capability: 7.0)
[1,81]<stderr>:2020-09-18 19:25:50.813826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.814929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,52]<stderr>:2020-09-18 19:25:50.815677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.816547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,87]<stderr>:2020-09-18 19:25:50.815808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,112]<stderr>:2020-09-18 19:25:50.817388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,80]<stderr>:2020-09-18 19:25:50.816007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29660 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:16.0, compute capability: 7.0)
[1,54]<stderr>:2020-09-18 19:25:50.818709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,117]<stderr>:2020-09-18 19:25:50.819561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,48]<stderr>:2020-09-18 19:25:50.819066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29660 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:16.0, compute capability: 7.0)
[1,55]<stderr>:2020-09-18 19:25:50.819374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,81]<stderr>:2020-09-18 19:25:50.821025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,116]<stderr>:2020-09-18 19:25:50.823212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,86]<stderr>:2020-09-18 19:25:50.822018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29600 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1c.0, compute capability: 7.0)
[1,87]<stderr>:2020-09-18 19:25:50.822800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29600 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1d.0, compute capability: 7.0)
[1,52]<stderr>:2020-09-18 19:25:50.823965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,118]<stderr>:2020-09-18 19:25:50.825490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29600 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1c.0, compute capability: 7.0)
[1,112]<stderr>:2020-09-18 19:25:50.826320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29660 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:16.0, compute capability: 7.0)
[1,54]<stderr>:2020-09-18 19:25:50.827069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29600 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1c.0, compute capability: 7.0)
[1,117]<stderr>:2020-09-18 19:25:50.828094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29660 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1b.0, compute capability: 7.0)
[1,81]<stderr>:2020-09-18 19:25:50.827150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29645 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:17.0, compute capability: 7.0)
[1,55]<stderr>:2020-09-18 19:25:50.828016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29599 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1d.0, compute capability: 7.0)
[1,116]<stderr>:2020-09-18 19:25:50.830751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29679 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1a.0, compute capability: 7.0)
[1,52]<stderr>:2020-09-18 19:25:50.831950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29679 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:1a.0, compute capability: 7.0)
[1,23]<stderr>:2020-09-18 19:26:11.827399: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,7]<stderr>:2020-09-18 19:26:11.866221: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,20]<stderr>:2020-09-18 19:26:11.890537: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,0]<stderr>:2020-09-18 19:26:11.979765: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,19]<stderr>:2020-09-18 19:26:12.009758: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,17]<stderr>:2020-09-18 19:26:12.015763: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,119]<stderr>:2020-09-18 19:26:12.023271: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,54]<stderr>:2020-09-18 19:26:12.031237: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,18]<stderr>:2020-09-18 19:26:12.057581: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,21]<stderr>:2020-09-18 19:26:12.103667: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,101]<stderr>:2020-09-18 19:26:12.110823: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,102]<stderr>:2020-09-18 19:26:12.113141: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,2]<stderr>:2020-09-18 19:26:12.139148: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,22]<stderr>:2020-09-18 19:26:12.143685: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,99]<stderr>:2020-09-18 19:26:12.149983: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,23]<stderr>:2020-09-18 19:26:12.165223: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,6]<stderr>:2020-09-18 19:26:12.181422: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,7]<stderr>:2020-09-18 19:26:12.197038: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,65]<stderr>:2020-09-18 19:26:12.223663: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,20]<stderr>:2020-09-18 19:26:12.228080: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,33]<stderr>:2020-09-18 19:26:12.235517: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,96]<stderr>:2020-09-18 19:26:12.237726: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,71]<stderr>:2020-09-18 19:26:12.242464: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,85]<stderr>:2020-09-18 19:26:12.246009: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,87]<stderr>:2020-09-18 19:26:12.247114: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,35]<stderr>:2020-09-18 19:26:12.260068: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,113]<stderr>:2020-09-18 19:26:12.261555: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,68]<stderr>:2020-09-18 19:26:12.270769: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,103]<stderr>:2020-09-18 19:26:12.274683: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,70]<stderr>:2020-09-18 19:26:12.274969: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,100]<stderr>:2020-09-18 19:26:12.276657: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,86]<stderr>:2020-09-18 19:26:12.294259: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,66]<stderr>:2020-09-18 19:26:12.296933: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,84]<stderr>:2020-09-18 19:26:12.296710: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,53]<stderr>:2020-09-18 19:26:12.306799: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,49]<stderr>:2020-09-18 19:26:12.312030: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,0]<stderr>:2020-09-18 19:26:12.314582: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,67]<stderr>:2020-09-18 19:26:12.315969: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,16]<stderr>:2020-09-18 19:26:12.325145: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,117]<stderr>:2020-09-18 19:26:12.327742: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,114]<stderr>:2020-09-18 19:26:12.332688: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,83]<stderr>:2020-09-18 19:26:12.335464: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,55]<stderr>:2020-09-18 19:26:12.336737: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,51]<stderr>:2020-09-18 19:26:12.340575: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,4]<stderr>:2020-09-18 19:26:12.348897: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,119]<stderr>:2020-09-18 19:26:12.351538: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,34]<stderr>:2020-09-18 19:26:12.350819: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,112]<stderr>:2020-09-18 19:26:12.355284: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,64]<stderr>:2020-09-18 19:26:12.357050: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,54]<stderr>:2020-09-18 19:26:12.359332: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,38]<stderr>:2020-09-18 19:26:12.361979: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,69]<stderr>:2020-09-18 19:26:12.363925: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,32]<stderr>:2020-09-18 19:26:12.371010: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,36]<stderr>:2020-09-18 19:26:12.371387: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,19]<stderr>:2020-09-18 19:26:12.386437: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,116]<stderr>:2020-09-18 19:26:12.388869: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,97]<stderr>:2020-09-18 19:26:12.392706: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,17]<stderr>:2020-09-18 19:26:12.393398: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,18]<stderr>:2020-09-18 19:26:12.408955: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,115]<stderr>:2020-09-18 19:26:12.435095: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,39]<stderr>:2020-09-18 19:26:12.438963: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,37]<stderr>:2020-09-18 19:26:12.445689: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,21]<stderr>:2020-09-18 19:26:12.455394: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,80]<stderr>:2020-09-18 19:26:12.463088: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,82]<stderr>:2020-09-18 19:26:12.468153: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,48]<stderr>:2020-09-18 19:26:12.482181: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,2]<stderr>:2020-09-18 19:26:12.481351: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,98]<stderr>:2020-09-18 19:26:12.488153: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,1]<stderr>:2020-09-18 19:26:12.499002: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,22]<stderr>:2020-09-18 19:26:12.498785: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,3]<stderr>:2020-09-18 19:26:12.504344: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,102]<stderr>:2020-09-18 19:26:12.518329: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,101]<stderr>:2020-09-18 19:26:12.518257: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,6]<stderr>:2020-09-18 19:26:12.520047: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,99]<stderr>:2020-09-18 19:26:12.526539: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,52]<stderr>:2020-09-18 19:26:12.541920: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,118]<stderr>:2020-09-18 19:26:12.554814: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,50]<stderr>:2020-09-18 19:26:12.560741: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,81]<stderr>:2020-09-18 19:26:12.563659: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,5]<stderr>:2020-09-18 19:26:12.579021: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
[1,65]<stderr>:2020-09-18 19:26:12.599664: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,96]<stderr>:2020-09-18 19:26:12.606164: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,71]<stderr>:2020-09-18 19:26:12.610053: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,113]<stderr>:2020-09-18 19:26:12.611029: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,33]<stderr>:2020-09-18 19:26:12.618526: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,85]<stderr>:2020-09-18 19:26:12.624567: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,87]<stderr>:2020-09-18 19:26:12.629409: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,35]<stderr>:2020-09-18 19:26:12.638818: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,68]<stderr>:2020-09-18 19:26:12.647282: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,70]<stderr>:2020-09-18 19:26:12.672913: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,66]<stderr>:2020-09-18 19:26:12.686918: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,67]<stderr>:2020-09-18 19:26:12.693397: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,117]<stderr>:2020-09-18 19:26:12.699686: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,16]<stderr>:2020-09-18 19:26:12.701271: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,86]<stderr>:2020-09-18 19:26:12.704414: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,84]<stderr>:2020-09-18 19:26:12.712277: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,53]<stderr>:2020-09-18 19:26:12.715874: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,114]<stderr>:2020-09-18 19:26:12.716864: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,83]<stderr>:2020-09-18 19:26:12.716570: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,49]<stderr>:2020-09-18 19:26:12.718361: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,103]<stderr>:2020-09-18 19:26:12.718910: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,100]<stderr>:2020-09-18 19:26:12.722332: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,34]<stderr>:2020-09-18 19:26:12.722639: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,64]<stderr>:2020-09-18 19:26:12.737280: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,4]<stderr>:2020-09-18 19:26:12.736838: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,112]<stderr>:2020-09-18 19:26:12.741230: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,55]<stderr>:2020-09-18 19:26:12.745049: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,69]<stderr>:2020-09-18 19:26:12.748632: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,51]<stderr>:2020-09-18 19:26:12.751788: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,38]<stderr>:2020-09-18 19:26:12.761155: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,116]<stderr>:2020-09-18 19:26:12.763328: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,97]<stderr>:2020-09-18 19:26:12.775622: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,32]<stderr>:2020-09-18 19:26:12.783923: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,36]<stderr>:2020-09-18 19:26:12.792985: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,115]<stderr>:2020-09-18 19:26:12.797218: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,37]<stderr>:2020-09-18 19:26:12.857534: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,39]<stderr>:2020-09-18 19:26:12.858356: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,1]<stderr>:2020-09-18 19:26:12.880304: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,80]<stderr>:2020-09-18 19:26:12.882818: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,98]<stderr>:2020-09-18 19:26:12.884744: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,82]<stderr>:2020-09-18 19:26:12.888518: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,48]<stderr>:2020-09-18 19:26:12.890176: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,3]<stderr>:2020-09-18 19:26:12.893100: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,5]<stderr>:2020-09-18 19:26:12.945327: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,81]<stderr>:2020-09-18 19:26:12.951815: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,52]<stderr>:2020-09-18 19:26:12.982842: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,50]<stderr>:2020-09-18 19:26:12.990276: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,118]<stderr>:2020-09-18 19:26:12.995613: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
[1,0]<stderr>:2020-09-18 19:26:14,895 - INFO - Loading weights from: /shared/awsdet/data/weights/resnet50v1_d
[1,23]<stdout>:loading annotations into memory...
[1,0]<stderr>:2020-09-18 19:26:25,183 - INFO - 	keras_backbone	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,183 - INFO - 		ResNet50V1_d	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,183 - INFO - 			input_1	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,183 - INFO - 			conv1_3x3_stem1	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,183 - INFO - 			conv1_3x3_1_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,184 - INFO - 			conv1_3x3_1_relu	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,184 - INFO - 			conv1_3x3_stem2	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,184 - INFO - 			conv1_3x3_2_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,184 - INFO - 			conv1_3x3_2_relu	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,184 - INFO - 			conv1_3x3_stem3	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,184 - INFO - 			conv1_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,184 - INFO - 			conv1_relu	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,184 - INFO - 			pool1_pool	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,184 - INFO - 			conv2_block1_1_conv	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,184 - INFO - 			conv2_block1_1_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,184 - INFO - 			conv2_block1_1_relu	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,184 - INFO - 			conv2_block1_2_conv	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,184 - INFO - 			conv2_block1_2_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,184 - INFO - 			average_pooling2d	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,184 - INFO - 			conv2_block1_2_relu	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,184 - INFO - 			conv2_block1_0_conv	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,184 - INFO - 			conv2_block1_3_conv	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,184 - INFO - 			conv2_block1_0_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,184 - INFO - 			conv2_block1_3_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,184 - INFO - 			conv2_block1_add	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,184 - INFO - 			conv2_block1_out	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,184 - INFO - 			conv2_block2_1_conv	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,184 - INFO - 			conv2_block2_1_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,184 - INFO - 			conv2_block2_1_relu	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			conv2_block2_2_conv	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			conv2_block2_2_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			conv2_block2_2_relu	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			conv2_block2_3_conv	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			conv2_block2_3_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			conv2_block2_add	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			conv2_block2_out	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			conv2_block3_1_conv	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			conv2_block3_1_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			conv2_block3_1_relu	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			conv2_block3_2_conv	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			conv2_block3_2_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			conv2_block3_2_relu	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			conv2_block3_3_conv	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			conv2_block3_3_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			conv2_block3_add	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			conv2_block3_out	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			conv3_block1_1_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			conv3_block1_1_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			conv3_block1_1_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			conv3_block1_2_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			conv3_block1_2_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			average_pooling2d_1	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			conv3_block1_2_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,185 - INFO - 			conv3_block1_0_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,186 - INFO - 			conv3_block1_3_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,186 - INFO - 			conv3_block1_0_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,186 - INFO - 			conv3_block1_3_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,186 - INFO - 			conv3_block1_add	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,186 - INFO - 			conv3_block1_out	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,186 - INFO - 			conv3_block2_1_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,186 - INFO - 			conv3_block2_1_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,186 - INFO - 			conv3_block2_1_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,186 - INFO - 			conv3_block2_2_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,186 - INFO - 			conv3_block2_2_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,186 - INFO - 			conv3_block2_2_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,186 - INFO - 			conv3_block2_3_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,186 - INFO - 			conv3_block2_3_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,186 - INFO - 			conv3_block2_add	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,186 - INFO - 			conv3_block2_out	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,186 - INFO - 			conv3_block3_1_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,186 - INFO - 			conv3_block3_1_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,186 - INFO - 			conv3_block3_1_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,186 - INFO - 			conv3_block3_2_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,186 - INFO - 			conv3_block3_2_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,186 - INFO - 			conv3_block3_2_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,186 - INFO - 			conv3_block3_3_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,186 - INFO - 			conv3_block3_3_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,187 - INFO - 			conv3_block3_add	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,187 - INFO - 			conv3_block3_out	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,187 - INFO - 			conv3_block4_1_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,187 - INFO - 			conv3_block4_1_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,187 - INFO - 			conv3_block4_1_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,187 - INFO - 			conv3_block4_2_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,187 - INFO - 			conv3_block4_2_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,187 - INFO - 			conv3_block4_2_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,187 - INFO - 			conv3_block4_3_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,187 - INFO - 			conv3_block4_3_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,187 - INFO - 			conv3_block4_add	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,187 - INFO - 			conv3_block4_out	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,187 - INFO - 			conv4_block1_1_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,187 - INFO - 			conv4_block1_1_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,187 - INFO - 			conv4_block1_1_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,187 - INFO - 			conv4_block1_2_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,187 - INFO - 			conv4_block1_2_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,187 - INFO - 			average_pooling2d_2	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,187 - INFO - 			conv4_block1_2_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,187 - INFO - 			conv4_block1_0_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,187 - INFO - 			conv4_block1_3_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,187 - INFO - 			conv4_block1_0_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,187 - INFO - 			conv4_block1_3_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,188 - INFO - 			conv4_block1_add	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,188 - INFO - 			conv4_block1_out	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,188 - INFO - 			conv4_block2_1_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,188 - INFO - 			conv4_block2_1_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,188 - INFO - 			conv4_block2_1_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,188 - INFO - 			conv4_block2_2_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,188 - INFO - 			conv4_block2_2_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,188 - INFO - 			conv4_block2_2_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,188 - INFO - 			conv4_block2_3_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,188 - INFO - 			conv4_block2_3_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,188 - INFO - 			conv4_block2_add	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,188 - INFO - 			conv4_block2_out	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,188 - INFO - 			conv4_block3_1_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,188 - INFO - 			conv4_block3_1_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,188 - INFO - 			conv4_block3_1_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,188 - INFO - 			conv4_block3_2_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,188 - INFO - 			conv4_block3_2_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,188 - INFO - 			conv4_block3_2_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,188 - INFO - 			conv4_block3_3_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,188 - INFO - 			conv4_block3_3_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,188 - INFO - 			conv4_block3_add	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,188 - INFO - 			conv4_block3_out	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,188 - INFO - 			conv4_block4_1_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block4_1_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block4_1_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block4_2_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block4_2_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block4_2_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block4_3_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block4_3_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block4_add	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block4_out	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block5_1_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block5_1_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block5_1_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block5_2_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block5_2_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block5_2_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block5_3_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block5_3_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block5_add	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block5_out	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block6_1_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block6_1_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block6_1_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block6_2_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block6_2_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,189 - INFO - 			conv4_block6_2_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			conv4_block6_3_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			conv4_block6_3_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			conv4_block6_add	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			conv4_block6_out	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			conv5_block1_1_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			conv5_block1_1_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			conv5_block1_1_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			conv5_block1_2_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			conv5_block1_2_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			average_pooling2d_3	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			conv5_block1_2_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			conv5_block1_0_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			conv5_block1_3_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			conv5_block1_0_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			conv5_block1_3_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			conv5_block1_add	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			conv5_block1_out	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			conv5_block2_1_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			conv5_block2_1_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			conv5_block2_1_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			conv5_block2_2_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			conv5_block2_2_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			conv5_block2_2_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			conv5_block2_3_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,190 - INFO - 			conv5_block2_3_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,191 - INFO - 			conv5_block2_add	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,191 - INFO - 			conv5_block2_out	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,191 - INFO - 			conv5_block3_1_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,191 - INFO - 			conv5_block3_1_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,191 - INFO - 			conv5_block3_1_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,191 - INFO - 			conv5_block3_2_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,191 - INFO - 			conv5_block3_2_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,191 - INFO - 			conv5_block3_2_relu	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,191 - INFO - 			conv5_block3_3_conv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,191 - INFO - 			conv5_block3_3_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,191 - INFO - 			conv5_block3_add	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,191 - INFO - 			conv5_block3_out	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,191 - INFO - 	fpn	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,191 - INFO - 		lateral_C2	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,191 - INFO - 		lateral_C3	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,191 - INFO - 		lateral_C4	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,191 - INFO - 		lateral_C5	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,191 - INFO - 		fpn_C2	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,191 - INFO - 		fpn_C3	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,191 - INFO - 		fpn_C4	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,191 - INFO - 		fpn_C5	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,191 - INFO - 		add_C3	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,192 - INFO - 		add_C4	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,192 - INFO - 		add_C5	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,192 - INFO - 	rpn_head	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,192 - INFO - 		rpn_conv_shared	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,192 - INFO - 		rpn_class_raw	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,192 - INFO - 		rpn_bbox_pred	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,192 - INFO - 	pyramid_roi_align	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,192 - INFO - 		average_pooling2d_4	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,192 - INFO - 	b_box_head	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,192 - INFO - 		flatten	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,192 - INFO - 		flatten_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,192 - INFO - 		fc1	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,192 - INFO - 		fc1_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,192 - INFO - 		fc2	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,192 - INFO - 		fc2_bn	trainable: False
[1,0]<stderr>:2020-09-18 19:26:25,192 - INFO - 		rcnn_class_logits	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,192 - INFO - 		rcnn_bbox_fc	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,192 - INFO - 	pyramid_roi_align_1	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,192 - INFO - 		average_pooling2d_5	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,192 - INFO - 	mask_head	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,193 - INFO - 		mask_conv_0	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,193 - INFO - 		mask_conv_1	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,193 - INFO - 		mask_conv_2	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,193 - INFO - 		mask_conv_3	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,193 - INFO - 		mask_bn_0	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,193 - INFO - 		mask_bn_1	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,193 - INFO - 		mask_bn_2	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,193 - INFO - 		mask_bn_3	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,193 - INFO - 		mask_deconv	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,193 - INFO - 		mask_output	trainable: True
[1,0]<stderr>:2020-09-18 19:26:25,193 - INFO - Trainable Variables:
[1,0]<stderr>:2020-09-18 19:26:25,195 - INFO - conv3_block1_1_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,195 - INFO - conv3_block1_2_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,195 - INFO - conv3_block1_0_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,195 - INFO - conv3_block1_3_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,195 - INFO - conv3_block2_1_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,195 - INFO - conv3_block2_2_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,195 - INFO - conv3_block2_3_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,195 - INFO - conv3_block3_1_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,195 - INFO - conv3_block3_2_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,195 - INFO - conv3_block3_3_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,195 - INFO - conv3_block4_1_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,195 - INFO - conv3_block4_2_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,195 - INFO - conv3_block4_3_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,195 - INFO - conv4_block1_1_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,195 - INFO - conv4_block1_2_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,195 - INFO - conv4_block1_0_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,195 - INFO - conv4_block1_3_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,195 - INFO - conv4_block2_1_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,195 - INFO - conv4_block2_2_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,195 - INFO - conv4_block2_3_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,195 - INFO - conv4_block3_1_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,196 - INFO - conv4_block3_2_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,196 - INFO - conv4_block3_3_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,196 - INFO - conv4_block4_1_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,196 - INFO - conv4_block4_2_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,196 - INFO - conv4_block4_3_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,196 - INFO - conv4_block5_1_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,196 - INFO - conv4_block5_2_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,196 - INFO - conv4_block5_3_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,196 - INFO - conv4_block6_1_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,196 - INFO - conv4_block6_2_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,196 - INFO - conv4_block6_3_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,196 - INFO - conv5_block1_1_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,196 - INFO - conv5_block1_2_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,196 - INFO - conv5_block1_0_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,196 - INFO - conv5_block1_3_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,196 - INFO - conv5_block2_1_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,196 - INFO - conv5_block2_2_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,196 - INFO - conv5_block2_3_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,196 - INFO - conv5_block3_1_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,196 - INFO - conv5_block3_2_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,196 - INFO - conv5_block3_3_conv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,196 - INFO - lateral_C2/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,196 - INFO - lateral_C2/bias:0
[1,0]<stderr>:2020-09-18 19:26:25,196 - INFO - lateral_C3/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - lateral_C3/bias:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - lateral_C4/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - lateral_C4/bias:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - lateral_C5/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - lateral_C5/bias:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - fpn_C2/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - fpn_C2/bias:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - fpn_C3/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - fpn_C3/bias:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - fpn_C4/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - fpn_C4/bias:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - fpn_C5/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - fpn_C5/bias:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - rpn_conv_shared/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - rpn_conv_shared/bias:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - rpn_class_raw/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - rpn_class_raw/bias:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - rpn_bbox_pred/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - rpn_bbox_pred/bias:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - fc1/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - fc2/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - rcnn_class_logits/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - rcnn_class_logits/bias:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - rcnn_bbox_fc/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,197 - INFO - rcnn_bbox_fc/bias:0
[1,0]<stderr>:2020-09-18 19:26:25,198 - INFO - mask_conv_0/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,198 - INFO - mask_conv_0/bias:0
[1,0]<stderr>:2020-09-18 19:26:25,198 - INFO - mask_conv_1/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,198 - INFO - mask_conv_1/bias:0
[1,0]<stderr>:2020-09-18 19:26:25,198 - INFO - mask_conv_2/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,198 - INFO - mask_conv_2/bias:0
[1,0]<stderr>:2020-09-18 19:26:25,198 - INFO - mask_conv_3/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,198 - INFO - mask_conv_3/bias:0
[1,0]<stderr>:2020-09-18 19:26:25,198 - INFO - mask_deconv/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,198 - INFO - mask_deconv/bias:0
[1,0]<stderr>:2020-09-18 19:26:25,198 - INFO - mask_output/kernel:0
[1,0]<stderr>:2020-09-18 19:26:25,198 - INFO - mask_output/bias:0
[1,0]<stdout>:loading annotations into memory...
[1,7]<stdout>:loading annotations into memory...
[1,20]<stdout>:loading annotations into memory...
[1,119]<stdout>:loading annotations into memory...
[1,54]<stdout>:loading annotations into memory...
[1,19]<stdout>:loading annotations into memory...
[1,2]<stdout>:loading annotations into memory...
[1,87]<stdout>:loading annotations into memory...
[1,17]<stdout>:loading annotations into memory...
[1,102]<stdout>:loading annotations into memory...
[1,114]<stdout>:loading annotations into memory...
[1,113]<stdout>:loading annotations into memory...
[1,53]<stdout>:loading annotations into memory...
[1,18]<stdout>:loading annotations into memory...
[1,6]<stdout>:loading annotations into memory...
[1,21]<stdout>:loading annotations into memory...
[1,5]<stdout>:loading annotations into memory...
[1,85]<stdout>:loading annotations into memory...
[1,16]<stdout>:loading annotations into memory...
[1,99]<stdout>:loading annotations into memory...
[1,101]<stdout>:loading annotations into memory...
[1,22]<stdout>:loading annotations into memory...
[1,96]<stdout>:loading annotations into memory...
[1,36]<stdout>:loading annotations into memory...
[1,32]<stdout>:loading annotations into memory...
[1,103]<stdout>:loading annotations into memory...
[1,49]<stdout>:loading annotations into memory...
[1,86]<stdout>:loading annotations into memory...
[1,117]<stdout>:loading annotations into memory...
[1,4]<stdout>:loading annotations into memory...
[1,55]<stdout>:loading annotations into memory...
[1,38]<stdout>:loading annotations into memory...
[1,100]<stdout>:loading annotations into memory...
[1,83]<stdout>:loading annotations into memory...
[1,112]<stdout>:loading annotations into memory...
[1,34]<stdout>:loading annotations into memory...
[1,97]<stdout>:loading annotations into memory...
[1,33]<stdout>:loading annotations into memory...
[1,51]<stdout>:loading annotations into memory...
[1,1]<stdout>:loading annotations into memory...
[1,116]<stdout>:loading annotations into memory...
[1,115]<stdout>:loading annotations into memory...
[1,118]<stdout>:loading annotations into memory...
[1,82]<stdout>:loading annotations into memory...
[1,84]<stdout>:loading annotations into memory...
[1,65]<stdout>:loading annotations into memory...
[1,69]<stdout>:loading annotations into memory...
[1,48]<stdout>:loading annotations into memory...
[1,66]<stdout>:loading annotations into memory...
[1,37]<stdout>:loading annotations into memory...
[1,3]<stdout>:loading annotations into memory...
[1,35]<stdout>:loading annotations into memory...
[1,52]<stdout>:loading annotations into memory...
[1,71]<stdout>:loading annotations into memory...
[1,98]<stdout>:loading annotations into memory...
[1,80]<stdout>:loading annotations into memory...
[1,70]<stdout>:loading annotations into memory...
[1,39]<stdout>:loading annotations into memory...
[1,67]<stdout>:loading annotations into memory...
[1,50]<stdout>:loading annotations into memory...
[1,68]<stdout>:loading annotations into memory...
[1,64]<stdout>:loading annotations into memory...
[1,81]<stdout>:loading annotations into memory...
[1,0]<stdout>:Done (t=15.94s)
[1,0]<stdout>:creating index...
[1,7]<stdout>:Done (t=16.26s)
[1,7]<stdout>:creating index...
[1,2]<stdout>:Done (t=16.15s)
[1,2]<stdout>:creating index...
[1,114]<stdout>:Done (t=15.87s)
[1,114]<stdout>:creating index...
[1,20]<stdout>:Done (t=16.45s)
[1,20]<stdout>:creating index...
[1,119]<stdout>:Done (t=16.43s)
[1,119]<stdout>:creating index...
[1,23]<stdout>:Done (t=16.75s)
[1,23]<stdout>:creating index...
[1,54]<stdout>:Done (t=16.41s)
[1,54]<stdout>:creating index...
[1,53]<stdout>:Done (t=16.07s)
[1,53]<stdout>:creating index...
[1,0]<stdout>:index created!
[1,49]<stdout>:Done (t=15.93s)
[1,49]<stdout>:creating index...
[1,5]<stdout>:Done (t=16.14s)
[1,5]<stdout>:creating index...
[1,102]<stdout>:Done (t=16.33s)
[1,102]<stdout>:creating index...
[1,96]<stdout>:Done (t=16.11s)
[1,96]<stdout>:creating index...
[1,16]<stdout>:Done (t=16.27s)
[1,16]<stdout>:creating index...
[1,22]<stdout>:Done (t=16.24s)
[1,22]<stdout>:creating index...
[1,101]<stdout>:Done (t=16.31s)
[1,101]<stdout>:creating index...
[1,55]<stdout>:Done (t=16.08s)
[1,55]<stdout>:creating index...
[1,6]<stdout>:Done (t=16.43s)
[1,6]<stdout>:creating index...
[1,18]<stdout>:Done (t=16.45s)
[1,18]<stdout>:creating index...
[1,87]<stdout>:Done (t=16.76s)
[1,87]<stdout>:creating index...
[1,113]<stdout>:Done (t=16.57s)
[1,113]<stdout>:creating index...
[1,99]<stdout>:Done (t=16.46s)
[1,99]<stdout>:creating index...
[1,32]<stdout>:Done (t=16.32s)
[1,32]<stdout>:creating index...
[1,19]<stdout>:Done (t=17.00s)
[1,19]<stdout>:creating index...
[1,118]<stdout>:Done (t=16.14s)
[1,118]<stdout>:creating index...
[1,7]<stdout>:index created!
[1,1]<stdout>:Done (t=16.18s)
[1,1]<stdout>:creating index...
[1,103]<stdout>:Done (t=16.37s)
[1,103]<stdout>:creating index...
[1,69]<stdout>:Done (t=16.13s)
[1,69]<stdout>:creating index...
[1,65]<stdout>:Done (t=16.14s)
[1,65]<stdout>:creating index...
[1,97]<stdout>:Done (t=16.23s)
[1,97]<stdout>:creating index...
[1,86]<stdout>:Done (t=16.37s)
[1,86]<stdout>:creating index...
[1,17]<stdout>:Done (t=16.78s)
[1,17]<stdout>:creating index...
[1,51]<stdout>:Done (t=16.25s)
[1,51]<stdout>:creating index...
[1,21]<stdout>:Done (t=16.64s)
[1,21]<stdout>:creating index...
[1,85]<stdout>:Done (t=16.65s)
[1,85]<stdout>:creating index...
[1,38]<stdout>:Done (t=16.36s)
[1,38]<stdout>:creating index...
[1,82]<stdout>:Done (t=16.29s)
[1,82]<stdout>:creating index...
[1,4]<stdout>:Done (t=16.47s)
[1,4]<stdout>:creating index...
[1,2]<stdout>:index created!
[1,34]<stdout>:Done (t=16.40s)
[1,34]<stdout>:creating index...
[1,100]<stdout>:Done (t=16.45s)
[1,100]<stdout>:creating index...
[1,119]<stdout>:index created!
[1,114]<stdout>:index created!
[1,3]<stdout>:Done (t=16.33s)
[1,3]<stdout>:creating index...
[1,70]<stdout>:Done (t=16.29s)
[1,70]<stdout>:creating index...
[1,20]<stdout>:index created!
[1,112]<stdout>:Done (t=16.50s)
[1,112]<stdout>:creating index...
[1,23]<stdout>:index created!
[1,98]<stdout>:Done (t=16.43s)
[1,98]<stdout>:creating index...
[1,66]<stdout>:Done (t=16.48s)
[1,66]<stdout>:creating index...
[1,80]<stdout>:Done (t=16.44s)
[1,80]<stdout>:creating index...
[1,71]<stdout>:Done (t=16.45s)
[1,71]<stdout>:creating index...
[1,48]<stdout>:Done (t=16.54s)
[1,48]<stdout>:creating index...
[1,54]<stdout>:index created!
[1,115]<stdout>:Done (t=16.62s)
[1,115]<stdout>:creating index...
[1,117]<stdout>:Done (t=16.77s)
[1,117]<stdout>:creating index...
[1,53]<stdout>:index created!
[1,83]<stdout>:Done (t=16.73s)
[1,83]<stdout>:creating index...
[1,52]<stdout>:Done (t=16.58s)
[1,52]<stdout>:creating index...
[1,36]<stdout>:Done (t=16.87s)
[1,36]<stdout>:creating index...
[1,116]<stdout>:Done (t=16.68s)
[1,116]<stdout>:creating index...
[1,67]<stdout>:Done (t=16.56s)
[1,67]<stdout>:creating index...
[1,49]<stdout>:index created!
[1,68]<stdout>:Done (t=16.60s)
[1,68]<stdout>:creating index...
[1,35]<stdout>:Done (t=16.67s)
[1,35]<stdout>:creating index...
[1,5]<stdout>:index created!
[1,102]<stdout>:index created!
[1,96]<stdout>:index created!
[1,81]<stdout>:Done (t=16.64s)
[1,81]<stdout>:creating index...
[1,50]<stdout>:Done (t=16.70s)
[1,50]<stdout>:creating index...
[1,39]<stdout>:Done (t=16.76s)
[1,39]<stdout>:creating index...
[1,64]<stdout>:Done (t=16.74s)
[1,64]<stdout>:creating index...
[1,37]<stdout>:Done (t=16.86s)
[1,37]<stdout>:creating index...
[1,84]<stdout>:Done (t=16.88s)
[1,84]<stdout>:creating index...
[1,16]<stdout>:index created!
[1,55]<stdout>:index created!
[1,101]<stdout>:index created!
[1,22]<stdout>:index created!
[1,6]<stdout>:index created!
[1,33]<stdout>:Done (t=17.02s)
[1,33]<stdout>:creating index...
[1,18]<stdout>:index created!
[1,87]<stdout>:index created!
[1,118]<stdout>:index created!
[1,113]<stdout>:index created!
[1,32]<stdout>:index created!
[1,99]<stdout>:index created!
[1,1]<stdout>:index created!
[1,69]<stdout>:index created!
[1,65]<stdout>:index created!
[1,97]<stdout>:index created!
[1,103]<stdout>:index created!
[1,86]<stdout>:index created!
[1,51]<stdout>:index created!
[1,38]<stdout>:index created!
[1,21]<stdout>:index created!
[1,19]<stdout>:index created!
[1,85]<stdout>:index created!
[1,4]<stdout>:index created!
[1,82]<stdout>:index created!
[1,17]<stdout>:index created!
[1,34]<stdout>:index created!
[1,100]<stdout>:index created!
[1,3]<stdout>:index created!
[1,70]<stdout>:index created!
[1,112]<stdout>:index created!
[1,98]<stdout>:index created!
[1,66]<stdout>:index created!
[1,71]<stdout>:index created!
[1,48]<stdout>:index created!
[1,80]<stdout>:index created!
[1,115]<stdout>:index created!
[1,52]<stdout>:index created!
[1,36]<stdout>:index created!
[1,117]<stdout>:index created!
[1,83]<stdout>:index created!
[1,68]<stdout>:index created!
[1,35]<stdout>:index created!
[1,116]<stdout>:index created!
[1,50]<stdout>:index created!
[1,67]<stdout>:index created!
[1,64]<stdout>:index created!
[1,39]<stdout>:index created!
[1,84]<stdout>:index created!
[1,81]<stdout>:index created!
[1,33]<stdout>:index created!
[1,37]<stdout>:index created!
[1,0]<stdout>:loading annotations into memory...
[1,7]<stdout>:loading annotations into memory...
[1,2]<stdout>:loading annotations into memory...
[1,114]<stdout>:loading annotations into memory...
[1,119]<stdout>:loading annotations into memory...
[1,20]<stdout>:loading annotations into memory...
[1,23]<stdout>:loading annotations into memory...
[1,53]<stdout>:loading annotations into memory...
[1,5]<stdout>:loading annotations into memory...
[1,49]<stdout>:loading annotations into memory...
[1,96]<stdout>:loading annotations into memory...
[1,102]<stdout>:loading annotations into memory...
[1,54]<stdout>:loading annotations into memory...
[1,55]<stdout>:loading annotations into memory...
[1,6]<stdout>:loading annotations into memory...
[1,16]<stdout>:loading annotations into memory...
[1,18]<stdout>:loading annotations into memory...
[1,1]<stdout>:loading annotations into memory...
[1,118]<stdout>:loading annotations into memory...
[1,69]<stdout>:loading annotations into memory...
[1,87]<stdout>:loading annotations into memory...
[1,101]<stdout>:loading annotations into memory...
[1,22]<stdout>:loading annotations into memory...
[1,113]<stdout>:loading annotations into memory...
[1,99]<stdout>:loading annotations into memory...
[1,86]<stdout>:loading annotations into memory...
[1,32]<stdout>:loading annotations into memory...
[1,103]<stdout>:loading annotations into memory...
[1,97]<stdout>:loading annotations into memory...
[1,65]<stdout>:loading annotations into memory...
[1,21]<stdout>:loading annotations into memory...
[1,38]<stdout>:loading annotations into memory...
[1,51]<stdout>:loading annotations into memory...
[1,85]<stdout>:loading annotations into memory...
[1,19]<stdout>:loading annotations into memory...
[1,34]<stdout>:loading annotations into memory...
[1,82]<stdout>:loading annotations into memory...
[1,3]<stdout>:loading annotations into memory...
[1,100]<stdout>:loading annotations into memory...
[1,70]<stdout>:loading annotations into memory...
[1,17]<stdout>:loading annotations into memory...
[1,112]<stdout>:loading annotations into memory...
[1,66]<stdout>:loading annotations into memory...
[1,98]<stdout>:loading annotations into memory...
[1,4]<stdout>:loading annotations into memory...
[1,48]<stdout>:loading annotations into memory...
[1,52]<stdout>:loading annotations into memory...
[1,115]<stdout>:loading annotations into memory...
[1,117]<stdout>:loading annotations into memory...
[1,80]<stdout>:loading annotations into memory...
[1,36]<stdout>:loading annotations into memory...
[1,68]<stdout>:loading annotations into memory...
[1,71]<stdout>:loading annotations into memory...
[1,35]<stdout>:loading annotations into memory...
[1,50]<stdout>:loading annotations into memory...
[1,116]<stdout>:loading annotations into memory...
[1,84]<stdout>:loading annotations into memory...
[1,64]<stdout>:loading annotations into memory...
[1,83]<stdout>:loading annotations into memory...
[1,39]<stdout>:loading annotations into memory...
[1,33]<stdout>:loading annotations into memory...
[1,67]<stdout>:loading annotations into memory...
[1,81]<stdout>:loading annotations into memory...
[1,37]<stdout>:loading annotations into memory...
[1,0]<stdout>:Done (t=15.00s)
[1,0]<stdout>:creating index...
[1,7]<stdout>:Done (t=15.23s)
[1,7]<stdout>:creating index...
[1,0]<stdout>:index created!
[1,2]<stdout>:Done (t=15.39s)
[1,2]<stdout>:creating index...
[1,114]<stdout>:Done (t=15.43s)
[1,114]<stdout>:creating index...
[1,49]<stdout>:Done (t=15.20s)
[1,49]<stdout>:creating index...
[1,119]<stdout>:Done (t=15.52s)
[1,119]<stdout>:creating index...
[1,5]<stdout>:Done (t=15.26s)
[1,5]<stdout>:creating index...
[1,53]<stdout>:Done (t=15.35s)
[1,53]<stdout>:creating index...
[1,55]<stdout>:Done (t=15.15s)
[1,55]<stdout>:creating index...
[1,96]<stdout>:Done (t=15.38s)
[1,96]<stdout>:creating index...
[1,16]<stdout>:Done (t=15.12s)
[1,16]<stdout>:creating index...
[1,69]<stdout>:Done (t=15.06s)
[1,69]<stdout>:creating index...
[1,20]<stdout>:Done (t=15.63s)
[1,20]<stdout>:creating index...
[1,101]<stdout>:Done (t=15.24s)
[1,101]<stdout>:creating index...
[1,118]<stdout>:Done (t=15.34s)
[1,118]<stdout>:creating index...
[1,100]<stdout>:Done (t=15.12s)
[1,100]<stdout>:creating index...
[1,51]<stdout>:Done (t=15.27s)
[1,51]<stdout>:creating index...
[1,18]<stdout>:Done (t=15.51s)
[1,18]<stdout>:creating index...
[1,7]<stdout>:index created!
[1,1]<stdout>:Done (t=15.52s)
[1,1]<stdout>:creating index...
[1,97]<stdout>:Done (t=15.37s)
[1,97]<stdout>:creating index...
[1,23]<stdout>:Done (t=16.03s)
[1,23]<stdout>:creating index...
[1,86]<stdout>:Done (t=15.42s)
[1,86]<stdout>:creating index...
[1,22]<stdout>:Done (t=15.50s)
[1,22]<stdout>:creating index...
[1,65]<stdout>:Done (t=15.40s)
[1,65]<stdout>:creating index...
[1,38]<stdout>:Done (t=15.39s)
[1,38]<stdout>:creating index...
[1,21]<stdout>:Done (t=15.42s)
[1,21]<stdout>:creating index...
[1,102]<stdout>:Done (t=15.86s)
[1,102]<stdout>:creating index...
[1,2]<stdout>:index created!
[1,54]<stdout>:Done (t=15.91s)
[1,54]<stdout>:creating index...
[1,99]<stdout>:Done (t=15.64s)
[1,99]<stdout>:creating index...
[1,114]<stdout>:index created!
[1,112]<stdout>:Done (t=15.28s)
[1,112]<stdout>:creating index...
[1,82]<stdout>:Done (t=15.45s)
[1,82]<stdout>:creating index...
[1,6]<stdout>:Done (t=15.83s)
[1,6]<stdout>:creating index...
[1,103]<stdout>:Done (t=15.64s)
[1,103]<stdout>:creating index...
[1,3]<stdout>:Done (t=15.47s)
[1,3]<stdout>:creating index...
[1,119]<stdout>:index created!
[1,32]<stdout>:Done (t=15.75s)
[1,32]<stdout>:creating index...
[1,34]<stdout>:Done (t=15.57s)
[1,34]<stdout>:creating index...
[1,49]<stdout>:index created!
[1,115]<stdout>:Done (t=15.28s)
[1,115]<stdout>:creating index...
[1,66]<stdout>:Done (t=15.47s)
[1,66]<stdout>:creating index...
[1,85]<stdout>:Done (t=15.75s)
[1,85]<stdout>:creating index...
[1,5]<stdout>:index created!
[1,53]<stdout>:index created!
[1,80]<stdout>:Done (t=15.36s)
[1,80]<stdout>:creating index...
[1,16]<stdout>:index created!
[1,69]<stdout>:index created!
[1,17]<stdout>:Done (t=15.69s)
[1,17]<stdout>:creating index...
[1,20]<stdout>:index created!
[1,55]<stdout>:index created!
[1,96]<stdout>:index created!
[1,87]<stdout>:Done (t=16.09s)
[1,87]<stdout>:creating index...
[1,113]<stdout>:Done (t=16.09s)
[1,113]<stdout>:creating index...
[1,101]<stdout>:index created!
[1,4]<stdout>:Done (t=15.74s)
[1,4]<stdout>:creating index...
[1,67]<stdout>:Done (t=15.33s)
[1,67]<stdout>:creating index...
[1,118]<stdout>:index created!
[1,19]<stdout>:Done (t=16.10s)
[1,19]<stdout>:creating index...
[1,116]<stdout>:Done (t=15.59s)
[1,116]<stdout>:creating index...
[1,98]<stdout>:Done (t=15.94s)
[1,98]<stdout>:creating index...
[1,71]<stdout>:Done (t=15.75s)
[1,71]<stdout>:creating index...
[1,48]<stdout>:Done (t=15.89s)
[1,48]<stdout>:creating index...
[1,117]<stdout>:Done (t=15.88s)
[1,117]<stdout>:creating index...
[1,81]<stdout>:Done (t=15.48s)
[1,81]<stdout>:creating index...
[1,51]<stdout>:index created!
[1,23]<stdout>:index created!
[1,65]<stdout>:index created!
[1,37]<stdout>:Done (t=15.49s)
[1,37]<stdout>:creating index...
[1,70]<stdout>:Done (t=16.18s)
[1,70]<stdout>:creating index...
[1,1]<stdout>:index created!
[1,22]<stdout>:index created!
[1,100]<stdout>:index created!
[1,84]<stdout>:Done (t=15.71s)
[1,84]<stdout>:creating index...
[1,97]<stdout>:index created!
[1,52]<stdout>:Done (t=16.01s)
[1,52]<stdout>:creating index...
[1,38]<stdout>:index created!
[1,86]<stdout>:index created!
[1,102]<stdout>:index created!
[1,18]<stdout>:index created!
[1,35]<stdout>:Done (t=15.94s)
[1,35]<stdout>:creating index...
[1,68]<stdout>:Done (t=15.99s)
[1,68]<stdout>:creating index...
[1,36]<stdout>:Done (t=16.02s)
[1,36]<stdout>:creating index...
[1,112]<stdout>:index created!
[1,21]<stdout>:index created!
[1,6]<stdout>:index created!
[1,83]<stdout>:Done (t=15.86s)
[1,83]<stdout>:creating index...
[1,50]<stdout>:Done (t=15.99s)
[1,50]<stdout>:creating index...
[1,54]<stdout>:index created!
[1,99]<stdout>:index created!
[1,82]<stdout>:index created!
[1,3]<stdout>:index created!
[1,32]<stdout>:index created!
[1,39]<stdout>:Done (t=16.01s)
[1,39]<stdout>:creating index...
[1,34]<stdout>:index created!
[1,103]<stdout>:index created!
[1,64]<stdout>:Done (t=16.10s)
[1,64]<stdout>:creating index...
[1,80]<stdout>:index created!
[1,85]<stdout>:index created!
[1,66]<stdout>:index created!
[1,115]<stdout>:index created!
[1,113]<stdout>:index created!
[1,87]<stdout>:index created!
[1,17]<stdout>:index created!
[1,33]<stdout>:Done (t=16.37s)
[1,33]<stdout>:creating index...
[1,19]<stdout>:index created!
[1,116]<stdout>:index created!
[1,48]<stdout>:index created!
[1,67]<stdout>:index created!
[1,98]<stdout>:index created!
[1,4]<stdout>:index created!
[1,81]<stdout>:index created!
[1,70]<stdout>:index created!
[1,117]<stdout>:index created!
[1,52]<stdout>:index created!
[1,71]<stdout>:index created!
[1,68]<stdout>:index created!
[1,84]<stdout>:index created!
[1,35]<stdout>:index created!
[1,36]<stdout>:index created!
[1,37]<stdout>:index created!
[1,50]<stdout>:index created!
[1,83]<stdout>:index created!
[1,64]<stdout>:index created!
[1,39]<stdout>:index created!
[1,33]<stdout>:index created!
[1,0]<stdout>:loading annotations into memory...
[1,7]<stdout>:loading annotations into memory...
[1,2]<stdout>:loading annotations into memory...
[1,119]<stdout>:loading annotations into memory...
[1,114]<stdout>:loading annotations into memory...
[1,49]<stdout>:loading annotations into memory...
[1,5]<stdout>:loading annotations into memory...
[1,96]<stdout>:loading annotations into memory...
[1,69]<stdout>:loading annotations into memory...
[1,53]<stdout>:loading annotations into memory...
[1,16]<stdout>:loading annotations into memory...
[1,20]<stdout>:loading annotations into memory...
[1,2]<stdout>:Done (t=0.45s)
[1,2]<stdout>:creating index...
[1,55]<stdout>:loading annotations into memory...
[1,2]<stdout>:index created!
[1,101]<stdout>:loading annotations into memory...
[1,2]<stdout>:setting Step LR 0.1599999964237213
[1,2]<stdout>:0.16 0.1 0 [8, 11] 0
[1,118]<stdout>:loading annotations into memory...
[1,2]<stdout>:Starting new loop for GPU: 2
[1,65]<stdout>:loading annotations into memory...
[1,96]<stdout>:Done (t=0.45s)
[1,96]<stdout>:creating index...
[1,96]<stdout>:index created!
[1,53]<stdout>:Done (t=0.45s)
[1,53]<stdout>:creating index...
[1,23]<stdout>:loading annotations into memory...
[1,53]<stdout>:index created!
[1,22]<stdout>:loading annotations into memory...
[1,100]<stdout>:loading annotations into memory...
[1,20]<stdout>:Done (t=0.45s)
[1,20]<stdout>:creating index...
[1,1]<stdout>:loading annotations into memory...
[1,96]<stdout>:setting Step LR 0.1599999964237213
[1,96]<stdout>:0.16 0.1 0 [8, 11] 0
[1,86]<stdout>:loading annotations into memory...
[1,55]<stdout>:Done (t=0.45s)
[1,55]<stdout>:creating index...
[1,51]<stdout>:loading annotations into memory...
[1,20]<stdout>:index created!
[1,96]<stdout>:Starting new loop for GPU: 48
[1,55]<stdout>:index created!
[1,53]<stdout>:setting Step LR 0.1599999964237213
[1,53]<stdout>:0.16 0.1 0 [8, 11] 0
[1,53]<stdout>:Starting new loop for GPU: 29
[1,38]<stdout>:loading annotations into memory...
[1,18]<stdout>:loading annotations into memory...
[1,21]<stdout>:loading annotations into memory...
[1,112]<stdout>:loading annotations into memory...
[1,20]<stdout>:setting Step LR 0.1599999964237213
[1,20]<stdout>:0.16 0.1 0 [8, 11] 0
[1,20]<stdout>:Starting new loop for GPU: 12
[1,97]<stdout>:loading annotations into memory...
[1,55]<stdout>:setting Step LR 0.1599999964237213
[1,55]<stdout>:0.16 0.1 0 [8, 11] 0
[1,55]<stdout>:Starting new loop for GPU: 31
[1,99]<stdout>:loading annotations into memory...
[1,102]<stdout>:loading annotations into memory...
[1,23]<stdout>:Done (t=0.46s)
[1,23]<stdout>:creating index...
[1,82]<stdout>:loading annotations into memory...
[1,6]<stdout>:loading annotations into memory...
[1,32]<stdout>:loading annotations into memory...
[1,23]<stdout>:index created!
[1,3]<stdout>:loading annotations into memory...
[1,1]<stdout>:Done (t=0.45s)
[1,1]<stdout>:creating index...
[1,86]<stdout>:Done (t=0.45s)
[1,86]<stdout>:creating index...
[1,103]<stdout>:loading annotations into memory...
[1,34]<stdout>:loading annotations into memory...
[1,1]<stdout>:index created!
[1,80]<stdout>:loading annotations into memory...
[1,86]<stdout>:index created!
[1,66]<stdout>:loading annotations into memory...
[1,23]<stdout>:setting Step LR 0.1599999964237213
[1,23]<stdout>:0.16 0.1 0 [8, 11] 0
[1,51]<stdout>:Done (t=0.51s)
[1,51]<stdout>:creating index...
[1,115]<stdout>:loading annotations into memory...
[1,113]<stdout>:loading annotations into memory...
[1,38]<stdout>:Done (t=0.45s)
[1,38]<stdout>:creating index...
[1,23]<stdout>:Starting new loop for GPU: 15
[1,51]<stdout>:index created!
[1,38]<stdout>:index created!
[1,21]<stdout>:Done (t=0.46s)
[1,21]<stdout>:creating index...
[1,1]<stdout>:setting Step LR 0.1599999964237213
[1,1]<stdout>:0.16 0.1 0 [8, 11] 0
[1,112]<stdout>:Done (t=0.45s)
[1,112]<stdout>:creating index...
[1,18]<stdout>:Done (t=0.50s)
[1,18]<stdout>:creating index...
[1,86]<stdout>:setting Step LR 0.1599999964237213
[1,86]<stdout>:0.16 0.1 0 [8, 11] 0
[1,21]<stdout>:index created!
[1,112]<stdout>:index created!
[1,1]<stdout>:Starting new loop for GPU: 1
[1,18]<stdout>:index created!
[1,86]<stdout>:Starting new loop for GPU: 46
[1,0]<stdout>:Done (t=2.68s)
[1,0]<stdout>:creating index...
[1,38]<stdout>:setting Step LR 0.1599999964237213
[1,38]<stdout>:0.16 0.1 0 [8, 11] 0
[1,54]<stdout>:loading annotations into memory...
[1,0]<stdout>:index created!
[1,51]<stdout>:setting Step LR 0.1599999964237213
[1,51]<stdout>:0.16 0.1 0 [8, 11] 0
[1,38]<stdout>:Starting new loop for GPU: 22
[1,99]<stdout>:Done (t=0.45s)
[1,99]<stdout>:creating index...
[1,85]<stdout>:loading annotations into memory...
[1,112]<stdout>:setting Step LR 0.1599999964237213
[1,112]<stdout>:0.16 0.1 0 [8, 11] 0
[1,51]<stdout>:Starting new loop for GPU: 27
[1,21]<stdout>:setting Step LR 0.1599999964237213
[1,21]<stdout>:0.16 0.1 0 [8, 11] 0
[1,18]<stdout>:setting Step LR 0.1599999964237213
[1,18]<stdout>:0.16 0.1 0 [8, 11] 0
[1,99]<stdout>:index created!
[1,112]<stdout>:Starting new loop for GPU: 56
[1,18]<stdout>:Starting new loop for GPU: 10
[1,21]<stdout>:Starting new loop for GPU: 13
[1,32]<stdout>:Done (t=0.47s)
[1,32]<stdout>:creating index...
[1,0]<stderr>:2020-09-18 19:27:09,180 - INFO - Start running, host: ubuntu@ip-192-168-64-81, work_dir: /shared/deep-learning-models/models/vision/detection/work_dirs/mask_rcnn_r50v1_d_fpn_1x_coco
[1,0]<stderr>:2020-09-18 19:27:09,180 - INFO - workflow: [('train', 1)], max: 12 epochs
[1,17]<stdout>:loading annotations into memory...
[1,0]<stdout>:setting Step LR 0.1599999964237213
[1,0]<stdout>:0.16 0.1 0 [8, 11] 0
[1,81]<stdout>:loading annotations into memory...
[1,32]<stdout>:index created!
[1,99]<stdout>:setting Step LR 0.1599999964237213
[1,99]<stdout>:0.16 0.1 0 [8, 11] 0
[1,0]<stdout>:Starting new loop for GPU: 0
[1,103]<stdout>:Done (t=0.45s)
[1,103]<stdout>:creating index...
[1,87]<stdout>:loading annotations into memory...
[1,34]<stdout>:Done (t=0.47s)
[1,34]<stdout>:creating index...
[1,99]<stdout>:Starting new loop for GPU: 51
[1,103]<stdout>:index created!
[1,66]<stdout>:Done (t=0.45s)
[1,66]<stdout>:creating index...
[1,34]<stdout>:index created!
[1,52]<stdout>:loading annotations into memory...
[1,19]<stdout>:loading annotations into memory...
[1,66]<stdout>:index created!
[1,113]<stdout>:Done (t=0.45s)
[1,113]<stdout>:creating index...
[1,48]<stdout>:loading annotations into memory...
[1,68]<stdout>:loading annotations into memory...
[1,98]<stdout>:loading annotations into memory...
[1,113]<stdout>:index created!
[1,32]<stdout>:setting Step LR 0.1599999964237213
[1,32]<stdout>:0.16 0.1 0 [8, 11] 0
[1,32]<stdout>:Starting new loop for GPU: 16
[1,70]<stdout>:loading annotations into memory...
[1,67]<stdout>:loading annotations into memory...
[1,66]<stdout>:setting Step LR 0.1599999964237213
[1,66]<stdout>:0.16 0.1 0 [8, 11] 0
[1,50]<stdout>:loading annotations into memory...
[1,34]<stdout>:setting Step LR 0.1599999964237213
[1,34]<stdout>:0.16 0.1 0 [8, 11] 0
[1,84]<stdout>:loading annotations into memory...
[1,103]<stdout>:setting Step LR 0.1599999964237213
[1,103]<stdout>:0.16 0.1 0 [8, 11] 0
[1,66]<stdout>:Starting new loop for GPU: 34
[1,54]<stdout>:Done (t=0.45s)
[1,54]<stdout>:creating index...
[1,113]<stdout>:setting Step LR 0.1599999964237213
[1,113]<stdout>:0.16 0.1 0 [8, 11] 0
[1,34]<stdout>:Starting new loop for GPU: 18
[1,54]<stdout>:index created!
[1,113]<stdout>:Starting new loop for GPU: 57
[1,103]<stdout>:Starting new loop for GPU: 55
[1,54]<stdout>:setting Step LR 0.1599999964237213
[1,54]<stdout>:0.16 0.1 0 [8, 11] 0
[1,81]<stdout>:Done (t=0.46s)
[1,81]<stdout>:creating index...
[1,4]<stdout>:loading annotations into memory...
[1,54]<stdout>:Starting new loop for GPU: 30
[1,117]<stdout>:loading annotations into memory...
[1,81]<stdout>:index created!
[1,36]<stdout>:loading annotations into memory...
[1,87]<stdout>:Done (t=0.46s)
[1,87]<stdout>:creating index...
[1,83]<stdout>:loading annotations into memory...
[1,64]<stdout>:loading annotations into memory...
[1,35]<stdout>:loading annotations into memory...
[1,17]<stdout>:Done (t=0.54s)
[1,17]<stdout>:creating index...
[1,87]<stdout>:index created!
[1,7]<stdout>:Done (t=2.64s)
[1,7]<stdout>:creating index...
[1,17]<stdout>:index created!
[1,71]<stdout>:loading annotations into memory...
[1,7]<stdout>:index created!
[1,98]<stdout>:Done (t=0.46s)
[1,98]<stdout>:creating index...
[1,19]<stdout>:Done (t=0.51s)
[1,19]<stdout>:creating index...
[1,81]<stdout>:setting Step LR 0.1599999964237213
[1,81]<stdout>:0.16 0.1 0 [8, 11] 0
[1,98]<stdout>:index created!
[1,19]<stdout>:index created!
[1,116]<stdout>:loading annotations into memory...
[1,81]<stdout>:Starting new loop for GPU: 41
[1,87]<stdout>:setting Step LR 0.1599999964237213
[1,87]<stdout>:0.16 0.1 0 [8, 11] 0
[1,37]<stdout>:loading annotations into memory...
[1,67]<stdout>:Done (t=0.45s)
[1,67]<stdout>:creating index...
[1,17]<stdout>:setting Step LR 0.1599999964237213
[1,17]<stdout>:0.16 0.1 0 [8, 11] 0
[1,87]<stdout>:Starting new loop for GPU: 47
[1,39]<stdout>:loading annotations into memory...
[1,67]<stdout>:index created!
[1,50]<stdout>:Done (t=0.48s)
[1,50]<stdout>:creating index...
[1,17]<stdout>:Starting new loop for GPU: 9
[1,7]<stdout>:setting Step LR 0.1599999964237213
[1,7]<stdout>:0.16 0.1 0 [8, 11] 0
[1,50]<stdout>:index created!
[1,7]<stdout>:Starting new loop for GPU: 7
[1,98]<stdout>:setting Step LR 0.1599999964237213
[1,98]<stdout>:0.16 0.1 0 [8, 11] 0
[1,19]<stdout>:setting Step LR 0.1599999964237213
[1,19]<stdout>:0.16 0.1 0 [8, 11] 0
[1,98]<stdout>:Starting new loop for GPU: 50
[1,19]<stdout>:Starting new loop for GPU: 11
[1,67]<stdout>:setting Step LR 0.1599999964237213
[1,67]<stdout>:0.16 0.1 0 [8, 11] 0
[1,67]<stdout>:Starting new loop for GPU: 35
[1,50]<stdout>:setting Step LR 0.1599999964237213
[1,50]<stdout>:0.16 0.1 0 [8, 11] 0
[1,119]<stdout>:Done (t=2.64s)
[1,119]<stdout>:creating index...
[1,4]<stdout>:Done (t=0.46s)
[1,4]<stdout>:creating index...
[1,50]<stdout>:Starting new loop for GPU: 26
[1,119]<stdout>:index created!
[1,4]<stdout>:index created!
[1,33]<stdout>:loading annotations into memory...
[1,114]<stdout>:Done (t=2.61s)
[1,114]<stdout>:creating index...
[1,117]<stdout>:Done (t=0.49s)
[1,117]<stdout>:creating index...
[1,64]<stdout>:Done (t=0.47s)
[1,64]<stdout>:creating index...
[1,114]<stdout>:index created!
[1,117]<stdout>:index created!
[1,64]<stdout>:index created!
[1,71]<stdout>:Done (t=0.46s)
[1,71]<stdout>:creating index...
[1,71]<stdout>:index created!
[1,119]<stdout>:setting Step LR 0.1599999964237213
[1,119]<stdout>:0.16 0.1 0 [8, 11] 0
[1,4]<stdout>:setting Step LR 0.1599999964237213
[1,4]<stdout>:0.16 0.1 0 [8, 11] 0
[1,119]<stdout>:Starting new loop for GPU: 63
[1,4]<stdout>:Starting new loop for GPU: 4
[1,114]<stdout>:setting Step LR 0.1599999964237213
[1,114]<stdout>:0.16 0.1 0 [8, 11] 0
[1,117]<stdout>:setting Step LR 0.1599999964237213
[1,117]<stdout>:0.16 0.1 0 [8, 11] 0
[1,64]<stdout>:setting Step LR 0.1599999964237213
[1,64]<stdout>:0.16 0.1 0 [8, 11] 0
[1,5]<stdout>:Done (t=2.73s)
[1,5]<stdout>:creating index...
[1,114]<stdout>:Starting new loop for GPU: 58
[1,71]<stdout>:setting Step LR 0.1599999964237213
[1,71]<stdout>:0.16 0.1 0 [8, 11] 0
[1,64]<stdout>:Starting new loop for GPU: 32
[1,117]<stdout>:Starting new loop for GPU: 61
[1,5]<stdout>:index created!
[1,69]<stdout>:Done (t=2.65s)
[1,69]<stdout>:creating index...
[1,71]<stdout>:Starting new loop for GPU: 39
[1,49]<stdout>:Done (t=2.82s)
[1,49]<stdout>:creating index...
[1,69]<stdout>:index created!
[1,16]<stdout>:Done (t=2.70s)
[1,16]<stdout>:creating index...
[1,49]<stdout>:index created!
[1,5]<stdout>:setting Step LR 0.1599999964237213
[1,5]<stdout>:0.16 0.1 0 [8, 11] 0
[1,16]<stdout>:index created!
[1,5]<stdout>:Starting new loop for GPU: 5
[1,101]<stdout>:Done (t=2.70s)
[1,101]<stdout>:creating index...
[1,33]<stdout>:Done (t=0.45s)
[1,33]<stdout>:creating index...
[1,69]<stdout>:setting Step LR 0.1599999964237213
[1,69]<stdout>:0.16 0.1 0 [8, 11] 0
[1,49]<stdout>:setting Step LR 0.1599999964237213
[1,49]<stdout>:0.16 0.1 0 [8, 11] 0
[1,101]<stdout>:index created!
[1,33]<stdout>:index created!
[1,49]<stdout>:Starting new loop for GPU: 25
[1,69]<stdout>:Starting new loop for GPU: 37
[1,16]<stdout>:setting Step LR 0.1599999964237213
[1,16]<stdout>:0.16 0.1 0 [8, 11] 0
[1,16]<stdout>:Starting new loop for GPU: 8
[1,101]<stdout>:setting Step LR 0.1599999964237213
[1,101]<stdout>:0.16 0.1 0 [8, 11] 0
[1,33]<stdout>:setting Step LR 0.1599999964237213
[1,33]<stdout>:0.16 0.1 0 [8, 11] 0
[1,118]<stdout>:Done (t=2.75s)
[1,118]<stdout>:creating index...
[1,101]<stdout>:Starting new loop for GPU: 53
[1,65]<stdout>:Done (t=2.63s)
[1,65]<stdout>:creating index...
[1,33]<stdout>:Starting new loop for GPU: 17
[1,118]<stdout>:index created!
[1,65]<stdout>:index created!
[1,118]<stdout>:setting Step LR 0.1599999964237213
[1,118]<stdout>:0.16 0.1 0 [8, 11] 0
[1,118]<stdout>:Starting new loop for GPU: 62
[1,100]<stdout>:Done (t=2.71s)
[1,100]<stdout>:creating index...
[1,65]<stdout>:setting Step LR 0.1599999964237213
[1,65]<stdout>:0.16 0.1 0 [8, 11] 0
[1,65]<stdout>:Starting new loop for GPU: 33
[1,100]<stdout>:index created!
[1,22]<stdout>:Done (t=2.80s)
[1,22]<stdout>:creating index...
[1,22]<stdout>:index created!
[1,100]<stdout>:setting Step LR 0.1599999964237213
[1,100]<stdout>:0.16 0.1 0 [8, 11] 0
[1,100]<stdout>:Starting new loop for GPU: 52
[1,97]<stdout>:Done (t=2.69s)
[1,97]<stdout>:creating index...
[1,22]<stdout>:setting Step LR 0.1599999964237213
[1,22]<stdout>:0.16 0.1 0 [8, 11] 0
[1,97]<stdout>:index created!
[1,22]<stdout>:Starting new loop for GPU: 14
[1,82]<stdout>:Done (t=2.69s)
[1,82]<stdout>:creating index...
[1,82]<stdout>:index created!
[1,97]<stdout>:setting Step LR 0.1599999964237213
[1,97]<stdout>:0.16 0.1 0 [8, 11] 0
[1,97]<stdout>:Starting new loop for GPU: 49
[1,3]<stdout>:Done (t=2.81s)
[1,3]<stdout>:creating index...
[1,82]<stdout>:setting Step LR 0.1599999964237213
[1,82]<stdout>:0.16 0.1 0 [8, 11] 0
[1,3]<stdout>:index created!
[1,82]<stdout>:Starting new loop for GPU: 42
[1,102]<stdout>:Done (t=2.98s)
[1,102]<stdout>:creating index...
[1,102]<stdout>:index created!
[1,6]<stdout>:Done (t=2.99s)
[1,6]<stdout>:creating index...
[1,80]<stdout>:Done (t=2.88s)
[1,80]<stdout>:creating index...
[1,3]<stdout>:setting Step LR 0.1599999964237213
[1,3]<stdout>:0.16 0.1 0 [8, 11] 0
[1,6]<stdout>:index created!
[1,115]<stdout>:Done (t=2.87s)
[1,115]<stdout>:creating index...
[1,80]<stdout>:index created!
[1,3]<stdout>:Starting new loop for GPU: 3
[1,115]<stdout>:index created!
[1,102]<stdout>:setting Step LR 0.1599999964237213
[1,102]<stdout>:0.16 0.1 0 [8, 11] 0
[1,102]<stdout>:Starting new loop for GPU: 54
[1,6]<stdout>:setting Step LR 0.1599999964237213
[1,6]<stdout>:0.16 0.1 0 [8, 11] 0
[1,6]<stdout>:Starting new loop for GPU: 6
[1,80]<stdout>:setting Step LR 0.1599999964237213
[1,80]<stdout>:0.16 0.1 0 [8, 11] 0
[1,85]<stdout>:Done (t=2.82s)
[1,85]<stdout>:creating index...
[1,80]<stdout>:Starting new loop for GPU: 40
[1,115]<stdout>:setting Step LR 0.1599999964237213
[1,115]<stdout>:0.16 0.1 0 [8, 11] 0
[1,85]<stdout>:index created!
[1,115]<stdout>:Starting new loop for GPU: 59
[1,85]<stdout>:setting Step LR 0.1599999964237213
[1,85]<stdout>:0.16 0.1 0 [8, 11] 0
[1,52]<stdout>:Done (t=2.77s)
[1,52]<stdout>:creating index...
[1,85]<stdout>:Starting new loop for GPU: 45
[1,52]<stdout>:index created!
[1,84]<stdout>:Done (t=2.75s)
[1,84]<stdout>:creating index...
[1,52]<stdout>:setting Step LR 0.1599999964237213
[1,52]<stdout>:0.16 0.1 0 [8, 11] 0
[1,52]<stdout>:Starting new loop for GPU: 28
[1,84]<stdout>:index created!
[1,68]<stdout>:Done (t=2.95s)
[1,68]<stdout>:creating index...
[1,48]<stdout>:Done (t=2.96s)
[1,48]<stdout>:creating index...
[1,68]<stdout>:index created!
[1,48]<stdout>:index created!
[1,84]<stdout>:setting Step LR 0.1599999964237213
[1,84]<stdout>:0.16 0.1 0 [8, 11] 0
[1,84]<stdout>:Starting new loop for GPU: 44
[1,68]<stdout>:setting Step LR 0.1599999964237213
[1,68]<stdout>:0.16 0.1 0 [8, 11] 0
[1,48]<stdout>:setting Step LR 0.1599999964237213
[1,48]<stdout>:0.16 0.1 0 [8, 11] 0
[1,68]<stdout>:Starting new loop for GPU: 36
[1,48]<stdout>:Starting new loop for GPU: 24
[1,36]<stdout>:Done (t=2.87s)
[1,36]<stdout>:creating index...
[1,70]<stdout>:Done (t=3.15s)
[1,70]<stdout>:creating index...
[1,36]<stdout>:index created!
[1,70]<stdout>:index created!
[1,37]<stdout>:Done (t=2.80s)
[1,37]<stdout>:creating index...
[1,37]<stdout>:index created!
[1,116]<stdout>:Done (t=2.85s)
[1,116]<stdout>:creating index...
[1,35]<stdout>:Done (t=2.98s)
[1,35]<stdout>:creating index...
[1,116]<stdout>:index created!
[1,36]<stdout>:setting Step LR 0.1599999964237213
[1,36]<stdout>:0.16 0.1 0 [8, 11] 0
[1,35]<stdout>:index created!
[1,83]<stdout>:Done (t=3.05s)
[1,83]<stdout>:creating index...
[1,36]<stdout>:Starting new loop for GPU: 20
[1,70]<stdout>:setting Step LR 0.1599999964237213
[1,70]<stdout>:0.16 0.1 0 [8, 11] 0
[1,83]<stdout>:index created!
[1,70]<stdout>:Starting new loop for GPU: 38
[1,37]<stdout>:setting Step LR 0.1599999964237213
[1,37]<stdout>:0.16 0.1 0 [8, 11] 0
[1,37]<stdout>:Starting new loop for GPU: 21
[1,116]<stdout>:setting Step LR 0.1599999964237213
[1,116]<stdout>:0.16 0.1 0 [8, 11] 0
[1,35]<stdout>:setting Step LR 0.1599999964237213
[1,35]<stdout>:0.16 0.1 0 [8, 11] 0
[1,39]<stdout>:Done (t=2.96s)
[1,39]<stdout>:creating index...
[1,116]<stdout>:Starting new loop for GPU: 60
[1,35]<stdout>:Starting new loop for GPU: 19
[1,39]<stdout>:index created!
[1,83]<stdout>:setting Step LR 0.1599999964237213
[1,83]<stdout>:0.16 0.1 0 [8, 11] 0
[1,83]<stdout>:Starting new loop for GPU: 43
[1,39]<stdout>:setting Step LR 0.1599999964237213
[1,39]<stdout>:0.16 0.1 0 [8, 11] 0
[1,39]<stdout>:Starting new loop for GPU: 23
[1,0]<stderr>:2020-09-18 19:27:28.658034: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,114]<stderr>:2020-09-18 19:27:30.088644: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,2]<stderr>:2020-09-18 19:27:30.147876: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,96]<stderr>:2020-09-18 19:27:30.168493: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,5]<stderr>:2020-09-18 19:27:30.176846: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,49]<stderr>:2020-09-18 19:27:30.209648: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,55]<stderr>:2020-09-18 19:27:30.340019: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,16]<stderr>:2020-09-18 19:27:30.439791: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,69]<stderr>:2020-09-18 19:27:30.510552: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,101]<stderr>:2020-09-18 19:27:30.511952: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,7]<stderr>:2020-09-18 19:27:30.602295: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,53]<stderr>:2020-09-18 19:27:30.665584: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,20]<stderr>:2020-09-18 19:27:30.755493: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,86]<stderr>:2020-09-18 19:27:30.757038: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,118]<stderr>:2020-09-18 19:27:30.787524: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,65]<stderr>:2020-09-18 19:27:30.998021: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,1]<stderr>:2020-09-18 19:27:31.004086: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,51]<stderr>:2020-09-18 19:27:31.074797: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,100]<stderr>:2020-09-18 19:27:31.201080: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,18]<stderr>:2020-09-18 19:27:31.235563: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,82]<stderr>:2020-09-18 19:27:31.242345: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,99]<stderr>:2020-09-18 19:27:31.369721: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,22]<stderr>:2020-09-18 19:27:31.397200: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,21]<stderr>:2020-09-18 19:27:31.437972: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,6]<stderr>:2020-09-18 19:27:31.509102: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,97]<stderr>:2020-09-18 19:27:31.523394: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,54]<stderr>:2020-09-18 19:27:31.589735: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,19]<stderr>:2020-09-18 19:27:31.636286: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,52]<stderr>:2020-09-18 19:27:31.651985: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,112]<stderr>:2020-09-18 19:27:31.665417: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,32]<stderr>:2020-09-18 19:27:31.690824: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,66]<stderr>:2020-09-18 19:27:31.819919: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,3]<stderr>:2020-09-18 19:27:31.828533: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,102]<stderr>:2020-09-18 19:27:31.855262: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,38]<stderr>:2020-09-18 19:27:31.927463: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,34]<stderr>:2020-09-18 19:27:31.938460: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,119]<stderr>:2020-09-18 19:27:31.991492: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,23]<stderr>:2020-09-18 19:27:32.023367: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,48]<stderr>:2020-09-18 19:27:32.050568: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,115]<stderr>:2020-09-18 19:27:32.058516: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,113]<stderr>:2020-09-18 19:27:32.059728: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,85]<stderr>:2020-09-18 19:27:32.090782: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,70]<stderr>:2020-09-18 19:27:32.222193: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,50]<stderr>:2020-09-18 19:27:32.318921: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,84]<stderr>:2020-09-18 19:27:32.368312: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,116]<stderr>:2020-09-18 19:27:32.385395: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,80]<stderr>:2020-09-18 19:27:32.400748: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,4]<stderr>:2020-09-18 19:27:32.475827: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,117]<stderr>:2020-09-18 19:27:32.477592: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,36]<stderr>:2020-09-18 19:27:32.488233: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,83]<stderr>:2020-09-18 19:27:32.490557: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,103]<stderr>:2020-09-18 19:27:32.602091: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,87]<stderr>:2020-09-18 19:27:32.657047: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,17]<stderr>:2020-09-18 19:27:32.671679: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,37]<stderr>:2020-09-18 19:27:32.789003: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,68]<stderr>:2020-09-18 19:27:32.833548: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,39]<stderr>:2020-09-18 19:27:32.878520: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,67]<stderr>:2020-09-18 19:27:32.893935: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,98]<stderr>:2020-09-18 19:27:32.904221: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,0]<stderr>:2020-09-18 19:27:32.984811: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,81]<stderr>:2020-09-18 19:27:33.079058: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,35]<stderr>:2020-09-18 19:27:33.079341: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,64]<stderr>:2020-09-18 19:27:33.147478: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,71]<stderr>:2020-09-18 19:27:33.217740: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,33]<stderr>:2020-09-18 19:27:33.546245: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8845 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,114]<stderr>:2020-09-18 19:27:34.460805: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,2]<stderr>:2020-09-18 19:27:34.483552: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,5]<stderr>:2020-09-18 19:27:34.519311: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,96]<stderr>:2020-09-18 19:27:34.524003: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,49]<stderr>:2020-09-18 19:27:34.542249: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,55]<stderr>:2020-09-18 19:27:34.648861: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,16]<stderr>:2020-09-18 19:27:34.761176: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,69]<stderr>:2020-09-18 19:27:34.839006: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,101]<stderr>:2020-09-18 19:27:34.846576: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,7]<stderr>:2020-09-18 19:27:34.936710: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,53]<stderr>:2020-09-18 19:27:34.974936: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,20]<stderr>:2020-09-18 19:27:35.108373: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,86]<stderr>:2020-09-18 19:27:35.134219: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,118]<stderr>:2020-09-18 19:27:35.136995: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,1]<stderr>:2020-09-18 19:27:35.338069: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,51]<stderr>:2020-09-18 19:27:35.362184: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,65]<stderr>:2020-09-18 19:27:35.436574: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,18]<stderr>:2020-09-18 19:27:35.540560: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,100]<stderr>:2020-09-18 19:27:35.549238: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,82]<stderr>:2020-09-18 19:27:35.589723: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,99]<stderr>:2020-09-18 19:27:35.685793: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,22]<stderr>:2020-09-18 19:27:35.763359: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,21]<stderr>:2020-09-18 19:27:35.830894: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,6]<stderr>:2020-09-18 19:27:35.896796: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,97]<stderr>:2020-09-18 19:27:35.901217: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,54]<stderr>:2020-09-18 19:27:35.903722: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,0]<stdout>:ip-192-168-64-81:24882:25471 [0] NCCL INFO Launch mode Parallel
[1,19]<stderr>:2020-09-18 19:27:35.975184: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,112]<stderr>:2020-09-18 19:27:36.005061: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,52]<stderr>:2020-09-18 19:27:36.020487: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,32]<stderr>:2020-09-18 19:27:36.078937: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,66]<stderr>:2020-09-18 19:27:36.147894: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,102]<stderr>:2020-09-18 19:27:36.209372: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,3]<stderr>:2020-09-18 19:27:36.209276: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,38]<stderr>:2020-09-18 19:27:36.288011: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,34]<stderr>:2020-09-18 19:27:36.325595: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,113]<stderr>:2020-09-18 19:27:36.380021: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,23]<stderr>:2020-09-18 19:27:36.413049: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,115]<stderr>:2020-09-18 19:27:36.420505: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,85]<stderr>:2020-09-18 19:27:36.444208: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,48]<stderr>:2020-09-18 19:27:36.454088: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,70]<stderr>:2020-09-18 19:27:36.597369: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,119]<stderr>:2020-09-18 19:27:36.599895: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,50]<stderr>:2020-09-18 19:27:36.659554: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,116]<stderr>:2020-09-18 19:27:36.721043: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,84]<stderr>:2020-09-18 19:27:36.749625: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,4]<stderr>:2020-09-18 19:27:36.778778: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,117]<stderr>:2020-09-18 19:27:36.826499: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,36]<stderr>:2020-09-18 19:27:36.830366: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,83]<stderr>:2020-09-18 19:27:36.830249: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,80]<stderr>:2020-09-18 19:27:36.949413: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,103]<stderr>:2020-09-18 19:27:36.954278: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,87]<stderr>:2020-09-18 19:27:37.019207: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,17]<stderr>:2020-09-18 19:27:37.018395: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,37]<stderr>:2020-09-18 19:27:37.194747: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,68]<stderr>:2020-09-18 19:27:37.209933: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,67]<stderr>:2020-09-18 19:27:37.232421: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,39]<stderr>:2020-09-18 19:27:37.254749: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,98]<stderr>:2020-09-18 19:27:37.276060: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,81]<stderr>:2020-09-18 19:27:37.418039: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,35]<stderr>:2020-09-18 19:27:37.419551: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,64]<stderr>:2020-09-18 19:27:37.529764: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,71]<stderr>:2020-09-18 19:27:37.574622: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,33]<stderr>:2020-09-18 19:27:37.965832: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,87]<stdout>:Rank 47 broadcasting
[1,81]<stdout>:Rank 41 broadcasting
[1,17]<stdout>:Rank 9 broadcasting
[1,98]<stdout>:Rank 50 broadcasting
[1,64]<stdout>:Rank 32 broadcasting
[1,23]<stdout>:Rank 15 broadcasting
[1,67]<stdout>:Rank 35 broadcasting
[1,48]<stdout>:Rank 24 broadcasting
[1,6]<stdout>:Rank 6 broadcasting
[1,65]<stdout>:Rank 33 broadcasting
[1,33]<stdout>:Rank 17 broadcasting
[1,71]<stdout>:Rank 39 broadcasting
[1,70]<stdout>:Rank 38 broadcasting
[1,83]<stdout>:Rank 43 broadcasting
[1,22]<stdout>:Rank 14 broadcasting
[1,7]<stdout>:Rank 7 broadcasting
[1,35]<stdout>:Rank 19 broadcasting
[1,21]<stdout>:Rank 13 broadcasting
[1,37]<stdout>:Rank 21 broadcasting
[1,39]<stdout>:Rank 23 broadcasting
[1,85]<stdout>:Rank 45 broadcasting
[1,66]<stdout>:Rank 34 broadcasting
[1,20]<stdout>:Rank 12 broadcasting
[1,16]<stdout>:Rank 8 broadcasting
[1,103]<stdout>:Rank 55 broadcasting
[1,101]<stdout>:Rank 53 broadcasting
[1,68]<stdout>:Rank 36 broadcasting
[1,3]<stdout>:Rank 3 broadcasting
[1,117]<stdout>:Rank 61 broadcasting
[1,99]<stdout>:Rank 51 broadcasting
[1,116]<stdout>:Rank 60 broadcasting
[1,84]<stdout>:Rank 44 broadcasting
[1,53]<stdout>:Rank 29 broadcasting
[1,80]<stdout>:Rank 40 broadcasting
[1,4]<stdout>:Rank 4 broadcasting
[1,55]<stdout>:Rank 31 broadcasting
[1,50]<stdout>:Rank 26 broadcasting
[1,119]<stdout>:Rank 63 broadcasting
[1,32]<stdout>:Rank 16 broadcasting
[1,5]<stdout>:Rank 5 broadcasting
[1,34]<stdout>:Rank 18 broadcasting
[1,38]<stdout>:Rank 22 broadcasting
[1,97]<stdout>:Rank 49 broadcasting
[1,52]<stdout>:Rank 28 broadcasting
[1,113]<stdout>:Rank 57 broadcasting
[1,51]<stdout>:Rank 27 broadcasting
[1,54]<stdout>:Rank 30 broadcasting
[1,49]<stdout>:Rank 25 broadcasting
[1,36]<stdout>:Rank 20 broadcasting
[1,2]<stdout>:Rank 2 broadcasting
[1,1]<stdout>:Rank 1 broadcasting
[1,69]<stdout>:Rank 37 broadcasting
[1,114]<stdout>:Rank 58 broadcasting
[1,112]<stdout>:Rank 56 broadcasting
[1,19]<stdout>:Rank 11 broadcasting
[1,18]<stdout>:Rank 10 broadcasting
[1,100]<stdout>:Rank 52 broadcasting
[1,102]<stdout>:Rank 54 broadcasting
[1,115]<stdout>:Rank 59 broadcasting
[1,82]<stdout>:Rank 42 broadcasting
[1,0]<stdout>:Rank 0 broadcasting
[1,86]<stdout>:Rank 46 broadcasting
[1,118]<stdout>:Rank 62 broadcasting
[1,96]<stdout>:Rank 48 broadcasting
[1,87]<stderr>:2020-09-18 19:27:43.482475: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,116]<stderr>:2020-09-18 19:27:43.485874: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,17]<stderr>:2020-09-18 19:27:43.488558: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,67]<stderr>:2020-09-18 19:27:43.490028: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,71]<stderr>:2020-09-18 19:27:43.490104: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,37]<stderr>:2020-09-18 19:27:43.490197: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,65]<stderr>:2020-09-18 19:27:43.492756: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,39]<stderr>:2020-09-18 19:27:43.493432: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,35]<stderr>:2020-09-18 19:27:43.493813: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,81]<stderr>:2020-09-18 19:27:43.494040: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,83]<stderr>:2020-09-18 19:27:43.494220: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,48]<stderr>:2020-09-18 19:27:43.494878: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,6]<stderr>:2020-09-18 19:27:43.494423: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,70]<stderr>:2020-09-18 19:27:43.495593: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,22]<stderr>:2020-09-18 19:27:43.495411: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,7]<stderr>:2020-09-18 19:27:43.497067: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,64]<stderr>:2020-09-18 19:27:43.503306: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,101]<stderr>:2020-09-18 19:27:43.503453: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,33]<stderr>:2020-09-18 19:27:43.503514: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,98]<stderr>:2020-09-18 19:27:43.504609: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,66]<stderr>:2020-09-18 19:27:43.507164: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,117]<stderr>:2020-09-18 19:27:43.509488: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,113]<stderr>:2020-09-18 19:27:43.510014: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,23]<stderr>:2020-09-18 19:27:43.508878: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,16]<stderr>:2020-09-18 19:27:43.511953: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,20]<stderr>:2020-09-18 19:27:43.513486: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,21]<stderr>:2020-09-18 19:27:43.513680: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,4]<stderr>:2020-09-18 19:27:43.514149: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,102]<stderr>:2020-09-18 19:27:43.516498: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,85]<stderr>:2020-09-18 19:27:43.517832: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,115]<stderr>:2020-09-18 19:27:43.519851: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,49]<stderr>:2020-09-18 19:27:43.521689: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,53]<stderr>:2020-09-18 19:27:43.522100: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,0]<stderr>:2020-09-18 19:27:43.527008: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,55]<stderr>:2020-09-18 19:27:43.528023: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,18]<stderr>:2020-09-18 19:27:43.526585: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,99]<stderr>:2020-09-18 19:27:43.527845: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,54]<stderr>:2020-09-18 19:27:43.528475: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,103]<stderr>:2020-09-18 19:27:43.529218: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,19]<stderr>:2020-09-18 19:27:43.528161: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,69]<stderr>:2020-09-18 19:27:43.529615: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,5]<stderr>:2020-09-18 19:27:43.529213: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,50]<stderr>:2020-09-18 19:27:43.531225: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,84]<stderr>:2020-09-18 19:27:43.531583: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,82]<stderr>:2020-09-18 19:27:43.531636: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,112]<stderr>:2020-09-18 19:27:43.534310: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,32]<stderr>:2020-09-18 19:27:43.533604: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,118]<stderr>:2020-09-18 19:27:43.535059: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,96]<stderr>:2020-09-18 19:27:43.534172: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,36]<stderr>:2020-09-18 19:27:43.534403: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,38]<stderr>:2020-09-18 19:27:43.534644: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,97]<stderr>:2020-09-18 19:27:43.534929: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,3]<stderr>:2020-09-18 19:27:43.534682: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,86]<stderr>:2020-09-18 19:27:43.535333: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,2]<stderr>:2020-09-18 19:27:43.536619: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,100]<stderr>:2020-09-18 19:27:43.537882: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,51]<stderr>:2020-09-18 19:27:43.544496: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,52]<stderr>:2020-09-18 19:27:43.551506: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,68]<stderr>:2020-09-18 19:27:43.556930: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,80]<stderr>:2020-09-18 19:27:43.558712: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,34]<stderr>:2020-09-18 19:27:43.567329: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,114]<stderr>:2020-09-18 19:27:43.568867: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,1]<stderr>:2020-09-18 19:27:43.571221: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,119]<stderr>:2020-09-18 19:27:43.583078: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,87]<stderr>:2020-09-18 19:27:43.614729: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,116]<stderr>:2020-09-18 19:27:43.618346: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,17]<stderr>:2020-09-18 19:27:43.621213: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,67]<stderr>:2020-09-18 19:27:43.623319: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,71]<stderr>:2020-09-18 19:27:43.623334: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,37]<stderr>:2020-09-18 19:27:43.623407: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,83]<stderr>:2020-09-18 19:27:43.625054: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,81]<stderr>:2020-09-18 19:27:43.625411: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,39]<stderr>:2020-09-18 19:27:43.625907: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,65]<stderr>:2020-09-18 19:27:43.626334: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,35]<stderr>:2020-09-18 19:27:43.626324: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,48]<stderr>:2020-09-18 19:27:43.627628: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,6]<stderr>:2020-09-18 19:27:43.627506: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,70]<stderr>:2020-09-18 19:27:43.629822: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,22]<stderr>:2020-09-18 19:27:43.629539: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,7]<stderr>:2020-09-18 19:27:43.630545: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,101]<stderr>:2020-09-18 19:27:43.635644: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,64]<stderr>:2020-09-18 19:27:43.637099: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,33]<stderr>:2020-09-18 19:27:43.637251: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,98]<stderr>:2020-09-18 19:27:43.638046: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,66]<stderr>:2020-09-18 19:27:43.639158: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,113]<stderr>:2020-09-18 19:27:43.641371: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,117]<stderr>:2020-09-18 19:27:43.641803: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,23]<stderr>:2020-09-18 19:27:43.644176: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,16]<stderr>:2020-09-18 19:27:43.645756: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,20]<stderr>:2020-09-18 19:27:43.646526: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,4]<stderr>:2020-09-18 19:27:43.647254: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,21]<stderr>:2020-09-18 19:27:43.647408: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,102]<stderr>:2020-09-18 19:27:43.650933: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,85]<stderr>:2020-09-18 19:27:43.651524: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,115]<stderr>:2020-09-18 19:27:43.653169: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,53]<stderr>:2020-09-18 19:27:43.653671: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,49]<stderr>:2020-09-18 19:27:43.654815: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,18]<stderr>:2020-09-18 19:27:43.658045: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,54]<stderr>:2020-09-18 19:27:43.660023: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,55]<stderr>:2020-09-18 19:27:43.660555: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,0]<stderr>:2020-09-18 19:27:43.659746: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,19]<stderr>:2020-09-18 19:27:43.659740: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,69]<stderr>:2020-09-18 19:27:43.661444: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,99]<stderr>:2020-09-18 19:27:43.661304: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,103]<stderr>:2020-09-18 19:27:43.662510: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,5]<stderr>:2020-09-18 19:27:43.662196: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,50]<stderr>:2020-09-18 19:27:43.663658: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,82]<stderr>:2020-09-18 19:27:43.665107: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,112]<stderr>:2020-09-18 19:27:43.667118: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,84]<stderr>:2020-09-18 19:27:43.666027: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,118]<stderr>:2020-09-18 19:27:43.668488: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,96]<stderr>:2020-09-18 19:27:43.667494: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,36]<stderr>:2020-09-18 19:27:43.667642: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,38]<stderr>:2020-09-18 19:27:43.668120: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,97]<stderr>:2020-09-18 19:27:43.668597: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,32]<stderr>:2020-09-18 19:27:43.669193: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,86]<stderr>:2020-09-18 19:27:43.670317: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,2]<stderr>:2020-09-18 19:27:43.671059: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,100]<stderr>:2020-09-18 19:27:43.671687: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,3]<stderr>:2020-09-18 19:27:43.671221: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,51]<stderr>:2020-09-18 19:27:43.679359: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,52]<stderr>:2020-09-18 19:27:43.683274: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,68]<stderr>:2020-09-18 19:27:43.690055: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,80]<stderr>:2020-09-18 19:27:43.698701: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,114]<stderr>:2020-09-18 19:27:43.702073: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,34]<stderr>:2020-09-18 19:27:43.701109: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,1]<stderr>:2020-09-18 19:27:43.705404: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,119]<stderr>:2020-09-18 19:27:43.727001: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1345] No whitelist ops found, nothing to do
[1,0]<stdout>:Variable broadcast done.
[1,5]<stdout>:Variable broadcast done.
[1,6]<stdout>:Variable broadcast done.
[1,16]<stdout>:Variable broadcast done.
[1,18]<stdout>:Variable broadcast done.
[1,21]<stdout>:Variable broadcast done.
[1,19]<stdout>:Variable broadcast done.
[1,22]<stdout>:Variable broadcast done.
[1,17]<stdout>:Variable broadcast done.
[1,23]<stdout>:Variable broadcast done.
[1,20]<stdout>:Variable broadcast done.
[1,39]<stdout>:Variable broadcast done.
[1,35]<stdout>:Variable broadcast done.
[1,33]<stdout>:Variable broadcast done.
[1,37]<stdout>:Variable broadcast done.
[1,34]<stdout>:Variable broadcast done.
[1,49]<stdout>:Variable broadcast done.
[1,38]<stdout>:Variable broadcast done.
[1,51]<stdout>:Variable broadcast done.
[1,32]<stdout>:Variable broadcast done.
[1,48]<stdout>:Variable broadcast done.
[1,36]<stdout>:Variable broadcast done.
[1,53]<stdout>:Variable broadcast done.
[1,55]<stdout>:Variable broadcast done.
[1,54]<stdout>:Variable broadcast done.
[1,69]<stdout>:Variable broadcast done.
[1,50]<stdout>:Variable broadcast done.
[1,70]<stdout>:Variable broadcast done.
[1,52]<stdout>:Variable broadcast done.
[1,66]<stdout>:Variable broadcast done.
[1,68]<stdout>:Variable broadcast done.
[1,67]<stdout>:Variable broadcast done.
[1,64]<stdout>:Variable broadcast done.
[1,71]<stdout>:Variable broadcast done.
[1,65]<stdout>:Variable broadcast done.
[1,102]<stdout>:Variable broadcast done.
[1,96]<stdout>:Variable broadcast done.
[1,98]<stdout>:Variable broadcast done.
[1,100]<stdout>:Variable broadcast done.
[1,103]<stdout>:Variable broadcast done.
[1,80]<stdout>:Variable broadcast done.
[1,101]<stdout>:Variable broadcast done.
[1,83]<stdout>:Variable broadcast done.
[1,1]<stdout>:Variable broadcast done.
[1,97]<stdout>:Variable broadcast done.
[1,113]<stdout>:Variable broadcast done.
[1,81]<stdout>:Variable broadcast done.
[1,4]<stdout>:Variable broadcast done.
[1,115]<stdout>:Variable broadcast done.
[1,87]<stdout>:Variable broadcast done.
[1,7]<stdout>:Variable broadcast done.
[1,116]<stdout>:Variable broadcast done.
[1,86]<stdout>:Variable broadcast done.
[1,3]<stdout>:Variable broadcast done.
[1,118]<stdout>:Variable broadcast done.
[1,82]<stdout>:Variable broadcast done.
[1,2]<stdout>:Variable broadcast done.
[1,112]<stdout>:Variable broadcast done.
[1,85]<stdout>:Variable broadcast done.
[1,117]<stdout>:Variable broadcast done.
[1,84]<stdout>:Variable broadcast done.
[1,114]<stdout>:Variable broadcast done.
[1,119]<stdout>:Variable broadcast done.
[1,99]<stdout>:Variable broadcast done.
[1,118]<stderr>:2020-09-18 19:27:55.742380: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8851 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,33]<stderr>:2020-09-18 19:27:55.953257: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,39]<stderr>:2020-09-18 19:27:55.997533: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,51]<stderr>:2020-09-18 19:27:56.018197: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,53]<stderr>:2020-09-18 19:27:56.018468: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,71]<stderr>:2020-09-18 19:27:56.063717: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,116]<stderr>:2020-09-18 19:27:56.084432: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,55]<stderr>:2020-09-18 19:27:56.106183: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,0]<stderr>:2020-09-18 19:27:56.140162: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,22]<stderr>:2020-09-18 19:27:56.152158: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,83]<stderr>:2020-09-18 19:27:56.161173: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,17]<stderr>:2020-09-18 19:27:56.167937: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,34]<stderr>:2020-09-18 19:27:56.172163: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,35]<stderr>:2020-09-18 19:27:56.174468: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,114]<stderr>:2020-09-18 19:27:56.178100: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,65]<stderr>:2020-09-18 19:27:56.177763: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,6]<stderr>:2020-09-18 19:27:56.189577: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,87]<stderr>:2020-09-18 19:27:56.202302: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,69]<stderr>:2020-09-18 19:27:56.203055: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,103]<stderr>:2020-09-18 19:27:56.219525: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,82]<stderr>:2020-09-18 19:27:56.226154: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,86]<stderr>:2020-09-18 19:27:56.232552: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,7]<stderr>:2020-09-18 19:27:56.241562: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,5]<stderr>:2020-09-18 19:27:56.244883: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,81]<stderr>:2020-09-18 19:27:56.255629: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,112]<stderr>:2020-09-18 19:27:56.258101: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,119]<stderr>:2020-09-18 19:27:56.272502: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,4]<stderr>:2020-09-18 19:27:56.272200: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,113]<stderr>:2020-09-18 19:27:56.278325: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,117]<stderr>:2020-09-18 19:27:56.284482: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,102]<stderr>:2020-09-18 19:27:56.291137: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,23]<stderr>:2020-09-18 19:27:56.292351: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,2]<stderr>:2020-09-18 19:27:56.294964: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,32]<stderr>:2020-09-18 19:27:56.320660: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,18]<stderr>:2020-09-18 19:27:56.320917: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,20]<stderr>:2020-09-18 19:27:56.326165: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,99]<stderr>:2020-09-18 19:27:56.336801: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,98]<stderr>:2020-09-18 19:27:56.352085: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,1]<stderr>:2020-09-18 19:27:56.364194: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,16]<stderr>:2020-09-18 19:27:56.364628: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,100]<stderr>:2020-09-18 19:27:56.370156: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,85]<stderr>:2020-09-18 19:27:56.379148: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,3]<stderr>:2020-09-18 19:27:56.387044: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,67]<stderr>:2020-09-18 19:27:56.391544: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,54]<stderr>:2020-09-18 19:27:56.398363: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,115]<stderr>:2020-09-18 19:27:56.402220: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,97]<stderr>:2020-09-18 19:27:56.436052: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,36]<stderr>:2020-09-18 19:27:56.468935: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,101]<stderr>:2020-09-18 19:27:56.473439: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,38]<stderr>:2020-09-18 19:27:56.475798: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,19]<stderr>:2020-09-18 19:27:56.501652: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,48]<stderr>:2020-09-18 19:27:56.545734: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,21]<stderr>:2020-09-18 19:27:56.568970: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,84]<stderr>:2020-09-18 19:27:56.570126: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,68]<stderr>:2020-09-18 19:27:56.575557: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,52]<stderr>:2020-09-18 19:27:56.583525: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,80]<stderr>:2020-09-18 19:27:56.627456: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,66]<stderr>:2020-09-18 19:27:56.659850: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,96]<stderr>:2020-09-18 19:27:56.662751: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,50]<stderr>:2020-09-18 19:27:56.723357: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,64]<stderr>:2020-09-18 19:27:56.842094: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,70]<stderr>:2020-09-18 19:27:56.893478: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,118]<stderr>:2020-09-18 19:28:00.107339: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7658 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,33]<stderr>:2020-09-18 19:28:00.206702: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,39]<stderr>:2020-09-18 19:28:00.234853: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,53]<stderr>:2020-09-18 19:28:00.237108: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,51]<stderr>:2020-09-18 19:28:00.238202: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,55]<stderr>:2020-09-18 19:28:00.330100: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,71]<stderr>:2020-09-18 19:28:00.459855: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,116]<stderr>:2020-09-18 19:28:00.516538: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,0]<stderr>:2020-09-18 19:28:00.537277: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,22]<stderr>:2020-09-18 19:28:00.542914: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,17]<stderr>:2020-09-18 19:28:00.556104: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,83]<stderr>:2020-09-18 19:28:00.559986: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,65]<stderr>:2020-09-18 19:28:00.563949: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,35]<stderr>:2020-09-18 19:28:00.564500: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,87]<stderr>:2020-09-18 19:28:00.582989: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,103]<stderr>:2020-09-18 19:28:00.586780: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,69]<stderr>:2020-09-18 19:28:00.589406: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,6]<stderr>:2020-09-18 19:28:00.599240: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,34]<stderr>:2020-09-18 19:28:00.603732: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,114]<stderr>:2020-09-18 19:28:00.611055: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,5]<stderr>:2020-09-18 19:28:00.631214: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,82]<stderr>:2020-09-18 19:28:00.633002: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,86]<stderr>:2020-09-18 19:28:00.650718: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,81]<stderr>:2020-09-18 19:28:00.663444: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,119]<stderr>:2020-09-18 19:28:00.670859: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,4]<stderr>:2020-09-18 19:28:00.674274: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,7]<stderr>:2020-09-18 19:28:00.683273: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,112]<stderr>:2020-09-18 19:28:00.686529: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,102]<stderr>:2020-09-18 19:28:00.688699: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,117]<stderr>:2020-09-18 19:28:00.692187: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,23]<stderr>:2020-09-18 19:28:00.691809: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,2]<stderr>:2020-09-18 19:28:00.716252: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,32]<stderr>:2020-09-18 19:28:00.735815: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,113]<stderr>:2020-09-18 19:28:00.746396: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,18]<stderr>:2020-09-18 19:28:00.747660: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,20]<stderr>:2020-09-18 19:28:00.754803: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,54]<stderr>:2020-09-18 19:28:00.760676: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,115]<stderr>:2020-09-18 19:28:00.767603: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,99]<stderr>:2020-09-18 19:28:00.773749: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,100]<stderr>:2020-09-18 19:28:00.782401: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,1]<stderr>:2020-09-18 19:28:00.790151: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,98]<stderr>:2020-09-18 19:28:00.791800: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,67]<stderr>:2020-09-18 19:28:00.805782: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,16]<stderr>:2020-09-18 19:28:00.808080: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,85]<stderr>:2020-09-18 19:28:00.842271: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,3]<stderr>:2020-09-18 19:28:00.853967: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,97]<stderr>:2020-09-18 19:28:00.878564: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,36]<stderr>:2020-09-18 19:28:00.896603: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,38]<stderr>:2020-09-18 19:28:00.921392: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,101]<stderr>:2020-09-18 19:28:00.945593: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,52]<stderr>:2020-09-18 19:28:00.969353: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,19]<stderr>:2020-09-18 19:28:00.977778: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,48]<stderr>:2020-09-18 19:28:00.990076: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,68]<stderr>:2020-09-18 19:28:01.017220: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,84]<stderr>:2020-09-18 19:28:01.038460: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,21]<stderr>:2020-09-18 19:28:01.037867: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,66]<stderr>:2020-09-18 19:28:01.045238: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,80]<stderr>:2020-09-18 19:28:01.064041: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,96]<stderr>:2020-09-18 19:28:01.151010: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,50]<stderr>:2020-09-18 19:28:01.286875: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,64]<stderr>:2020-09-18 19:28:01.337706: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,70]<stderr>:2020-09-18 19:28:01.393374: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,0]<stdout>:ip-192-168-64-81:24882:25445 [0] NCCL INFO Launch mode Parallel
[1,112]<stdout>:ip-192-168-90-179:25775:26321 [0] NCCL INFO Launch mode Parallel
[1,32]<stdout>:ip-192-168-72-95:25431:25990 [0] NCCL INFO Launch mode Parallel
[1,16]<stdout>:ip-192-168-71-105:27897:28434 [0] NCCL INFO Launch mode Parallel
[1,80]<stdout>:ip-192-168-87-97:23446:23997 [0] NCCL INFO Launch mode Parallel
[1,48]<stdout>:ip-192-168-95-203:24938:25470 [0] NCCL INFO Launch mode Parallel
[1,96]<stdout>:ip-192-168-64-19:28228:28798 [0] NCCL INFO Launch mode Parallel
[1,64]<stdout>:ip-192-168-83-55:53989:54550 [0] NCCL INFO Launch mode Parallel
[1,112]<stderr>:2020-09-18 19:28:12.141221: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,116]<stderr>:2020-09-18 19:28:12.273451: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,55]<stderr>:2020-09-18 19:28:12.278140: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,0]<stderr>:2020-09-18 19:28:12.280856: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,39]<stderr>:2020-09-18 19:28:12.307663: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,82]<stderr>:2020-09-18 19:28:12.343022: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,5]<stderr>:2020-09-18 19:28:12.345734: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,51]<stderr>:2020-09-18 19:28:12.375852: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,54]<stderr>:2020-09-18 19:28:12.377523: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,101]<stderr>:2020-09-18 19:28:12.378746: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,38]<stderr>:2020-09-18 19:28:12.380677: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,3]<stderr>:2020-09-18 19:28:12.392568: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,22]<stderr>:2020-09-18 19:28:12.401421: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,102]<stderr>:2020-09-18 19:28:12.407796: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,64]<stderr>:2020-09-18 19:28:12.407995: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,16]<stderr>:2020-09-18 19:28:12.413105: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,52]<stderr>:2020-09-18 19:28:12.415057: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,35]<stderr>:2020-09-18 19:28:12.417429: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,33]<stderr>:2020-09-18 19:28:12.418381: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,4]<stderr>:2020-09-18 19:28:12.418712: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,98]<stderr>:2020-09-18 19:28:12.420302: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,1]<stderr>:2020-09-18 19:28:12.433141: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,19]<stderr>:2020-09-18 19:28:12.433282: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,69]<stderr>:2020-09-18 19:28:12.435780: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,85]<stderr>:2020-09-18 19:28:12.439394: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,53]<stderr>:2020-09-18 19:28:12.443711: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,81]<stderr>:2020-09-18 19:28:12.450023: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,86]<stderr>:2020-09-18 19:28:12.456219: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,23]<stderr>:2020-09-18 19:28:12.458340: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,18]<stderr>:2020-09-18 19:28:12.460158: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,65]<stderr>:2020-09-18 19:28:12.466598: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,48]<stderr>:2020-09-18 19:28:12.466984: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,97]<stderr>:2020-09-18 19:28:12.467193: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,117]<stderr>:2020-09-18 19:28:12.471257: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,20]<stderr>:2020-09-18 19:28:12.469161: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,115]<stderr>:2020-09-18 19:28:12.476703: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,84]<stderr>:2020-09-18 19:28:12.476330: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,96]<stderr>:2020-09-18 19:28:12.481797: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,32]<stderr>:2020-09-18 19:28:12.496805: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,34]<stderr>:2020-09-18 19:28:12.499328: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,113]<stderr>:2020-09-18 19:28:12.507322: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,21]<stderr>:2020-09-18 19:28:12.513611: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,71]<stderr>:2020-09-18 19:28:12.515719: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,17]<stderr>:2020-09-18 19:28:12.519535: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,6]<stderr>:2020-09-18 19:28:12.530276: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,66]<stderr>:2020-09-18 19:28:12.535215: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,83]<stderr>:2020-09-18 19:28:12.544961: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,7]<stderr>:2020-09-18 19:28:12.547494: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,100]<stderr>:2020-09-18 19:28:12.553289: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,119]<stderr>:2020-09-18 19:28:12.563442: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,67]<stderr>:2020-09-18 19:28:12.572085: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,80]<stderr>:2020-09-18 19:28:12.578260: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,70]<stderr>:2020-09-18 19:28:12.601156: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,2]<stderr>:2020-09-18 19:28:12.607221: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,36]<stderr>:2020-09-18 19:28:12.612096: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,50]<stderr>:2020-09-18 19:28:12.620764: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,68]<stderr>:2020-09-18 19:28:12.739787: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,103]<stderr>:2020-09-18 19:28:12.783398: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8930 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,87]<stderr>:2020-09-18 19:28:13.058593: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,112]<stderr>:2020-09-18 19:28:16.299436: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,116]<stderr>:2020-09-18 19:28:16.422764: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,101]<stderr>:2020-09-18 19:28:16.677385: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,0]<stderr>:2020-09-18 19:28:16.724212: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,55]<stderr>:2020-09-18 19:28:16.747852: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,39]<stderr>:2020-09-18 19:28:16.776750: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,82]<stderr>:2020-09-18 19:28:16.790845: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,16]<stderr>:2020-09-18 19:28:16.792083: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,5]<stderr>:2020-09-18 19:28:16.795709: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,51]<stderr>:2020-09-18 19:28:16.799503: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,38]<stderr>:2020-09-18 19:28:16.815350: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,54]<stderr>:2020-09-18 19:28:16.821172: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,3]<stderr>:2020-09-18 19:28:16.828329: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,102]<stderr>:2020-09-18 19:28:16.830390: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,1]<stderr>:2020-09-18 19:28:16.835854: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,52]<stderr>:2020-09-18 19:28:16.846079: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,69]<stderr>:2020-09-18 19:28:16.865623: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,64]<stderr>:2020-09-18 19:28:16.874958: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,85]<stderr>:2020-09-18 19:28:16.877579: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,4]<stderr>:2020-09-18 19:28:16.879841: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,81]<stderr>:2020-09-18 19:28:16.883075: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,18]<stderr>:2020-09-18 19:28:16.884990: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,22]<stderr>:2020-09-18 19:28:16.885584: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,19]<stderr>:2020-09-18 19:28:16.897517: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,97]<stderr>:2020-09-18 19:28:16.900769: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,48]<stderr>:2020-09-18 19:28:16.901924: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,86]<stderr>:2020-09-18 19:28:16.901668: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,35]<stderr>:2020-09-18 19:28:16.903476: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,33]<stderr>:2020-09-18 19:28:16.906898: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,65]<stderr>:2020-09-18 19:28:16.911749: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,117]<stderr>:2020-09-18 19:28:16.913218: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,20]<stderr>:2020-09-18 19:28:16.919933: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,98]<stderr>:2020-09-18 19:28:16.921045: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,115]<stderr>:2020-09-18 19:28:16.922393: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,71]<stderr>:2020-09-18 19:28:16.926108: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,23]<stderr>:2020-09-18 19:28:16.926378: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,96]<stderr>:2020-09-18 19:28:16.942590: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,84]<stderr>:2020-09-18 19:28:16.947495: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,17]<stderr>:2020-09-18 19:28:16.960417: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,21]<stderr>:2020-09-18 19:28:16.961008: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,119]<stderr>:2020-09-18 19:28:16.966433: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,6]<stderr>:2020-09-18 19:28:16.973577: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,113]<stderr>:2020-09-18 19:28:16.980908: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,83]<stderr>:2020-09-18 19:28:16.980655: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,53]<stderr>:2020-09-18 19:28:17.002051: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,66]<stderr>:2020-09-18 19:28:17.013339: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,100]<stderr>:2020-09-18 19:28:17.014866: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,7]<stderr>:2020-09-18 19:28:17.016002: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,37]<stderr>:2020-09-18 19:28:17.029267: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,32]<stderr>:2020-09-18 19:28:17.037832: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,36]<stderr>:2020-09-18 19:28:17.052080: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,67]<stderr>:2020-09-18 19:28:17.064328: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,70]<stderr>:2020-09-18 19:28:17.077278: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,34]<stderr>:2020-09-18 19:28:17.089078: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,80]<stderr>:2020-09-18 19:28:17.104812: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,2]<stderr>:2020-09-18 19:28:17.133928: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,103]<stderr>:2020-09-18 19:28:17.153706: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7736 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,50]<stderr>:2020-09-18 19:28:17.202249: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,49]<stderr>:2020-09-18 19:28:17.213519: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8858 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,68]<stderr>:2020-09-18 19:28:17.384643: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,87]<stderr>:2020-09-18 19:28:17.754455: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,37]<stderr>:2020-09-18 19:28:21.188726: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,49]<stderr>:2020-09-18 19:28:21.411821: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7660 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,49]<stderr>:2020-09-18 19:28:31.256666: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,37]<stderr>:2020-09-18 19:28:31.324328: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,114]<stderr>:2020-09-18 19:28:31.331028: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,99]<stderr>:2020-09-18 19:28:31.530687: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,103]<stderr>:2020-09-18 19:28:31.918331: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,49]<stderr>:2020-09-18 19:28:35.022325: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,114]<stderr>:2020-09-18 19:28:35.139205: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,37]<stderr>:2020-09-18 19:28:35.154874: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,99]<stderr>:2020-09-18 19:28:35.624391: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,103]<stderr>:2020-09-18 19:28:36.111081: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,118]<stderr>:2020-09-18 19:28:50.863555: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 637/8959 nodes to float16 precision using 36 cast(s) to float16 (excluding Const and Variable casts)
[1,118]<stderr>:2020-09-18 19:28:54.670238: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/7769 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,0]<stderr>:/shared/conda/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
[1,0]<stderr>:  warnings.warn(
[1,0]<stderr>:2020-09-18 19:29:38,596 - INFO - Epoch [1][50/458]	lr: 0.00538, eta: 4:31:10, time: 2.988, data_time: 0.057, rpn_class_loss: 0.2891, rpn_bbox_loss: 0.0871, rcnn_class_loss: 0.7869, rcnn_bbox_loss: 0.1206, rcnn_mask_loss: 0.6921, reg_loss: 0.4335, loss: 2.4094, learning_rate: 0.0028
[1,0]<stderr>:2020-09-18 19:30:21,821 - INFO - Epoch [1][100/458]	lr: 0.01071, eta: 2:53:12, time: 0.865, data_time: 0.037, rpn_class_loss: 0.0939, rpn_bbox_loss: 0.0367, rcnn_class_loss: 0.4856, rcnn_bbox_loss: 0.1947, rcnn_mask_loss: 0.6865, reg_loss: 0.4332, loss: 1.9306, learning_rate: 0.0081
[1,0]<stderr>:2020-09-18 19:31:02,425 - INFO - Epoch [1][150/458]	lr: 0.01604, eta: 2:18:31, time: 0.812, data_time: 0.037, rpn_class_loss: 0.0745, rpn_bbox_loss: 0.0280, rcnn_class_loss: 0.4958, rcnn_bbox_loss: 0.2165, rcnn_mask_loss: 0.6608, reg_loss: 0.4328, loss: 1.9083, learning_rate: 0.0134
[1,0]<stderr>:2020-09-18 19:31:43,000 - INFO - Epoch [1][200/458]	lr: 0.02137, eta: 2:00:49, time: 0.812, data_time: 0.034, rpn_class_loss: 0.0559, rpn_bbox_loss: 0.0222, rcnn_class_loss: 0.4702, rcnn_bbox_loss: 0.2105, rcnn_mask_loss: 0.5838, reg_loss: 0.4321, loss: 1.7746, learning_rate: 0.0188
[1,0]<stderr>:2020-09-18 19:32:23,548 - INFO - Epoch [1][250/458]	lr: 0.02669, eta: 1:49:55, time: 0.811, data_time: 0.040, rpn_class_loss: 0.0612, rpn_bbox_loss: 0.0241, rcnn_class_loss: 0.4809, rcnn_bbox_loss: 0.2313, rcnn_mask_loss: 0.5177, reg_loss: 0.4313, loss: 1.7465, learning_rate: 0.0241
[1,0]<stderr>:2020-09-18 19:33:04,372 - INFO - Epoch [1][300/458]	lr: 0.03202, eta: 1:42:31, time: 0.816, data_time: 0.040, rpn_class_loss: 0.0478, rpn_bbox_loss: 0.0219, rcnn_class_loss: 0.4454, rcnn_bbox_loss: 0.2269, rcnn_mask_loss: 0.4608, reg_loss: 0.4303, loss: 1.6331, learning_rate: 0.0294
[1,0]<stderr>:2020-09-18 19:33:44,838 - INFO - Epoch [1][350/458]	lr: 0.03735, eta: 1:36:56, time: 0.809, data_time: 0.041, rpn_class_loss: 0.0478, rpn_bbox_loss: 0.0198, rcnn_class_loss: 0.4294, rcnn_bbox_loss: 0.2279, rcnn_mask_loss: 0.4482, reg_loss: 0.4291, loss: 1.6021, learning_rate: 0.0347
[1,0]<stderr>:2020-09-18 19:34:25,120 - INFO - Epoch [1][400/458]	lr: 0.04268, eta: 1:32:33, time: 0.806, data_time: 0.036, rpn_class_loss: 0.0454, rpn_bbox_loss: 0.0183, rcnn_class_loss: 0.3879, rcnn_bbox_loss: 0.2052, rcnn_mask_loss: 0.4303, reg_loss: 0.4278, loss: 1.5149, learning_rate: 0.0401
[1,0]<stderr>:2020-09-18 19:35:05,344 - INFO - Epoch [1][450/458]	lr: 0.04801, eta: 1:28:58, time: 0.804, data_time: 0.039, rpn_class_loss: 0.0424, rpn_bbox_loss: 0.0178, rcnn_class_loss: 0.3497, rcnn_bbox_loss: 0.2008, rcnn_mask_loss: 0.3979, reg_loss: 0.4263, loss: 1.4349, learning_rate: 0.0454
[1,118]<stdout>:setting Step LR 0.1599999964237213
[1,118]<stdout>:0.16 0.1 0 [8, 11] 1
[1,23]<stdout>:setting Step LR 0.1599999964237213
[1,23]<stdout>:0.16 0.1 0 [8, 11] 1
[1,86]<stdout>:setting Step LR 0.1599999964237213
[1,86]<stdout>:0.16 0.1 0 [8, 11] 1
[1,87]<stdout>:setting Step LR 0.1599999964237213
[1,87]<stdout>:0.16 0.1 0 [8, 11] 1
[1,37]<stdout>:setting Step LR 0.1599999964237213
[1,37]<stdout>:0.16 0.1 0 [8, 11] 1
[1,113]<stdout>:setting Step LR 0.1599999964237213
[1,113]<stdout>:0.16 0.1 0 [8, 11] 1
[1,83]<stdout>:setting Step LR 0.1599999964237213
[1,83]<stdout>:0.16 0.1 0 [8, 11] 1
[1,119]<stdout>:setting Step LR 0.1599999964237213
[1,119]<stdout>:0.16 0.1 0 [8, 11] 1
[1,55]<stdout>:setting Step LR 0.1599999964237213
[1,55]<stdout>:0.16 0.1 0 [8, 11] 1
[1,64]<stdout>:setting Step LR 0.1599999964237213
[1,64]<stdout>:0.16 0.1 0 [8, 11] 1
[1,118]<stdout>:Starting new loop for GPU: 62
[1,7]<stdout>:setting Step LR 0.1599999964237213
[1,7]<stdout>:0.16 0.1 0 [8, 11] 1
[1,4]<stdout>:setting Step LR 0.1599999964237213
[1,4]<stdout>:0.16 0.1 0 [8, 11] 1
[1,71]<stdout>:setting Step LR 0.1599999964237213
[1,71]<stdout>:0.16 0.1 0 [8, 11] 1
[1,100]<stdout>:setting Step LR 0.1599999964237213
[1,100]<stdout>:0.16 0.1 0 [8, 11] 1
[1,97]<stdout>:setting Step LR 0.1599999964237213
[1,97]<stdout>:0.16 0.1 0 [8, 11] 1
[1,49]<stdout>:setting Step LR 0.1599999964237213
[1,49]<stdout>:0.16 0.1 0 [8, 11] 1
[1,38]<stdout>:setting Step LR 0.1599999964237213
[1,38]<stdout>:0.16 0.1 0 [8, 11] 1
[1,19]<stdout>:setting Step LR 0.1599999964237213
[1,19]<stdout>:0.16 0.1 0 [8, 11] 1
[1,82]<stdout>:setting Step LR 0.1599999964237213
[1,82]<stdout>:0.16 0.1 0 [8, 11] 1
[1,23]<stdout>:Starting new loop for GPU: 15
[1,53]<stdout>:setting Step LR 0.1599999964237213
[1,53]<stdout>:0.16 0.1 0 [8, 11] 1
[1,65]<stdout>:setting Step LR 0.1599999964237213
[1,65]<stdout>:0.16 0.1 0 [8, 11] 1
[1,116]<stdout>:setting Step LR 0.1599999964237213
[1,116]<stdout>:0.16 0.1 0 [8, 11] 1
[1,112]<stdout>:setting Step LR 0.1599999964237213
[1,112]<stdout>:0.16 0.1 0 [8, 11] 1
[1,66]<stdout>:setting Step LR 0.1599999964237213
[1,66]<stdout>:0.16 0.1 0 [8, 11] 1
[1,21]<stdout>:setting Step LR 0.1599999964237213
[1,21]<stdout>:0.16 0.1 0 [8, 11] 1
[1,54]<stdout>:setting Step LR 0.1599999964237213
[1,54]<stdout>:0.16 0.1 0 [8, 11] 1
[1,3]<stdout>:setting Step LR 0.1599999964237213
[1,3]<stdout>:0.16 0.1 0 [8, 11] 1
[1,32]<stdout>:setting Step LR 0.1599999964237213
[1,32]<stdout>:0.16 0.1 0 [8, 11] 1
[1,87]<stdout>:Starting new loop for GPU: 47
[1,37]<stdout>:Starting new loop for GPU: 21
[1,35]<stdout>:setting Step LR 0.1599999964237213
[1,35]<stdout>:0.16 0.1 0 [8, 11] 1
[1,83]<stdout>:Starting new loop for GPU: 43
[1,113]<stdout>:Starting new loop for GPU: 57
[1,51]<stdout>:setting Step LR 0.1599999964237213
[1,51]<stdout>:0.16 0.1 0 [8, 11] 1
[1,55]<stdout>:Starting new loop for GPU: 31
[1,101]<stdout>:setting Step LR 0.1599999964237213
[1,101]<stdout>:0.16 0.1 0 [8, 11] 1
[1,119]<stdout>:Starting new loop for GPU: 63
[1,6]<stdout>:setting Step LR 0.1599999964237213
[1,6]<stdout>:0.16 0.1 0 [8, 11] 1
[1,68]<stdout>:setting Step LR 0.1599999964237213
[1,68]<stdout>:0.16 0.1 0 [8, 11] 1
[1,86]<stdout>:Starting new loop for GPU: 46
[1,70]<stdout>:setting Step LR 0.1599999964237213
[1,70]<stdout>:0.16 0.1 0 [8, 11] 1
[1,64]<stdout>:Starting new loop for GPU: 32
[1,69]<stdout>:setting Step LR 0.1599999964237213
[1,69]<stdout>:0.16 0.1 0 [8, 11] 1
[1,114]<stdout>:setting Step LR 0.1599999964237213
[1,114]<stdout>:0.16 0.1 0 [8, 11] 1
[1,103]<stdout>:setting Step LR 0.1599999964237213
[1,103]<stdout>:0.16 0.1 0 [8, 11] 1
[1,34]<stdout>:setting Step LR 0.1599999964237213
[1,34]<stdout>:0.16 0.1 0 [8, 11] 1
[1,99]<stdout>:setting Step LR 0.1599999964237213
[1,99]<stdout>:0.16 0.1 0 [8, 11] 1
[1,100]<stdout>:Starting new loop for GPU: 52
[1,71]<stdout>:Starting new loop for GPU: 39
[1,115]<stdout>:setting Step LR 0.1599999964237213
[1,115]<stdout>:0.16 0.1 0 [8, 11] 1
[1,36]<stdout>:setting Step LR 0.1599999964237213
[1,36]<stdout>:0.16 0.1 0 [8, 11] 1
[1,4]<stdout>:Starting new loop for GPU: 4
[1,81]<stdout>:setting Step LR 0.1599999964237213
[1,81]<stdout>:0.16 0.1 0 [8, 11] 1
[1,49]<stdout>:Starting new loop for GPU: 25
[1,97]<stdout>:Starting new loop for GPU: 49
[1,38]<stdout>:Starting new loop for GPU: 22
[1,2]<stdout>:setting Step LR 0.1599999964237213
[1,2]<stdout>:0.16 0.1 0 [8, 11] 1
[1,7]<stdout>:Starting new loop for GPU: 7
[1,48]<stdout>:setting Step LR 0.1599999964237213
[1,48]<stdout>:0.16 0.1 0 [8, 11] 1
[1,18]<stdout>:setting Step LR 0.1599999964237213
[1,18]<stdout>:0.16 0.1 0 [8, 11] 1
[1,22]<stdout>:setting Step LR 0.1599999964237213
[1,22]<stdout>:0.16 0.1 0 [8, 11] 1
[1,96]<stdout>:setting Step LR 0.1599999964237213
[1,96]<stdout>:0.16 0.1 0 [8, 11] 1
[1,53]<stdout>:Starting new loop for GPU: 29
[1,19]<stdout>:Starting new loop for GPU: 11
[1,1]<stdout>:setting Step LR 0.1599999964237213
[1,1]<stdout>:0.16 0.1 0 [8, 11] 1
[1,82]<stdout>:Starting new loop for GPU: 42
[1,65]<stdout>:Starting new loop for GPU: 33
[1,52]<stdout>:setting Step LR 0.1599999964237213
[1,52]<stdout>:0.16 0.1 0 [8, 11] 1
[1,54]<stdout>:Starting new loop for GPU: 30
[1,66]<stdout>:Starting new loop for GPU: 34
[1,116]<stdout>:Starting new loop for GPU: 60
[1,84]<stdout>:setting Step LR 0.1599999964237213
[1,84]<stdout>:0.16 0.1 0 [8, 11] 1
[1,16]<stdout>:setting Step LR 0.1599999964237213
[1,16]<stdout>:0.16 0.1 0 [8, 11] 1
[1,5]<stdout>:setting Step LR 0.1599999964237213
[1,5]<stdout>:0.16 0.1 0 [8, 11] 1
[1,112]<stdout>:Starting new loop for GPU: 56
[1,32]<stdout>:Starting new loop for GPU: 16
[1,21]<stdout>:Starting new loop for GPU: 13
[1,3]<stdout>:Starting new loop for GPU: 3
[1,50]<stdout>:setting Step LR 0.1599999964237213
[1,50]<stdout>:0.16 0.1 0 [8, 11] 1
[1,39]<stdout>:setting Step LR 0.1599999964237213
[1,39]<stdout>:0.16 0.1 0 [8, 11] 1
[1,101]<stdout>:Starting new loop for GPU: 53
[1,51]<stdout>:Starting new loop for GPU: 27
[1,6]<stdout>:Starting new loop for GPU: 6
[1,70]<stdout>:Starting new loop for GPU: 38
[1,68]<stdout>:Starting new loop for GPU: 36
[1,98]<stdout>:setting Step LR 0.1599999964237213
[1,98]<stdout>:0.16 0.1 0 [8, 11] 1
[1,114]<stdout>:Starting new loop for GPU: 58
[1,117]<stdout>:setting Step LR 0.1599999964237213
[1,117]<stdout>:0.16 0.1 0 [8, 11] 1
[1,103]<stdout>:Starting new loop for GPU: 55
[1,69]<stdout>:Starting new loop for GPU: 37
[1,35]<stdout>:Starting new loop for GPU: 19
[1,99]<stdout>:Starting new loop for GPU: 51
[1,18]<stdout>:Starting new loop for GPU: 10
[1,48]<stdout>:Starting new loop for GPU: 24
[1,22]<stdout>:Starting new loop for GPU: 14
[1,33]<stdout>:setting Step LR 0.1599999964237213
[1,33]<stdout>:0.16 0.1 0 [8, 11] 1
[1,34]<stdout>:Starting new loop for GPU: 18
[1,36]<stdout>:Starting new loop for GPU: 20
[1,96]<stdout>:Starting new loop for GPU: 48
[1,52]<stdout>:Starting new loop for GPU: 28
[1,115]<stdout>:Starting new loop for GPU: 59
[1,81]<stdout>:Starting new loop for GPU: 41
[1,2]<stdout>:Starting new loop for GPU: 2
[1,85]<stdout>:setting Step LR 0.1599999964237213
[1,85]<stdout>:0.16 0.1 0 [8, 11] 1
[1,16]<stdout>:Starting new loop for GPU: 8
[1,1]<stdout>:Starting new loop for GPU: 1
[1,84]<stdout>:Starting new loop for GPU: 44
[1,67]<stdout>:setting Step LR 0.1599999964237213
[1,67]<stdout>:0.16 0.1 0 [8, 11] 1
[1,50]<stdout>:Starting new loop for GPU: 26
[1,39]<stdout>:Starting new loop for GPU: 23
[1,98]<stdout>:Starting new loop for GPU: 50
[1,102]<stdout>:setting Step LR 0.1599999964237213
[1,102]<stdout>:0.16 0.1 0 [8, 11] 1
[1,117]<stdout>:Starting new loop for GPU: 61
[1,5]<stdout>:Starting new loop for GPU: 5
[1,17]<stdout>:setting Step LR 0.1599999964237213
[1,17]<stdout>:0.16 0.1 0 [8, 11] 1
[1,33]<stdout>:Starting new loop for GPU: 17
[1,20]<stdout>:setting Step LR 0.1599999964237213
[1,20]<stdout>:0.16 0.1 0 [8, 11] 1
[1,85]<stdout>:Starting new loop for GPU: 45
[1,67]<stdout>:Starting new loop for GPU: 35
[1,102]<stdout>:Starting new loop for GPU: 54
[1,80]<stdout>:setting Step LR 0.1599999964237213
[1,80]<stdout>:0.16 0.1 0 [8, 11] 1
[1,17]<stdout>:Starting new loop for GPU: 9
[1,20]<stdout>:Starting new loop for GPU: 12
[1,80]<stdout>:Starting new loop for GPU: 40
[1,0]<stderr>:2020-09-18 19:35:13,180 - INFO - Saved checkpoint at: /shared/deep-learning-models/models/vision/detection/work_dirs/mask_rcnn_r50v1_d_fpn_1x_coco/000/faster_rcnn
[1,0]<stdout>:setting Step LR 0.1599999964237213
[1,0]<stdout>:0.16 0.1 0 [8, 11] 1
[1,0]<stdout>:Starting new loop for GPU: 0
[1,23]<stdout>:Rank 15 broadcasting
[1,21]<stdout>:Rank 13 broadcasting
[1,1]<stdout>:Rank 1 broadcasting
[1,22]<stdout>:Rank 14 broadcasting
[1,17]<stdout>:Rank 9 broadcasting
[1,18]<stdout>:Rank 10 broadcasting
[1,19]<stdout>:Rank 11 broadcasting
[1,98]<stdout>:Rank 50 broadcasting
[1,0]<stdout>:Rank 0 broadcasting
[1,20]<stdout>:Rank 12 broadcasting
[1,55]<stdout>:Rank 31 broadcasting
[1,6]<stdout>:Rank 6 broadcasting
[1,70]<stdout>:Rank 38 broadcasting
[1,112]<stdout>:Rank 56 broadcasting
[1,49]<stdout>:Rank 25 broadcasting
[1,3]<stdout>:Rank 3 broadcasting
[1,16]<stdout>:Rank 8 broadcasting
[1,102]<stdout>:Rank 54 broadcasting
[1,66]<stdout>:Rank 34 broadcasting
[1,114]<stdout>:Rank 58 broadcasting
[1,7]<stdout>:Rank 7 broadcasting
[1,97]<stdout>:Rank 49 broadcasting
[1,64]<stdout>:Rank 32 broadcasting
[1,32]<stdout>:Rank 16 broadcasting
[1,101]<stdout>:Rank 53 broadcasting
[1,68]<stdout>:Rank 36 broadcasting
[1,52]<stdout>:Rank 28 broadcasting
[1,34]<stdout>:Rank 18 broadcasting
[1,96]<stdout>:Rank 48 broadcasting
[1,69]<stdout>:Rank 37 broadcasting
[1,48]<stdout>:Rank 24 broadcasting
[1,51]<stdout>:Rank 27 broadcasting
[1,83]<stdout>:Rank 43 broadcasting
[1,100]<stdout>:Rank 52 broadcasting
[1,65]<stdout>:Rank 33 broadcasting
[1,81]<stdout>:Rank 41 broadcasting
[1,53]<stdout>:Rank 29 broadcasting
[1,82]<stdout>:Rank 42 broadcasting
[1,103]<stdout>:Rank 55 broadcasting
[1,54]<stdout>:Rank 30 broadcasting
[1,80]<stdout>:Rank 40 broadcasting
[1,86]<stdout>:Rank 46 broadcasting
[1,85]<stdout>:Rank 45 broadcasting
[1,5]<stdout>:Rank 5 broadcasting
[1,71]<stdout>:Rank 39 broadcasting
[1,39]<stdout>:Rank 23 broadcasting
[1,38]<stdout>:Rank 22 broadcasting
[1,116]<stdout>:Rank 60 broadcasting
[1,113]<stdout>:Rank 57 broadcasting
[1,33]<stdout>:Rank 17 broadcasting
[1,87]<stdout>:Rank 47 broadcasting
[1,67]<stdout>:Rank 35 broadcasting
[1,36]<stdout>:Rank 20 broadcasting
[1,35]<stdout>:Rank 19 broadcasting
[1,119]<stdout>:Rank 63 broadcasting
[1,115]<stdout>:Rank 59 broadcasting
[1,50]<stdout>:Rank 26 broadcasting
[1,37]<stdout>:Rank 21 broadcasting
[1,99]<stdout>:Rank 51 broadcasting
[1,117]<stdout>:Rank 61 broadcasting
[1,118]<stdout>:Rank 62 broadcasting
[1,84]<stdout>:Rank 44 broadcasting
[1,2]<stdout>:Rank 2 broadcasting
[1,4]<stdout>:Rank 4 broadcasting
[1,0]<stdout>:Variable broadcast done.
[1,5]<stdout>:Variable broadcast done.
[1,6]<stdout>:Variable broadcast done.
[1,16]<stdout>:Variable broadcast done.
[1,18]<stdout>:Variable broadcast done.
[1,19]<stdout>:Variable broadcast done.
[1,17]<stdout>:Variable broadcast done.
[1,22]<stdout>:Variable broadcast done.
[1,23]<stdout>:Variable broadcast done.
[1,21]<stdout>:Variable broadcast done.
[1,20]<stdout>:Variable broadcast done.
[1,35]<stdout>:Variable broadcast done.
[1,33]<stdout>:Variable broadcast done.
[1,37]<stdout>:Variable broadcast done.
[1,32]<stdout>:Variable broadcast done.
[1,38]<stdout>:Variable broadcast done.
[1,54]<stdout>:Variable broadcast done.
[1,34]<stdout>:Variable broadcast done.
[1,50]<stdout>:Variable broadcast done.
[1,39]<stdout>:Variable broadcast done.
[1,51]<stdout>:Variable broadcast done.
[1,36]<stdout>:Variable broadcast done.
[1,55]<stdout>:Variable broadcast done.
[1,53]<stdout>:Variable broadcast done.
[1,49]<stdout>:Variable broadcast done.
[1,52]<stdout>:Variable broadcast done.
[1,48]<stdout>:Variable broadcast done.
[1,70]<stdout>:Variable broadcast done.
[1,64]<stdout>:Variable broadcast done.
[1,67]<stdout>:Variable broadcast done.
[1,69]<stdout>:Variable broadcast done.
[1,68]<stdout>:Variable broadcast done.
[1,66]<stdout>:Variable broadcast done.
[1,71]<stdout>:Variable broadcast done.
[1,65]<stdout>:Variable broadcast done.
[1,86]<stdout>:Variable broadcast done.
[1,87]<stdout>:Variable broadcast done.
[1,101]<stdout>:Variable broadcast done.
[1,80]<stdout>:Variable broadcast done.
[1,2]<stdout>:Variable broadcast done.
[1,96]<stdout>:Variable broadcast done.
[1,81]<stdout>:Variable broadcast done.
[1,4]<stdout>:Variable broadcast done.
[1,98]<stdout>:Variable broadcast done.
[1,114]<stdout>:Variable broadcast done.
[1,82]<stdout>:Variable broadcast done.
[1,7]<stdout>:Variable broadcast done.
[1,102]<stdout>:Variable broadcast done.
[1,113]<stdout>:Variable broadcast done.
[1,85]<stdout>:Variable broadcast done.
[1,1]<stdout>:Variable broadcast done.
[1,99]<stdout>:Variable broadcast done.
[1,116]<stdout>:Variable broadcast done.
[1,83]<stdout>:Variable broadcast done.
[1,3]<stdout>:Variable broadcast done.
[1,103]<stdout>:Variable broadcast done.
[1,112]<stdout>:Variable broadcast done.
[1,84]<stdout>:Variable broadcast done.
[1,100]<stdout>:Variable broadcast done.
[1,118]<stdout>:Variable broadcast done.
[1,97]<stdout>:Variable broadcast done.
[1,115]<stdout>:Variable broadcast done.
[1,117]<stdout>:Variable broadcast done.
[1,119]<stdout>:Variable broadcast done.
[1,0]<stderr>:2020-09-18 19:36:01,164 - INFO - Epoch [2][50/458]	lr: 0.05419, eta: 1:25:45, time: 0.959, data_time: 0.054, rpn_class_loss: 0.0430, rpn_bbox_loss: 0.0164, rcnn_class_loss: 0.3899, rcnn_bbox_loss: 0.2008, rcnn_mask_loss: 0.4032, reg_loss: 0.4244, loss: 1.4777, learning_rate: 0.0516
[1,0]<stderr>:2020-09-18 19:36:44,061 - INFO - Epoch [2][100/458]	lr: 0.05951, eta: 1:23:37, time: 0.858, data_time: 0.033, rpn_class_loss: 14.0343, rpn_bbox_loss: 5.8740, rcnn_class_loss: 11.4110, rcnn_bbox_loss: 2.9961, rcnn_mask_loss: 9.3428, reg_loss: 0.4250, loss: 44.0831, learning_rate: 0.0569
[1,0]<stderr>:2020-09-18 19:37:24,268 - INFO - Epoch [2][150/458]	lr: 0.06484, eta: 1:21:21, time: 0.804, data_time: 0.040, rpn_class_loss: 2.3633, rpn_bbox_loss: 11.1310, rcnn_class_loss: 29.9611, rcnn_bbox_loss: 10.6556, rcnn_mask_loss: 11.4888, reg_loss: 0.4283, loss: 66.0280, learning_rate: 0.0622
[1,0]<stderr>:2020-09-18 19:38:04,433 - INFO - Epoch [2][200/458]	lr: 0.07017, eta: 1:19:19, time: 0.803, data_time: 0.039, rpn_class_loss: 2.2644, rpn_bbox_loss: 9.9697, rcnn_class_loss: 29.9373, rcnn_bbox_loss: 10.7279, rcnn_mask_loss: 11.0336, reg_loss: 0.4283, loss: 64.3612, learning_rate: 0.0676
[1,0]<stderr>:2020-09-18 19:38:44,353 - INFO - Epoch [2][250/458]	lr: 0.07550, eta: 1:17:27, time: 0.798, data_time: 0.038, rpn_class_loss: 1.9877, rpn_bbox_loss: 9.3036, rcnn_class_loss: 27.8213, rcnn_bbox_loss: 10.1979, rcnn_mask_loss: 10.7665, reg_loss: 0.4283, loss: 60.5053, learning_rate: 0.0729
[1,0]<stderr>:2020-09-18 19:39:24,522 - INFO - Epoch [2][300/458]	lr: 0.08083, eta: 1:15:46, time: 0.803, data_time: 0.039, rpn_class_loss: 2.1649, rpn_bbox_loss: 9.4881, rcnn_class_loss: 28.1466, rcnn_bbox_loss: 10.1164, rcnn_mask_loss: 11.0050, reg_loss: 0.4283, loss: 61.3493, learning_rate: 0.0782
[1,0]<stderr>:2020-09-18 19:40:04,992 - INFO - Epoch [2][350/458]	lr: 0.08615, eta: 1:14:15, time: 0.809, data_time: 0.037, rpn_class_loss: 2.2764, rpn_bbox_loss: 9.9003, rcnn_class_loss: 28.1947, rcnn_bbox_loss: 10.2195, rcnn_mask_loss: 11.3271, reg_loss: 0.4283, loss: 62.3463, learning_rate: 0.0835
[1,0]<stderr>:2020-09-18 19:40:45,251 - INFO - Epoch [2][400/458]	lr: 0.09148, eta: 1:12:48, time: 0.805, data_time: 0.040, rpn_class_loss: 1.9947, rpn_bbox_loss: 8.8563, rcnn_class_loss: 27.8502, rcnn_bbox_loss: 9.8287, rcnn_mask_loss: 11.4471, reg_loss: 0.4283, loss: 60.4054, learning_rate: 0.0889
[1,0]<stderr>:2020-09-18 19:41:25,197 - INFO - Epoch [2][450/458]	lr: 0.09681, eta: 1:11:25, time: 0.799, data_time: 0.036, rpn_class_loss: 1.9952, rpn_bbox_loss: 8.4940, rcnn_class_loss: 26.9096, rcnn_bbox_loss: 9.1285, rcnn_mask_loss: 10.9014, reg_loss: 0.4283, loss: 57.8569, learning_rate: 0.0942
[1,96]<stdout>:setting Step LR 0.1599999964237213
[1,96]<stdout>:0.16 0.1 0 [8, 11] 2
[1,51]<stdout>:setting Step LR 0.1599999964237213
[1,51]<stdout>:0.16 0.1 0 [8, 11] 2
[1,16]<stdout>:setting Step LR 0.1599999964237213
[1,16]<stdout>:0.16 0.1 0 [8, 11] 2
[1,34]<stdout>:setting Step LR 0.1599999964237213
[1,34]<stdout>:0.16 0.1 0 [8, 11] 2
[1,2]<stdout>:setting Step LR 0.1599999964237213
[1,2]<stdout>:0.16 0.1 0 [8, 11] 2
[1,52]<stdout>:setting Step LR 0.1599999964237213
[1,52]<stdout>:0.16 0.1 0 [8, 11] 2
[1,3]<stdout>:setting Step LR 0.1599999964237213
[1,3]<stdout>:0.16 0.1 0 [8, 11] 2
[1,114]<stdout>:setting Step LR 0.1599999964237213
[1,114]<stdout>:0.16 0.1 0 [8, 11] 2
[1,55]<stdout>:setting Step LR 0.1599999964237213
[1,55]<stdout>:0.16 0.1 0 [8, 11] 2
[1,99]<stdout>:setting Step LR 0.1599999964237213
[1,99]<stdout>:0.16 0.1 0 [8, 11] 2
[1,98]<stdout>:setting Step LR 0.1599999964237213
[1,98]<stdout>:0.16 0.1 0 [8, 11] 2
[1,96]<stdout>:Starting new loop for GPU: 48
[1,37]<stdout>:setting Step LR 0.1599999964237213
[1,37]<stdout>:0.16 0.1 0 [8, 11] 2
[1,54]<stdout>:setting Step LR 0.1599999964237213
[1,54]<stdout>:0.16 0.1 0 [8, 11] 2
[1,1]<stdout>:setting Step LR 0.1599999964237213
[1,1]<stdout>:0.16 0.1 0 [8, 11] 2
[1,5]<stdout>:setting Step LR 0.1599999964237213
[1,5]<stdout>:0.16 0.1 0 [8, 11] 2
[1,85]<stdout>:setting Step LR 0.1599999964237213
[1,85]<stdout>:0.16 0.1 0 [8, 11] 2
[1,22]<stdout>:setting Step LR 0.1599999964237213
[1,22]<stdout>:0.16 0.1 0 [8, 11] 2
[1,23]<stdout>:setting Step LR 0.1599999964237213
[1,23]<stdout>:0.16 0.1 0 [8, 11] 2
[1,4]<stdout>:setting Step LR 0.1599999964237213
[1,4]<stdout>:0.16 0.1 0 [8, 11] 2
[1,67]<stdout>:setting Step LR 0.1599999964237213
[1,67]<stdout>:0.16 0.1 0 [8, 11] 2
[1,64]<stdout>:setting Step LR 0.1599999964237213
[1,64]<stdout>:0.16 0.1 0 [8, 11] 2
[1,102]<stdout>:setting Step LR 0.1599999964237213
[1,102]<stdout>:0.16 0.1 0 [8, 11] 2
[1,6]<stdout>:setting Step LR 0.1599999964237213
[1,6]<stdout>:0.16 0.1 0 [8, 11] 2
[1,115]<stdout>:setting Step LR 0.1599999964237213
[1,115]<stdout>:0.16 0.1 0 [8, 11] 2
[1,118]<stdout>:setting Step LR 0.1599999964237213
[1,118]<stdout>:0.16 0.1 0 [8, 11] 2
[1,17]<stdout>:setting Step LR 0.1599999964237213
[1,17]<stdout>:0.16 0.1 0 [8, 11] 2
[1,86]<stdout>:setting Step LR 0.1599999964237213
[1,86]<stdout>:0.16 0.1 0 [8, 11] 2
[1,16]<stdout>:Starting new loop for GPU: 8
[1,51]<stdout>:Starting new loop for GPU: 27
[1,36]<stdout>:setting Step LR 0.1599999964237213
[1,36]<stdout>:0.16 0.1 0 [8, 11] 2
[1,38]<stdout>:setting Step LR 0.1599999964237213
[1,38]<stdout>:0.16 0.1 0 [8, 11] 2
[1,34]<stdout>:Starting new loop for GPU: 18
[1,53]<stdout>:setting Step LR 0.1599999964237213
[1,53]<stdout>:0.16 0.1 0 [8, 11] 2
[1,101]<stdout>:setting Step LR 0.1599999964237213
[1,101]<stdout>:0.16 0.1 0 [8, 11] 2
[1,2]<stdout>:Starting new loop for GPU: 2
[1,3]<stdout>:Starting new loop for GPU: 3
[1,119]<stdout>:setting Step LR 0.1599999964237213
[1,119]<stdout>:0.16 0.1 0 [8, 11] 2
[1,114]<stdout>:Starting new loop for GPU: 58
[1,52]<stdout>:Starting new loop for GPU: 28
[1,35]<stdout>:setting Step LR 0.1599999964237213
[1,35]<stdout>:0.16 0.1 0 [8, 11] 2
[1,116]<stdout>:setting Step LR 0.1599999964237213
[1,116]<stdout>:0.16 0.1 0 [8, 11] 2
[1,7]<stdout>:setting Step LR 0.1599999964237213
[1,7]<stdout>:0.16 0.1 0 [8, 11] 2
[1,21]<stdout>:setting Step LR 0.1599999964237213
[1,21]<stdout>:0.16 0.1 0 [8, 11] 2
[1,99]<stdout>:Starting new loop for GPU: 51
[1,55]<stdout>:Starting new loop for GPU: 31
[1,66]<stdout>:setting Step LR 0.1599999964237213
[1,66]<stdout>:0.16 0.1 0 [8, 11] 2
[1,50]<stdout>:setting Step LR 0.1599999964237213
[1,50]<stdout>:0.16 0.1 0 [8, 11] 2
[1,71]<stdout>:setting Step LR 0.1599999964237213
[1,71]<stdout>:0.16 0.1 0 [8, 11] 2
[1,100]<stdout>:setting Step LR 0.1599999964237213
[1,100]<stdout>:0.16 0.1 0 [8, 11] 2
[1,37]<stdout>:Starting new loop for GPU: 21
[1,33]<stdout>:setting Step LR 0.1599999964237213
[1,33]<stdout>:0.16 0.1 0 [8, 11] 2
[1,49]<stdout>:setting Step LR 0.1599999964237213
[1,49]<stdout>:0.16 0.1 0 [8, 11] 2
[1,54]<stdout>:Starting new loop for GPU: 30
[1,20]<stdout>:setting Step LR 0.1599999964237213
[1,20]<stdout>:0.16 0.1 0 [8, 11] 2
[1,98]<stdout>:Starting new loop for GPU: 50
[1,68]<stdout>:setting Step LR 0.1599999964237213
[1,68]<stdout>:0.16 0.1 0 [8, 11] 2
[1,80]<stdout>:setting Step LR 0.1599999964237213
[1,80]<stdout>:0.16 0.1 0 [8, 11] 2
[1,5]<stdout>:Starting new loop for GPU: 5
[1,64]<stdout>:Starting new loop for GPU: 32
[1,23]<stdout>:Starting new loop for GPU: 15
[1,86]<stdout>:Starting new loop for GPU: 46
[1,115]<stdout>:Starting new loop for GPU: 59
[1,82]<stdout>:setting Step LR 0.1599999964237213
[1,22]<stdout>:Starting new loop for GPU: 14
[1,82]<stdout>:0.16 0.1 0 [8, 11] 2
[1,85]<stdout>:Starting new loop for GPU: 45
[1,67]<stdout>:Starting new loop for GPU: 35
[1,17]<stdout>:Starting new loop for GPU: 9
[1,1]<stdout>:Starting new loop for GPU: 1
[1,39]<stdout>:setting Step LR 0.1599999964237213
[1,39]<stdout>:0.16 0.1 0 [8, 11] 2
[1,102]<stdout>:Starting new loop for GPU: 54
[1,4]<stdout>:Starting new loop for GPU: 4
[1,118]<stdout>:Starting new loop for GPU: 62
[1,6]<stdout>:Starting new loop for GPU: 6
[1,119]<stdout>:Starting new loop for GPU: 63
[1,36]<stdout>:Starting new loop for GPU: 20
[1,38]<stdout>:Starting new loop for GPU: 22
[1,35]<stdout>:Starting new loop for GPU: 19
[1,101]<stdout>:Starting new loop for GPU: 53
[1,116]<stdout>:Starting new loop for GPU: 60
[1,21]<stdout>:Starting new loop for GPU: 13
[1,18]<stdout>:setting Step LR 0.1599999964237213
[1,18]<stdout>:0.16 0.1 0 [8, 11] 2
[1,65]<stdout>:setting Step LR 0.1599999964237213
[1,65]<stdout>:0.16 0.1 0 [8, 11] 2
[1,53]<stdout>:Starting new loop for GPU: 29
[1,7]<stdout>:Starting new loop for GPU: 7
[1,87]<stdout>:setting Step LR 0.1599999964237213
[1,87]<stdout>:0.16 0.1 0 [8, 11] 2
[1,50]<stdout>:Starting new loop for GPU: 26
[1,66]<stdout>:Starting new loop for GPU: 34
[1,71]<stdout>:Starting new loop for GPU: 39
[1,70]<stdout>:setting Step LR 0.1599999964237213
[1,70]<stdout>:0.16 0.1 0 [8, 11] 2
[1,33]<stdout>:Starting new loop for GPU: 17
[1,69]<stdout>:setting Step LR 0.1599999964237213
[1,69]<stdout>:0.16 0.1 0 [8, 11] 2
[1,81]<stdout>:setting Step LR 0.1599999964237213
[1,81]<stdout>:0.16 0.1 0 [8, 11] 2
[1,100]<stdout>:Starting new loop for GPU: 52
[1,49]<stdout>:Starting new loop for GPU: 25
[1,80]<stdout>:Starting new loop for GPU: 40
[1,82]<stdout>:Starting new loop for GPU: 42
[1,20]<stdout>:Starting new loop for GPU: 12
[1,83]<stdout>:setting Step LR 0.1599999964237213
[1,83]<stdout>:0.16 0.1 0 [8, 11] 2
[1,68]<stdout>:Starting new loop for GPU: 36
[1,113]<stdout>:setting Step LR 0.1599999964237213
[1,113]<stdout>:0.16 0.1 0 [8, 11] 2
[1,39]<stdout>:Starting new loop for GPU: 23
[1,32]<stdout>:setting Step LR 0.1599999964237213
[1,32]<stdout>:0.16 0.1 0 [8, 11] 2
[1,112]<stdout>:setting Step LR 0.1599999964237213
[1,112]<stdout>:0.16 0.1 0 [8, 11] 2
[1,97]<stdout>:setting Step LR 0.1599999964237213
[1,97]<stdout>:0.16 0.1 0 [8, 11] 2
[1,18]<stdout>:Starting new loop for GPU: 10
[1,84]<stdout>:setting Step LR 0.1599999964237213
[1,84]<stdout>:0.16 0.1 0 [8, 11] 2
[1,87]<stdout>:Starting new loop for GPU: 47
[1,65]<stdout>:Starting new loop for GPU: 33
[1,19]<stdout>:setting Step LR 0.1599999964237213
[1,19]<stdout>:0.16 0.1 0 [8, 11] 2
[1,69]<stdout>:Starting new loop for GPU: 37
[1,81]<stdout>:Starting new loop for GPU: 41
[1,48]<stdout>:setting Step LR 0.1599999964237213
[1,48]<stdout>:0.16 0.1 0 [8, 11] 2
[1,83]<stdout>:Starting new loop for GPU: 43
[1,117]<stdout>:setting Step LR 0.1599999964237213
[1,117]<stdout>:0.16 0.1 0 [8, 11] 2
[1,70]<stdout>:Starting new loop for GPU: 38
[1,103]<stdout>:setting Step LR 0.1599999964237213
[1,103]<stdout>:0.16 0.1 0 [8, 11] 2
[1,97]<stdout>:Starting new loop for GPU: 49
[1,113]<stdout>:Starting new loop for GPU: 57
[1,32]<stdout>:Starting new loop for GPU: 16
[1,112]<stdout>:Starting new loop for GPU: 56
[1,19]<stdout>:Starting new loop for GPU: 11
[1,84]<stdout>:Starting new loop for GPU: 44
[1,117]<stdout>:Starting new loop for GPU: 61
[1,48]<stdout>:Starting new loop for GPU: 24
[1,103]<stdout>:Starting new loop for GPU: 55
[1,0]<stderr>:2020-09-18 19:41:32,819 - INFO - Saved checkpoint at: /shared/deep-learning-models/models/vision/detection/work_dirs/mask_rcnn_r50v1_d_fpn_1x_coco/001/faster_rcnn
[1,0]<stdout>:setting Step LR 0.1599999964237213
[1,0]<stdout>:0.16 0.1 0 [8, 11] 2
[1,0]<stdout>:Starting new loop for GPU: 0
[1,114]<stdout>:Rank 58 broadcasting
[1,98]<stdout>:Rank 50 broadcasting
[1,66]<stdout>:Rank 34 broadcasting
[1,117]<stdout>:Rank 61 broadcasting
[1,96]<stdout>:Rank 48 broadcasting
[1,65]<stdout>:Rank 33 broadcasting
[1,48]<stdout>:Rank 24 broadcasting
[1,64]<stdout>:Rank 32 broadcasting
[1,50]<stdout>:Rank 26 broadcasting
[1,17]<stdout>:Rank 9 broadcasting
[1,69]<stdout>:Rank 37 broadcasting
[1,55]<stdout>:Rank 31 broadcasting
[1,7]<stdout>:Rank 7 broadcasting
[1,22]<stdout>:Rank 14 broadcasting
[1,71]<stdout>:Rank 39 broadcasting
[1,53]<stdout>:Rank 29 broadcasting
[1,21]<stdout>:Rank 13 broadcasting
[1,67]<stdout>:Rank 35 broadcasting
[1,52]<stdout>:Rank 28 broadcasting
[1,85]<stdout>:Rank 45 broadcasting
[1,5]<stdout>:Rank 5 broadcasting
[1,18]<stdout>:Rank 10 broadcasting
[1,54]<stdout>:Rank 30 broadcasting
[1,38]<stdout>:Rank 22 broadcasting
[1,3]<stdout>:Rank 3 broadcasting
[1,16]<stdout>:Rank 8 broadcasting
[1,101]<stdout>:Rank 53 broadcasting
[1,39]<stdout>:Rank 23 broadcasting
[1,86]<stdout>:Rank 46 broadcasting
[1,4]<stdout>:Rank 4 broadcasting
[1,103]<stdout>:Rank 55 broadcasting
[1,34]<stdout>:Rank 18 broadcasting
[1,6]<stdout>:Rank 6 broadcasting
[1,100]<stdout>:Rank 52 broadcasting
[1,112]<stdout>:Rank 56 broadcasting
[1,32]<stdout>:Rank 16 broadcasting
[1,80]<stdout>:Rank 40 broadcasting
[1,2]<stdout>:Rank 2 broadcasting
[1,97]<stdout>:Rank 49 broadcasting
[1,99]<stdout>:Rank 51 broadcasting
[1,115]<stdout>:Rank 59 broadcasting
[1,0]<stdout>:Rank 0 broadcasting
[1,119]<stdout>:Rank 63 broadcasting
[1,113]<stdout>:Rank 57 broadcasting
[1,82]<stdout>:Rank 42 broadcasting
[1,70]<stdout>:Rank 38 broadcasting
[1,102]<stdout>:Rank 54 broadcasting
[1,36]<stdout>:Rank 20 broadcasting
[1,68]<stdout>:Rank 36 broadcasting
[1,1]<stdout>:Rank 1 broadcasting
[1,116]<stdout>:Rank 60 broadcasting
[1,118]<stdout>:Rank 62 broadcasting
[1,84]<stdout>:Rank 44 broadcasting
[1,37]<stdout>:Rank 21 broadcasting
[1,33]<stdout>:Rank 17 broadcasting
[1,83]<stdout>:Rank 43 broadcasting
[1,20]<stdout>:Rank 12 broadcasting
[1,35]<stdout>:Rank 19 broadcasting
[1,23]<stdout>:Rank 15 broadcasting
[1,87]<stdout>:Rank 47 broadcasting
[1,81]<stdout>:Rank 41 broadcasting
[1,19]<stdout>:Rank 11 broadcasting
[1,49]<stdout>:Rank 25 broadcasting
[1,51]<stdout>:Rank 27 broadcasting
[1,0]<stdout>:Variable broadcast done.
[1,5]<stdout>:Variable broadcast done.
[1,6]<stdout>:Variable broadcast done.
[1,17]<stdout>:Variable broadcast done.
[1,22]<stdout>:Variable broadcast done.
[1,16]<stdout>:Variable broadcast done.
[1,18]<stdout>:Variable broadcast done.
[1,19]<stdout>:Variable broadcast done.
[1,21]<stdout>:Variable broadcast done.
[1,23]<stdout>:Variable broadcast done.
[1,20]<stdout>:Variable broadcast done.
[1,38]<stdout>:Variable broadcast done.
[1,37]<stdout>:Variable broadcast done.
[1,33]<stdout>:Variable broadcast done.
[1,32]<stdout>:Variable broadcast done.
[1,35]<stdout>:Variable broadcast done.
[1,39]<stdout>:Variable broadcast done.
[1,34]<stdout>:Variable broadcast done.
[1,36]<stdout>:Variable broadcast done.
[1,50]<stdout>:Variable broadcast done.
[1,55]<stdout>:Variable broadcast done.
[1,51]<stdout>:Variable broadcast done.
[1,49]<stdout>:Variable broadcast done.
[1,54]<stdout>:Variable broadcast done.
[1,48]<stdout>:Variable broadcast done.
[1,53]<stdout>:Variable broadcast done.
[1,52]<stdout>:Variable broadcast done.
[1,68]<stdout>:Variable broadcast done.
[1,67]<stdout>:Variable broadcast done.
[1,66]<stdout>:Variable broadcast done.
[1,70]<stdout>:Variable broadcast done.
[1,71]<stdout>:Variable broadcast done.
[1,64]<stdout>:Variable broadcast done.
[1,69]<stdout>:Variable broadcast done.
[1,65]<stdout>:Variable broadcast done.
[1,96]<stdout>:Variable broadcast done.
[1,102]<stdout>:Variable broadcast done.
[1,82]<stdout>:Variable broadcast done.
[1,98]<stdout>:Variable broadcast done.
[1,84]<stdout>:Variable broadcast done.
[1,101]<stdout>:Variable broadcast done.
[1,85]<stdout>:Variable broadcast done.
[1,2]<stdout>:Variable broadcast done.
[1,103]<stdout>:Variable broadcast done.
[1,81]<stdout>:Variable broadcast done.
[1,3]<stdout>:Variable broadcast done.
[1,100]<stdout>:Variable broadcast done.
[1,80]<stdout>:Variable broadcast done.
[1,4]<stdout>:Variable broadcast done.
[1,99]<stdout>:Variable broadcast done.
[1,115]<stdout>:Variable broadcast done.
[1,86]<stdout>:Variable broadcast done.
[1,1]<stdout>:Variable broadcast done.
[1,97]<stdout>:Variable broadcast done.
[1,112]<stdout>:Variable broadcast done.
[1,83]<stdout>:Variable broadcast done.
[1,7]<stdout>:Variable broadcast done.
[1,113]<stdout>:Variable broadcast done.
[1,87]<stdout>:Variable broadcast done.
[1,114]<stdout>:Variable broadcast done.
[1,118]<stdout>:Variable broadcast done.
[1,116]<stdout>:Variable broadcast done.
[1,119]<stdout>:Variable broadcast done.
[1,117]<stdout>:Variable broadcast done.
[1,0]<stderr>:2020-09-18 19:42:18,091 - INFO - Epoch [3][50/458]	lr: 0.10299, eta: 1:09:49, time: 0.904, data_time: 0.050, rpn_class_loss: 2.2224, rpn_bbox_loss: 9.5288, rcnn_class_loss: 27.3264, rcnn_bbox_loss: 9.8404, rcnn_mask_loss: 10.8133, reg_loss: 0.4283, loss: 60.1595, learning_rate: 0.1004
[1,0]<stderr>:2020-09-18 19:42:59,126 - INFO - Epoch [3][100/458]	lr: 0.10832, eta: 1:08:40, time: 0.821, data_time: 0.037, rpn_class_loss: 2.0608, rpn_bbox_loss: 9.6447, rcnn_class_loss: 26.6371, rcnn_bbox_loss: 9.5857, rcnn_mask_loss: 10.9580, reg_loss: 0.4283, loss: 59.3145, learning_rate: 0.1057
[1,0]<stderr>:2020-09-18 19:43:39,762 - INFO - Epoch [3][150/458]	lr: 0.11365, eta: 1:07:31, time: 0.813, data_time: 0.039, rpn_class_loss: 2.1631, rpn_bbox_loss: 9.4036, rcnn_class_loss: 28.6317, rcnn_bbox_loss: 10.5715, rcnn_mask_loss: 10.7837, reg_loss: 0.4283, loss: 61.9819, learning_rate: 0.1110
[1,0]<stderr>:2020-09-18 19:44:21,466 - INFO - Epoch [3][200/458]	lr: 0.11897, eta: 1:06:30, time: 0.834, data_time: 0.038, rpn_class_loss: 2.0878, rpn_bbox_loss: 9.0844, rcnn_class_loss: 31.4457, rcnn_bbox_loss: 11.1067, rcnn_mask_loss: 11.4570, reg_loss: 0.4283, loss: 65.6098, learning_rate: 0.1164
[1,0]<stderr>:2020-09-18 19:45:01,452 - INFO - Epoch [3][250/458]	lr: 0.12430, eta: 1:05:24, time: 0.800, data_time: 0.041, rpn_class_loss: 2.4450, rpn_bbox_loss: 10.6840, rcnn_class_loss: 31.4322, rcnn_bbox_loss: 11.4768, rcnn_mask_loss: 10.9505, reg_loss: 0.4283, loss: 67.4167, learning_rate: 0.1217
[1,0]<stderr>:2020-09-18 19:45:41,806 - INFO - Epoch [3][300/458]	lr: 0.12963, eta: 1:04:21, time: 0.807, data_time: 0.038, rpn_class_loss: 2.2416, rpn_bbox_loss: 10.0187, rcnn_class_loss: 29.8902, rcnn_bbox_loss: 10.9264, rcnn_mask_loss: 11.5336, reg_loss: 0.4283, loss: 65.0388, learning_rate: 0.1270
[1,0]<stderr>:2020-09-18 19:46:22,149 - INFO - Epoch [3][350/458]	lr: 0.13496, eta: 1:03:20, time: 0.807, data_time: 0.036, rpn_class_loss: 1.8912, rpn_bbox_loss: 8.0389, rcnn_class_loss: 27.9985, rcnn_bbox_loss: 10.0084, rcnn_mask_loss: 12.5378, reg_loss: 0.4283, loss: 60.9031, learning_rate: 0.1323
[1,0]<stderr>:2020-09-18 19:47:02,158 - INFO - Epoch [3][400/458]	lr: 0.14029, eta: 1:02:19, time: 0.800, data_time: 0.038, rpn_class_loss: 2.2422, rpn_bbox_loss: 9.8381, rcnn_class_loss: 28.7197, rcnn_bbox_loss: 10.7783, rcnn_mask_loss: 10.3386, reg_loss: 0.4283, loss: 62.3453, learning_rate: 0.1377
[1,0]<stderr>:2020-09-18 19:47:42,017 - INFO - Epoch [3][450/458]	lr: 0.14561, eta: 1:01:20, time: 0.797, data_time: 0.046, rpn_class_loss: 2.9248, rpn_bbox_loss: 12.8824, rcnn_class_loss: 32.4842, rcnn_bbox_loss: 11.6117, rcnn_mask_loss: 11.1688, reg_loss: 0.4283, loss: 71.5001, learning_rate: 0.1430
[1,19]<stdout>:setting Step LR 0.1599999964237213
[1,19]<stdout>:0.16 0.1 0 [8, 11] 3
[1,81]<stdout>:setting Step LR 0.1599999964237213
[1,81]<stdout>:0.16 0.1 0 [8, 11] 3
[1,65]<stdout>:setting Step LR 0.1599999964237213
[1,65]<stdout>:0.16 0.1 0 [8, 11] 3
[1,96]<stdout>:setting Step LR 0.1599999964237213
[1,96]<stdout>:0.16 0.1 0 [8, 11] 3
[1,119]<stdout>:setting Step LR 0.1599999964237213
[1,119]<stdout>:0.16 0.1 0 [8, 11] 3
[1,16]<stdout>:setting Step LR 0.1599999964237213
[1,16]<stdout>:0.16 0.1 0 [8, 11] 3
[1,21]<stdout>:setting Step LR 0.1599999964237213
[1,21]<stdout>:0.16 0.1 0 [8, 11] 3
[1,51]<stdout>:setting Step LR 0.1599999964237213
[1,51]<stdout>:0.16 0.1 0 [8, 11] 3
[1,19]<stdout>:Starting new loop for GPU: 11
[1,85]<stdout>:setting Step LR 0.1599999964237213
[1,85]<stdout>:0.16 0.1 0 [8, 11] 3
[1,66]<stdout>:setting Step LR 0.1599999964237213
[1,66]<stdout>:0.16 0.1 0 [8, 11] 3
[1,32]<stdout>:setting Step LR 0.1599999964237213
[1,32]<stdout>:0.16 0.1 0 [8, 11] 3
[1,102]<stdout>:setting Step LR 0.1599999964237213
[1,102]<stdout>:0.16 0.1 0 [8, 11] 3
[1,114]<stdout>:setting Step LR 0.1599999964237213
[1,114]<stdout>:0.16 0.1 0 [8, 11] 3
[1,81]<stdout>:Starting new loop for GPU: 41
[1,86]<stdout>:setting Step LR 0.1599999964237213
[1,86]<stdout>:0.16 0.1 0 [8, 11] 3
[1,70]<stdout>:setting Step LR 0.1599999964237213
[1,70]<stdout>:0.16 0.1 0 [8, 11] 3
[1,118]<stdout>:setting Step LR 0.1599999964237213
[1,118]<stdout>:0.16 0.1 0 [8, 11] 3
[1,4]<stdout>:setting Step LR 0.1599999964237213
[1,4]<stdout>:0.16 0.1 0 [8, 11] 3
[1,82]<stdout>:setting Step LR 0.1599999964237213
[1,82]<stdout>:0.16 0.1 0 [8, 11] 3
[1,87]<stdout>:setting Step LR 0.1599999964237213
[1,87]<stdout>:0.16 0.1 0 [8, 11] 3
[1,35]<stdout>:setting Step LR 0.1599999964237213
[1,35]<stdout>:0.16 0.1 0 [8, 11] 3
[1,71]<stdout>:setting Step LR 0.1599999964237213
[1,71]<stdout>:0.16 0.1 0 [8, 11] 3
[1,22]<stdout>:setting Step LR 0.1599999964237213
[1,22]<stdout>:0.16 0.1 0 [8, 11] 3
[1,113]<stdout>:setting Step LR 0.1599999964237213
[1,113]<stdout>:0.16 0.1 0 [8, 11] 3
[1,34]<stdout>:setting Step LR 0.1599999964237213
[1,34]<stdout>:0.16 0.1 0 [8, 11] 3
[1,116]<stdout>:setting Step LR 0.1599999964237213
[1,116]<stdout>:0.16 0.1 0 [8, 11] 3
[1,18]<stdout>:setting Step LR 0.1599999964237213
[1,18]<stdout>:0.16 0.1 0 [8, 11] 3
[1,54]<stdout>:setting Step LR 0.1599999964237213
[1,54]<stdout>:0.16 0.1 0 [8, 11] 3
[1,96]<stdout>:Starting new loop for GPU: 48
[1,65]<stdout>:Starting new loop for GPU: 33
[1,119]<stdout>:Starting new loop for GPU: 63
[1,51]<stdout>:Starting new loop for GPU: 27
[1,33]<stdout>:setting Step LR 0.1599999964237213
[1,33]<stdout>:0.16 0.1 0 [8, 11] 3
[1,37]<stdout>:setting Step LR 0.1599999964237213
[1,37]<stdout>:0.16 0.1 0 [8, 11] 3
[1,80]<stdout>:setting Step LR 0.1599999964237213
[1,80]<stdout>:0.16 0.1 0 [8, 11] 3
[1,85]<stdout>:Starting new loop for GPU: 45
[1,16]<stdout>:Starting new loop for GPU: 8
[1,97]<stdout>:setting Step LR 0.1599999964237213
[1,97]<stdout>:0.16 0.1 0 [8, 11] 3
[1,103]<stdout>:setting Step LR 0.1599999964237213
[1,103]<stdout>:0.16 0.1 0 [8, 11] 3
[1,3]<stdout>:setting Step LR 0.1599999964237213
[1,3]<stdout>:0.16 0.1 0 [8, 11] 3
[1,32]<stdout>:Starting new loop for GPU: 16
[1,102]<stdout>:Starting new loop for GPU: 54
[1,53]<stdout>:setting Step LR 0.1599999964237213
[1,53]<stdout>:0.16 0.1 0 [8, 11] 3
[1,21]<stdout>:Starting new loop for GPU: 13
[1,55]<stdout>:setting Step LR 0.1599999964237213
[1,55]<stdout>:0.16 0.1 0 [8, 11] 3
[1,49]<stdout>:setting Step LR 0.1599999964237213
[1,49]<stdout>:0.16 0.1 0 [8, 11] 3
[1,114]<stdout>:Starting new loop for GPU: 58
[1,66]<stdout>:Starting new loop for GPU: 34
[1,5]<stdout>:setting Step LR 0.1599999964237213
[1,5]<stdout>:0.16 0.1 0 [8, 11] 3
[1,117]<stdout>:setting Step LR 0.1599999964237213
[1,117]<stdout>:0.16 0.1 0 [8, 11] 3
[1,70]<stdout>:Starting new loop for GPU: 38
[1,86]<stdout>:Starting new loop for GPU: 46
[1,4]<stdout>:Starting new loop for GPU: 4
[1,118]<stdout>:Starting new loop for GPU: 62
[1,82]<stdout>:Starting new loop for GPU: 42
[1,50]<stdout>:setting Step LR 0.1599999964237213
[1,50]<stdout>:0.16 0.1 0 [8, 11] 3
[1,87]<stdout>:Starting new loop for GPU: 47
[1,98]<stdout>:setting Step LR 0.1599999964237213
[1,98]<stdout>:0.16 0.1 0 [8, 11] 3
[1,35]<stdout>:Starting new loop for GPU: 19
[1,100]<stdout>:setting Step LR 0.1599999964237213
[1,100]<stdout>:0.16 0.1 0 [8, 11] 3
[1,36]<stdout>:setting Step LR 0.1599999964237213
[1,36]<stdout>:0.16 0.1 0 [8, 11] 3
[1,38]<stdout>:setting Step LR 0.1599999964237213
[1,38]<stdout>:0.16 0.1 0 [8, 11] 3
[1,101]<stdout>:setting Step LR 0.1599999964237213
[1,101]<stdout>:0.16 0.1 0 [8, 11] 3
[1,48]<stdout>:setting Step LR 0.1599999964237213
[1,48]<stdout>:0.16 0.1 0 [8, 11] 3
[1,68]<stdout>:setting Step LR 0.1599999964237213
[1,68]<stdout>:0.16 0.1 0 [8, 11] 3
[1,54]<stdout>:Starting new loop for GPU: 30
[1,22]<stdout>:Starting new loop for GPU: 14
[1,71]<stdout>:Starting new loop for GPU: 39
[1,2]<stdout>:setting Step LR 0.1599999964237213
[1,2]<stdout>:0.16 0.1 0 [8, 11] 3
[1,113]<stdout>:Starting new loop for GPU: 57
[1,34]<stdout>:Starting new loop for GPU: 18
[1,116]<stdout>:Starting new loop for GPU: 60
[1,52]<stdout>:setting Step LR 0.1599999964237213
[1,52]<stdout>:0.16 0.1 0 [8, 11] 3
[1,18]<stdout>:Starting new loop for GPU: 10
[1,33]<stdout>:Starting new loop for GPU: 17
[1,37]<stdout>:Starting new loop for GPU: 21
[1,99]<stdout>:setting Step LR 0.1599999964237213
[1,99]<stdout>:0.16 0.1 0 [8, 11] 3
[1,97]<stdout>:Starting new loop for GPU: 49
[1,3]<stdout>:Starting new loop for GPU: 3
[1,80]<stdout>:Starting new loop for GPU: 40
[1,103]<stdout>:Starting new loop for GPU: 55
[1,5]<stdout>:Starting new loop for GPU: 5
[1,117]<stdout>:Starting new loop for GPU: 61
[1,6]<stdout>:setting Step LR 0.1599999964237213
[1,6]<stdout>:0.16 0.1 0 [8, 11] 3
[1,53]<stdout>:Starting new loop for GPU: 29
[1,55]<stdout>:Starting new loop for GPU: 31
[1,17]<stdout>:setting Step LR 0.1599999964237213
[1,17]<stdout>:0.16 0.1 0 [8, 11] 3
[1,49]<stdout>:Starting new loop for GPU: 25
[1,69]<stdout>:setting Step LR 0.1599999964237213
[1,69]<stdout>:0.16 0.1 0 [8, 11] 3
[1,50]<stdout>:Starting new loop for GPU: 26
[1,36]<stdout>:Starting new loop for GPU: 20
[1,38]<stdout>:Starting new loop for GPU: 22
[1,68]<stdout>:Starting new loop for GPU: 36
[1,48]<stdout>:Starting new loop for GPU: 24
[1,2]<stdout>:Starting new loop for GPU: 2
[1,101]<stdout>:Starting new loop for GPU: 53
[1,84]<stdout>:setting Step LR 0.1599999964237213
[1,84]<stdout>:0.16 0.1 0 [8, 11] 3
[1,100]<stdout>:Starting new loop for GPU: 52
[1,98]<stdout>:Starting new loop for GPU: 50
[1,52]<stdout>:Starting new loop for GPU: 28
[1,99]<stdout>:Starting new loop for GPU: 51
[1,64]<stdout>:setting Step LR 0.1599999964237213
[1,64]<stdout>:0.16 0.1 0 [8, 11] 3
[1,112]<stdout>:setting Step LR 0.1599999964237213
[1,112]<stdout>:0.16 0.1 0 [8, 11] 3
[1,6]<stdout>:Starting new loop for GPU: 6
[1,69]<stdout>:Starting new loop for GPU: 37
[1,115]<stdout>:setting Step LR 0.1599999964237213
[1,115]<stdout>:0.16 0.1 0 [8, 11] 3
[1,17]<stdout>:Starting new loop for GPU: 9
[1,84]<stdout>:Starting new loop for GPU: 44
[1,67]<stdout>:setting Step LR 0.1599999964237213
[1,67]<stdout>:0.16 0.1 0 [8, 11] 3
[1,1]<stdout>:setting Step LR 0.1599999964237213
[1,1]<stdout>:0.16 0.1 0 [8, 11] 3
[1,39]<stdout>:setting Step LR 0.1599999964237213
[1,39]<stdout>:0.16 0.1 0 [8, 11] 3
[1,64]<stdout>:Starting new loop for GPU: 32
[1,112]<stdout>:Starting new loop for GPU: 56
[1,7]<stdout>:setting Step LR 0.1599999964237213
[1,7]<stdout>:0.16 0.1 0 [8, 11] 3
[1,115]<stdout>:Starting new loop for GPU: 59
[1,1]<stdout>:Starting new loop for GPU: 1
[1,67]<stdout>:Starting new loop for GPU: 35
[1,23]<stdout>:setting Step LR 0.1599999964237213
[1,23]<stdout>:0.16 0.1 0 [8, 11] 3
[1,39]<stdout>:Starting new loop for GPU: 23
[1,7]<stdout>:Starting new loop for GPU: 7
[1,23]<stdout>:Starting new loop for GPU: 15
[1,20]<stdout>:setting Step LR 0.1599999964237213
[1,20]<stdout>:0.16 0.1 0 [8, 11] 3
[1,20]<stdout>:Starting new loop for GPU: 12
[1,83]<stdout>:setting Step LR 0.1599999964237213
[1,83]<stdout>:0.16 0.1 0 [8, 11] 3
[1,83]<stdout>:Starting new loop for GPU: 43
[1,0]<stderr>:2020-09-18 19:47:49,535 - INFO - Saved checkpoint at: /shared/deep-learning-models/models/vision/detection/work_dirs/mask_rcnn_r50v1_d_fpn_1x_coco/002/faster_rcnn
[1,0]<stdout>:setting Step LR 0.1599999964237213
[1,0]<stdout>:0.16 0.1 0 [8, 11] 3
[1,0]<stdout>:Starting new loop for GPU: 0
[1,32]<stdout>:Rank 16 broadcasting
[1,98]<stdout>:Rank 50 broadcasting
[1,34]<stdout>:Rank 18 broadcasting
[1,37]<stdout>:Rank 21 broadcasting
[1,35]<stdout>:Rank 19 broadcasting
[1,33]<stdout>:Rank 17 broadcasting
[1,97]<stdout>:Rank 49 broadcasting
[1,65]<stdout>:Rank 33 broadcasting
[1,5]<stdout>:Rank 5 broadcasting
[1,102]<stdout>:Rank 54 broadcasting
[1,66]<stdout>:Rank 34 broadcasting
[1,80]<stdout>:Rank 40 broadcasting
[1,7]<stdout>:Rank 7 broadcasting
[1,103]<stdout>:Rank 55 broadcasting
[1,70]<stdout>:Rank 38 broadcasting
[1,82]<stdout>:Rank 42 broadcasting
[1,0]<stdout>:Rank 0 broadcasting
[1,100]<stdout>:Rank 52 broadcasting
[1,68]<stdout>:Rank 36 broadcasting
[1,112]<stdout>:Rank 56 broadcasting
[1,38]<stdout>:Rank 22 broadcasting
[1,86]<stdout>:Rank 46 broadcasting
[1,4]<stdout>:Rank 4 broadcasting
[1,71]<stdout>:Rank 39 broadcasting
[1,113]<stdout>:Rank 57 broadcasting
[1,67]<stdout>:Rank 35 broadcasting
[1,119]<stdout>:Rank 63 broadcasting
[1,69]<stdout>:Rank 37 broadcasting
[1,115]<stdout>:Rank 59 broadcasting
[1,117]<stdout>:Rank 61 broadcasting
[1,36]<stdout>:Rank 20 broadcasting
[1,64]<stdout>:Rank 32 broadcasting
[1,48]<stdout>:Rank 24 broadcasting
[1,3]<stdout>:Rank 3 broadcasting
[1,49]<stdout>:Rank 25 broadcasting
[1,54]<stdout>:Rank 30 broadcasting
[1,39]<stdout>:Rank 23 broadcasting
[1,53]<stdout>:Rank 29 broadcasting
[1,101]<stdout>:Rank 53 broadcasting
[1,50]<stdout>:Rank 26 broadcasting
[1,84]<stdout>:Rank 44 broadcasting
[1,118]<stdout>:Rank 62 broadcasting
[1,99]<stdout>:Rank 51 broadcasting
[1,1]<stdout>:Rank 1 broadcasting
[1,22]<stdout>:Rank 14 broadcasting
[1,114]<stdout>:Rank 58 broadcasting
[1,21]<stdout>:Rank 13 broadcasting
[1,116]<stdout>:Rank 60 broadcasting
[1,55]<stdout>:Rank 31 broadcasting
[1,19]<stdout>:Rank 11 broadcasting
[1,16]<stdout>:Rank 8 broadcasting
[1,20]<stdout>:Rank 12 broadcasting
[1,87]<stdout>:Rank 47 broadcasting
[1,17]<stdout>:Rank 9 broadcasting
[1,85]<stdout>:Rank 45 broadcasting
[1,18]<stdout>:Rank 10 broadcasting
[1,2]<stdout>:Rank 2 broadcasting
[1,51]<stdout>:Rank 27 broadcasting
[1,6]<stdout>:Rank 6 broadcasting
[1,52]<stdout>:Rank 28 broadcasting
[1,23]<stdout>:Rank 15 broadcasting
[1,81]<stdout>:Rank 41 broadcasting
[1,83]<stdout>:Rank 43 broadcasting
[1,96]<stdout>:Rank 48 broadcasting
[1,0]<stdout>:Variable broadcast done.
[1,5]<stdout>:Variable broadcast done.
[1,6]<stdout>:Variable broadcast done.
[1,16]<stdout>:Variable broadcast done.
[1,19]<stdout>:Variable broadcast done.
[1,18]<stdout>:Variable broadcast done.
[1,22]<stdout>:Variable broadcast done.
[1,17]<stdout>:Variable broadcast done.
[1,21]<stdout>:Variable broadcast done.
[1,23]<stdout>:Variable broadcast done.
[1,20]<stdout>:Variable broadcast done.
[1,39]<stdout>:Variable broadcast done.
[1,38]<stdout>:Variable broadcast done.
[1,37]<stdout>:Variable broadcast done.
[1,32]<stdout>:Variable broadcast done.
[1,35]<stdout>:Variable broadcast done.
[1,34]<stdout>:Variable broadcast done.
[1,54]<stdout>:Variable broadcast done.
[1,33]<stdout>:Variable broadcast done.
[1,48]<stdout>:Variable broadcast done.
[1,36]<stdout>:Variable broadcast done.
[1,49]<stdout>:Variable broadcast done.
[1,51]<stdout>:Variable broadcast done.
[1,50]<stdout>:Variable broadcast done.
[1,52]<stdout>:Variable broadcast done.
[1,53]<stdout>:Variable broadcast done.
[1,55]<stdout>:Variable broadcast done.
[1,70]<stdout>:Variable broadcast done.
[1,66]<stdout>:Variable broadcast done.
[1,68]<stdout>:Variable broadcast done.
[1,64]<stdout>:Variable broadcast done.
[1,67]<stdout>:Variable broadcast done.
[1,69]<stdout>:Variable broadcast done.
[1,71]<stdout>:Variable broadcast done.
[1,82]<stdout>:Variable broadcast done.
[1,65]<stdout>:Variable broadcast done.
[1,80]<stdout>:Variable broadcast done.
[1,85]<stdout>:Variable broadcast done.
[1,87]<stdout>:Variable broadcast done.
[1,81]<stdout>:Variable broadcast done.
[1,86]<stdout>:Variable broadcast done.
[1,83]<stdout>:Variable broadcast done.
[1,84]<stdout>:Variable broadcast done.
[1,1]<stdout>:Variable broadcast done.
[1,102]<stdout>:Variable broadcast done.
[1,118]<stdout>:Variable broadcast done.
[1,2]<stdout>:Variable broadcast done.
[1,98]<stdout>:Variable broadcast done.
[1,112]<stdout>:Variable broadcast done.
[1,4]<stdout>:Variable broadcast done.
[1,99]<stdout>:Variable broadcast done.
[1,113]<stdout>:Variable broadcast done.
[1,97]<stdout>:Variable broadcast done.
[1,119]<stdout>:Variable broadcast done.
[1,3]<stdout>:Variable broadcast done.
[1,100]<stdout>:Variable broadcast done.
[1,117]<stdout>:Variable broadcast done.
[1,7]<stdout>:Variable broadcast done.
[1,101]<stdout>:Variable broadcast done.
[1,116]<stdout>:Variable broadcast done.
[1,103]<stdout>:Variable broadcast done.
[1,114]<stdout>:Variable broadcast done.
[1,96]<stdout>:Variable broadcast done.
[1,115]<stdout>:Variable broadcast done.
[1,0]<stderr>:2020-09-18 19:48:35,080 - INFO - Epoch [4][50/458]	lr: 0.15179, eta: 1:00:10, time: 0.910, data_time: 0.046, rpn_class_loss: 2.3832, rpn_bbox_loss: 11.3357, rcnn_class_loss: 30.8851, rcnn_bbox_loss: 10.9830, rcnn_mask_loss: 11.0943, reg_loss: 0.4283, loss: 67.1096, learning_rate: 0.1492
[1,0]<stderr>:2020-09-18 19:49:16,665 - INFO - Epoch [4][100/458]	lr: 0.15712, eta: 0:59:19, time: 0.832, data_time: 0.045, rpn_class_loss: 2.5771, rpn_bbox_loss: 11.0134, rcnn_class_loss: 29.7700, rcnn_bbox_loss: 11.0091, rcnn_mask_loss: 11.4811, reg_loss: 0.4283, loss: 66.2790, learning_rate: 0.1545
[1,0]<stderr>:2020-09-18 19:49:56,562 - INFO - Epoch [4][150/458]	lr: 0.16000, eta: 0:58:23, time: 0.798, data_time: 0.036, rpn_class_loss: 1.9040, rpn_bbox_loss: 8.7543, rcnn_class_loss: 28.7608, rcnn_bbox_loss: 10.4439, rcnn_mask_loss: 11.0814, reg_loss: 0.4283, loss: 61.3727, learning_rate: 0.1593
[1,0]<stderr>:2020-09-18 19:50:36,367 - INFO - Epoch [4][200/458]	lr: 0.16000, eta: 0:57:28, time: 0.796, data_time: 0.033, rpn_class_loss: 1.8285, rpn_bbox_loss: 8.0570, rcnn_class_loss: 24.5881, rcnn_bbox_loss: 8.5910, rcnn_mask_loss: 11.0762, reg_loss: 0.4283, loss: 54.5690, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 19:51:16,644 - INFO - Epoch [4][250/458]	lr: 0.16000, eta: 0:56:35, time: 0.806, data_time: 0.038, rpn_class_loss: 1.8500, rpn_bbox_loss: 8.3992, rcnn_class_loss: 25.9457, rcnn_bbox_loss: 9.4667, rcnn_mask_loss: 11.0437, reg_loss: 0.4283, loss: 57.1335, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 19:51:56,672 - INFO - Epoch [4][300/458]	lr: 0.16000, eta: 0:55:43, time: 0.801, data_time: 0.036, rpn_class_loss: 2.2543, rpn_bbox_loss: 9.5372, rcnn_class_loss: 26.8449, rcnn_bbox_loss: 10.1478, rcnn_mask_loss: 11.0478, reg_loss: 0.4283, loss: 60.2602, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 19:52:37,140 - INFO - Epoch [4][350/458]	lr: 0.16000, eta: 0:54:52, time: 0.809, data_time: 0.034, rpn_class_loss: 1.8459, rpn_bbox_loss: 7.6407, rcnn_class_loss: 26.2771, rcnn_bbox_loss: 9.4440, rcnn_mask_loss: 10.5350, reg_loss: 0.4283, loss: 56.1710, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 19:53:17,203 - INFO - Epoch [4][400/458]	lr: 0.16000, eta: 0:54:01, time: 0.801, data_time: 0.047, rpn_class_loss: 2.3858, rpn_bbox_loss: 10.9075, rcnn_class_loss: 30.8434, rcnn_bbox_loss: 11.0153, rcnn_mask_loss: 11.4437, reg_loss: 0.4283, loss: 67.0240, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 19:53:56,816 - INFO - Epoch [4][450/458]	lr: 0.16000, eta: 0:53:09, time: 0.792, data_time: 0.035, rpn_class_loss: 1.9355, rpn_bbox_loss: 8.9166, rcnn_class_loss: 26.8642, rcnn_bbox_loss: 9.6648, rcnn_mask_loss: 11.2512, reg_loss: 0.4283, loss: 59.0605, learning_rate: 0.1600
[1,80]<stdout>:setting Step LR 0.1599999964237213
[1,80]<stdout>:0.16 0.1 0 [8, 11] 4
[1,96]<stdout>:setting Step LR 0.1599999964237213
[1,96]<stdout>:0.16 0.1 0 [8, 11] 4
[1,3]<stdout>:setting Step LR 0.1599999964237213
[1,3]<stdout>:0.16 0.1 0 [8, 11] 4
[1,39]<stdout>:setting Step LR 0.1599999964237213
[1,39]<stdout>:0.16 0.1 0 [8, 11] 4
[1,7]<stdout>:setting Step LR 0.1599999964237213
[1,7]<stdout>:0.16 0.1 0 [8, 11] 4
[1,53]<stdout>:setting Step LR 0.1599999964237213
[1,53]<stdout>:0.16 0.1 0 [8, 11] 4
[1,118]<stdout>:setting Step LR 0.1599999964237213
[1,118]<stdout>:0.16 0.1 0 [8, 11] 4
[1,6]<stdout>:setting Step LR 0.1599999964237213
[1,6]<stdout>:0.16 0.1 0 [8, 11] 4
[1,112]<stdout>:setting Step LR 0.1599999964237213
[1,112]<stdout>:0.16 0.1 0 [8, 11] 4
[1,17]<stdout>:setting Step LR 0.1599999964237213
[1,17]<stdout>:0.16 0.1 0 [8, 11] 4
[1,34]<stdout>:setting Step LR 0.1599999964237213
[1,34]<stdout>:0.16 0.1 0 [8, 11] 4
[1,69]<stdout>:setting Step LR 0.1599999964237213
[1,69]<stdout>:0.16 0.1 0 [8, 11] 4
[1,84]<stdout>:setting Step LR 0.1599999964237213
[1,84]<stdout>:0.16 0.1 0 [8, 11] 4
[1,22]<stdout>:setting Step LR 0.1599999964237213
[1,22]<stdout>:0.16 0.1 0 [8, 11] 4
[1,80]<stdout>:Starting new loop for GPU: 40
[1,50]<stdout>:setting Step LR 0.1599999964237213
[1,50]<stdout>:0.16 0.1 0 [8, 11] 4
[1,96]<stdout>:Starting new loop for GPU: 48
[1,3]<stdout>:Starting new loop for GPU: 3
[1,20]<stdout>:setting Step LR 0.1599999964237213
[1,20]<stdout>:0.16 0.1 0 [8, 11] 4
[1,67]<stdout>:setting Step LR 0.1599999964237213
[1,67]<stdout>:0.16 0.1 0 [8, 11] 4
[1,39]<stdout>:Starting new loop for GPU: 23
[1,70]<stdout>:setting Step LR 0.1599999964237213
[1,70]<stdout>:0.16 0.1 0 [8, 11] 4
[1,4]<stdout>:setting Step LR 0.1599999964237213
[1,4]<stdout>:0.16 0.1 0 [8, 11] 4
[1,53]<stdout>:Starting new loop for GPU: 29
[1,7]<stdout>:Starting new loop for GPU: 7
[1,99]<stdout>:setting Step LR 0.1599999964237213
[1,99]<stdout>:0.16 0.1 0 [8, 11] 4
[1,66]<stdout>:setting Step LR 0.1599999964237213
[1,66]<stdout>:0.16 0.1 0 [8, 11] 4
[1,86]<stdout>:setting Step LR 0.1599999964237213
[1,86]<stdout>:0.16 0.1 0 [8, 11] 4
[1,16]<stdout>:setting Step LR 0.1599999964237213
[1,16]<stdout>:0.16 0.1 0 [8, 11] 4
[1,52]<stdout>:setting Step LR 0.1599999964237213
[1,52]<stdout>:0.16 0.1 0 [8, 11] 4
[1,100]<stdout>:setting Step LR 0.1599999964237213
[1,100]<stdout>:0.16 0.1 0 [8, 11] 4
[1,81]<stdout>:setting Step LR 0.1599999964237213
[1,81]<stdout>:0.16 0.1 0 [8, 11] 4
[1,118]<stdout>:Starting new loop for GPU: 62
[1,51]<stdout>:setting Step LR 0.1599999964237213
[1,51]<stdout>:0.16 0.1 0 [8, 11] 4
[1,6]<stdout>:Starting new loop for GPU: 6
[1,2]<stdout>:setting Step LR 0.1599999964237213
[1,2]<stdout>:0.16 0.1 0 [8, 11] 4
[1,112]<stdout>:Starting new loop for GPU: 56
[1,103]<stdout>:setting Step LR 0.1599999964237213
[1,103]<stdout>:0.16 0.1 0 [8, 11] 4
[1,97]<stdout>:setting Step LR 0.1599999964237213
[1,97]<stdout>:0.16 0.1 0 [8, 11] 4
[1,101]<stdout>:setting Step LR 0.1599999964237213
[1,101]<stdout>:0.16 0.1 0 [8, 11] 4
[1,113]<stdout>:setting Step LR 0.1599999964237213
[1,113]<stdout>:0.16 0.1 0 [8, 11] 4
[1,17]<stdout>:Starting new loop for GPU: 9
[1,34]<stdout>:Starting new loop for GPU: 18
[1,49]<stdout>:setting Step LR 0.1599999964237213
[1,49]<stdout>:0.16 0.1 0 [8, 11] 4
[1,117]<stdout>:setting Step LR 0.1599999964237213
[1,117]<stdout>:0.16 0.1 0 [8, 11] 4
[1,82]<stdout>:setting Step LR 0.1599999964237213
[1,82]<stdout>:0.16 0.1 0 [8, 11] 4
[1,54]<stdout>:setting Step LR 0.1599999964237213
[1,54]<stdout>:0.16 0.1 0 [8, 11] 4
[1,21]<stdout>:setting Step LR 0.1599999964237213
[1,21]<stdout>:0.16 0.1 0 [8, 11] 4
[1,68]<stdout>:setting Step LR 0.1599999964237213
[1,68]<stdout>:0.16 0.1 0 [8, 11] 4
[1,33]<stdout>:setting Step LR 0.1599999964237213
[1,33]<stdout>:0.16 0.1 0 [8, 11] 4
[1,69]<stdout>:Starting new loop for GPU: 37
[1,65]<stdout>:setting Step LR 0.1599999964237213
[1,65]<stdout>:0.16 0.1 0 [8, 11] 4
[1,18]<stdout>:setting Step LR 0.1599999964237213
[1,18]<stdout>:0.16 0.1 0 [8, 11] 4
[1,32]<stdout>:setting Step LR 0.1599999964237213
[1,32]<stdout>:0.16 0.1 0 [8, 11] 4
[1,22]<stdout>:Starting new loop for GPU: 14
[1,115]<stdout>:setting Step LR 0.1599999964237213
[1,115]<stdout>:0.16 0.1 0 [8, 11] 4
[1,84]<stdout>:Starting new loop for GPU: 44
[1,50]<stdout>:Starting new loop for GPU: 26
[1,20]<stdout>:Starting new loop for GPU: 12
[1,48]<stdout>:setting Step LR 0.1599999964237213
[1,48]<stdout>:0.16 0.1 0 [8, 11] 4
[1,67]<stdout>:Starting new loop for GPU: 35
[1,5]<stdout>:setting Step LR 0.1599999964237213
[1,5]<stdout>:0.16 0.1 0 [8, 11] 4
[1,23]<stdout>:setting Step LR 0.1599999964237213
[1,23]<stdout>:0.16 0.1 0 [8, 11] 4
[1,87]<stdout>:setting Step LR 0.1599999964237213
[1,87]<stdout>:0.16 0.1 0 [8, 11] 4
[1,52]<stdout>:Starting new loop for GPU: 28
[1,16]<stdout>:Starting new loop for GPU: 8
[1,81]<stdout>:Starting new loop for GPU: 41
[1,114]<stdout>:setting Step LR 0.1599999964237213
[1,114]<stdout>:0.16 0.1 0 [8, 11] 4
[1,99]<stdout>:Starting new loop for GPU: 51
[1,66]<stdout>:Starting new loop for GPU: 34
[1,4]<stdout>:Starting new loop for GPU: 4
[1,70]<stdout>:Starting new loop for GPU: 38
[1,113]<stdout>:Starting new loop for GPU: 57
[1,86]<stdout>:Starting new loop for GPU: 46
[1,51]<stdout>:Starting new loop for GPU: 27
[1,97]<stdout>:Starting new loop for GPU: 49
[1,117]<stdout>:Starting new loop for GPU: 61
[1,100]<stdout>:Starting new loop for GPU: 52
[1,103]<stdout>:Starting new loop for GPU: 55
[1,101]<stdout>:Starting new loop for GPU: 53
[1,19]<stdout>:setting Step LR 0.1599999964237213
[1,19]<stdout>:0.16 0.1 0 [8, 11] 4
[1,33]<stdout>:Starting new loop for GPU: 17
[1,82]<stdout>:Starting new loop for GPU: 42
[1,2]<stdout>:Starting new loop for GPU: 2
[1,21]<stdout>:Starting new loop for GPU: 13
[1,54]<stdout>:Starting new loop for GPU: 30
[1,85]<stdout>:setting Step LR 0.1599999964237213
[1,85]<stdout>:0.16 0.1 0 [8, 11] 4
[1,49]<stdout>:Starting new loop for GPU: 25
[1,36]<stdout>:setting Step LR 0.1599999964237213
[1,36]<stdout>:0.16 0.1 0 [8, 11] 4
[1,115]<stdout>:Starting new loop for GPU: 59
[1,119]<stdout>:setting Step LR 0.1599999964237213
[1,119]<stdout>:0.16 0.1 0 [8, 11] 4
[1,68]<stdout>:Starting new loop for GPU: 36
[1,32]<stdout>:Starting new loop for GPU: 16
[1,83]<stdout>:setting Step LR 0.1599999964237213
[1,83]<stdout>:0.16 0.1 0 [8, 11] 4
[1,37]<stdout>:setting Step LR 0.1599999964237213
[1,37]<stdout>:0.16 0.1 0 [8, 11] 4
[1,98]<stdout>:setting Step LR 0.1599999964237213
[1,98]<stdout>:0.16 0.1 0 [8, 11] 4
[1,65]<stdout>:Starting new loop for GPU: 33
[1,38]<stdout>:setting Step LR 0.1599999964237213
[1,38]<stdout>:0.16 0.1 0 [8, 11] 4
[1,87]<stdout>:Starting new loop for GPU: 47
[1,48]<stdout>:Starting new loop for GPU: 24
[1,5]<stdout>:Starting new loop for GPU: 5
[1,23]<stdout>:Starting new loop for GPU: 15
[1,71]<stdout>:setting Step LR 0.1599999964237213
[1,71]<stdout>:0.16 0.1 0 [8, 11] 4
[1,18]<stdout>:Starting new loop for GPU: 10
[1,35]<stdout>:setting Step LR 0.1599999964237213
[1,35]<stdout>:0.16 0.1 0 [8, 11] 4
[1,19]<stdout>:Starting new loop for GPU: 11
[1,114]<stdout>:Starting new loop for GPU: 58
[1,102]<stdout>:setting Step LR 0.1599999964237213
[1,102]<stdout>:0.16 0.1 0 [8, 11] 4
[1,85]<stdout>:Starting new loop for GPU: 45
[1,83]<stdout>:Starting new loop for GPU: 43
[1,36]<stdout>:Starting new loop for GPU: 20
[1,98]<stdout>:Starting new loop for GPU: 50
[1,116]<stdout>:setting Step LR 0.1599999964237213
[1,116]<stdout>:0.16 0.1 0 [8, 11] 4
[1,38]<stdout>:Starting new loop for GPU: 22
[1,119]<stdout>:Starting new loop for GPU: 63
[1,55]<stdout>:setting Step LR 0.1599999964237213
[1,55]<stdout>:0.16 0.1 0 [8, 11] 4
[1,71]<stdout>:Starting new loop for GPU: 39
[1,35]<stdout>:Starting new loop for GPU: 19
[1,37]<stdout>:Starting new loop for GPU: 21
[1,102]<stdout>:Starting new loop for GPU: 54
[1,116]<stdout>:Starting new loop for GPU: 60
[1,55]<stdout>:Starting new loop for GPU: 31
[1,64]<stdout>:setting Step LR 0.1599999964237213
[1,64]<stdout>:0.16 0.1 0 [8, 11] 4
[1,64]<stdout>:Starting new loop for GPU: 32
[1,1]<stdout>:setting Step LR 0.1599999964237213
[1,1]<stdout>:0.16 0.1 0 [8, 11] 4
[1,1]<stdout>:Starting new loop for GPU: 1
[1,0]<stderr>:2020-09-18 19:54:04,188 - INFO - Saved checkpoint at: /shared/deep-learning-models/models/vision/detection/work_dirs/mask_rcnn_r50v1_d_fpn_1x_coco/003/faster_rcnn
[1,0]<stdout>:setting Step LR 0.1599999964237213
[1,0]<stdout>:0.16 0.1 0 [8, 11] 4
[1,0]<stdout>:Starting new loop for GPU: 0
[1,85]<stdout>:Rank 45 broadcasting
[1,18]<stdout>:Rank 10 broadcasting
[1,84]<stdout>:Rank 44 broadcasting
[1,7]<stdout>:Rank 7 broadcasting
[1,16]<stdout>:Rank 8 broadcasting
[1,96]<stdout>:Rank 48 broadcasting
[1,112]<stdout>:Rank 56 broadcasting
[1,34]<stdout>:Rank 18 broadcasting
[1,87]<stdout>:Rank 47 broadcasting
[1,5]<stdout>:Rank 5 broadcasting
[1,20]<stdout>:Rank 12 broadcasting
[1,103]<stdout>:Rank 55 broadcasting
[1,68]<stdout>:Rank 36 broadcasting
[1,117]<stdout>:Rank 61 broadcasting
[1,38]<stdout>:Rank 22 broadcasting
[1,80]<stdout>:Rank 40 broadcasting
[1,2]<stdout>:Rank 2 broadcasting
[1,21]<stdout>:Rank 13 broadcasting
[1,102]<stdout>:Rank 54 broadcasting
[1,70]<stdout>:Rank 38 broadcasting
[1,116]<stdout>:Rank 60 broadcasting
[1,36]<stdout>:Rank 20 broadcasting
[1,83]<stdout>:Rank 43 broadcasting
[1,3]<stdout>:Rank 3 broadcasting
[1,22]<stdout>:Rank 14 broadcasting
[1,100]<stdout>:Rank 52 broadcasting
[1,64]<stdout>:Rank 32 broadcasting
[1,113]<stdout>:Rank 57 broadcasting
[1,48]<stdout>:Rank 24 broadcasting
[1,39]<stdout>:Rank 23 broadcasting
[1,1]<stdout>:Rank 1 broadcasting
[1,23]<stdout>:Rank 15 broadcasting
[1,97]<stdout>:Rank 49 broadcasting
[1,67]<stdout>:Rank 35 broadcasting
[1,119]<stdout>:Rank 63 broadcasting
[1,33]<stdout>:Rank 17 broadcasting
[1,4]<stdout>:Rank 4 broadcasting
[1,101]<stdout>:Rank 53 broadcasting
[1,71]<stdout>:Rank 39 broadcasting
[1,114]<stdout>:Rank 58 broadcasting
[1,35]<stdout>:Rank 19 broadcasting
[1,81]<stdout>:Rank 41 broadcasting
[1,99]<stdout>:Rank 51 broadcasting
[1,118]<stdout>:Rank 62 broadcasting
[1,32]<stdout>:Rank 16 broadcasting
[1,98]<stdout>:Rank 50 broadcasting
[1,49]<stdout>:Rank 25 broadcasting
[1,53]<stdout>:Rank 29 broadcasting
[1,50]<stdout>:Rank 26 broadcasting
[1,52]<stdout>:Rank 28 broadcasting
[1,54]<stdout>:Rank 30 broadcasting
[1,82]<stdout>:Rank 42 broadcasting
[1,65]<stdout>:Rank 33 broadcasting
[1,0]<stdout>:Rank 0 broadcasting
[1,86]<stdout>:Rank 46 broadcasting
[1,69]<stdout>:Rank 37 broadcasting
[1,55]<stdout>:Rank 31 broadcasting
[1,66]<stdout>:Rank 34 broadcasting
[1,6]<stdout>:Rank 6 broadcasting
[1,37]<stdout>:Rank 21 broadcasting
[1,115]<stdout>:Rank 59 broadcasting
[1,51]<stdout>:Rank 27 broadcasting
[1,17]<stdout>:Rank 9 broadcasting
[1,19]<stdout>:Rank 11 broadcasting
[1,0]<stdout>:Variable broadcast done.
[1,6]<stdout>:Variable broadcast done.
[1,5]<stdout>:Variable broadcast done.
[1,18]<stdout>:Variable broadcast done.
[1,16]<stdout>:Variable broadcast done.
[1,19]<stdout>:Variable broadcast done.
[1,17]<stdout>:Variable broadcast done.
[1,22]<stdout>:Variable broadcast done.
[1,21]<stdout>:Variable broadcast done.
[1,23]<stdout>:Variable broadcast done.
[1,20]<stdout>:Variable broadcast done.
[1,35]<stdout>:Variable broadcast done.
[1,34]<stdout>:Variable broadcast done.
[1,37]<stdout>:Variable broadcast done.
[1,39]<stdout>:Variable broadcast done.
[1,33]<stdout>:Variable broadcast done.
[1,32]<stdout>:Variable broadcast done.
[1,38]<stdout>:Variable broadcast done.
[1,36]<stdout>:Variable broadcast done.
[1,55]<stdout>:Variable broadcast done.
[1,49]<stdout>:Variable broadcast done.
[1,54]<stdout>:Variable broadcast done.
[1,51]<stdout>:Variable broadcast done.
[1,53]<stdout>:Variable broadcast done.
[1,50]<stdout>:Variable broadcast done.
[1,48]<stdout>:Variable broadcast done.
[1,52]<stdout>:Variable broadcast done.
[1,80]<stdout>:Variable broadcast done.
[1,87]<stdout>:Variable broadcast done.
[1,64]<stdout>:Variable broadcast done.
[1,86]<stdout>:Variable broadcast done.
[1,70]<stdout>:Variable broadcast done.
[1,68]<stdout>:Variable broadcast done.
[1,82]<stdout>:Variable broadcast done.
[1,69]<stdout>:Variable broadcast done.
[1,81]<stdout>:Variable broadcast done.
[1,65]<stdout>:Variable broadcast done.
[1,83]<stdout>:Variable broadcast done.
[1,71]<stdout>:Variable broadcast done.
[1,84]<stdout>:Variable broadcast done.
[1,66]<stdout>:Variable broadcast done.
[1,85]<stdout>:Variable broadcast done.
[1,4]<stdout>:Variable broadcast done.
[1,67]<stdout>:Variable broadcast done.
[1,7]<stdout>:Variable broadcast done.
[1,2]<stdout>:Variable broadcast done.
[1,99]<stdout>:Variable broadcast done.
[1,3]<stdout>:Variable broadcast done.
[1,97]<stdout>:Variable broadcast done.
[1,1]<stdout>:Variable broadcast done.
[1,102]<stdout>:Variable broadcast done.
[1,98]<stdout>:Variable broadcast done.
[1,103]<stdout>:Variable broadcast done.
[1,116]<stdout>:Variable broadcast done.
[1,96]<stdout>:Variable broadcast done.
[1,101]<stdout>:Variable broadcast done.
[1,114]<stdout>:Variable broadcast done.
[1,100]<stdout>:Variable broadcast done.
[1,112]<stdout>:Variable broadcast done.
[1,119]<stdout>:Variable broadcast done.
[1,118]<stdout>:Variable broadcast done.
[1,115]<stdout>:Variable broadcast done.
[1,113]<stdout>:Variable broadcast done.
[1,117]<stdout>:Variable broadcast done.
[1,0]<stderr>:2020-09-18 19:54:50,171 - INFO - Epoch [5][50/458]	lr: 0.16000, eta: 0:52:10, time: 0.919, data_time: 0.044, rpn_class_loss: 2.0707, rpn_bbox_loss: 8.8565, rcnn_class_loss: 29.7499, rcnn_bbox_loss: 10.5760, rcnn_mask_loss: 11.0669, reg_loss: 0.4283, loss: 62.7482, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 19:55:31,128 - INFO - Epoch [5][100/458]	lr: 0.16000, eta: 0:51:23, time: 0.819, data_time: 0.035, rpn_class_loss: 1.9843, rpn_bbox_loss: 8.7200, rcnn_class_loss: 27.7218, rcnn_bbox_loss: 9.9335, rcnn_mask_loss: 11.3965, reg_loss: 0.4283, loss: 60.1843, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 19:56:11,201 - INFO - Epoch [5][150/458]	lr: 0.16000, eta: 0:50:34, time: 0.802, data_time: 0.038, rpn_class_loss: 1.8962, rpn_bbox_loss: 8.6480, rcnn_class_loss: 26.8340, rcnn_bbox_loss: 9.9756, rcnn_mask_loss: 11.2738, reg_loss: 0.4283, loss: 59.0559, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 19:56:50,987 - INFO - Epoch [5][200/458]	lr: 0.16000, eta: 0:49:45, time: 0.795, data_time: 0.040, rpn_class_loss: 2.4458, rpn_bbox_loss: 10.3149, rcnn_class_loss: 29.6835, rcnn_bbox_loss: 11.1387, rcnn_mask_loss: 10.9572, reg_loss: 0.4283, loss: 64.9685, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 19:57:32,280 - INFO - Epoch [5][250/458]	lr: 0.16000, eta: 0:48:59, time: 0.826, data_time: 0.042, rpn_class_loss: 2.4581, rpn_bbox_loss: 10.2738, rcnn_class_loss: 30.3191, rcnn_bbox_loss: 10.9862, rcnn_mask_loss: 11.0930, reg_loss: 0.4283, loss: 65.5585, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 19:58:12,551 - INFO - Epoch [5][300/458]	lr: 0.16000, eta: 0:48:11, time: 0.805, data_time: 0.033, rpn_class_loss: 2.1880, rpn_bbox_loss: 9.7152, rcnn_class_loss: 28.7611, rcnn_bbox_loss: 10.4045, rcnn_mask_loss: 11.8797, reg_loss: 0.4283, loss: 63.3768, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 19:58:53,329 - INFO - Epoch [5][350/458]	lr: 0.16000, eta: 0:47:25, time: 0.816, data_time: 0.039, rpn_class_loss: 2.1852, rpn_bbox_loss: 9.3631, rcnn_class_loss: 28.2686, rcnn_bbox_loss: 9.9498, rcnn_mask_loss: 10.7936, reg_loss: 0.4283, loss: 60.9885, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 19:59:33,262 - INFO - Epoch [5][400/458]	lr: 0.16000, eta: 0:46:38, time: 0.799, data_time: 0.040, rpn_class_loss: 2.2696, rpn_bbox_loss: 9.9573, rcnn_class_loss: 29.5086, rcnn_bbox_loss: 10.6751, rcnn_mask_loss: 11.0945, reg_loss: 0.4283, loss: 63.9334, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:00:13,992 - INFO - Epoch [5][450/458]	lr: 0.16000, eta: 0:45:52, time: 0.815, data_time: 0.036, rpn_class_loss: 1.8931, rpn_bbox_loss: 7.9515, rcnn_class_loss: 27.2814, rcnn_bbox_loss: 9.8196, rcnn_mask_loss: 11.2111, reg_loss: 0.4283, loss: 58.5849, learning_rate: 0.1600
[1,35]<stdout>:setting Step LR 0.1599999964237213
[1,35]<stdout>:0.16 0.1 0 [8, 11] 5
[1,23]<stdout>:setting Step LR 0.1599999964237213
[1,23]<stdout>:0.16 0.1 0 [8, 11] 5
[1,16]<stdout>:setting Step LR 0.1599999964237213
[1,16]<stdout>:0.16 0.1 0 [8, 11] 5
[1,82]<stdout>:setting Step LR 0.1599999964237213
[1,82]<stdout>:0.16 0.1 0 [8, 11] 5
[1,36]<stdout>:setting Step LR 0.1599999964237213
[1,36]<stdout>:0.16 0.1 0 [8, 11] 5
[1,17]<stdout>:setting Step LR 0.1599999964237213
[1,17]<stdout>:0.16 0.1 0 [8, 11] 5
[1,102]<stdout>:setting Step LR 0.1599999964237213
[1,102]<stdout>:0.16 0.1 0 [8, 11] 5
[1,33]<stdout>:setting Step LR 0.1599999964237213
[1,33]<stdout>:0.16 0.1 0 [8, 11] 5
[1,35]<stdout>:Starting new loop for GPU: 19
[1,6]<stdout>:setting Step LR 0.1599999964237213
[1,6]<stdout>:0.16 0.1 0 [8, 11] 5
[1,19]<stdout>:setting Step LR 0.1599999964237213
[1,19]<stdout>:0.16 0.1 0 [8, 11] 5
[1,113]<stdout>:setting Step LR 0.1599999964237213
[1,113]<stdout>:0.16 0.1 0 [8, 11] 5
[1,23]<stdout>:Starting new loop for GPU: 15
[1,16]<stdout>:Starting new loop for GPU: 8
[1,119]<stdout>:setting Step LR 0.1599999964237213
[1,119]<stdout>:0.16 0.1 0 [8, 11] 5
[1,1]<stdout>:setting Step LR 0.1599999964237213
[1,1]<stdout>:0.16 0.1 0 [8, 11] 5
[1,83]<stdout>:setting Step LR 0.1599999964237213
[1,83]<stdout>:0.16 0.1 0 [8, 11] 5
[1,115]<stdout>:setting Step LR 0.1599999964237213
[1,115]<stdout>:0.16 0.1 0 [8, 11] 5
[1,116]<stdout>:setting Step LR 0.1599999964237213
[1,116]<stdout>:0.16 0.1 0 [8, 11] 5
[1,82]<stdout>:Starting new loop for GPU: 42
[1,18]<stdout>:setting Step LR 0.1599999964237213
[1,18]<stdout>:0.16 0.1 0 [8, 11] 5
[1,80]<stdout>:setting Step LR 0.1599999964237213
[1,80]<stdout>:0.16 0.1 0 [8, 11] 5
[1,36]<stdout>:Starting new loop for GPU: 20
[1,7]<stdout>:setting Step LR 0.1599999964237213
[1,7]<stdout>:0.16 0.1 0 [8, 11] 5
[1,53]<stdout>:setting Step LR 0.1599999964237213
[1,53]<stdout>:0.16 0.1 0 [8, 11] 5
[1,17]<stdout>:Starting new loop for GPU: 9
[1,69]<stdout>:setting Step LR 0.1599999964237213
[1,69]<stdout>:0.16 0.1 0 [8, 11] 5
[1,112]<stdout>:setting Step LR 0.1599999964237213
[1,112]<stdout>:0.16 0.1 0 [8, 11] 5
[1,67]<stdout>:setting Step LR 0.1599999964237213
[1,67]<stdout>:0.16 0.1 0 [8, 11] 5
[1,98]<stdout>:setting Step LR 0.1599999964237213
[1,98]<stdout>:0.16 0.1 0 [8, 11] 5
[1,102]<stdout>:Starting new loop for GPU: 54
[1,4]<stdout>:setting Step LR 0.1599999964237213
[1,4]<stdout>:0.16 0.1 0 [8, 11] 5
[1,49]<stdout>:setting Step LR 0.1599999964237213
[1,49]<stdout>:0.16 0.1 0 [8, 11] 5
[1,118]<stdout>:setting Step LR 0.1599999964237213
[1,118]<stdout>:0.16 0.1 0 [8, 11] 5
[1,3]<stdout>:setting Step LR 0.1599999964237213
[1,3]<stdout>:0.16 0.1 0 [8, 11] 5
[1,52]<stdout>:setting Step LR 0.1599999964237213
[1,52]<stdout>:0.16 0.1 0 [8, 11] 5
[1,100]<stdout>:setting Step LR 0.1599999964237213
[1,100]<stdout>:0.16 0.1 0 [8, 11] 5
[1,6]<stdout>:Starting new loop for GPU: 6
[1,33]<stdout>:Starting new loop for GPU: 17
[1,83]<stdout>:Starting new loop for GPU: 43
[1,1]<stdout>:Starting new loop for GPU: 1
[1,113]<stdout>:Starting new loop for GPU: 57
[1,119]<stdout>:Starting new loop for GPU: 63
[1,87]<stdout>:setting Step LR 0.1599999964237213
[1,87]<stdout>:0.16 0.1 0 [8, 11] 5
[1,96]<stdout>:setting Step LR 0.1599999964237213
[1,96]<stdout>:0.16 0.1 0 [8, 11] 5
[1,19]<stdout>:Starting new loop for GPU: 11
[1,115]<stdout>:Starting new loop for GPU: 59
[1,5]<stdout>:setting Step LR 0.1599999964237213
[1,5]<stdout>:0.16 0.1 0 [8, 11] 5
[1,20]<stdout>:setting Step LR 0.1599999964237213
[1,20]<stdout>:0.16 0.1 0 [8, 11] 5
[1,66]<stdout>:setting Step LR 0.1599999964237213
[1,66]<stdout>:0.16 0.1 0 [8, 11] 5
[1,116]<stdout>:Starting new loop for GPU: 60
[1,2]<stdout>:setting Step LR 0.1599999964237213
[1,2]<stdout>:0.16 0.1 0 [8, 11] 5
[1,7]<stdout>:Starting new loop for GPU: 7
[1,54]<stdout>:setting Step LR 0.1599999964237213
[1,54]<stdout>:0.16 0.1 0 [8, 11] 5
[1,18]<stdout>:Starting new loop for GPU: 10
[1,80]<stdout>:Starting new loop for GPU: 40
[1,68]<stdout>:setting Step LR 0.1599999964237213
[1,68]<stdout>:0.16 0.1 0 [8, 11] 5
[1,38]<stdout>:setting Step LR 0.1599999964237213
[1,38]<stdout>:0.16 0.1 0 [8, 11] 5
[1,22]<stdout>:setting Step LR 0.1599999964237213
[1,22]<stdout>:0.16 0.1 0 [8, 11] 5
[1,103]<stdout>:setting Step LR 0.1599999964237213
[1,103]<stdout>:0.16 0.1 0 [8, 11] 5
[1,53]<stdout>:Starting new loop for GPU: 29
[1,69]<stdout>:Starting new loop for GPU: 37
[1,67]<stdout>:Starting new loop for GPU: 35
[1,112]<stdout>:Starting new loop for GPU: 56
[1,55]<stdout>:setting Step LR 0.1599999964237213
[1,55]<stdout>:0.16 0.1 0 [8, 11] 5
[1,50]<stdout>:setting Step LR 0.1599999964237213
[1,50]<stdout>:0.16 0.1 0 [8, 11] 5
[1,85]<stdout>:setting Step LR 0.1599999964237213
[1,85]<stdout>:0.16 0.1 0 [8, 11] 5
[1,71]<stdout>:setting Step LR 0.1599999964237213
[1,71]<stdout>:0.16 0.1 0 [8, 11] 5
[1,98]<stdout>:Starting new loop for GPU: 50
[1,49]<stdout>:Starting new loop for GPU: 25
[1,114]<stdout>:setting Step LR 0.1599999964237213
[1,114]<stdout>:0.16 0.1 0 [8, 11] 5
[1,81]<stdout>:setting Step LR 0.1599999964237213
[1,81]<stdout>:0.16 0.1 0 [8, 11] 5
[1,52]<stdout>:Starting new loop for GPU: 28
[1,4]<stdout>:Starting new loop for GPU: 4
[1,118]<stdout>:Starting new loop for GPU: 62
[1,100]<stdout>:Starting new loop for GPU: 52
[1,66]<stdout>:Starting new loop for GPU: 34
[1,3]<stdout>:Starting new loop for GPU: 3
[1,101]<stdout>:setting Step LR 0.1599999964237213
[1,101]<stdout>:0.16 0.1 0 [8, 11] 5
[1,87]<stdout>:Starting new loop for GPU: 47
[1,54]<stdout>:Starting new loop for GPU: 30
[1,68]<stdout>:Starting new loop for GPU: 36
[1,21]<stdout>:setting Step LR 0.1599999964237213
[1,21]<stdout>:0.16 0.1 0 [8, 11] 5
[1,103]<stdout>:Starting new loop for GPU: 55
[1,5]<stdout>:Starting new loop for GPU: 5
[1,38]<stdout>:Starting new loop for GPU: 22
[1,2]<stdout>:Starting new loop for GPU: 2
[1,96]<stdout>:Starting new loop for GPU: 48
[1,97]<stdout>:setting Step LR 0.1599999964237213
[1,97]<stdout>:0.16 0.1 0 [8, 11] 5
[1,84]<stdout>:setting Step LR 0.1599999964237213
[1,84]<stdout>:0.16 0.1 0 [8, 11] 5
[1,70]<stdout>:setting Step LR 0.1599999964237213
[1,70]<stdout>:0.16 0.1 0 [8, 11] 5
[1,20]<stdout>:Starting new loop for GPU: 12
[1,85]<stdout>:Starting new loop for GPU: 45
[1,50]<stdout>:Starting new loop for GPU: 26
[1,55]<stdout>:Starting new loop for GPU: 31
[1,34]<stdout>:setting Step LR 0.1599999964237213
[1,34]<stdout>:0.16 0.1 0 [8, 11] 5
[1,71]<stdout>:Starting new loop for GPU: 39
[1,48]<stdout>:setting Step LR 0.1599999964237213
[1,48]<stdout>:0.16 0.1 0 [8, 11] 5
[1,22]<stdout>:Starting new loop for GPU: 14
[1,81]<stdout>:Starting new loop for GPU: 41
[1,101]<stdout>:Starting new loop for GPU: 53
[1,64]<stdout>:setting Step LR 0.1599999964237213
[1,64]<stdout>:0.16 0.1 0 [8, 11] 5
[1,114]<stdout>:Starting new loop for GPU: 58
[1,21]<stdout>:Starting new loop for GPU: 13
[1,97]<stdout>:Starting new loop for GPU: 49
[1,84]<stdout>:Starting new loop for GPU: 44
[1,70]<stdout>:Starting new loop for GPU: 38
[1,34]<stdout>:Starting new loop for GPU: 18
[1,48]<stdout>:Starting new loop for GPU: 24
[1,64]<stdout>:Starting new loop for GPU: 32
[1,65]<stdout>:setting Step LR 0.1599999964237213
[1,65]<stdout>:0.16 0.1 0 [8, 11] 5
[1,39]<stdout>:setting Step LR 0.1599999964237213
[1,39]<stdout>:0.16 0.1 0 [8, 11] 5
[1,86]<stdout>:setting Step LR 0.1599999964237213
[1,86]<stdout>:0.16 0.1 0 [8, 11] 5
[1,51]<stdout>:setting Step LR 0.1599999964237213
[1,51]<stdout>:0.16 0.1 0 [8, 11] 5
[1,99]<stdout>:setting Step LR 0.1599999964237213
[1,99]<stdout>:0.16 0.1 0 [8, 11] 5
[1,117]<stdout>:setting Step LR 0.1599999964237213
[1,39]<stdout>:Starting new loop for GPU: 23
[1,117]<stdout>:0.16 0.1 0 [8, 11] 5
[1,65]<stdout>:Starting new loop for GPU: 33
[1,51]<stdout>:Starting new loop for GPU: 27
[1,99]<stdout>:Starting new loop for GPU: 51
[1,32]<stdout>:setting Step LR 0.1599999964237213
[1,32]<stdout>:0.16 0.1 0 [8, 11] 5
[1,86]<stdout>:Starting new loop for GPU: 46
[1,117]<stdout>:Starting new loop for GPU: 61
[1,37]<stdout>:setting Step LR 0.1599999964237213
[1,37]<stdout>:0.16 0.1 0 [8, 11] 5
[1,32]<stdout>:Starting new loop for GPU: 16
[1,37]<stdout>:Starting new loop for GPU: 21
[1,0]<stderr>:2020-09-18 20:00:21,465 - INFO - Saved checkpoint at: /shared/deep-learning-models/models/vision/detection/work_dirs/mask_rcnn_r50v1_d_fpn_1x_coco/004/faster_rcnn
[1,0]<stdout>:setting Step LR 0.1599999964237213
[1,0]<stdout>:0.16 0.1 0 [8, 11] 5
[1,0]<stdout>:Starting new loop for GPU: 0
[1,112]<stdout>:Rank 56 broadcasting
[1,113]<stdout>:Rank 57 broadcasting
[1,67]<stdout>:Rank 35 broadcasting
[1,102]<stdout>:Rank 54 broadcasting
[1,64]<stdout>:Rank 32 broadcasting
[1,119]<stdout>:Rank 63 broadcasting
[1,39]<stdout>:Rank 23 broadcasting
[1,80]<stdout>:Rank 40 broadcasting
[1,0]<stdout>:Rank 0 broadcasting
[1,100]<stdout>:Rank 52 broadcasting
[1,71]<stdout>:Rank 39 broadcasting
[1,117]<stdout>:Rank 61 broadcasting
[1,32]<stdout>:Rank 16 broadcasting
[1,83]<stdout>:Rank 43 broadcasting
[1,2]<stdout>:Rank 2 broadcasting
[1,20]<stdout>:Rank 12 broadcasting
[1,99]<stdout>:Rank 51 broadcasting
[1,68]<stdout>:Rank 36 broadcasting
[1,115]<stdout>:Rank 59 broadcasting
[1,48]<stdout>:Rank 24 broadcasting
[1,38]<stdout>:Rank 22 broadcasting
[1,84]<stdout>:Rank 44 broadcasting
[1,4]<stdout>:Rank 4 broadcasting
[1,22]<stdout>:Rank 14 broadcasting
[1,97]<stdout>:Rank 49 broadcasting
[1,70]<stdout>:Rank 38 broadcasting
[1,114]<stdout>:Rank 58 broadcasting
[1,54]<stdout>:Rank 30 broadcasting
[1,34]<stdout>:Rank 18 broadcasting
[1,87]<stdout>:Rank 47 broadcasting
[1,5]<stdout>:Rank 5 broadcasting
[1,16]<stdout>:Rank 8 broadcasting
[1,98]<stdout>:Rank 50 broadcasting
[1,66]<stdout>:Rank 34 broadcasting
[1,50]<stdout>:Rank 26 broadcasting
[1,37]<stdout>:Rank 21 broadcasting
[1,81]<stdout>:Rank 41 broadcasting
[1,7]<stdout>:Rank 7 broadcasting
[1,19]<stdout>:Rank 11 broadcasting
[1,52]<stdout>:Rank 28 broadcasting
[1,85]<stdout>:Rank 45 broadcasting
[1,6]<stdout>:Rank 6 broadcasting
[1,23]<stdout>:Rank 15 broadcasting
[1,51]<stdout>:Rank 27 broadcasting
[1,18]<stdout>:Rank 10 broadcasting
[1,101]<stdout>:Rank 53 broadcasting
[1,55]<stdout>:Rank 31 broadcasting
[1,21]<stdout>:Rank 13 broadcasting
[1,103]<stdout>:Rank 55 broadcasting
[1,36]<stdout>:Rank 20 broadcasting
[1,118]<stdout>:Rank 62 broadcasting
[1,65]<stdout>:Rank 33 broadcasting
[1,69]<stdout>:Rank 37 broadcasting
[1,96]<stdout>:Rank 48 broadcasting
[1,3]<stdout>:Rank 3 broadcasting
[1,82]<stdout>:Rank 42 broadcasting
[1,35]<stdout>:Rank 19 broadcasting
[1,33]<stdout>:Rank 17 broadcasting
[1,86]<stdout>:Rank 46 broadcasting
[1,1]<stdout>:Rank 1 broadcasting
[1,53]<stdout>:Rank 29 broadcasting
[1,116]<stdout>:Rank 60 broadcasting
[1,49]<stdout>:Rank 25 broadcasting
[1,17]<stdout>:Rank 9 broadcasting
[1,0]<stdout>:Variable broadcast done.
[1,6]<stdout>:Variable broadcast done.
[1,5]<stdout>:Variable broadcast done.
[1,16]<stdout>:Variable broadcast done.
[1,17]<stdout>:Variable broadcast done.
[1,22]<stdout>:Variable broadcast done.
[1,18]<stdout>:Variable broadcast done.
[1,19]<stdout>:Variable broadcast done.
[1,21]<stdout>:Variable broadcast done.
[1,23]<stdout>:Variable broadcast done.
[1,20]<stdout>:Variable broadcast done.
[1,38]<stdout>:Variable broadcast done.
[1,32]<stdout>:Variable broadcast done.
[1,37]<stdout>:Variable broadcast done.
[1,34]<stdout>:Variable broadcast done.
[1,35]<stdout>:Variable broadcast done.
[1,39]<stdout>:Variable broadcast done.
[1,33]<stdout>:Variable broadcast done.
[1,36]<stdout>:Variable broadcast done.
[1,48]<stdout>:Variable broadcast done.
[1,54]<stdout>:Variable broadcast done.
[1,53]<stdout>:Variable broadcast done.
[1,55]<stdout>:Variable broadcast done.
[1,85]<stdout>:Variable broadcast done.
[1,51]<stdout>:Variable broadcast done.
[1,64]<stdout>:Variable broadcast done.
[1,50]<stdout>:Variable broadcast done.
[1,65]<stdout>:Variable broadcast done.
[1,49]<stdout>:Variable broadcast done.
[1,80]<stdout>:Variable broadcast done.
[1,96]<stdout>:Variable broadcast done.
[1,71]<stdout>:Variable broadcast done.
[1,52]<stdout>:Variable broadcast done.
[1,83]<stdout>:Variable broadcast done.
[1,99]<stdout>:Variable broadcast done.
[1,68]<stdout>:Variable broadcast done.
[1,82]<stdout>:Variable broadcast done.
[1,98]<stdout>:Variable broadcast done.
[1,70]<stdout>:Variable broadcast done.
[1,84]<stdout>:Variable broadcast done.
[1,103]<stdout>:Variable broadcast done.
[1,67]<stdout>:Variable broadcast done.
[1,87]<stdout>:Variable broadcast done.
[1,101]<stdout>:Variable broadcast done.
[1,69]<stdout>:Variable broadcast done.
[1,86]<stdout>:Variable broadcast done.
[1,102]<stdout>:Variable broadcast done.
[1,66]<stdout>:Variable broadcast done.
[1,81]<stdout>:Variable broadcast done.
[1,3]<stdout>:Variable broadcast done.
[1,100]<stdout>:Variable broadcast done.
[1,112]<stdout>:Variable broadcast done.
[1,7]<stdout>:Variable broadcast done.
[1,97]<stdout>:Variable broadcast done.
[1,2]<stdout>:Variable broadcast done.
[1,113]<stdout>:Variable broadcast done.
[1,4]<stdout>:Variable broadcast done.
[1,115]<stdout>:Variable broadcast done.
[1,1]<stdout>:Variable broadcast done.
[1,119]<stdout>:Variable broadcast done.
[1,114]<stdout>:Variable broadcast done.
[1,116]<stdout>:Variable broadcast done.
[1,118]<stdout>:Variable broadcast done.
[1,117]<stdout>:Variable broadcast done.
[1,0]<stderr>:2020-09-18 20:01:07,827 - INFO - Epoch [6][50/458]	lr: 0.16000, eta: 0:44:58, time: 0.926, data_time: 0.057, rpn_class_loss: 2.0062, rpn_bbox_loss: 9.4160, rcnn_class_loss: 27.3428, rcnn_bbox_loss: 9.7582, rcnn_mask_loss: 11.8393, reg_loss: 0.4283, loss: 60.7907, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:01:49,377 - INFO - Epoch [6][100/458]	lr: 0.16000, eta: 0:44:13, time: 0.831, data_time: 0.039, rpn_class_loss: 2.5702, rpn_bbox_loss: 10.8323, rcnn_class_loss: 30.5556, rcnn_bbox_loss: 10.5950, rcnn_mask_loss: 11.8692, reg_loss: 0.4283, loss: 66.8506, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:02:29,542 - INFO - Epoch [6][150/458]	lr: 0.16000, eta: 0:43:27, time: 0.803, data_time: 0.037, rpn_class_loss: 2.0291, rpn_bbox_loss: 9.2690, rcnn_class_loss: 26.9910, rcnn_bbox_loss: 9.5684, rcnn_mask_loss: 11.3172, reg_loss: 0.4283, loss: 59.6030, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:03:09,635 - INFO - Epoch [6][200/458]	lr: 0.16000, eta: 0:42:42, time: 0.802, data_time: 0.040, rpn_class_loss: 2.4725, rpn_bbox_loss: 11.3869, rcnn_class_loss: 29.6410, rcnn_bbox_loss: 10.9476, rcnn_mask_loss: 10.6063, reg_loss: 0.4283, loss: 65.4826, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:03:49,440 - INFO - Epoch [6][250/458]	lr: 0.16000, eta: 0:41:56, time: 0.796, data_time: 0.039, rpn_class_loss: 1.8518, rpn_bbox_loss: 8.6193, rcnn_class_loss: 30.1015, rcnn_bbox_loss: 10.7227, rcnn_mask_loss: 11.4877, reg_loss: 0.4283, loss: 63.2113, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:04:29,771 - INFO - Epoch [6][300/458]	lr: 0.16000, eta: 0:41:11, time: 0.807, data_time: 0.040, rpn_class_loss: 2.0483, rpn_bbox_loss: 8.9874, rcnn_class_loss: 27.0107, rcnn_bbox_loss: 10.0347, rcnn_mask_loss: 10.6916, reg_loss: 0.4283, loss: 59.2010, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:05:09,625 - INFO - Epoch [6][350/458]	lr: 0.16000, eta: 0:40:25, time: 0.797, data_time: 0.036, rpn_class_loss: 1.8674, rpn_bbox_loss: 8.4509, rcnn_class_loss: 26.9065, rcnn_bbox_loss: 9.7145, rcnn_mask_loss: 11.2093, reg_loss: 0.4283, loss: 58.5770, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:05:49,781 - INFO - Epoch [6][400/458]	lr: 0.16000, eta: 0:39:40, time: 0.803, data_time: 0.039, rpn_class_loss: 2.4253, rpn_bbox_loss: 9.8244, rcnn_class_loss: 28.5368, rcnn_bbox_loss: 10.0320, rcnn_mask_loss: 11.6412, reg_loss: 0.4283, loss: 62.8880, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:06:29,535 - INFO - Epoch [6][450/458]	lr: 0.16000, eta: 0:38:55, time: 0.795, data_time: 0.038, rpn_class_loss: 2.4356, rpn_bbox_loss: 10.5466, rcnn_class_loss: 30.3963, rcnn_bbox_loss: 11.0601, rcnn_mask_loss: 11.3868, reg_loss: 0.4283, loss: 66.2537, learning_rate: 0.1600
[1,18]<stdout>:setting Step LR 0.1599999964237213
[1,18]<stdout>:0.16 0.1 0 [8, 11] 6
[1,23]<stdout>:setting Step LR 0.1599999964237213
[1,23]<stdout>:0.16 0.1 0 [8, 11] 6
[1,51]<stdout>:setting Step LR 0.1599999964237213
[1,51]<stdout>:0.16 0.1 0 [8, 11] 6
[1,16]<stdout>:setting Step LR 0.1599999964237213
[1,16]<stdout>:0.16 0.1 0 [8, 11] 6
[1,118]<stdout>:setting Step LR 0.1599999964237213
[1,118]<stdout>:0.16 0.1 0 [8, 11] 6
[1,114]<stdout>:setting Step LR 0.1599999964237213
[1,114]<stdout>:0.16 0.1 0 [8, 11] 6
[1,48]<stdout>:setting Step LR 0.1599999964237213
[1,48]<stdout>:0.16 0.1 0 [8, 11] 6
[1,67]<stdout>:setting Step LR 0.1599999964237213
[1,67]<stdout>:0.16 0.1 0 [8, 11] 6
[1,64]<stdout>:setting Step LR 0.1599999964237213
[1,64]<stdout>:0.16 0.1 0 [8, 11] 6
[1,35]<stdout>:setting Step LR 0.1599999964237213
[1,35]<stdout>:0.16 0.1 0 [8, 11] 6
[1,55]<stdout>:setting Step LR 0.1599999964237213
[1,55]<stdout>:0.16 0.1 0 [8, 11] 6
[1,81]<stdout>:setting Step LR 0.1599999964237213
[1,81]<stdout>:0.16 0.1 0 [8, 11] 6
[1,5]<stdout>:setting Step LR 0.1599999964237213
[1,5]<stdout>:0.16 0.1 0 [8, 11] 6
[1,103]<stdout>:setting Step LR 0.1599999964237213
[1,103]<stdout>:0.16 0.1 0 [8, 11] 6
[1,117]<stdout>:setting Step LR 0.1599999964237213
[1,117]<stdout>:0.16 0.1 0 [8, 11] 6
[1,98]<stdout>:setting Step LR 0.1599999964237213
[1,98]<stdout>:0.16 0.1 0 [8, 11] 6
[1,69]<stdout>:setting Step LR 0.1599999964237213
[1,69]<stdout>:0.16 0.1 0 [8, 11] 6
[1,18]<stdout>:Starting new loop for GPU: 10
[1,32]<stdout>:setting Step LR 0.1599999964237213
[1,32]<stdout>:0.16 0.1 0 [8, 11] 6
[1,38]<stdout>:setting Step LR 0.1599999964237213
[1,38]<stdout>:0.16 0.1 0 [8, 11] 6
[1,53]<stdout>:setting Step LR 0.1599999964237213
[1,53]<stdout>:0.16 0.1 0 [8, 11] 6
[1,87]<stdout>:setting Step LR 0.1599999964237213
[1,87]<stdout>:0.16 0.1 0 [8, 11] 6
[1,49]<stdout>:setting Step LR 0.1599999964237213
[1,49]<stdout>:0.16 0.1 0 [8, 11] 6
[1,3]<stdout>:setting Step LR 0.1599999964237213
[1,3]<stdout>:0.16 0.1 0 [8, 11] 6
[1,119]<stdout>:setting Step LR 0.1599999964237213
[1,119]<stdout>:0.16 0.1 0 [8, 11] 6
[1,23]<stdout>:Starting new loop for GPU: 15
[1,86]<stdout>:setting Step LR 0.1599999964237213
[1,86]<stdout>:0.16 0.1 0 [8, 11] 6
[1,50]<stdout>:setting Step LR 0.1599999964237213
[1,50]<stdout>:0.16 0.1 0 [8, 11] 6
[1,51]<stdout>:Starting new loop for GPU: 27
[1,113]<stdout>:setting Step LR 0.1599999964237213
[1,113]<stdout>:0.16 0.1 0 [8, 11] 6
[1,4]<stdout>:setting Step LR 0.1599999964237213
[1,4]<stdout>:0.16 0.1 0 [8, 11] 6
[1,16]<stdout>:Starting new loop for GPU: 8
[1,115]<stdout>:setting Step LR 0.1599999964237213
[1,115]<stdout>:0.16 0.1 0 [8, 11] 6
[1,96]<stdout>:setting Step LR 0.1599999964237213
[1,96]<stdout>:0.16 0.1 0 [8, 11] 6
[1,17]<stdout>:setting Step LR 0.1599999964237213
[1,17]<stdout>:0.16 0.1 0 [8, 11] 6
[1,97]<stdout>:setting Step LR 0.1599999964237213
[1,97]<stdout>:0.16 0.1 0 [8, 11] 6
[1,37]<stdout>:setting Step LR 0.1599999964237213
[1,37]<stdout>:0.16 0.1 0 [8, 11] 6
[1,112]<stdout>:setting Step LR 0.1599999964237213
[1,112]<stdout>:0.16 0.1 0 [8, 11] 6
[1,34]<stdout>:setting Step LR 0.1599999964237213
[1,34]<stdout>:0.16 0.1 0 [8, 11] 6
[1,80]<stdout>:setting Step LR 0.1599999964237213
[1,80]<stdout>:0.16 0.1 0 [8, 11] 6
[1,118]<stdout>:Starting new loop for GPU: 62
[1,114]<stdout>:Starting new loop for GPU: 58
[1,48]<stdout>:Starting new loop for GPU: 24
[1,21]<stdout>:setting Step LR 0.1599999964237213
[1,21]<stdout>:0.16 0.1 0 [8, 11] 6
[1,2]<stdout>:setting Step LR 0.1599999964237213
[1,2]<stdout>:0.16 0.1 0 [8, 11] 6
[1,64]<stdout>:Starting new loop for GPU: 32
[1,36]<stdout>:setting Step LR 0.1599999964237213
[1,36]<stdout>:0.16 0.1 0 [8, 11] 6
[1,99]<stdout>:setting Step LR 0.1599999964237213
[1,99]<stdout>:0.16 0.1 0 [8, 11] 6
[1,35]<stdout>:Starting new loop for GPU: 19
[1,67]<stdout>:Starting new loop for GPU: 35
[1,81]<stdout>:Starting new loop for GPU: 41
[1,103]<stdout>:Starting new loop for GPU: 55
[1,55]<stdout>:Starting new loop for GPU: 31
[1,5]<stdout>:Starting new loop for GPU: 5
[1,117]<stdout>:Starting new loop for GPU: 61
[1,65]<stdout>:setting Step LR 0.1599999964237213
[1,65]<stdout>:0.16 0.1 0 [8, 11] 6
[1,100]<stdout>:setting Step LR 0.1599999964237213
[1,100]<stdout>:0.16 0.1 0 [8, 11] 6
[1,101]<stdout>:setting Step LR 0.1599999964237213
[1,101]<stdout>:0.16 0.1 0 [8, 11] 6
[1,82]<stdout>:setting Step LR 0.1599999964237213
[1,82]<stdout>:0.16 0.1 0 [8, 11] 6
[1,68]<stdout>:setting Step LR 0.1599999964237213
[1,68]<stdout>:0.16 0.1 0 [8, 11] 6
[1,7]<stdout>:setting Step LR 0.1599999964237213
[1,7]<stdout>:0.16 0.1 0 [8, 11] 6
[1,70]<stdout>:setting Step LR 0.1599999964237213
[1,70]<stdout>:0.16 0.1 0 [8, 11] 6
[1,69]<stdout>:Starting new loop for GPU: 37
[1,98]<stdout>:Starting new loop for GPU: 50
[1,32]<stdout>:Starting new loop for GPU: 16
[1,54]<stdout>:setting Step LR 0.1599999964237213
[1,54]<stdout>:0.16 0.1 0 [8, 11] 6
[1,38]<stdout>:Starting new loop for GPU: 22
[1,87]<stdout>:Starting new loop for GPU: 47
[1,84]<stdout>:setting Step LR 0.1599999964237213
[1,84]<stdout>:0.16 0.1 0 [8, 11] 6
[1,3]<stdout>:Starting new loop for GPU: 3
[1,119]<stdout>:Starting new loop for GPU: 63
[1,53]<stdout>:Starting new loop for GPU: 29
[1,86]<stdout>:Starting new loop for GPU: 46
[1,6]<stdout>:setting Step LR 0.1599999964237213
[1,6]<stdout>:0.16 0.1 0 [8, 11] 6
[1,49]<stdout>:Starting new loop for GPU: 25
[1,50]<stdout>:Starting new loop for GPU: 26
[1,19]<stdout>:setting Step LR 0.1599999964237213
[1,19]<stdout>:0.16 0.1 0 [8, 11] 6
[1,4]<stdout>:Starting new loop for GPU: 4
[1,66]<stdout>:setting Step LR 0.1599999964237213
[1,66]<stdout>:0.16 0.1 0 [8, 11] 6
[1,113]<stdout>:Starting new loop for GPU: 57
[1,80]<stdout>:Starting new loop for GPU: 40
[1,17]<stdout>:Starting new loop for GPU: 9
[1,2]<stdout>:Starting new loop for GPU: 2
[1,115]<stdout>:Starting new loop for GPU: 59
[1,52]<stdout>:setting Step LR 0.1599999964237213
[1,52]<stdout>:0.16 0.1 0 [8, 11] 6
[1,34]<stdout>:Starting new loop for GPU: 18
[1,96]<stdout>:Starting new loop for GPU: 48
[1,37]<stdout>:Starting new loop for GPU: 21
[1,21]<stdout>:Starting new loop for GPU: 13
[1,85]<stdout>:setting Step LR 0.1599999964237213
[1,85]<stdout>:0.16 0.1 0 [8, 11] 6
[1,97]<stdout>:Starting new loop for GPU: 49
[1,112]<stdout>:Starting new loop for GPU: 56
[1,36]<stdout>:Starting new loop for GPU: 20
[1,99]<stdout>:Starting new loop for GPU: 51
[1,116]<stdout>:setting Step LR 0.1599999964237213
[1,116]<stdout>:0.16 0.1 0 [8, 11] 6
[1,82]<stdout>:Starting new loop for GPU: 42
[1,101]<stdout>:Starting new loop for GPU: 53
[1,65]<stdout>:Starting new loop for GPU: 33
[1,68]<stdout>:Starting new loop for GPU: 36
[1,70]<stdout>:Starting new loop for GPU: 38
[1,100]<stdout>:Starting new loop for GPU: 52
[1,7]<stdout>:Starting new loop for GPU: 7
[1,6]<stdout>:Starting new loop for GPU: 6
[1,54]<stdout>:Starting new loop for GPU: 30
[1,19]<stdout>:Starting new loop for GPU: 11
[1,39]<stdout>:setting Step LR 0.1599999964237213
[1,39]<stdout>:0.16 0.1 0 [8, 11] 6
[1,66]<stdout>:Starting new loop for GPU: 34
[1,33]<stdout>:setting Step LR 0.1599999964237213
[1,33]<stdout>:0.16 0.1 0 [8, 11] 6
[1,84]<stdout>:Starting new loop for GPU: 44
[1,71]<stdout>:setting Step LR 0.1599999964237213
[1,71]<stdout>:0.16 0.1 0 [8, 11] 6
[1,52]<stdout>:Starting new loop for GPU: 28
[1,20]<stdout>:setting Step LR 0.1599999964237213
[1,20]<stdout>:0.16 0.1 0 [8, 11] 6
[1,85]<stdout>:Starting new loop for GPU: 45
[1,83]<stdout>:setting Step LR 0.1599999964237213
[1,83]<stdout>:0.16 0.1 0 [8, 11] 6
[1,116]<stdout>:Starting new loop for GPU: 60
[1,33]<stdout>:Starting new loop for GPU: 17
[1,39]<stdout>:Starting new loop for GPU: 23
[1,20]<stdout>:Starting new loop for GPU: 12
[1,71]<stdout>:Starting new loop for GPU: 39
[1,83]<stdout>:Starting new loop for GPU: 43
[1,102]<stdout>:setting Step LR 0.1599999964237213
[1,102]<stdout>:0.16 0.1 0 [8, 11] 6
[1,102]<stdout>:Starting new loop for GPU: 54
[1,1]<stdout>:setting Step LR 0.1599999964237213
[1,1]<stdout>:0.16 0.1 0 [8, 11] 6
[1,1]<stdout>:Starting new loop for GPU: 1
[1,22]<stdout>:setting Step LR 0.1599999964237213
[1,22]<stdout>:0.16 0.1 0 [8, 11] 6
[1,22]<stdout>:Starting new loop for GPU: 14
[1,0]<stderr>:2020-09-18 20:06:37,271 - INFO - Saved checkpoint at: /shared/deep-learning-models/models/vision/detection/work_dirs/mask_rcnn_r50v1_d_fpn_1x_coco/005/faster_rcnn
[1,0]<stdout>:setting Step LR 0.1599999964237213
[1,0]<stdout>:0.16 0.1 0 [8, 11] 6
[1,0]<stdout>:Starting new loop for GPU: 0
[1,0]<stdout>:Rank 0 broadcasting
[1,3]<stdout>:Rank 3 broadcasting
[1,68]<stdout>:Rank 36 broadcasting
[1,7]<stdout>:Rank 7 broadcasting
[1,98]<stdout>:Rank 50 broadcasting
[1,69]<stdout>:Rank 37 broadcasting
[1,67]<stdout>:Rank 35 broadcasting
[1,102]<stdout>:Rank 54 broadcasting
[1,66]<stdout>:Rank 34 broadcasting
[1,71]<stdout>:Rank 39 broadcasting
[1,54]<stdout>:Rank 30 broadcasting
[1,96]<stdout>:Rank 48 broadcasting
[1,70]<stdout>:Rank 38 broadcasting
[1,4]<stdout>:Rank 4 broadcasting
[1,48]<stdout>:Rank 24 broadcasting
[1,38]<stdout>:Rank 22 broadcasting
[1,1]<stdout>:Rank 1 broadcasting
[1,36]<stdout>:Rank 20 broadcasting
[1,5]<stdout>:Rank 5 broadcasting
[1,33]<stdout>:Rank 17 broadcasting
[1,20]<stdout>:Rank 12 broadcasting
[1,32]<stdout>:Rank 16 broadcasting
[1,87]<stdout>:Rank 47 broadcasting
[1,34]<stdout>:Rank 18 broadcasting
[1,55]<stdout>:Rank 31 broadcasting
[1,39]<stdout>:Rank 23 broadcasting
[1,2]<stdout>:Rank 2 broadcasting
[1,18]<stdout>:Rank 10 broadcasting
[1,86]<stdout>:Rank 46 broadcasting
[1,49]<stdout>:Rank 25 broadcasting
[1,84]<stdout>:Rank 44 broadcasting
[1,83]<stdout>:Rank 43 broadcasting
[1,112]<stdout>:Rank 56 broadcasting
[1,80]<stdout>:Rank 40 broadcasting
[1,51]<stdout>:Rank 27 broadcasting
[1,85]<stdout>:Rank 45 broadcasting
[1,64]<stdout>:Rank 32 broadcasting
[1,100]<stdout>:Rank 52 broadcasting
[1,117]<stdout>:Rank 61 broadcasting
[1,16]<stdout>:Rank 8 broadcasting
[1,103]<stdout>:Rank 55 broadcasting
[1,113]<stdout>:Rank 57 broadcasting
[1,101]<stdout>:Rank 53 broadcasting
[1,23]<stdout>:Rank 15 broadcasting
[1,99]<stdout>:Rank 51 broadcasting
[1,19]<stdout>:Rank 11 broadcasting
[1,21]<stdout>:Rank 13 broadcasting
[1,22]<stdout>:Rank 14 broadcasting
[1,65]<stdout>:Rank 33 broadcasting
[1,116]<stdout>:Rank 60 broadcasting
[1,53]<stdout>:Rank 29 broadcasting
[1,82]<stdout>:Rank 42 broadcasting
[1,35]<stdout>:Rank 19 broadcasting
[1,119]<stdout>:Rank 63 broadcasting
[1,37]<stdout>:Rank 21 broadcasting
[1,97]<stdout>:Rank 49 broadcasting
[1,115]<stdout>:Rank 59 broadcasting
[1,52]<stdout>:Rank 28 broadcasting
[1,17]<stdout>:Rank 9 broadcasting
[1,6]<stdout>:Rank 6 broadcasting
[1,50]<stdout>:Rank 26 broadcasting
[1,114]<stdout>:Rank 58 broadcasting
[1,118]<stdout>:Rank 62 broadcasting
[1,81]<stdout>:Rank 41 broadcasting
[1,0]<stdout>:Variable broadcast done.
[1,5]<stdout>:Variable broadcast done.
[1,6]<stdout>:Variable broadcast done.
[1,18]<stdout>:Variable broadcast done.
[1,16]<stdout>:Variable broadcast done.
[1,17]<stdout>:Variable broadcast done.
[1,19]<stdout>:Variable broadcast done.
[1,22]<stdout>:Variable broadcast done.
[1,21]<stdout>:Variable broadcast done.
[1,23]<stdout>:Variable broadcast done.
[1,20]<stdout>:Variable broadcast done.
[1,34]<stdout>:Variable broadcast done.
[1,38]<stdout>:Variable broadcast done.
[1,35]<stdout>:Variable broadcast done.
[1,33]<stdout>:Variable broadcast done.
[1,32]<stdout>:Variable broadcast done.
[1,37]<stdout>:Variable broadcast done.
[1,39]<stdout>:Variable broadcast done.
[1,36]<stdout>:Variable broadcast done.
[1,51]<stdout>:Variable broadcast done.
[1,49]<stdout>:Variable broadcast done.
[1,50]<stdout>:Variable broadcast done.
[1,68]<stdout>:Variable broadcast done.
[1,55]<stdout>:Variable broadcast done.
[1,48]<stdout>:Variable broadcast done.
[1,66]<stdout>:Variable broadcast done.
[1,54]<stdout>:Variable broadcast done.
[1,65]<stdout>:Variable broadcast done.
[1,52]<stdout>:Variable broadcast done.
[1,70]<stdout>:Variable broadcast done.
[1,53]<stdout>:Variable broadcast done.
[1,67]<stdout>:Variable broadcast done.
[1,64]<stdout>:Variable broadcast done.
[1,69]<stdout>:Variable broadcast done.
[1,87]<stdout>:Variable broadcast done.
[1,71]<stdout>:Variable broadcast done.
[1,83]<stdout>:Variable broadcast done.
[1,7]<stdout>:Variable broadcast done.
[1,2]<stdout>:Variable broadcast done.
[1,86]<stdout>:Variable broadcast done.
[1,1]<stdout>:Variable broadcast done.
[1,85]<stdout>:Variable broadcast done.
[1,4]<stdout>:Variable broadcast done.
[1,80]<stdout>:Variable broadcast done.
[1,3]<stdout>:Variable broadcast done.
[1,96]<stdout>:Variable broadcast done.
[1,81]<stdout>:Variable broadcast done.
[1,99]<stdout>:Variable broadcast done.
[1,82]<stdout>:Variable broadcast done.
[1,98]<stdout>:Variable broadcast done.
[1,84]<stdout>:Variable broadcast done.
[1,100]<stdout>:Variable broadcast done.
[1,97]<stdout>:Variable broadcast done.
[1,114]<stdout>:Variable broadcast done.
[1,101]<stdout>:Variable broadcast done.
[1,102]<stdout>:Variable broadcast done.
[1,103]<stdout>:Variable broadcast done.
[1,115]<stdout>:Variable broadcast done.
[1,119]<stdout>:Variable broadcast done.
[1,113]<stdout>:Variable broadcast done.
[1,117]<stdout>:Variable broadcast done.
[1,112]<stdout>:Variable broadcast done.
[1,116]<stdout>:Variable broadcast done.
[1,118]<stdout>:Variable broadcast done.
[1,0]<stderr>:2020-09-18 20:07:24,060 - INFO - Epoch [7][50/458]	lr: 0.16000, eta: 0:38:04, time: 0.935, data_time: 0.065, rpn_class_loss: 2.2030, rpn_bbox_loss: 9.6538, rcnn_class_loss: 29.0465, rcnn_bbox_loss: 10.6504, rcnn_mask_loss: 11.6317, reg_loss: 0.4283, loss: 63.6136, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:08:06,562 - INFO - Epoch [7][100/458]	lr: 0.16000, eta: 0:37:22, time: 0.850, data_time: 0.039, rpn_class_loss: 2.2319, rpn_bbox_loss: 9.8631, rcnn_class_loss: 29.1505, rcnn_bbox_loss: 10.8520, rcnn_mask_loss: 10.8595, reg_loss: 0.4283, loss: 63.3852, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:08:46,832 - INFO - Epoch [7][150/458]	lr: 0.16000, eta: 0:36:37, time: 0.805, data_time: 0.032, rpn_class_loss: 1.7383, rpn_bbox_loss: 7.7410, rcnn_class_loss: 27.3515, rcnn_bbox_loss: 9.6864, rcnn_mask_loss: 11.0686, reg_loss: 0.4283, loss: 58.0140, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:09:27,140 - INFO - Epoch [7][200/458]	lr: 0.16000, eta: 0:35:53, time: 0.806, data_time: 0.038, rpn_class_loss: 2.1290, rpn_bbox_loss: 9.3598, rcnn_class_loss: 29.2458, rcnn_bbox_loss: 10.6238, rcnn_mask_loss: 11.2458, reg_loss: 0.4283, loss: 63.0325, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:10:07,344 - INFO - Epoch [7][250/458]	lr: 0.16000, eta: 0:35:09, time: 0.804, data_time: 0.035, rpn_class_loss: 2.0456, rpn_bbox_loss: 8.7793, rcnn_class_loss: 27.5558, rcnn_bbox_loss: 9.4718, rcnn_mask_loss: 11.0246, reg_loss: 0.4283, loss: 59.3054, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:10:47,614 - INFO - Epoch [7][300/458]	lr: 0.16000, eta: 0:34:26, time: 0.805, data_time: 0.037, rpn_class_loss: 2.0307, rpn_bbox_loss: 8.9489, rcnn_class_loss: 26.1044, rcnn_bbox_loss: 9.3376, rcnn_mask_loss: 10.8537, reg_loss: 0.4283, loss: 57.7036, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:11:27,696 - INFO - Epoch [7][350/458]	lr: 0.16000, eta: 0:33:42, time: 0.802, data_time: 0.041, rpn_class_loss: 1.8578, rpn_bbox_loss: 8.0583, rcnn_class_loss: 27.3542, rcnn_bbox_loss: 9.5316, rcnn_mask_loss: 11.1834, reg_loss: 0.4283, loss: 58.4135, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:12:07,874 - INFO - Epoch [7][400/458]	lr: 0.16000, eta: 0:32:58, time: 0.804, data_time: 0.038, rpn_class_loss: 1.9578, rpn_bbox_loss: 8.9520, rcnn_class_loss: 29.8395, rcnn_bbox_loss: 10.5617, rcnn_mask_loss: 11.2915, reg_loss: 0.4283, loss: 63.0308, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:12:48,327 - INFO - Epoch [7][450/458]	lr: 0.16000, eta: 0:32:15, time: 0.809, data_time: 0.039, rpn_class_loss: 2.2952, rpn_bbox_loss: 9.9330, rcnn_class_loss: 29.1000, rcnn_bbox_loss: 10.4628, rcnn_mask_loss: 11.6408, reg_loss: 0.4283, loss: 63.8601, learning_rate: 0.1600
[1,18]<stdout>:setting Step LR 0.1599999964237213
[1,18]<stdout>:0.16 0.1 0 [8, 11] 7
[1,1]<stdout>:setting Step LR 0.1599999964237213
[1,1]<stdout>:0.16 0.1 0 [8, 11] 7
[1,83]<stdout>:setting Step LR 0.1599999964237213
[1,83]<stdout>:0.16 0.1 0 [8, 11] 7
[1,67]<stdout>:setting Step LR 0.1599999964237213
[1,67]<stdout>:0.16 0.1 0 [8, 11] 7
[1,17]<stdout>:setting Step LR 0.1599999964237213
[1,17]<stdout>:0.16 0.1 0 [8, 11] 7
[1,2]<stdout>:setting Step LR 0.1599999964237213
[1,2]<stdout>:0.16 0.1 0 [8, 11] 7
[1,5]<stdout>:setting Step LR 0.1599999964237213
[1,5]<stdout>:0.16 0.1 0 [8, 11] 7
[1,101]<stdout>:setting Step LR 0.1599999964237213
[1,101]<stdout>:0.16 0.1 0 [8, 11] 7
[1,86]<stdout>:setting Step LR 0.1599999964237213
[1,86]<stdout>:0.16 0.1 0 [8, 11] 7
[1,23]<stdout>:setting Step LR 0.1599999964237213
[1,23]<stdout>:0.16 0.1 0 [8, 11] 7
[1,22]<stdout>:setting Step LR 0.1599999964237213
[1,22]<stdout>:0.16 0.1 0 [8, 11] 7
[1,96]<stdout>:setting Step LR 0.1599999964237213
[1,96]<stdout>:0.16 0.1 0 [8, 11] 7
[1,16]<stdout>:setting Step LR 0.1599999964237213
[1,16]<stdout>:0.16 0.1 0 [8, 11] 7
[1,39]<stdout>:setting Step LR 0.1599999964237213
[1,39]<stdout>:0.16 0.1 0 [8, 11] 7
[1,6]<stdout>:setting Step LR 0.1599999964237213
[1,6]<stdout>:0.16 0.1 0 [8, 11] 7
[1,4]<stdout>:setting Step LR 0.1599999964237213
[1,4]<stdout>:0.16 0.1 0 [8, 11] 7
[1,65]<stdout>:setting Step LR 0.1599999964237213
[1,65]<stdout>:0.16 0.1 0 [8, 11] 7
[1,36]<stdout>:setting Step LR 0.1599999964237213
[1,36]<stdout>:0.16 0.1 0 [8, 11] 7
[1,82]<stdout>:setting Step LR 0.1599999964237213
[1,82]<stdout>:0.16 0.1 0 [8, 11] 7
[1,66]<stdout>:setting Step LR 0.1599999964237213
[1,66]<stdout>:0.16 0.1 0 [8, 11] 7
[1,112]<stdout>:setting Step LR 0.1599999964237213
[1,112]<stdout>:0.16 0.1 0 [8, 11] 7
[1,7]<stdout>:setting Step LR 0.1599999964237213
[1,7]<stdout>:0.16 0.1 0 [8, 11] 7
[1,114]<stdout>:setting Step LR 0.1599999964237213
[1,114]<stdout>:0.16 0.1 0 [8, 11] 7
[1,21]<stdout>:setting Step LR 0.1599999964237213
[1,21]<stdout>:0.16 0.1 0 [8, 11] 7
[1,50]<stdout>:setting Step LR 0.1599999964237213
[1,50]<stdout>:0.16 0.1 0 [8, 11] 7
[1,18]<stdout>:Starting new loop for GPU: 10
[1,84]<stdout>:setting Step LR 0.1599999964237213
[1,84]<stdout>:0.16 0.1 0 [8, 11] 7
[1,100]<stdout>:setting Step LR 0.1599999964237213
[1,100]<stdout>:0.16 0.1 0 [8, 11] 7
[1,83]<stdout>:Starting new loop for GPU: 43
[1,115]<stdout>:setting Step LR 0.1599999964237213
[1,115]<stdout>:0.16 0.1 0 [8, 11] 7
[1,1]<stdout>:Starting new loop for GPU: 1
[1,68]<stdout>:setting Step LR 0.1599999964237213
[1,68]<stdout>:0.16 0.1 0 [8, 11] 7
[1,67]<stdout>:Starting new loop for GPU: 35
[1,113]<stdout>:setting Step LR 0.1599999964237213
[1,113]<stdout>:0.16 0.1 0 [8, 11] 7
[1,2]<stdout>:Starting new loop for GPU: 2
[1,17]<stdout>:Starting new loop for GPU: 9
[1,5]<stdout>:Starting new loop for GPU: 5
[1,70]<stdout>:setting Step LR 0.1599999964237213
[1,70]<stdout>:0.16 0.1 0 [8, 11] 7
[1,52]<stdout>:setting Step LR 0.1599999964237213
[1,52]<stdout>:0.16 0.1 0 [8, 11] 7
[1,101]<stdout>:Starting new loop for GPU: 53
[1,34]<stdout>:setting Step LR 0.1599999964237213
[1,34]<stdout>:0.16 0.1 0 [8, 11] 7
[1,38]<stdout>:setting Step LR 0.1599999964237213
[1,38]<stdout>:0.16 0.1 0 [8, 11] 7
[1,86]<stdout>:Starting new loop for GPU: 46
[1,54]<stdout>:setting Step LR 0.1599999964237213
[1,54]<stdout>:0.16 0.1 0 [8, 11] 7
[1,55]<stdout>:setting Step LR 0.1599999964237213
[1,55]<stdout>:0.16 0.1 0 [8, 11] 7
[1,116]<stdout>:setting Step LR 0.1599999964237213
[1,116]<stdout>:0.16 0.1 0 [8, 11] 7
[1,23]<stdout>:Starting new loop for GPU: 15
[1,80]<stdout>:setting Step LR 0.1599999964237213
[1,80]<stdout>:0.16 0.1 0 [8, 11] 7
[1,69]<stdout>:setting Step LR 0.1599999964237213
[1,69]<stdout>:0.16 0.1 0 [8, 11] 7
[1,81]<stdout>:setting Step LR 0.1599999964237213
[1,81]<stdout>:0.16 0.1 0 [8, 11] 7
[1,22]<stdout>:Starting new loop for GPU: 14
[1,96]<stdout>:Starting new loop for GPU: 48
[1,33]<stdout>:setting Step LR 0.1599999964237213
[1,33]<stdout>:0.16 0.1 0 [8, 11] 7
[1,36]<stdout>:Starting new loop for GPU: 20
[1,16]<stdout>:Starting new loop for GPU: 8
[1,48]<stdout>:setting Step LR 0.1599999964237213
[1,48]<stdout>:0.16 0.1 0 [8, 11] 7
[1,117]<stdout>:setting Step LR 0.1599999964237213
[1,117]<stdout>:0.16 0.1 0 [8, 11] 7
[1,114]<stdout>:Starting new loop for GPU: 58
[1,82]<stdout>:Starting new loop for GPU: 42
[1,50]<stdout>:Starting new loop for GPU: 26
[1,39]<stdout>:Starting new loop for GPU: 23
[1,112]<stdout>:Starting new loop for GPU: 56
[1,65]<stdout>:Starting new loop for GPU: 33
[1,100]<stdout>:Starting new loop for GPU: 52
[1,66]<stdout>:Starting new loop for GPU: 34
[1,53]<stdout>:setting Step LR 0.1599999964237213
[1,53]<stdout>:0.16 0.1 0 [8, 11] 7
[1,6]<stdout>:Starting new loop for GPU: 6
[1,84]<stdout>:Starting new loop for GPU: 44
[1,21]<stdout>:Starting new loop for GPU: 13
[1,4]<stdout>:Starting new loop for GPU: 4
[1,115]<stdout>:Starting new loop for GPU: 59
[1,119]<stdout>:setting Step LR 0.1599999964237213
[1,119]<stdout>:0.16 0.1 0 [8, 11] 7
[1,113]<stdout>:Starting new loop for GPU: 57
[1,68]<stdout>:Starting new loop for GPU: 36
[1,7]<stdout>:Starting new loop for GPU: 7
[1,70]<stdout>:Starting new loop for GPU: 38
[1,52]<stdout>:Starting new loop for GPU: 28
[1,37]<stdout>:setting Step LR 0.1599999964237213
[1,37]<stdout>:0.16 0.1 0 [8, 11] 7
[1,20]<stdout>:setting Step LR 0.1599999964237213
[1,20]<stdout>:0.16 0.1 0 [8, 11] 7
[1,49]<stdout>:setting Step LR 0.1599999964237213
[1,49]<stdout>:0.16 0.1 0 [8, 11] 7
[1,34]<stdout>:Starting new loop for GPU: 18
[1,38]<stdout>:Starting new loop for GPU: 22
[1,55]<stdout>:Starting new loop for GPU: 31
[1,54]<stdout>:Starting new loop for GPU: 30
[1,116]<stdout>:Starting new loop for GPU: 60
[1,35]<stdout>:setting Step LR 0.1599999964237213
[1,35]<stdout>:0.16 0.1 0 [8, 11] 7
[1,53]<stdout>:Starting new loop for GPU: 29
[1,80]<stdout>:Starting new loop for GPU: 40
[1,81]<stdout>:Starting new loop for GPU: 41
[1,117]<stdout>:Starting new loop for GPU: 61
[1,48]<stdout>:Starting new loop for GPU: 24
[1,87]<stdout>:setting Step LR 0.1599999964237213
[1,87]<stdout>:0.16 0.1 0 [8, 11] 7
[1,33]<stdout>:Starting new loop for GPU: 17
[1,69]<stdout>:Starting new loop for GPU: 37
[1,71]<stdout>:setting Step LR 0.1599999964237213
[1,71]<stdout>:0.16 0.1 0 [8, 11] 7
[1,51]<stdout>:setting Step LR 0.1599999964237213
[1,51]<stdout>:0.16 0.1 0 [8, 11] 7
[1,119]<stdout>:Starting new loop for GPU: 63
[1,37]<stdout>:Starting new loop for GPU: 21
[1,98]<stdout>:setting Step LR 0.1599999964237213
[1,98]<stdout>:0.16 0.1 0 [8, 11] 7
[1,49]<stdout>:Starting new loop for GPU: 25
[1,85]<stdout>:setting Step LR 0.1599999964237213
[1,85]<stdout>:0.16 0.1 0 [8, 11] 7
[1,20]<stdout>:Starting new loop for GPU: 12
[1,99]<stdout>:setting Step LR 0.1599999964237213
[1,99]<stdout>:0.16 0.1 0 [8, 11] 7
[1,35]<stdout>:Starting new loop for GPU: 19
[1,19]<stdout>:setting Step LR 0.1599999964237213
[1,19]<stdout>:0.16 0.1 0 [8, 11] 7
[1,87]<stdout>:Starting new loop for GPU: 47
[1,97]<stdout>:setting Step LR 0.1599999964237213
[1,97]<stdout>:0.16 0.1 0 [8, 11] 7
[1,71]<stdout>:Starting new loop for GPU: 39
[1,51]<stdout>:Starting new loop for GPU: 27
[1,98]<stdout>:Starting new loop for GPU: 50
[1,85]<stdout>:Starting new loop for GPU: 45
[1,103]<stdout>:setting Step LR 0.1599999964237213
[1,103]<stdout>:0.16 0.1 0 [8, 11] 7
[1,99]<stdout>:Starting new loop for GPU: 51
[1,64]<stdout>:setting Step LR 0.1599999964237213
[1,64]<stdout>:0.16 0.1 0 [8, 11] 7
[1,97]<stdout>:Starting new loop for GPU: 49
[1,118]<stdout>:setting Step LR 0.1599999964237213
[1,118]<stdout>:0.16 0.1 0 [8, 11] 7
[1,19]<stdout>:Starting new loop for GPU: 11
[1,103]<stdout>:Starting new loop for GPU: 55
[1,64]<stdout>:Starting new loop for GPU: 32
[1,118]<stdout>:Starting new loop for GPU: 62
[1,102]<stdout>:setting Step LR 0.1599999964237213
[1,102]<stdout>:0.16 0.1 0 [8, 11] 7
[1,102]<stdout>:Starting new loop for GPU: 54
[1,3]<stdout>:setting Step LR 0.1599999964237213
[1,3]<stdout>:0.16 0.1 0 [8, 11] 7
[1,32]<stdout>:setting Step LR 0.1599999964237213
[1,32]<stdout>:0.16 0.1 0 [8, 11] 7
[1,3]<stdout>:Starting new loop for GPU: 3
[1,32]<stdout>:Starting new loop for GPU: 16
[1,0]<stderr>:2020-09-18 20:12:55,777 - INFO - Saved checkpoint at: /shared/deep-learning-models/models/vision/detection/work_dirs/mask_rcnn_r50v1_d_fpn_1x_coco/006/faster_rcnn
[1,0]<stdout>:setting Step LR 0.1599999964237213
[1,0]<stdout>:0.16 0.1 0 [8, 11] 7
[1,0]<stdout>:Starting new loop for GPU: 0
[1,98]<stdout>:Rank 50 broadcasting
[1,101]<stdout>:Rank 53 broadcasting
[1,97]<stdout>:Rank 49 broadcasting
[1,99]<stdout>:Rank 51 broadcasting
[1,103]<stdout>:Rank 55 broadcasting
[1,82]<stdout>:Rank 42 broadcasting
[1,85]<stdout>:Rank 45 broadcasting
[1,39]<stdout>:Rank 23 broadcasting
[1,87]<stdout>:Rank 47 broadcasting
[1,23]<stdout>:Rank 15 broadcasting
[1,70]<stdout>:Rank 38 broadcasting
[1,50]<stdout>:Rank 26 broadcasting
[1,32]<stdout>:Rank 16 broadcasting
[1,86]<stdout>:Rank 46 broadcasting
[1,5]<stdout>:Rank 5 broadcasting
[1,20]<stdout>:Rank 12 broadcasting
[1,100]<stdout>:Rank 52 broadcasting
[1,66]<stdout>:Rank 34 broadcasting
[1,119]<stdout>:Rank 63 broadcasting
[1,49]<stdout>:Rank 25 broadcasting
[1,38]<stdout>:Rank 22 broadcasting
[1,0]<stdout>:Rank 0 broadcasting
[1,18]<stdout>:Rank 10 broadcasting
[1,67]<stdout>:Rank 35 broadcasting
[1,116]<stdout>:Rank 60 broadcasting
[1,48]<stdout>:Rank 24 broadcasting
[1,35]<stdout>:Rank 19 broadcasting
[1,6]<stdout>:Rank 6 broadcasting
[1,22]<stdout>:Rank 14 broadcasting
[1,96]<stdout>:Rank 48 broadcasting
[1,68]<stdout>:Rank 36 broadcasting
[1,115]<stdout>:Rank 59 broadcasting
[1,53]<stdout>:Rank 29 broadcasting
[1,33]<stdout>:Rank 17 broadcasting
[1,2]<stdout>:Rank 2 broadcasting
[1,17]<stdout>:Rank 9 broadcasting
[1,102]<stdout>:Rank 54 broadcasting
[1,64]<stdout>:Rank 32 broadcasting
[1,118]<stdout>:Rank 62 broadcasting
[1,4]<stdout>:Rank 4 broadcasting
[1,21]<stdout>:Rank 13 broadcasting
[1,69]<stdout>:Rank 37 broadcasting
[1,7]<stdout>:Rank 7 broadcasting
[1,81]<stdout>:Rank 41 broadcasting
[1,52]<stdout>:Rank 28 broadcasting
[1,83]<stdout>:Rank 43 broadcasting
[1,37]<stdout>:Rank 21 broadcasting
[1,55]<stdout>:Rank 31 broadcasting
[1,16]<stdout>:Rank 8 broadcasting
[1,54]<stdout>:Rank 30 broadcasting
[1,80]<stdout>:Rank 40 broadcasting
[1,19]<stdout>:Rank 11 broadcasting
[1,3]<stdout>:Rank 3 broadcasting
[1,117]<stdout>:Rank 61 broadcasting
[1,36]<stdout>:Rank 20 broadcasting
[1,1]<stdout>:Rank 1 broadcasting
[1,34]<stdout>:Rank 18 broadcasting
[1,113]<stdout>:Rank 57 broadcasting
[1,51]<stdout>:Rank 27 broadcasting
[1,112]<stdout>:Rank 56 broadcasting
[1,114]<stdout>:Rank 58 broadcasting
[1,84]<stdout>:Rank 44 broadcasting
[1,65]<stdout>:Rank 33 broadcasting
[1,71]<stdout>:Rank 39 broadcasting
[1,0]<stdout>:Variable broadcast done.
[1,5]<stdout>:Variable broadcast done.
[1,6]<stdout>:Variable broadcast done.
[1,16]<stdout>:Variable broadcast done.
[1,18]<stdout>:Variable broadcast done.
[1,19]<stdout>:Variable broadcast done.
[1,17]<stdout>:Variable broadcast done.
[1,22]<stdout>:Variable broadcast done.
[1,21]<stdout>:Variable broadcast done.
[1,23]<stdout>:Variable broadcast done.
[1,20]<stdout>:Variable broadcast done.
[1,38]<stdout>:Variable broadcast done.
[1,37]<stdout>:Variable broadcast done.
[1,35]<stdout>:Variable broadcast done.
[1,34]<stdout>:Variable broadcast done.
[1,33]<stdout>:Variable broadcast done.
[1,39]<stdout>:Variable broadcast done.
[1,32]<stdout>:Variable broadcast done.
[1,36]<stdout>:Variable broadcast done.
[1,7]<stdout>:Variable broadcast done.
[1,4]<stdout>:Variable broadcast done.
[1,49]<stdout>:Variable broadcast done.
[1,55]<stdout>:Variable broadcast done.
[1,51]<stdout>:Variable broadcast done.
[1,48]<stdout>:Variable broadcast done.
[1,53]<stdout>:Variable broadcast done.
[1,54]<stdout>:Variable broadcast done.
[1,52]<stdout>:Variable broadcast done.
[1,68]<stdout>:Variable broadcast done.
[1,50]<stdout>:Variable broadcast done.
[1,70]<stdout>:Variable broadcast done.
[1,66]<stdout>:Variable broadcast done.
[1,67]<stdout>:Variable broadcast done.
[1,64]<stdout>:Variable broadcast done.
[1,71]<stdout>:Variable broadcast done.
[1,69]<stdout>:Variable broadcast done.
[1,65]<stdout>:Variable broadcast done.
[1,85]<stdout>:Variable broadcast done.
[1,103]<stdout>:Variable broadcast done.
[1,102]<stdout>:Variable broadcast done.
[1,98]<stdout>:Variable broadcast done.
[1,83]<stdout>:Variable broadcast done.
[1,82]<stdout>:Variable broadcast done.
[1,101]<stdout>:Variable broadcast done.
[1,97]<stdout>:Variable broadcast done.
[1,84]<stdout>:Variable broadcast done.
[1,99]<stdout>:Variable broadcast done.
[1,80]<stdout>:Variable broadcast done.
[1,96]<stdout>:Variable broadcast done.
[1,81]<stdout>:Variable broadcast done.
[1,100]<stdout>:Variable broadcast done.
[1,87]<stdout>:Variable broadcast done.
[1,86]<stdout>:Variable broadcast done.
[1,119]<stdout>:Variable broadcast done.
[1,116]<stdout>:Variable broadcast done.
[1,2]<stdout>:Variable broadcast done.
[1,113]<stdout>:Variable broadcast done.
[1,115]<stdout>:Variable broadcast done.
[1,1]<stdout>:Variable broadcast done.
[1,118]<stdout>:Variable broadcast done.
[1,3]<stdout>:Variable broadcast done.
[1,112]<stdout>:Variable broadcast done.
[1,114]<stdout>:Variable broadcast done.
[1,117]<stdout>:Variable broadcast done.
[1,0]<stderr>:2020-09-18 20:13:41,311 - INFO - Epoch [8][50/458]	lr: 0.16000, eta: 0:31:24, time: 0.910, data_time: 0.052, rpn_class_loss: 2.1007, rpn_bbox_loss: 9.1488, rcnn_class_loss: 29.8560, rcnn_bbox_loss: 10.2880, rcnn_mask_loss: 11.2840, reg_loss: 0.4283, loss: 63.1057, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:14:21,613 - INFO - Epoch [8][100/458]	lr: 0.16000, eta: 0:30:40, time: 0.806, data_time: 0.036, rpn_class_loss: 2.2230, rpn_bbox_loss: 9.8371, rcnn_class_loss: 27.1261, rcnn_bbox_loss: 9.5275, rcnn_mask_loss: 10.8280, reg_loss: 0.4283, loss: 59.9700, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:15:01,461 - INFO - Epoch [8][150/458]	lr: 0.16000, eta: 0:29:57, time: 0.797, data_time: 0.039, rpn_class_loss: 2.3979, rpn_bbox_loss: 10.0084, rcnn_class_loss: 27.6663, rcnn_bbox_loss: 9.9358, rcnn_mask_loss: 10.7232, reg_loss: 0.4283, loss: 61.1599, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:15:41,568 - INFO - Epoch [8][200/458]	lr: 0.16000, eta: 0:29:14, time: 0.802, data_time: 0.033, rpn_class_loss: 1.9287, rpn_bbox_loss: 8.1482, rcnn_class_loss: 26.1693, rcnn_bbox_loss: 9.3560, rcnn_mask_loss: 11.5331, reg_loss: 0.4283, loss: 57.5636, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:16:22,486 - INFO - Epoch [8][250/458]	lr: 0.16000, eta: 0:28:31, time: 0.818, data_time: 0.041, rpn_class_loss: 2.6397, rpn_bbox_loss: 11.4487, rcnn_class_loss: 31.4006, rcnn_bbox_loss: 11.4591, rcnn_mask_loss: 11.2934, reg_loss: 0.4283, loss: 68.6697, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:17:03,397 - INFO - Epoch [8][300/458]	lr: 0.16000, eta: 0:27:49, time: 0.818, data_time: 0.038, rpn_class_loss: 2.2980, rpn_bbox_loss: 9.9566, rcnn_class_loss: 26.9438, rcnn_bbox_loss: 9.6379, rcnn_mask_loss: 11.4237, reg_loss: 0.4283, loss: 60.6881, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:17:43,986 - INFO - Epoch [8][350/458]	lr: 0.16000, eta: 0:27:06, time: 0.812, data_time: 0.037, rpn_class_loss: 2.1373, rpn_bbox_loss: 9.6099, rcnn_class_loss: 27.5995, rcnn_bbox_loss: 9.8690, rcnn_mask_loss: 11.9548, reg_loss: 0.4283, loss: 61.5987, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:18:24,165 - INFO - Epoch [8][400/458]	lr: 0.16000, eta: 0:26:23, time: 0.804, data_time: 0.038, rpn_class_loss: 2.0299, rpn_bbox_loss: 9.2296, rcnn_class_loss: 29.1552, rcnn_bbox_loss: 10.5118, rcnn_mask_loss: 11.2143, reg_loss: 0.4283, loss: 62.5689, learning_rate: 0.1600
[1,0]<stderr>:2020-09-18 20:19:04,630 - INFO - Epoch [8][450/458]	lr: 0.16000, eta: 0:25:41, time: 0.809, data_time: 0.037, rpn_class_loss: 2.0345, rpn_bbox_loss: 9.0582, rcnn_class_loss: 28.0376, rcnn_bbox_loss: 10.2145, rcnn_mask_loss: 11.2312, reg_loss: 0.4283, loss: 61.0043, learning_rate: 0.1600
[1,118]<stdout>:setting Step LR 0.015999999642372132
[1,118]<stdout>:0.16 0.1 1 [8, 11] 8
[1,1]<stdout>:setting Step LR 0.015999999642372132
[1,1]<stdout>:0.16 0.1 1 [8, 11] 8
[1,83]<stdout>:setting Step LR 0.015999999642372132
[1,83]<stdout>:0.16 0.1 1 [8, 11] 8
[1,85]<stdout>:setting Step LR 0.015999999642372132
[1,85]<stdout>:0.16 0.1 1 [8, 11] 8
[1,116]<stdout>:setting Step LR 0.015999999642372132
[1,116]<stdout>:0.16 0.1 1 [8, 11] 8
[1,66]<stdout>:setting Step LR 0.015999999642372132
[1,66]<stdout>:0.16 0.1 1 [8, 11] 8
[1,54]<stdout>:setting Step LR 0.015999999642372132
[1,54]<stdout>:0.16 0.1 1 [8, 11] 8
[1,21]<stdout>:setting Step LR 0.015999999642372132
[1,21]<stdout>:0.16 0.1 1 [8, 11] 8
[1,34]<stdout>:setting Step LR 0.015999999642372132
[1,34]<stdout>:0.16 0.1 1 [8, 11] 8
[1,32]<stdout>:setting Step LR 0.015999999642372132
[1,32]<stdout>:0.16 0.1 1 [8, 11] 8
[1,36]<stdout>:setting Step LR 0.015999999642372132
[1,36]<stdout>:0.16 0.1 1 [8, 11] 8
[1,35]<stdout>:setting Step LR 0.015999999642372132
[1,35]<stdout>:0.16 0.1 1 [8, 11] 8
[1,118]<stdout>:Starting new loop for GPU: 62
[1,7]<stdout>:setting Step LR 0.015999999642372132
[1,7]<stdout>:0.16 0.1 1 [8, 11] 8
[1,101]<stdout>:setting Step LR 0.015999999642372132
[1,101]<stdout>:0.16 0.1 1 [8, 11] 8
[1,3]<stdout>:setting Step LR 0.015999999642372132
[1,3]<stdout>:0.16 0.1 1 [8, 11] 8
[1,20]<stdout>:setting Step LR 0.015999999642372132
[1,20]<stdout>:0.16 0.1 1 [8, 11] 8
[1,1]<stdout>:Starting new loop for GPU: 1
[1,39]<stdout>:setting Step LR 0.015999999642372132
[1,39]<stdout>:0.16 0.1 1 [8, 11] 8
[1,17]<stdout>:setting Step LR 0.015999999642372132
[1,17]<stdout>:0.16 0.1 1 [8, 11] 8
[1,19]<stdout>:setting Step LR 0.015999999642372132
[1,19]<stdout>:0.16 0.1 1 [8, 11] 8
[1,52]<stdout>:setting Step LR 0.015999999642372132
[1,52]<stdout>:0.16 0.1 1 [8, 11] 8
[1,83]<stdout>:Starting new loop for GPU: 43
[1,37]<stdout>:setting Step LR 0.015999999642372132
[1,37]<stdout>:0.16 0.1 1 [8, 11] 8
[1,116]<stdout>:Starting new loop for GPU: 60
[1,85]<stdout>:Starting new loop for GPU: 45
[1,114]<stdout>:setting Step LR 0.015999999642372132
[1,114]<stdout>:0.16 0.1 1 [8, 11] 8
[1,53]<stdout>:setting Step LR 0.015999999642372132
[1,53]<stdout>:0.16 0.1 1 [8, 11] 8
[1,6]<stdout>:setting Step LR 0.015999999642372132
[1,6]<stdout>:0.16 0.1 1 [8, 11] 8
[1,115]<stdout>:setting Step LR 0.015999999642372132
[1,115]<stdout>:0.16 0.1 1 [8, 11] 8
[1,87]<stdout>:setting Step LR 0.015999999642372132
[1,87]<stdout>:0.16 0.1 1 [8, 11] 8
[1,96]<stdout>:setting Step LR 0.015999999642372132
[1,96]<stdout>:0.16 0.1 1 [8, 11] 8
[1,70]<stdout>:setting Step LR 0.015999999642372132
[1,70]<stdout>:0.16 0.1 1 [8, 11] 8
[1,64]<stdout>:setting Step LR 0.015999999642372132
[1,64]<stdout>:0.16 0.1 1 [8, 11] 8
[1,51]<stdout>:setting Step LR 0.015999999642372132
[1,51]<stdout>:0.16 0.1 1 [8, 11] 8
[1,103]<stdout>:setting Step LR 0.015999999642372132
[1,103]<stdout>:0.16 0.1 1 [8, 11] 8
[1,112]<stdout>:setting Step LR 0.015999999642372132
[1,112]<stdout>:0.16 0.1 1 [8, 11] 8
[1,86]<stdout>:setting Step LR 0.015999999642372132
[1,86]<stdout>:0.16 0.1 1 [8, 11] 8
[1,65]<stdout>:setting Step LR 0.015999999642372132
[1,65]<stdout>:0.16 0.1 1 [8, 11] 8
[1,81]<stdout>:setting Step LR 0.015999999642372132
[1,81]<stdout>:0.16 0.1 1 [8, 11] 8
[1,66]<stdout>:Starting new loop for GPU: 34
[1,48]<stdout>:setting Step LR 0.015999999642372132
[1,48]<stdout>:0.16 0.1 1 [8, 11] 8
[1,54]<stdout>:Starting new loop for GPU: 30
[1,16]<stdout>:setting Step LR 0.015999999642372132
[1,16]<stdout>:0.16 0.1 1 [8, 11] 8
[1,21]<stdout>:Starting new loop for GPU: 13
[1,18]<stdout>:setting Step LR 0.015999999642372132
[1,18]<stdout>:0.16 0.1 1 [8, 11] 8
[1,100]<stdout>:setting Step LR 0.015999999642372132
[1,100]<stdout>:0.16 0.1 1 [8, 11] 8
[1,2]<stdout>:setting Step LR 0.015999999642372132
[1,2]<stdout>:0.16 0.1 1 [8, 11] 8
[1,34]<stdout>:Starting new loop for GPU: 18
[1,101]<stdout>:Starting new loop for GPU: 53
[1,36]<stdout>:Starting new loop for GPU: 20
[1,20]<stdout>:Starting new loop for GPU: 12
[1,50]<stdout>:setting Step LR 0.015999999642372132
[1,50]<stdout>:0.16 0.1 1 [8, 11] 8
[1,22]<stdout>:setting Step LR 0.015999999642372132
[1,22]<stdout>:0.16 0.1 1 [8, 11] 8
[1,32]<stdout>:Starting new loop for GPU: 16
[1,7]<stdout>:Starting new loop for GPU: 7
[1,3]<stdout>:Starting new loop for GPU: 3
[1,35]<stdout>:Starting new loop for GPU: 19
[1,52]<stdout>:Starting new loop for GPU: 28
[1,17]<stdout>:Starting new loop for GPU: 9
[1,19]<stdout>:Starting new loop for GPU: 11
[1,39]<stdout>:Starting new loop for GPU: 23
[1,37]<stdout>:Starting new loop for GPU: 21
[1,4]<stdout>:setting Step LR 0.015999999642372132
[1,4]<stdout>:0.16 0.1 1 [8, 11] 8
[1,6]<stdout>:Starting new loop for GPU: 6
[1,49]<stdout>:setting Step LR 0.015999999642372132
[1,49]<stdout>:0.16 0.1 1 [8, 11] 8
[1,84]<stdout>:setting Step LR 0.015999999642372132
[1,84]<stdout>:0.16 0.1 1 [8, 11] 8
[1,113]<stdout>:setting Step LR 0.015999999642372132
[1,113]<stdout>:0.16 0.1 1 [8, 11] 8
[1,115]<stdout>:Starting new loop for GPU: 59
[1,5]<stdout>:setting Step LR 0.015999999642372132
[1,5]<stdout>:0.16 0.1 1 [8, 11] 8
[1,51]<stdout>:Starting new loop for GPU: 27
[1,53]<stdout>:Starting new loop for GPU: 29
[1,80]<stdout>:setting Step LR 0.015999999642372132
[1,80]<stdout>:0.16 0.1 1 [8, 11] 8
[1,86]<stdout>:Starting new loop for GPU: 46
[1,55]<stdout>:setting Step LR 0.015999999642372132
[1,55]<stdout>:0.16 0.1 1 [8, 11] 8
[1,114]<stdout>:Starting new loop for GPU: 58
[1,98]<stdout>:setting Step LR 0.015999999642372132
[1,98]<stdout>:0.16 0.1 1 [8, 11] 8
[1,38]<stdout>:setting Step LR 0.015999999642372132
[1,38]<stdout>:0.16 0.1 1 [8, 11] 8
[1,64]<stdout>:Starting new loop for GPU: 32
[1,96]<stdout>:Starting new loop for GPU: 48
[1,65]<stdout>:Starting new loop for GPU: 33
[1,70]<stdout>:Starting new loop for GPU: 38
[1,103]<stdout>:Starting new loop for GPU: 55
[1,48]<stdout>:Starting new loop for GPU: 24
[1,112]<stdout>:Starting new loop for GPU: 56
[1,99]<stdout>:setting Step LR 0.015999999642372132
[1,99]<stdout>:0.16 0.1 1 [8, 11] 8
[1,87]<stdout>:Starting new loop for GPU: 47
[1,81]<stdout>:Starting new loop for GPU: 41
[1,100]<stdout>:Starting new loop for GPU: 52
[1,2]<stdout>:Starting new loop for GPU: 2
[1,97]<stdout>:setting Step LR 0.015999999642372132
[1,97]<stdout>:0.16 0.1 1 [8, 11] 8
[1,119]<stdout>:setting Step LR 0.015999999642372132
[1,119]<stdout>:0.16 0.1 1 [8, 11] 8
[1,67]<stdout>:setting Step LR 0.015999999642372132
[1,67]<stdout>:0.16 0.1 1 [8, 11] 8
[1,82]<stdout>:setting Step LR 0.015999999642372132
[1,82]<stdout>:0.16 0.1 1 [8, 11] 8
[1,16]<stdout>:Starting new loop for GPU: 8
[1,18]<stdout>:Starting new loop for GPU: 10
[1,22]<stdout>:Starting new loop for GPU: 14
[1,50]<stdout>:Starting new loop for GPU: 26
[1,23]<stdout>:setting Step LR 0.015999999642372132
[1,23]<stdout>:0.16 0.1 1 [8, 11] 8
[1,4]<stdout>:Starting new loop for GPU: 4
[1,113]<stdout>:Starting new loop for GPU: 57
[1,49]<stdout>:Starting new loop for GPU: 25
[1,69]<stdout>:setting Step LR 0.015999999642372132
[1,69]<stdout>:0.16 0.1 1 [8, 11] 8
[1,84]<stdout>:Starting new loop for GPU: 44
[1,80]<stdout>:Starting new loop for GPU: 40
[1,5]<stdout>:Starting new loop for GPU: 5
[1,98]<stdout>:Starting new loop for GPU: 50
[1,55]<stdout>:Starting new loop for GPU: 31
[1,117]<stdout>:setting Step LR 0.015999999642372132
[1,117]<stdout>:0.16 0.1 1 [8, 11] 8
[1,38]<stdout>:Starting new loop for GPU: 22
[1,67]<stdout>:Starting new loop for GPU: 35
[1,119]<stdout>:Starting new loop for GPU: 63
[1,99]<stdout>:Starting new loop for GPU: 51
[1,97]<stdout>:Starting new loop for GPU: 49
[1,82]<stdout>:Starting new loop for GPU: 42
[1,71]<stdout>:setting Step LR 0.015999999642372132
[1,71]<stdout>:0.16 0.1 1 [8, 11] 8
[1,23]<stdout>:Starting new loop for GPU: 15
[1,68]<stdout>:setting Step LR 0.015999999642372132
[1,68]<stdout>:0.16 0.1 1 [8, 11] 8
[1,69]<stdout>:Starting new loop for GPU: 37
[1,117]<stdout>:Starting new loop for GPU: 61
[1,71]<stdout>:Starting new loop for GPU: 39
[1,68]<stdout>:Starting new loop for GPU: 36
[1,102]<stdout>:setting Step LR 0.015999999642372132
[1,102]<stdout>:0.16 0.1 1 [8, 11] 8
[1,102]<stdout>:Starting new loop for GPU: 54
[1,33]<stdout>:setting Step LR 0.015999999642372132
[1,33]<stdout>:0.16 0.1 1 [8, 11] 8
[1,33]<stdout>:Starting new loop for GPU: 17
[1,0]<stderr>:2020-09-18 20:19:12,294 - INFO - Saved checkpoint at: /shared/deep-learning-models/models/vision/detection/work_dirs/mask_rcnn_r50v1_d_fpn_1x_coco/007/faster_rcnn
[1,0]<stdout>:setting Step LR 0.015999999642372132
[1,0]<stdout>:0.16 0.1 1 [8, 11] 8
[1,0]<stdout>:Starting new loop for GPU: 0
[1,32]<stdout>:Rank 16 broadcasting
[1,34]<stdout>:Rank 18 broadcasting
[1,82]<stdout>:Rank 42 broadcasting
[1,39]<stdout>:Rank 23 broadcasting
[1,84]<stdout>:Rank 44 broadcasting
[1,37]<stdout>:Rank 21 broadcasting
[1,86]<stdout>:Rank 46 broadcasting
[1,38]<stdout>:Rank 22 broadcasting
[1,80]<stdout>:Rank 40 broadcasting
[1,35]<stdout>:Rank 19 broadcasting
[1,0]<stdout>:Rank 0 broadcasting
[1,119]<stdout>:Rank 63 broadcasting
[1,50]<stdout>:Rank 26 broadcasting
[1,33]<stdout>:Rank 17 broadcasting
[1,2]<stdout>:Rank 2 broadcasting
[1,117]<stdout>:Rank 61 broadcasting
[1,54]<stdout>:Rank 30 broadcasting
[1,36]<stdout>:Rank 20 broadcasting
[1,81]<stdout>:Rank 41 broadcasting
[1,4]<stdout>:Rank 4 broadcasting
[1,98]<stdout>:Rank 50 broadcasting
[1,118]<stdout>:Rank 62 broadcasting
[1,53]<stdout>:Rank 29 broadcasting
[1,6]<stdout>:Rank 6 broadcasting
[1,116]<stdout>:Rank 60 broadcasting
[1,52]<stdout>:Rank 28 broadcasting
[1,49]<stdout>:Rank 25 broadcasting
[1,66]<stdout>:Rank 34 broadcasting
[1,55]<stdout>:Rank 31 broadcasting
[1,20]<stdout>:Rank 12 broadcasting
[1,85]<stdout>:Rank 45 broadcasting
[1,19]<stdout>:Rank 11 broadcasting
[1,18]<stdout>:Rank 10 broadcasting
[1,101]<stdout>:Rank 53 broadcasting
[1,68]<stdout>:Rank 36 broadcasting
[1,22]<stdout>:Rank 14 broadcasting
[1,103]<stdout>:Rank 55 broadcasting
[1,17]<stdout>:Rank 9 broadcasting
[1,97]<stdout>:Rank 49 broadcasting
[1,69]<stdout>:Rank 37 broadcasting
[1,23]<stdout>:Rank 15 broadcasting
[1,102]<stdout>:Rank 54 broadcasting
[1,71]<stdout>:Rank 39 broadcasting
[1,16]<stdout>:Rank 8 broadcasting
[1,100]<stdout>:Rank 52 broadcasting
[1,64]<stdout>:Rank 32 broadcasting
[1,87]<stdout>:Rank 47 broadcasting
[1,3]<stdout>:Rank 3 broadcasting
[1,48]<stdout>:Rank 24 broadcasting
[1,1]<stdout>:Rank 1 broadcasting
[1,51]<stdout>:Rank 27 broadcasting
[1,113]<stdout>:Rank 57 broadcasting
[1,5]<stdout>:Rank 5 broadcasting
[1,83]<stdout>:Rank 43 broadcasting
[1,21]<stdout>:Rank 13 broadcasting
[1,70]<stdout>:Rank 38 broadcasting
[1,7]<stdout>:Rank 7 broadcasting
[1,96]<stdout>:Rank 48 broadcasting
[1,99]<stdout>:Rank 51 broadcasting
[1,114]<stdout>:Rank 58 broadcasting
[1,65]<stdout>:Rank 33 broadcasting
[1,67]<stdout>:Rank 35 broadcasting
[1,115]<stdout>:Rank 59 broadcasting
[1,112]<stdout>:Rank 56 broadcasting
[1,0]<stdout>:Variable broadcast done.
[1,6]<stdout>:Variable broadcast done.
[1,5]<stdout>:Variable broadcast done.
[1,16]<stdout>:Variable broadcast done.
[1,19]<stdout>:Variable broadcast done.
[1,18]<stdout>:Variable broadcast done.
[1,21]<stdout>:Variable broadcast done.
[1,22]<stdout>:Variable broadcast done.
[1,17]<stdout>:Variable broadcast done.
[1,23]<stdout>:Variable broadcast done.
[1,20]<stdout>:Variable broadcast done.
[1,32]<stdout>:Variable broadcast done.
[1,39]<stdout>:Variable broadcast done.
[1,50]<stdout>:Variable broadcast done.
[1,37]<stdout>:Variable broadcast done.
[1,54]<stdout>:Variable broadcast done.
[1,38]<stdout>:Variable broadcast done.
[1,48]<stdout>:Variable broadcast done.
[1,35]<stdout>:Variable broadcast done.
[1,49]<stdout>:Variable broadcast done.
[1,34]<stdout>:Variable broadcast done.
[1,70]<stdout>:Variable broadcast done.
[1,55]<stdout>:Variable broadcast done.
[1,33]<stdout>:Variable broadcast done.
[1,80]<stdout>:Variable broadcast done.
[1,71]<stdout>:Variable broadcast done.
[1,51]<stdout>:Variable broadcast done.
[1,36]<stdout>:Variable broadcast done.
[1,66]<stdout>:Variable broadcast done.
[1,53]<stdout>:Variable broadcast done.
[1,82]<stdout>:Variable broadcast done.
[1,64]<stdout>:Variable broadcast done.
[1,52]<stdout>:Variable broadcast done.
[1,83]<stdout>:Variable broadcast done.
[1,67]<stdout>:Variable broadcast done.
[1,85]<stdout>:Variable broadcast done.
[1,65]<stdout>:Variable broadcast done.
[1,68]<stdout>:Variable broadcast done.
[1,69]<stdout>:Variable broadcast done.
[1,86]<stdout>:Variable broadcast done.
[1,81]<stdout>:Variable broadcast done.
[1,87]<stdout>:Variable broadcast done.
[1,84]<stdout>:Variable broadcast done.
[1,2]<stdout>:Variable broadcast done.
[1,103]<stdout>:Variable broadcast done.
[1,4]<stdout>:Variable broadcast done.
[1,98]<stdout>:Variable broadcast done.
[1,118]<stdout>:Variable broadcast done.
[1,3]<stdout>:Variable broadcast done.
[1,101]<stdout>:Variable broadcast done.
[1,114]<stdout>:Variable broadcast done.
[1,7]<stdout>:Variable broadcast done.
[1,97]<stdout>:Variable broadcast done.
[1,116]<stdout>:Variable broadcast done.
[1,1]<stdout>:Variable broadcast done.
[1,102]<stdout>:Variable broadcast done.
[1,112]<stdout>:Variable broadcast done.
[1,99]<stdout>:Variable broadcast done.
[1,119]<stdout>:Variable broadcast done.
[1,96]<stdout>:Variable broadcast done.
[1,115]<stdout>:Variable broadcast done.
[1,100]<stdout>:Variable broadcast done.
[1,117]<stdout>:Variable broadcast done.
[1,113]<stdout>:Variable broadcast done.
[1,0]<stderr>:2020-09-18 20:19:58,979 - INFO - Epoch [9][50/458]	lr: 0.01600, eta: 0:24:51, time: 0.932, data_time: 0.054, rpn_class_loss: 1.8498, rpn_bbox_loss: 8.8990, rcnn_class_loss: 28.3319, rcnn_bbox_loss: 9.9605, rcnn_mask_loss: 11.5888, reg_loss: 0.4283, loss: 61.0583, learning_rate: 0.0160
[1,0]<stderr>:2020-09-18 20:20:41,516 - INFO - Epoch [9][100/458]	lr: 0.01600, eta: 0:24:10, time: 0.851, data_time: 0.040, rpn_class_loss: 2.7702, rpn_bbox_loss: 11.8095, rcnn_class_loss: 29.8970, rcnn_bbox_loss: 10.7816, rcnn_mask_loss: 11.4661, reg_loss: 0.4283, loss: 67.1527, learning_rate: 0.0160
[1,0]<stderr>:2020-09-18 20:21:22,816 - INFO - Epoch [9][150/458]	lr: 0.01600, eta: 0:23:27, time: 0.826, data_time: 0.037, rpn_class_loss: 2.3147, rpn_bbox_loss: 10.1920, rcnn_class_loss: 29.1287, rcnn_bbox_loss: 10.1936, rcnn_mask_loss: 11.8839, reg_loss: 0.4283, loss: 64.1411, learning_rate: 0.0160
[1,0]<stderr>:2020-09-18 20:22:02,846 - INFO - Epoch [9][200/458]	lr: 0.01600, eta: 0:22:45, time: 0.801, data_time: 0.041, rpn_class_loss: 2.2621, rpn_bbox_loss: 9.8120, rcnn_class_loss: 29.6369, rcnn_bbox_loss: 10.5026, rcnn_mask_loss: 11.0857, reg_loss: 0.4283, loss: 63.7275, learning_rate: 0.0160
[1,0]<stderr>:2020-09-18 20:22:43,152 - INFO - Epoch [9][250/458]	lr: 0.01600, eta: 0:22:02, time: 0.806, data_time: 0.041, rpn_class_loss: 2.1583, rpn_bbox_loss: 9.3814, rcnn_class_loss: 27.3262, rcnn_bbox_loss: 9.7984, rcnn_mask_loss: 10.9996, reg_loss: 0.4283, loss: 60.0922, learning_rate: 0.0160
[1,0]<stderr>:2020-09-18 20:23:23,499 - INFO - Epoch [9][300/458]	lr: 0.01600, eta: 0:21:20, time: 0.807, data_time: 0.039, rpn_class_loss: 2.2713, rpn_bbox_loss: 10.1073, rcnn_class_loss: 29.4845, rcnn_bbox_loss: 10.5997, rcnn_mask_loss: 11.7635, reg_loss: 0.4283, loss: 64.6546, learning_rate: 0.0160
[1,0]<stderr>:2020-09-18 20:24:03,635 - INFO - Epoch [9][350/458]	lr: 0.01600, eta: 0:20:38, time: 0.803, data_time: 0.038, rpn_class_loss: 2.1486, rpn_bbox_loss: 9.4187, rcnn_class_loss: 28.5846, rcnn_bbox_loss: 10.1345, rcnn_mask_loss: 10.8696, reg_loss: 0.4283, loss: 61.5842, learning_rate: 0.0160
[1,0]<stderr>:2020-09-18 20:24:43,808 - INFO - Epoch [9][400/458]	lr: 0.01600, eta: 0:19:55, time: 0.803, data_time: 0.037, rpn_class_loss: 1.9987, rpn_bbox_loss: 9.0169, rcnn_class_loss: 27.9564, rcnn_bbox_loss: 10.2406, rcnn_mask_loss: 11.6770, reg_loss: 0.4283, loss: 61.3179, learning_rate: 0.0160
[1,0]<stderr>:2020-09-18 20:25:24,048 - INFO - Epoch [9][450/458]	lr: 0.01600, eta: 0:19:13, time: 0.805, data_time: 0.041, rpn_class_loss: 2.4047, rpn_bbox_loss: 10.8429, rcnn_class_loss: 29.5467, rcnn_bbox_loss: 10.6697, rcnn_mask_loss: 11.4479, reg_loss: 0.4283, loss: 65.3402, learning_rate: 0.0160
[1,23]<stdout>:setting Step LR 0.015999999642372132
[1,23]<stdout>:0.16 0.1 1 [8, 11] 9
[1,1]<stdout>:setting Step LR 0.015999999642372132
[1,1]<stdout>:0.16 0.1 1 [8, 11] 9
[1,81]<stdout>:setting Step LR 0.015999999642372132
[1,81]<stdout>:0.16 0.1 1 [8, 11] 9
[1,33]<stdout>:setting Step LR 0.015999999642372132
[1,33]<stdout>:0.16 0.1 1 [8, 11] 9
[1,97]<stdout>:setting Step LR 0.015999999642372132
[1,97]<stdout>:0.16 0.1 1 [8, 11] 9
[1,37]<stdout>:setting Step LR 0.015999999642372132
[1,37]<stdout>:0.16 0.1 1 [8, 11] 9
[1,48]<stdout>:setting Step LR 0.015999999642372132
[1,48]<stdout>:0.16 0.1 1 [8, 11] 9
[1,6]<stdout>:setting Step LR 0.015999999642372132
[1,6]<stdout>:0.16 0.1 1 [8, 11] 9
[1,70]<stdout>:setting Step LR 0.015999999642372132
[1,70]<stdout>:0.16 0.1 1 [8, 11] 9
[1,38]<stdout>:setting Step LR 0.015999999642372132
[1,38]<stdout>:0.16 0.1 1 [8, 11] 9
[1,112]<stdout>:setting Step LR 0.015999999642372132
[1,112]<stdout>:0.16 0.1 1 [8, 11] 9
[1,55]<stdout>:setting Step LR 0.015999999642372132
[1,55]<stdout>:0.16 0.1 1 [8, 11] 9
[1,65]<stdout>:setting Step LR 0.015999999642372132
[1,65]<stdout>:0.16 0.1 1 [8, 11] 9
[1,23]<stdout>:Starting new loop for GPU: 15
[1,49]<stdout>:setting Step LR 0.015999999642372132
[1,49]<stdout>:0.16 0.1 1 [8, 11] 9
[1,3]<stdout>:setting Step LR 0.015999999642372132
[1,3]<stdout>:0.16 0.1 1 [8, 11] 9
[1,71]<stdout>:setting Step LR 0.015999999642372132
[1,71]<stdout>:0.16 0.1 1 [8, 11] 9
[1,52]<stdout>:setting Step LR 0.015999999642372132
[1,52]<stdout>:0.16 0.1 1 [8, 11] 9
[1,102]<stdout>:setting Step LR 0.015999999642372132
[1,102]<stdout>:0.16 0.1 1 [8, 11] 9
[1,35]<stdout>:setting Step LR 0.015999999642372132
[1,35]<stdout>:0.16 0.1 1 [8, 11] 9
[1,1]<stdout>:Starting new loop for GPU: 1
[1,36]<stdout>:setting Step LR 0.015999999642372132
[1,36]<stdout>:0.16 0.1 1 [8, 11] 9
[1,96]<stdout>:setting Step LR 0.015999999642372132
[1,96]<stdout>:0.16 0.1 1 [8, 11] 9
[1,7]<stdout>:setting Step LR 0.015999999642372132
[1,7]<stdout>:0.16 0.1 1 [8, 11] 9
[1,83]<stdout>:setting Step LR 0.015999999642372132
[1,83]<stdout>:0.16 0.1 1 [8, 11] 9
[1,85]<stdout>:setting Step LR 0.015999999642372132
[1,85]<stdout>:0.16 0.1 1 [8, 11] 9
[1,113]<stdout>:setting Step LR 0.015999999642372132
[1,113]<stdout>:0.16 0.1 1 [8, 11] 9
[1,81]<stdout>:Starting new loop for GPU: 41
[1,118]<stdout>:setting Step LR 0.015999999642372132
[1,118]<stdout>:0.16 0.1 1 [8, 11] 9
[1,22]<stdout>:setting Step LR 0.015999999642372132
[1,22]<stdout>:0.16 0.1 1 [8, 11] 9
[1,86]<stdout>:setting Step LR 0.015999999642372132
[1,86]<stdout>:0.16 0.1 1 [8, 11] 9
[1,33]<stdout>:Starting new loop for GPU: 17
[1,100]<stdout>:setting Step LR 0.015999999642372132
[1,100]<stdout>:0.16 0.1 1 [8, 11] 9
[1,32]<stdout>:setting Step LR 0.015999999642372132
[1,32]<stdout>:0.16 0.1 1 [8, 11] 9
[1,87]<stdout>:setting Step LR 0.015999999642372132
[1,87]<stdout>:0.16 0.1 1 [8, 11] 9
[1,98]<stdout>:setting Step LR 0.015999999642372132
[1,98]<stdout>:0.16 0.1 1 [8, 11] 9
[1,53]<stdout>:setting Step LR 0.015999999642372132
[1,53]<stdout>:0.16 0.1 1 [8, 11] 9
[1,37]<stdout>:Starting new loop for GPU: 21
[1,97]<stdout>:Starting new loop for GPU: 49
[1,84]<stdout>:setting Step LR 0.015999999642372132
[1,84]<stdout>:0.16 0.1 1 [8, 11] 9
[1,6]<stdout>:Starting new loop for GPU: 6
[1,70]<stdout>:Starting new loop for GPU: 38
[1,48]<stdout>:Starting new loop for GPU: 24
[1,64]<stdout>:setting Step LR 0.015999999642372132
[1,64]<stdout>:0.16 0.1 1 [8, 11] 9
[1,38]<stdout>:Starting new loop for GPU: 22
[1,112]<stdout>:Starting new loop for GPU: 56
[1,65]<stdout>:Starting new loop for GPU: 33
[1,66]<stdout>:setting Step LR 0.015999999642372132
[1,66]<stdout>:0.16 0.1 1 [8, 11] 9
[1,55]<stdout>:Starting new loop for GPU: 31
[1,2]<stdout>:setting Step LR 0.015999999642372132
[1,2]<stdout>:0.16 0.1 1 [8, 11] 9
[1,101]<stdout>:setting Step LR 0.015999999642372132
[1,101]<stdout>:0.16 0.1 1 [8, 11] 9
[1,103]<stdout>:setting Step LR 0.015999999642372132
[1,103]<stdout>:0.16 0.1 1 [8, 11] 9
[1,16]<stdout>:setting Step LR 0.015999999642372132
[1,16]<stdout>:0.16 0.1 1 [8, 11] 9
[1,5]<stdout>:setting Step LR 0.015999999642372132
[1,5]<stdout>:0.16 0.1 1 [8, 11] 9
[1,17]<stdout>:setting Step LR 0.015999999642372132
[1,17]<stdout>:0.16 0.1 1 [8, 11] 9
[1,18]<stdout>:setting Step LR 0.015999999642372132
[1,18]<stdout>:0.16 0.1 1 [8, 11] 9
[1,68]<stdout>:setting Step LR 0.015999999642372132
[1,68]<stdout>:0.16 0.1 1 [8, 11] 9
[1,49]<stdout>:Starting new loop for GPU: 25
[1,119]<stdout>:setting Step LR 0.015999999642372132
[1,119]<stdout>:0.16 0.1 1 [8, 11] 9
[1,71]<stdout>:Starting new loop for GPU: 39
[1,102]<stdout>:Starting new loop for GPU: 54
[1,52]<stdout>:Starting new loop for GPU: 28
[1,69]<stdout>:setting Step LR 0.015999999642372132
[1,69]<stdout>:0.16 0.1 1 [8, 11] 9
[1,21]<stdout>:setting Step LR 0.015999999642372132
[1,21]<stdout>:0.16 0.1 1 [8, 11] 9
[1,51]<stdout>:setting Step LR 0.015999999642372132
[1,51]<stdout>:0.16 0.1 1 [8, 11] 9
[1,3]<stdout>:Starting new loop for GPU: 3
[1,96]<stdout>:Starting new loop for GPU: 48
[1,82]<stdout>:setting Step LR 0.015999999642372132
[1,82]<stdout>:0.16 0.1 1 [8, 11] 9
[1,7]<stdout>:Starting new loop for GPU: 7
[1,36]<stdout>:Starting new loop for GPU: 20
[1,99]<stdout>:setting Step LR 0.015999999642372132
[1,99]<stdout>:0.16 0.1 1 [8, 11] 9
[1,35]<stdout>:Starting new loop for GPU: 19
[1,22]<stdout>:Starting new loop for GPU: 14
[1,113]<stdout>:Starting new loop for GPU: 57
[1,100]<stdout>:Starting new loop for GPU: 52
[1,118]<stdout>:Starting new loop for GPU: 62
[1,98]<stdout>:Starting new loop for GPU: 50
[1,115]<stdout>:setting Step LR 0.015999999642372132
[1,115]<stdout>:0.16 0.1 1 [8, 11] 9
[1,86]<stdout>:Starting new loop for GPU: 46
[1,32]<stdout>:Starting new loop for GPU: 16
[1,53]<stdout>:Starting new loop for GPU: 29
[1,85]<stdout>:Starting new loop for GPU: 45
[1,54]<stdout>:setting Step LR 0.015999999642372132
[1,54]<stdout>:0.16 0.1 1 [8, 11] 9
[1,84]<stdout>:Starting new loop for GPU: 44
[1,83]<stdout>:Starting new loop for GPU: 43
[1,64]<stdout>:Starting new loop for GPU: 32
[1,87]<stdout>:Starting new loop for GPU: 47
[1,19]<stdout>:setting Step LR 0.015999999642372132
[1,19]<stdout>:0.16 0.1 1 [8, 11] 9
[1,66]<stdout>:Starting new loop for GPU: 34
[1,16]<stdout>:Starting new loop for GPU: 8
[1,101]<stdout>:Starting new loop for GPU: 53
[1,116]<stdout>:setting Step LR 0.015999999642372132
[1,116]<stdout>:0.16 0.1 1 [8, 11] 9
[1,20]<stdout>:setting Step LR 0.015999999642372132
[1,20]<stdout>:0.16 0.1 1 [8, 11] 9
[1,103]<stdout>:Starting new loop for GPU: 55
[1,2]<stdout>:Starting new loop for GPU: 2
[1,117]<stdout>:setting Step LR 0.015999999642372132
[1,117]<stdout>:0.16 0.1 1 [8, 11] 9
[1,119]<stdout>:Starting new loop for GPU: 63
[1,18]<stdout>:Starting new loop for GPU: 10
[1,114]<stdout>:setting Step LR 0.015999999642372132
[1,114]<stdout>:0.16 0.1 1 [8, 11] 9
[1,5]<stdout>:Starting new loop for GPU: 5
[1,34]<stdout>:setting Step LR 0.015999999642372132
[1,34]<stdout>:0.16 0.1 1 [8, 11] 9
[1,68]<stdout>:Starting new loop for GPU: 36
[1,39]<stdout>:setting Step LR 0.015999999642372132
[1,39]<stdout>:0.16 0.1 1 [8, 11] 9
[1,99]<stdout>:Starting new loop for GPU: 51
[1,21]<stdout>:Starting new loop for GPU: 13
[1,17]<stdout>:Starting new loop for GPU: 9
[1,82]<stdout>:Starting new loop for GPU: 42
[1,69]<stdout>:Starting new loop for GPU: 37
[1,51]<stdout>:Starting new loop for GPU: 27
[1,115]<stdout>:Starting new loop for GPU: 59
[1,67]<stdout>:setting Step LR 0.015999999642372132
[1,67]<stdout>:0.16 0.1 1 [8, 11] 9
[1,19]<stdout>:Starting new loop for GPU: 11
[1,54]<stdout>:Starting new loop for GPU: 30
[1,80]<stdout>:setting Step LR 0.015999999642372132
[1,80]<stdout>:0.16 0.1 1 [8, 11] 9
[1,117]<stdout>:Starting new loop for GPU: 61
[1,116]<stdout>:Starting new loop for GPU: 60
[1,20]<stdout>:Starting new loop for GPU: 12
[1,114]<stdout>:Starting new loop for GPU: 58
[1,34]<stdout>:Starting new loop for GPU: 18
[1,4]<stdout>:setting Step LR 0.015999999642372132
[1,4]<stdout>:0.16 0.1 1 [8, 11] 9
[1,39]<stdout>:Starting new loop for GPU: 23
[1,67]<stdout>:Starting new loop for GPU: 35
[1,80]<stdout>:Starting new loop for GPU: 40
[1,4]<stdout>:Starting new loop for GPU: 4
[1,50]<stdout>:setting Step LR 0.015999999642372132
[1,50]<stdout>:0.16 0.1 1 [8, 11] 9
[1,50]<stdout>:Starting new loop for GPU: 26
[1,0]<stderr>:2020-09-18 20:25:31,432 - INFO - Saved checkpoint at: /shared/deep-learning-models/models/vision/detection/work_dirs/mask_rcnn_r50v1_d_fpn_1x_coco/008/faster_rcnn
[1,0]<stdout>:setting Step LR 0.015999999642372132
[1,0]<stdout>:0.16 0.1 1 [8, 11] 9
[1,0]<stdout>:Starting new loop for GPU: 0
[1,3]<stdout>:Rank 3 broadcasting
[1,7]<stdout>:Rank 7 broadcasting
[1,5]<stdout>:Rank 5 broadcasting
[1,0]<stdout>:Rank 0 broadcasting
[1,2]<stdout>:Rank 2 broadcasting
[1,4]<stdout>:Rank 4 broadcasting
[1,82]<stdout>:Rank 42 broadcasting
[1,86]<stdout>:Rank 46 broadcasting
[1,84]<stdout>:Rank 44 broadcasting
[1,100]<stdout>:Rank 52 broadcasting
[1,103]<stdout>:Rank 55 broadcasting
[1,96]<stdout>:Rank 48 broadcasting
[1,6]<stdout>:Rank 6 broadcasting
[1,99]<stdout>:Rank 51 broadcasting
[1,113]<stdout>:Rank 57 broadcasting
[1,119]<stdout>:Rank 63 broadcasting
[1,85]<stdout>:Rank 45 broadcasting
[1,114]<stdout>:Rank 58 broadcasting
[1,55]<stdout>:Rank 31 broadcasting
[1,116]<stdout>:Rank 60 broadcasting
[1,69]<stdout>:Rank 37 broadcasting
[1,117]<stdout>:Rank 61 broadcasting
[1,115]<stdout>:Rank 59 broadcasting
[1,32]<stdout>:Rank 16 broadcasting
[1,53]<stdout>:Rank 29 broadcasting
[1,37]<stdout>:Rank 21 broadcasting
[1,21]<stdout>:Rank 13 broadcasting
[1,50]<stdout>:Rank 26 broadcasting
[1,39]<stdout>:Rank 23 broadcasting
[1,18]<stdout>:Rank 10 broadcasting
[1,54]<stdout>:Rank 30 broadcasting
[1,34]<stdout>:Rank 18 broadcasting
[1,23]<stdout>:Rank 15 broadcasting
[1,51]<stdout>:Rank 27 broadcasting
[1,36]<stdout>:Rank 20 broadcasting
[1,65]<stdout>:Rank 33 broadcasting
[1,33]<stdout>:Rank 17 broadcasting
[1,20]<stdout>:Rank 12 broadcasting
[1,35]<stdout>:Rank 19 broadcasting
[1,49]<stdout>:Rank 25 broadcasting
[1,38]<stdout>:Rank 22 broadcasting
[1,22]<stdout>:Rank 14 broadcasting
[1,67]<stdout>:Rank 35 broadcasting
[1,64]<stdout>:Rank 32 broadcasting
[1,70]<stdout>:Rank 38 broadcasting
[1,71]<stdout>:Rank 39 broadcasting
[1,66]<stdout>:Rank 34 broadcasting
[1,48]<stdout>:Rank 24 broadcasting
[1,101]<stdout>:Rank 53 broadcasting
[1,68]<stdout>:Rank 36 broadcasting
[1,80]<stdout>:Rank 40 broadcasting
[1,98]<stdout>:Rank 50 broadcasting
[1,97]<stdout>:Rank 49 broadcasting
[1,81]<stdout>:Rank 41 broadcasting
[1,102]<stdout>:Rank 54 broadcasting
[1,83]<stdout>:Rank 43 broadcasting
[1,1]<stdout>:Rank 1 broadcasting
[1,118]<stdout>:Rank 62 broadcasting
[1,112]<stdout>:Rank 56 broadcasting
[1,52]<stdout>:Rank 28 broadcasting
[1,87]<stdout>:Rank 47 broadcasting
[1,19]<stdout>:Rank 11 broadcasting
[1,17]<stdout>:Rank 9 broadcasting
[1,16]<stdout>:Rank 8 broadcasting
[1,0]<stdout>:Variable broadcast done.
[1,6]<stdout>:Variable broadcast done.
[1,5]<stdout>:Variable broadcast done.
[1,19]<stdout>:Variable broadcast done.
[1,18]<stdout>:Variable broadcast done.
[1,17]<stdout>:Variable broadcast done.
[1,16]<stdout>:Variable broadcast done.
[1,22]<stdout>:Variable broadcast done.
[1,21]<stdout>:Variable broadcast done.
[1,23]<stdout>:Variable broadcast done.
[1,20]<stdout>:Variable broadcast done.
[1,39]<stdout>:Variable broadcast done.
[1,35]<stdout>:Variable broadcast done.
[1,33]<stdout>:Variable broadcast done.
[1,55]<stdout>:Variable broadcast done.
[1,34]<stdout>:Variable broadcast done.
[1,53]<stdout>:Variable broadcast done.
[1,37]<stdout>:Variable broadcast done.
[1,49]<stdout>:Variable broadcast done.
[1,32]<stdout>:Variable broadcast done.
[1,54]<stdout>:Variable broadcast done.
[1,38]<stdout>:Variable broadcast done.
[1,64]<stdout>:Variable broadcast done.
[1,50]<stdout>:Variable broadcast done.
[1,36]<stdout>:Variable broadcast done.
[1,80]<stdout>:Variable broadcast done.
[1,68]<stdout>:Variable broadcast done.
[1,48]<stdout>:Variable broadcast done.
[1,65]<stdout>:Variable broadcast done.
[1,51]<stdout>:Variable broadcast done.
[1,71]<stdout>:Variable broadcast done.
[1,52]<stdout>:Variable broadcast done.
[1,67]<stdout>:Variable broadcast done.
[1,70]<stdout>:Variable broadcast done.
[1,82]<stdout>:Variable broadcast done.
[1,66]<stdout>:Variable broadcast done.
[1,69]<stdout>:Variable broadcast done.
[1,86]<stdout>:Variable broadcast done.
[1,85]<stdout>:Variable broadcast done.
[1,81]<stdout>:Variable broadcast done.
[1,83]<stdout>:Variable broadcast done.
[1,4]<stdout>:Variable broadcast done.
[1,96]<stdout>:Variable broadcast done.
[1,84]<stdout>:Variable broadcast done.
[1,2]<stdout>:Variable broadcast done.
[1,87]<stdout>:Variable broadcast done.
[1,7]<stdout>:Variable broadcast done.
[1,100]<stdout>:Variable broadcast done.
[1,3]<stdout>:Variable broadcast done.
[1,98]<stdout>:Variable broadcast done.
[1,1]<stdout>:Variable broadcast done.
[1,102]<stdout>:Variable broadcast done.
[1,101]<stdout>:Variable broadcast done.
[1,118]<stdout>:Variable broadcast done.
[1,99]<stdout>:Variable broadcast done.
[1,103]<stdout>:Variable broadcast done.
[1,97]<stdout>:Variable broadcast done.
[1,113]<stdout>:Variable broadcast done.
[1,112]<stdout>:Variable broadcast done.
[1,119]<stdout>:Variable broadcast done.
[1,115]<stdout>:Variable broadcast done.
[1,114]<stdout>:Variable broadcast done.
[1,116]<stdout>:Variable broadcast done.
[1,117]<stdout>:Variable broadcast done.
[1,0]<stderr>:2020-09-18 20:26:18,421 - INFO - Epoch [10][50/458]	lr: 0.01600, eta: 0:18:24, time: 0.939, data_time: 0.062, rpn_class_loss: 2.0830, rpn_bbox_loss: 9.3623, rcnn_class_loss: 29.5147, rcnn_bbox_loss: 10.3346, rcnn_mask_loss: 11.6714, reg_loss: 0.4283, loss: 63.3943, learning_rate: 0.0160
[1,0]<stderr>:2020-09-18 20:27:00,422 - INFO - Epoch [10][100/458]	lr: 0.01600, eta: 0:17:42, time: 0.840, data_time: 0.037, rpn_class_loss: 2.3271, rpn_bbox_loss: 10.8513, rcnn_class_loss: 30.4419, rcnn_bbox_loss: 11.0003, rcnn_mask_loss: 11.4118, reg_loss: 0.4283, loss: 66.4606, learning_rate: 0.0160
[1,0]<stderr>:2020-09-18 20:27:40,744 - INFO - Epoch [10][150/458]	lr: 0.01600, eta: 0:17:00, time: 0.806, data_time: 0.037, rpn_class_loss: 2.1719, rpn_bbox_loss: 9.8484, rcnn_class_loss: 27.9963, rcnn_bbox_loss: 9.9603, rcnn_mask_loss: 11.3635, reg_loss: 0.4283, loss: 61.7686, learning_rate: 0.0160
[1,0]<stderr>:2020-09-18 20:28:21,346 - INFO - Epoch [10][200/458]	lr: 0.01600, eta: 0:16:18, time: 0.812, data_time: 0.035, rpn_class_loss: 2.1818, rpn_bbox_loss: 9.7216, rcnn_class_loss: 30.6256, rcnn_bbox_loss: 10.6580, rcnn_mask_loss: 11.1942, reg_loss: 0.4283, loss: 64.8094, learning_rate: 0.0160
[1,0]<stderr>:2020-09-18 20:29:01,439 - INFO - Epoch [10][250/458]	lr: 0.01600, eta: 0:15:36, time: 0.802, data_time: 0.037, rpn_class_loss: 1.9753, rpn_bbox_loss: 8.8135, rcnn_class_loss: 29.7809, rcnn_bbox_loss: 10.3981, rcnn_mask_loss: 12.1270, reg_loss: 0.4283, loss: 63.5232, learning_rate: 0.0160
[1,0]<stderr>:2020-09-18 20:29:41,405 - INFO - Epoch [10][300/458]	lr: 0.01600, eta: 0:14:54, time: 0.799, data_time: 0.039, rpn_class_loss: 2.3398, rpn_bbox_loss: 10.4119, rcnn_class_loss: 30.7552, rcnn_bbox_loss: 10.9054, rcnn_mask_loss: 11.0366, reg_loss: 0.4283, loss: 65.8773, learning_rate: 0.0160
[1,0]<stderr>:2020-09-18 20:30:22,175 - INFO - Epoch [10][350/458]	lr: 0.01600, eta: 0:14:12, time: 0.816, data_time: 0.043, rpn_class_loss: 2.5623, rpn_bbox_loss: 11.0335, rcnn_class_loss: 31.1088, rcnn_bbox_loss: 11.2903, rcnn_mask_loss: 11.0904, reg_loss: 0.4283, loss: 67.5136, learning_rate: 0.0160
[1,0]<stderr>:2020-09-18 20:31:02,263 - INFO - Epoch [10][400/458]	lr: 0.01600, eta: 0:13:30, time: 0.802, data_time: 0.039, rpn_class_loss: 2.3059, rpn_bbox_loss: 10.0670, rcnn_class_loss: 27.7464, rcnn_bbox_loss: 9.8674, rcnn_mask_loss: 11.2144, reg_loss: 0.4283, loss: 61.6294, learning_rate: 0.0160
[1,0]<stderr>:2020-09-18 20:31:42,554 - INFO - Epoch [10][450/458]	lr: 0.01600, eta: 0:12:48, time: 0.806, data_time: 0.039, rpn_class_loss: 2.4130, rpn_bbox_loss: 10.3685, rcnn_class_loss: 26.7765, rcnn_bbox_loss: 9.8816, rcnn_mask_loss: 11.3931, reg_loss: 0.4283, loss: 61.2610, learning_rate: 0.0160
[1,65]<stdout>:setting Step LR 0.015999999642372132
[1,65]<stdout>:0.16 0.1 1 [8, 11] 10
[1,97]<stdout>:setting Step LR 0.015999999642372132
[1,97]<stdout>:0.16 0.1 1 [8, 11] 10
[1,66]<stdout>:setting Step LR 0.015999999642372132
[1,66]<stdout>:0.16 0.1 1 [8, 11] 10
[1,86]<stdout>:setting Step LR 0.015999999642372132
[1,86]<stdout>:0.16 0.1 1 [8, 11] 10
[1,118]<stdout>:setting Step LR 0.015999999642372132
[1,118]<stdout>:0.16 0.1 1 [8, 11] 10
[1,55]<stdout>:setting Step LR 0.015999999642372132
[1,55]<stdout>:0.16 0.1 1 [8, 11] 10
[1,113]<stdout>:setting Step LR 0.015999999642372132
[1,113]<stdout>:0.16 0.1 1 [8, 11] 10
[1,70]<stdout>:setting Step LR 0.015999999642372132
[1,70]<stdout>:0.16 0.1 1 [8, 11] 10
[1,83]<stdout>:setting Step LR 0.015999999642372132
[1,83]<stdout>:0.16 0.1 1 [8, 11] 10
[1,53]<stdout>:setting Step LR 0.015999999642372132
[1,53]<stdout>:0.16 0.1 1 [8, 11] 10
[1,50]<stdout>:setting Step LR 0.015999999642372132
[1,50]<stdout>:0.16 0.1 1 [8, 11] 10
[1,33]<stdout>:setting Step LR 0.015999999642372132
[1,33]<stdout>:0.16 0.1 1 [8, 11] 10
[1,7]<stdout>:setting Step LR 0.015999999642372132
[1,7]<stdout>:0.16 0.1 1 [8, 11] 10
[1,5]<stdout>:setting Step LR 0.015999999642372132
[1,5]<stdout>:0.16 0.1 1 [8, 11] 10
[1,6]<stdout>:setting Step LR 0.015999999642372132
[1,6]<stdout>:0.16 0.1 1 [8, 11] 10
[1,103]<stdout>:setting Step LR 0.015999999642372132
[1,103]<stdout>:0.16 0.1 1 [8, 11] 10
[1,21]<stdout>:setting Step LR 0.015999999642372132
[1,21]<stdout>:0.16 0.1 1 [8, 11] 10
[1,98]<stdout>:setting Step LR 0.015999999642372132
[1,98]<stdout>:0.16 0.1 1 [8, 11] 10
[1,16]<stdout>:setting Step LR 0.015999999642372132
[1,16]<stdout>:0.16 0.1 1 [8, 11] 10
[1,82]<stdout>:setting Step LR 0.015999999642372132
[1,82]<stdout>:0.16 0.1 1 [8, 11] 10
[1,81]<stdout>:setting Step LR 0.015999999642372132
[1,81]<stdout>:0.16 0.1 1 [8, 11] 10
[1,23]<stdout>:setting Step LR 0.015999999642372132
[1,23]<stdout>:0.16 0.1 1 [8, 11] 10
[1,102]<stdout>:setting Step LR 0.015999999642372132
[1,102]<stdout>:0.16 0.1 1 [8, 11] 10
[1,32]<stdout>:setting Step LR 0.015999999642372132
[1,32]<stdout>:0.16 0.1 1 [8, 11] 10
[1,35]<stdout>:setting Step LR 0.015999999642372132
[1,35]<stdout>:0.16 0.1 1 [8, 11] 10
[1,65]<stdout>:Starting new loop for GPU: 33
[1,19]<stdout>:setting Step LR 0.015999999642372132
[1,19]<stdout>:0.16 0.1 1 [8, 11] 10
[1,66]<stdout>:Starting new loop for GPU: 34
[1,97]<stdout>:Starting new loop for GPU: 49
[1,4]<stdout>:setting Step LR 0.015999999642372132
[1,4]<stdout>:0.16 0.1 1 [8, 11] 10
[1,38]<stdout>:setting Step LR 0.015999999642372132
[1,38]<stdout>:0.16 0.1 1 [8, 11] 10
[1,85]<stdout>:setting Step LR 0.015999999642372132
[1,85]<stdout>:0.16 0.1 1 [8, 11] 10
[1,80]<stdout>:setting Step LR 0.015999999642372132
[1,80]<stdout>:0.16 0.1 1 [8, 11] 10
[1,116]<stdout>:setting Step LR 0.015999999642372132
[1,116]<stdout>:0.16 0.1 1 [8, 11] 10
[1,3]<stdout>:setting Step LR 0.015999999642372132
[1,3]<stdout>:0.16 0.1 1 [8, 11] 10
[1,52]<stdout>:setting Step LR 0.015999999642372132
[1,52]<stdout>:0.16 0.1 1 [8, 11] 10
[1,69]<stdout>:setting Step LR 0.015999999642372132
[1,69]<stdout>:0.16 0.1 1 [8, 11] 10
[1,36]<stdout>:setting Step LR 0.015999999642372132
[1,36]<stdout>:0.16 0.1 1 [8, 11] 10
[1,86]<stdout>:Starting new loop for GPU: 46
[1,67]<stdout>:setting Step LR 0.015999999642372132
[1,67]<stdout>:0.16 0.1 1 [8, 11] 10
[1,20]<stdout>:setting Step LR 0.015999999642372132
[1,20]<stdout>:0.16 0.1 1 [8, 11] 10
[1,48]<stdout>:setting Step LR 0.015999999642372132
[1,48]<stdout>:0.16 0.1 1 [8, 11] 10
[1,118]<stdout>:Starting new loop for GPU: 62
[1,114]<stdout>:setting Step LR 0.015999999642372132
[1,114]<stdout>:0.16 0.1 1 [8, 11] 10
[1,54]<stdout>:setting Step LR 0.015999999642372132
[1,54]<stdout>:0.16 0.1 1 [8, 11] 10
[1,22]<stdout>:setting Step LR 0.015999999642372132
[1,22]<stdout>:0.16 0.1 1 [8, 11] 10
[1,70]<stdout>:Starting new loop for GPU: 38
[1,113]<stdout>:Starting new loop for GPU: 57
[1,34]<stdout>:setting Step LR 0.015999999642372132
[1,34]<stdout>:0.16 0.1 1 [8, 11] 10
[1,55]<stdout>:Starting new loop for GPU: 31
[1,83]<stdout>:Starting new loop for GPU: 43
[1,112]<stdout>:setting Step LR 0.015999999642372132
[1,112]<stdout>:0.16 0.1 1 [8, 11] 10
[1,119]<stdout>:setting Step LR 0.015999999642372132
[1,119]<stdout>:0.16 0.1 1 [8, 11] 10
[1,33]<stdout>:Starting new loop for GPU: 17
[1,53]<stdout>:Starting new loop for GPU: 29
[1,7]<stdout>:Starting new loop for GPU: 7
[1,50]<stdout>:Starting new loop for GPU: 26
[1,51]<stdout>:setting Step LR 0.015999999642372132
[1,51]<stdout>:0.16 0.1 1 [8, 11] 10
[1,117]<stdout>:setting Step LR 0.015999999642372132
[1,117]<stdout>:0.16 0.1 1 [8, 11] 10
[1,17]<stdout>:setting Step LR 0.015999999642372132
[1,17]<stdout>:0.16 0.1 1 [8, 11] 10
[1,5]<stdout>:Starting new loop for GPU: 5
[1,21]<stdout>:Starting new loop for GPU: 13
[1,99]<stdout>:setting Step LR 0.015999999642372132
[1,99]<stdout>:0.16 0.1 1 [8, 11] 10
[1,103]<stdout>:Starting new loop for GPU: 55
[1,16]<stdout>:Starting new loop for GPU: 8
[1,6]<stdout>:Starting new loop for GPU: 6
[1,98]<stdout>:Starting new loop for GPU: 50
[1,102]<stdout>:Starting new loop for GPU: 54
[1,32]<stdout>:Starting new loop for GPU: 16
[1,23]<stdout>:Starting new loop for GPU: 15
[1,71]<stdout>:setting Step LR 0.015999999642372132
[1,71]<stdout>:0.16 0.1 1 [8, 11] 10
[1,19]<stdout>:Starting new loop for GPU: 11
[1,82]<stdout>:Starting new loop for GPU: 42
[1,81]<stdout>:Starting new loop for GPU: 41
[1,35]<stdout>:Starting new loop for GPU: 19
[1,96]<stdout>:setting Step LR 0.015999999642372132
[1,96]<stdout>:0.16 0.1 1 [8, 11] 10
[1,4]<stdout>:Starting new loop for GPU: 4
[1,38]<stdout>:Starting new loop for GPU: 22
[1,85]<stdout>:Starting new loop for GPU: 45
[1,101]<stdout>:setting Step LR 0.015999999642372132
[1,101]<stdout>:0.16 0.1 1 [8, 11] 10
[1,116]<stdout>:Starting new loop for GPU: 60
[1,3]<stdout>:Starting new loop for GPU: 3
[1,115]<stdout>:setting Step LR 0.015999999642372132
[1,115]<stdout>:0.16 0.1 1 [8, 11] 10
[1,52]<stdout>:Starting new loop for GPU: 28
[1,36]<stdout>:Starting new loop for GPU: 20
[1,80]<stdout>:Starting new loop for GPU: 40
[1,37]<stdout>:setting Step LR 0.015999999642372132
[1,37]<stdout>:0.16 0.1 1 [8, 11] 10
[1,49]<stdout>:setting Step LR 0.015999999642372132
[1,49]<stdout>:0.16 0.1 1 [8, 11] 10
[1,48]<stdout>:Starting new loop for GPU: 24
[1,1]<stdout>:setting Step LR 0.015999999642372132
[1,1]<stdout>:0.16 0.1 1 [8, 11] 10
[1,34]<stdout>:Starting new loop for GPU: 18
[1,67]<stdout>:Starting new loop for GPU: 35
[1,87]<stdout>:setting Step LR 0.015999999642372132
[1,87]<stdout>:0.16 0.1 1 [8, 11] 10
[1,69]<stdout>:Starting new loop for GPU: 37
[1,39]<stdout>:setting Step LR 0.015999999642372132
[1,39]<stdout>:0.16 0.1 1 [8, 11] 10
[1,114]<stdout>:Starting new loop for GPU: 58
[1,54]<stdout>:Starting new loop for GPU: 30
[1,20]<stdout>:Starting new loop for GPU: 12
[1,112]<stdout>:Starting new loop for GPU: 56
[1,68]<stdout>:setting Step LR 0.015999999642372132
[1,68]<stdout>:0.16 0.1 1 [8, 11] 10
[1,22]<stdout>:Starting new loop for GPU: 14
[1,84]<stdout>:setting Step LR 0.015999999642372132
[1,84]<stdout>:0.16 0.1 1 [8, 11] 10
[1,117]<stdout>:Starting new loop for GPU: 61
[1,119]<stdout>:Starting new loop for GPU: 63
[1,17]<stdout>:Starting new loop for GPU: 9
[1,71]<stdout>:Starting new loop for GPU: 39
[1,99]<stdout>:Starting new loop for GPU: 51
[1,51]<stdout>:Starting new loop for GPU: 27
[1,96]<stdout>:Starting new loop for GPU: 48
[1,64]<stdout>:setting Step LR 0.015999999642372132
[1,64]<stdout>:0.16 0.1 1 [8, 11] 10
[1,115]<stdout>:Starting new loop for GPU: 59
[1,37]<stdout>:Starting new loop for GPU: 21
[1,1]<stdout>:Starting new loop for GPU: 1
[1,101]<stdout>:Starting new loop for GPU: 53
[1,100]<stdout>:setting Step LR 0.015999999642372132
[1,100]<stdout>:0.16 0.1 1 [8, 11] 10
[1,39]<stdout>:Starting new loop for GPU: 23
[1,68]<stdout>:Starting new loop for GPU: 36
[1,49]<stdout>:Starting new loop for GPU: 25
[1,84]<stdout>:Starting new loop for GPU: 44
[1,87]<stdout>:Starting new loop for GPU: 47
[1,2]<stdout>:setting Step LR 0.015999999642372132
[1,2]<stdout>:0.16 0.1 1 [8, 11] 10
[1,64]<stdout>:Starting new loop for GPU: 32
[1,100]<stdout>:Starting new loop for GPU: 52
[1,2]<stdout>:Starting new loop for GPU: 2
[1,18]<stdout>:setting Step LR 0.015999999642372132
[1,18]<stdout>:0.16 0.1 1 [8, 11] 10
[1,18]<stdout>:Starting new loop for GPU: 10
[1,0]<stderr>:2020-09-18 20:31:50,330 - INFO - Saved checkpoint at: /shared/deep-learning-models/models/vision/detection/work_dirs/mask_rcnn_r50v1_d_fpn_1x_coco/009/faster_rcnn
[1,0]<stdout>:setting Step LR 0.015999999642372132
[1,0]<stdout>:0.16 0.1 1 [8, 11] 10
[1,0]<stdout>:Starting new loop for GPU: 0
[1,2]<stdout>:Rank 2 broadcasting
[1,4]<stdout>:Rank 4 broadcasting
[1,6]<stdout>:Rank 6 broadcasting
[1,5]<stdout>:Rank 5 broadcasting
[1,0]<stdout>:Rank 0 broadcasting
[1,39]<stdout>:Rank 23 broadcasting
[1,7]<stdout>:Rank 7 broadcasting
[1,16]<stdout>:Rank 8 broadcasting
[1,98]<stdout>:Rank 50 broadcasting
[1,38]<stdout>:Rank 22 broadcasting
[1,82]<stdout>:Rank 42 broadcasting
[1,3]<stdout>:Rank 3 broadcasting
[1,22]<stdout>:Rank 14 broadcasting
[1,96]<stdout>:Rank 48 broadcasting
[1,71]<stdout>:Rank 39 broadcasting
[1,114]<stdout>:Rank 58 broadcasting
[1,32]<stdout>:Rank 16 broadcasting
[1,87]<stdout>:Rank 47 broadcasting
[1,20]<stdout>:Rank 12 broadcasting
[1,102]<stdout>:Rank 54 broadcasting
[1,70]<stdout>:Rank 38 broadcasting
[1,117]<stdout>:Rank 61 broadcasting
[1,34]<stdout>:Rank 18 broadcasting
[1,81]<stdout>:Rank 41 broadcasting
[1,100]<stdout>:Rank 52 broadcasting
[1,67]<stdout>:Rank 35 broadcasting
[1,118]<stdout>:Rank 62 broadcasting
[1,50]<stdout>:Rank 26 broadcasting
[1,35]<stdout>:Rank 19 broadcasting
[1,103]<stdout>:Rank 55 broadcasting
[1,68]<stdout>:Rank 36 broadcasting
[1,119]<stdout>:Rank 63 broadcasting
[1,48]<stdout>:Rank 24 broadcasting
[1,33]<stdout>:Rank 17 broadcasting
[1,101]<stdout>:Rank 53 broadcasting
[1,69]<stdout>:Rank 37 broadcasting
[1,113]<stdout>:Rank 57 broadcasting
[1,52]<stdout>:Rank 28 broadcasting
[1,36]<stdout>:Rank 20 broadcasting
[1,99]<stdout>:Rank 51 broadcasting
[1,66]<stdout>:Rank 34 broadcasting
[1,116]<stdout>:Rank 60 broadcasting
[1,54]<stdout>:Rank 30 broadcasting
[1,37]<stdout>:Rank 21 broadcasting
[1,97]<stdout>:Rank 49 broadcasting
[1,64]<stdout>:Rank 32 broadcasting
[1,112]<stdout>:Rank 56 broadcasting
[1,51]<stdout>:Rank 27 broadcasting
[1,49]<stdout>:Rank 25 broadcasting
[1,23]<stdout>:Rank 15 broadcasting
[1,21]<stdout>:Rank 13 broadcasting
[1,19]<stdout>:Rank 11 broadcasting
[1,18]<stdout>:Rank 10 broadcasting
[1,17]<stdout>:Rank 9 broadcasting
[1,85]<stdout>:Rank 45 broadcasting
[1,115]<stdout>:Rank 59 broadcasting
[1,83]<stdout>:Rank 43 broadcasting
[1,53]<stdout>:Rank 29 broadcasting
[1,65]<stdout>:Rank 33 broadcasting
[1,86]<stdout>:Rank 46 broadcasting
[1,84]<stdout>:Rank 44 broadcasting
[1,80]<stdout>:Rank 40 broadcasting
[1,55]<stdout>:Rank 31 broadcasting
[1,1]<stdout>:Rank 1 broadcasting
[1,0]<stdout>:Variable broadcast done.
[1,5]<stdout>:Variable broadcast done.
[1,6]<stdout>:Variable broadcast done.
[1,18]<stdout>:Variable broadcast done.
[1,19]<stdout>:Variable broadcast done.
[1,17]<stdout>:Variable broadcast done.
[1,16]<stdout>:Variable broadcast done.
[1,22]<stdout>:Variable broadcast done.
[1,21]<stdout>:Variable broadcast done.
[1,23]<stdout>:Variable broadcast done.
[1,20]<stdout>:Variable broadcast done.
[1,34]<stdout>:Variable broadcast done.
[1,39]<stdout>:Variable broadcast done.
[1,38]<stdout>:Variable broadcast done.
[1,32]<stdout>:Variable broadcast done.
[1,35]<stdout>:Variable broadcast done.
[1,33]<stdout>:Variable broadcast done.
[1,37]<stdout>:Variable broadcast done.
[1,36]<stdout>:Variable broadcast done.
[1,51]<stdout>:Variable broadcast done.
[1,49]<stdout>:Variable broadcast done.
[1,50]<stdout>:Variable broadcast done.
[1,48]<stdout>:Variable broadcast done.
[1,54]<stdout>:Variable broadcast done.
[1,53]<stdout>:Variable broadcast done.
[1,55]<stdout>:Variable broadcast done.
[1,70]<stdout>:Variable broadcast done.
[1,52]<stdout>:Variable broadcast done.
[1,86]<stdout>:Variable broadcast done.
[1,2]<stdout>:Variable broadcast done.
[1,64]<stdout>:Variable broadcast done.
[1,85]<stdout>:Variable broadcast done.
[1,4]<stdout>:Variable broadcast done.
[1,98]<stdout>:Variable broadcast done.
[1,67]<stdout>:Variable broadcast done.
[1,81]<stdout>:Variable broadcast done.
[1,3]<stdout>:Variable broadcast done.
[1,96]<stdout>:Variable broadcast done.
[1,65]<stdout>:Variable broadcast done.
[1,112]<stdout>:Variable broadcast done.
[1,87]<stdout>:Variable broadcast done.
[1,7]<stdout>:Variable broadcast done.
[1,103]<stdout>:Variable broadcast done.
[1,68]<stdout>:Variable broadcast done.
[1,115]<stdout>:Variable broadcast done.
[1,83]<stdout>:Variable broadcast done.
[1,101]<stdout>:Variable broadcast done.
[1,66]<stdout>:Variable broadcast done.
[1,119]<stdout>:Variable broadcast done.
[1,84]<stdout>:Variable broadcast done.
[1,97]<stdout>:Variable broadcast done.
[1,69]<stdout>:Variable broadcast done.
[1,116]<stdout>:Variable broadcast done.
[1,80]<stdout>:Variable broadcast done.
[1,100]<stdout>:Variable broadcast done.
[1,71]<stdout>:Variable broadcast done.
[1,117]<stdout>:Variable broadcast done.
[1,82]<stdout>:Variable broadcast done.
[1,99]<stdout>:Variable broadcast done.
[1,118]<stdout>:Variable broadcast done.
[1,102]<stdout>:Variable broadcast done.
[1,114]<stdout>:Variable broadcast done.
[1,113]<stdout>:Variable broadcast done.
[1,1]<stdout>:Variable broadcast done.
[1,0]<stderr>:2020-09-18 20:32:37,135 - INFO - Epoch [11][50/458]	lr: 0.01600, eta: 0:12:00, time: 0.935, data_time: 0.046, rpn_class_loss: 2.1266, rpn_bbox_loss: 9.1750, rcnn_class_loss: 28.1807, rcnn_bbox_loss: 9.9100, rcnn_mask_loss: 11.0927, reg_loss: 0.4283, loss: 60.9133, learning_rate: 0.0160
[1,0]<stderr>:2020-09-18 20:33:18,666 - INFO - Epoch [11][100/458]	lr: 0.01600, eta: 0:11:18, time: 0.831, data_time: 0.039, rpn_class_loss: 2.6240, rpn_bbox_loss: 11.6220, rcnn_class_loss: 33.2229, rcnn_bbox_loss: 11.5753, rcnn_mask_loss: 11.4671, reg_loss: 0.4283, loss: 70.9396, learning_rate: 0.0160
[1,0]<stderr>:2020-09-18 20:33:58,544 - INFO - Epoch [11][150/458]	lr: 0.01600, eta: 0:10:36, time: 0.798, data_time: 0.040, rpn_class_loss: 2.3691, rpn_bbox_loss: 10.4045, rcnn_class_loss: 30.2692, rcnn_bbox_loss: 10.6693, rcnn_mask_loss: 11.0945, reg_loss: 0.4283, loss: 65.2348, learning_rate: 0.0160
[1,0]<stderr>:2020-09-18 20:34:39,027 - INFO - Epoch [11][200/458]	lr: 0.01600, eta: 0:09:55, time: 0.810, data_time: 0.037, rpn_class_loss: 2.4359, rpn_bbox_loss: 10.4317, rcnn_class_loss: 30.9764, rcnn_bbox_loss: 11.1058, rcnn_mask_loss: 11.7938, reg_loss: 0.4283, loss: 67.1719, learning_rate: 0.0160
[1,0]<stderr>:2020-09-18 20:35:18,856 - INFO - Epoch [11][250/458]	lr: 0.01600, eta: 0:09:13, time: 0.797, data_time: 0.041, rpn_class_loss: 2.3361, rpn_bbox_loss: 10.3316, rcnn_class_loss: 29.2857, rcnn_bbox_loss: 10.8128, rcnn_mask_loss: 11.3897, reg_loss: 0.4283, loss: 64.5842, learning_rate: 0.0160
[1,0]<stderr>:2020-09-18 20:35:59,151 - INFO - Epoch [11][300/458]	lr: 0.01600, eta: 0:08:31, time: 0.806, data_time: 0.037, rpn_class_loss: 2.1896, rpn_bbox_loss: 9.6400, rcnn_class_loss: 29.1256, rcnn_bbox_loss: 10.3005, rcnn_mask_loss: 10.7832, reg_loss: 0.4283, loss: 62.4671, learning_rate: 0.0160
[1,0]<stderr>:2020-09-18 20:36:39,014 - INFO - Epoch [11][350/458]	lr: 0.01600, eta: 0:07:49, time: 0.797, data_time: 0.042, rpn_class_loss: 2.1182, rpn_bbox_loss: 9.6989, rcnn_class_loss: 29.3478, rcnn_bbox_loss: 10.7564, rcnn_mask_loss: 10.5372, reg_loss: 0.4283, loss: 62.8868, learning_rate: 0.0160
[1,0]<stderr>:2020-09-18 20:37:18,948 - INFO - Epoch [11][400/458]	lr: 0.01600, eta: 0:07:08, time: 0.799, data_time: 0.040, rpn_class_loss: 2.3329, rpn_bbox_loss: 10.4334, rcnn_class_loss: 30.9070, rcnn_bbox_loss: 11.4549, rcnn_mask_loss: 10.8149, reg_loss: 0.4283, loss: 66.3714, learning_rate: 0.0160
[1,0]<stderr>:2020-09-18 20:37:59,872 - INFO - Epoch [11][450/458]	lr: 0.01600, eta: 0:06:26, time: 0.819, data_time: 0.038, rpn_class_loss: 2.1034, rpn_bbox_loss: 9.5011, rcnn_class_loss: 29.6488, rcnn_bbox_loss: 10.4403, rcnn_mask_loss: 11.8518, reg_loss: 0.4283, loss: 63.9737, learning_rate: 0.0160
[1,101]<stdout>:setting Step LR 0.0015999999642372135
[1,101]<stdout>:0.16 0.1 2 [8, 11] 11
[1,48]<stdout>:setting Step LR 0.0015999999642372135
[1,48]<stdout>:0.16 0.1 2 [8, 11] 11
[1,32]<stdout>:setting Step LR 0.0015999999642372135
[1,32]<stdout>:0.16 0.1 2 [8, 11] 11
[1,53]<stdout>:setting Step LR 0.0015999999642372135
[1,53]<stdout>:0.16 0.1 2 [8, 11] 11
[1,82]<stdout>:setting Step LR 0.0015999999642372135
[1,82]<stdout>:0.16 0.1 2 [8, 11] 11
[1,118]<stdout>:setting Step LR 0.0015999999642372135
[1,118]<stdout>:0.16 0.1 2 [8, 11] 11
[1,35]<stdout>:setting Step LR 0.0015999999642372135
[1,35]<stdout>:0.16 0.1 2 [8, 11] 11
[1,5]<stdout>:setting Step LR 0.0015999999642372135
[1,5]<stdout>:0.16 0.1 2 [8, 11] 11
[1,52]<stdout>:setting Step LR 0.0015999999642372135
[1,52]<stdout>:0.16 0.1 2 [8, 11] 11
[1,101]<stdout>:Starting new loop for GPU: 53
[1,84]<stdout>:setting Step LR 0.0015999999642372135
[1,84]<stdout>:0.16 0.1 2 [8, 11] 11
[1,7]<stdout>:setting Step LR 0.0015999999642372135
[1,7]<stdout>:0.16 0.1 2 [8, 11] 11
[1,99]<stdout>:setting Step LR 0.0015999999642372135
[1,99]<stdout>:0.16 0.1 2 [8, 11] 11
[1,18]<stdout>:setting Step LR 0.0015999999642372135
[1,18]<stdout>:0.16 0.1 2 [8, 11] 11
[1,48]<stdout>:Starting new loop for GPU: 24
[1,85]<stdout>:setting Step LR 0.0015999999642372135
[1,85]<stdout>:0.16 0.1 2 [8, 11] 11
[1,33]<stdout>:setting Step LR 0.0015999999642372135
[1,33]<stdout>:0.16 0.1 2 [8, 11] 11
[1,114]<stdout>:setting Step LR 0.0015999999642372135
[1,114]<stdout>:0.16 0.1 2 [8, 11] 11
[1,80]<stdout>:setting Step LR 0.0015999999642372135
[1,80]<stdout>:0.16 0.1 2 [8, 11] 11
[1,103]<stdout>:setting Step LR 0.0015999999642372135
[1,103]<stdout>:0.16 0.1 2 [8, 11] 11
[1,69]<stdout>:setting Step LR 0.0015999999642372135
[1,69]<stdout>:0.16 0.1 2 [8, 11] 11
[1,49]<stdout>:setting Step LR 0.0015999999642372135
[1,49]<stdout>:0.16 0.1 2 [8, 11] 11
[1,115]<stdout>:setting Step LR 0.0015999999642372135
[1,115]<stdout>:0.16 0.1 2 [8, 11] 11
[1,1]<stdout>:setting Step LR 0.0015999999642372135
[1,1]<stdout>:0.16 0.1 2 [8, 11] 11
[1,39]<stdout>:setting Step LR 0.0015999999642372135
[1,39]<stdout>:0.16 0.1 2 [8, 11] 11
[1,32]<stdout>:Starting new loop for GPU: 16
[1,23]<stdout>:setting Step LR 0.0015999999642372135
[1,23]<stdout>:0.16 0.1 2 [8, 11] 11
[1,21]<stdout>:setting Step LR 0.0015999999642372135
[1,21]<stdout>:0.16 0.1 2 [8, 11] 11
[1,53]<stdout>:Starting new loop for GPU: 29
[1,82]<stdout>:Starting new loop for GPU: 42
[1,116]<stdout>:setting Step LR 0.0015999999642372135
[1,116]<stdout>:0.16 0.1 2 [8, 11] 11
[1,118]<stdout>:Starting new loop for GPU: 62
[1,5]<stdout>:Starting new loop for GPU: 5
[1,35]<stdout>:Starting new loop for GPU: 19
[1,64]<stdout>:setting Step LR 0.0015999999642372135
[1,64]<stdout>:0.16 0.1 2 [8, 11] 11
[1,55]<stdout>:setting Step LR 0.0015999999642372135
[1,55]<stdout>:0.16 0.1 2 [8, 11] 11
[1,66]<stdout>:setting Step LR 0.0015999999642372135
[1,66]<stdout>:0.16 0.1 2 [8, 11] 11
[1,84]<stdout>:Starting new loop for GPU: 44
[1,7]<stdout>:Starting new loop for GPU: 7
[1,52]<stdout>:Starting new loop for GPU: 28
[1,50]<stdout>:setting Step LR 0.0015999999642372135
[1,50]<stdout>:0.16 0.1 2 [8, 11] 11
[1,38]<stdout>:setting Step LR 0.0015999999642372135
[1,38]<stdout>:0.16 0.1 2 [8, 11] 11
[1,70]<stdout>:setting Step LR 0.0015999999642372135
[1,70]<stdout>:0.16 0.1 2 [8, 11] 11
[1,18]<stdout>:Starting new loop for GPU: 10
[1,102]<stdout>:setting Step LR 0.0015999999642372135
[1,102]<stdout>:0.16 0.1 2 [8, 11] 11
[1,96]<stdout>:setting Step LR 0.0015999999642372135
[1,96]<stdout>:0.16 0.1 2 [8, 11] 11
[1,22]<stdout>:setting Step LR 0.0015999999642372135
[1,22]<stdout>:0.16 0.1 2 [8, 11] 11
[1,33]<stdout>:Starting new loop for GPU: 17
[1,99]<stdout>:Starting new loop for GPU: 51
[1,85]<stdout>:Starting new loop for GPU: 45
[1,17]<stdout>:setting Step LR 0.0015999999642372135
[1,17]<stdout>:0.16 0.1 2 [8, 11] 11
[1,113]<stdout>:setting Step LR 0.0015999999642372135
[1,113]<stdout>:0.16 0.1 2 [8, 11] 11
[1,6]<stdout>:setting Step LR 0.0015999999642372135
[1,6]<stdout>:0.16 0.1 2 [8, 11] 11
[1,114]<stdout>:Starting new loop for GPU: 58
[1,100]<stdout>:setting Step LR 0.0015999999642372135
[1,100]<stdout>:0.16 0.1 2 [8, 11] 11
[1,69]<stdout>:Starting new loop for GPU: 37
[1,67]<stdout>:setting Step LR 0.0015999999642372135
[1,67]<stdout>:0.16 0.1 2 [8, 11] 11
[1,80]<stdout>:Starting new loop for GPU: 40
[1,65]<stdout>:setting Step LR 0.0015999999642372135
[1,65]<stdout>:0.16 0.1 2 [8, 11] 11
[1,16]<stdout>:setting Step LR 0.0015999999642372135
[1,16]<stdout>:0.16 0.1 2 [8, 11] 11
[1,51]<stdout>:setting Step LR 0.0015999999642372135
[1,51]<stdout>:0.16 0.1 2 [8, 11] 11
[1,4]<stdout>:setting Step LR 0.0015999999642372135
[1,4]<stdout>:0.16 0.1 2 [8, 11] 11
[1,2]<stdout>:setting Step LR 0.0015999999642372135
[1,2]<stdout>:0.16 0.1 2 [8, 11] 11
[1,68]<stdout>:setting Step LR 0.0015999999642372135
[1,68]<stdout>:0.16 0.1 2 [8, 11] 11
[1,103]<stdout>:Starting new loop for GPU: 55
[1,39]<stdout>:Starting new loop for GPU: 23
[1,23]<stdout>:Starting new loop for GPU: 15
[1,1]<stdout>:Starting new loop for GPU: 1
[1,49]<stdout>:Starting new loop for GPU: 25
[1,21]<stdout>:Starting new loop for GPU: 13
[1,83]<stdout>:setting Step LR 0.0015999999642372135
[1,83]<stdout>:0.16 0.1 2 [8, 11] 11
[1,115]<stdout>:Starting new loop for GPU: 59
[1,112]<stdout>:setting Step LR 0.0015999999642372135
[1,112]<stdout>:0.16 0.1 2 [8, 11] 11
[1,34]<stdout>:setting Step LR 0.0015999999642372135
[1,34]<stdout>:0.16 0.1 2 [8, 11] 11
[1,98]<stdout>:setting Step LR 0.0015999999642372135
[1,98]<stdout>:0.16 0.1 2 [8, 11] 11
[1,71]<stdout>:setting Step LR 0.0015999999642372135
[1,71]<stdout>:0.16 0.1 2 [8, 11] 11
[1,64]<stdout>:Starting new loop for GPU: 32
[1,116]<stdout>:Starting new loop for GPU: 60
[1,66]<stdout>:Starting new loop for GPU: 34
[1,19]<stdout>:setting Step LR 0.0015999999642372135
[1,19]<stdout>:0.16 0.1 2 [8, 11] 11
[1,70]<stdout>:Starting new loop for GPU: 38
[1,102]<stdout>:Starting new loop for GPU: 54
[1,96]<stdout>:Starting new loop for GPU: 48
[1,38]<stdout>:Starting new loop for GPU: 22
[1,22]<stdout>:Starting new loop for GPU: 14
[1,117]<stdout>:setting Step LR 0.0015999999642372135
[1,117]<stdout>:0.16 0.1 2 [8, 11] 11
[1,20]<stdout>:setting Step LR 0.0015999999642372135
[1,20]<stdout>:0.16 0.1 2 [8, 11] 11
[1,100]<stdout>:Starting new loop for GPU: 52
[1,50]<stdout>:Starting new loop for GPU: 26
[1,6]<stdout>:Starting new loop for GPU: 6
[1,55]<stdout>:Starting new loop for GPU: 31
[1,17]<stdout>:Starting new loop for GPU: 9
[1,113]<stdout>:Starting new loop for GPU: 57
[1,4]<stdout>:Starting new loop for GPU: 4
[1,67]<stdout>:Starting new loop for GPU: 35
[1,37]<stdout>:setting Step LR 0.0015999999642372135
[1,37]<stdout>:0.16 0.1 2 [8, 11] 11
[1,16]<stdout>:Starting new loop for GPU: 8
[1,2]<stdout>:Starting new loop for GPU: 2
[1,65]<stdout>:Starting new loop for GPU: 33
[1,3]<stdout>:setting Step LR 0.0015999999642372135
[1,3]<stdout>:0.16 0.1 2 [8, 11] 11
[1,51]<stdout>:Starting new loop for GPU: 27
[1,68]<stdout>:Starting new loop for GPU: 36
[1,83]<stdout>:Starting new loop for GPU: 43
[1,97]<stdout>:setting Step LR 0.0015999999642372135
[1,97]<stdout>:0.16 0.1 2 [8, 11] 11
[1,98]<stdout>:Starting new loop for GPU: 50
[1,34]<stdout>:Starting new loop for GPU: 18
[1,71]<stdout>:Starting new loop for GPU: 39
[1,112]<stdout>:Starting new loop for GPU: 56
[1,20]<stdout>:Starting new loop for GPU: 12
[1,117]<stdout>:Starting new loop for GPU: 61
[1,54]<stdout>:setting Step LR 0.0015999999642372135
[1,54]<stdout>:0.16 0.1 2 [8, 11] 11
[1,37]<stdout>:Starting new loop for GPU: 21
[1,86]<stdout>:setting Step LR 0.0015999999642372135
[1,86]<stdout>:0.16 0.1 2 [8, 11] 11
[1,19]<stdout>:Starting new loop for GPU: 11
[1,81]<stdout>:setting Step LR 0.0015999999642372135
[1,81]<stdout>:0.16 0.1 2 [8, 11] 11
[1,3]<stdout>:Starting new loop for GPU: 3
[1,97]<stdout>:Starting new loop for GPU: 49
[1,87]<stdout>:setting Step LR 0.0015999999642372135
[1,87]<stdout>:0.16 0.1 2 [8, 11] 11
[1,86]<stdout>:Starting new loop for GPU: 46
[1,81]<stdout>:Starting new loop for GPU: 41
[1,54]<stdout>:Starting new loop for GPU: 30
[1,119]<stdout>:setting Step LR 0.0015999999642372135
[1,119]<stdout>:0.16 0.1 2 [8, 11] 11
[1,87]<stdout>:Starting new loop for GPU: 47
[1,119]<stdout>:Starting new loop for GPU: 63
[1,36]<stdout>:setting Step LR 0.0015999999642372135
[1,36]<stdout>:0.16 0.1 2 [8, 11] 11
[1,36]<stdout>:Starting new loop for GPU: 20
[1,0]<stderr>:2020-09-18 20:38:07,284 - INFO - Saved checkpoint at: /shared/deep-learning-models/models/vision/detection/work_dirs/mask_rcnn_r50v1_d_fpn_1x_coco/010/faster_rcnn
[1,0]<stdout>:setting Step LR 0.0015999999642372135
[1,0]<stdout>:0.16 0.1 2 [8, 11] 11
[1,0]<stdout>:Starting new loop for GPU: 0
[1,112]<stdout>:Rank 56 broadcasting
[1,80]<stdout>:Rank 40 broadcasting
[1,119]<stdout>:Rank 63 broadcasting
[1,82]<stdout>:Rank 42 broadcasting
[1,71]<stdout>:Rank 39 broadcasting
[1,116]<stdout>:Rank 60 broadcasting
[1,87]<stdout>:Rank 47 broadcasting
[1,7]<stdout>:Rank 7 broadcasting
[1,100]<stdout>:Rank 52 broadcasting
[1,68]<stdout>:Rank 36 broadcasting
[1,118]<stdout>:Rank 62 broadcasting
[1,84]<stdout>:Rank 44 broadcasting
[1,5]<stdout>:Rank 5 broadcasting
[1,98]<stdout>:Rank 50 broadcasting
[1,66]<stdout>:Rank 34 broadcasting
[1,117]<stdout>:Rank 61 broadcasting
[1,55]<stdout>:Rank 31 broadcasting
[1,81]<stdout>:Rank 41 broadcasting
[1,1]<stdout>:Rank 1 broadcasting
[1,67]<stdout>:Rank 35 broadcasting
[1,48]<stdout>:Rank 24 broadcasting
[1,32]<stdout>:Rank 16 broadcasting
[1,3]<stdout>:Rank 3 broadcasting
[1,101]<stdout>:Rank 53 broadcasting
[1,69]<stdout>:Rank 37 broadcasting
[1,52]<stdout>:Rank 28 broadcasting
[1,39]<stdout>:Rank 23 broadcasting
[1,64]<stdout>:Rank 32 broadcasting
[1,33]<stdout>:Rank 17 broadcasting
[1,102]<stdout>:Rank 54 broadcasting
[1,70]<stdout>:Rank 38 broadcasting
[1,54]<stdout>:Rank 30 broadcasting
[1,37]<stdout>:Rank 21 broadcasting
[1,103]<stdout>:Rank 55 broadcasting
[1,38]<stdout>:Rank 22 broadcasting
[1,96]<stdout>:Rank 48 broadcasting
[1,51]<stdout>:Rank 27 broadcasting
[1,23]<stdout>:Rank 15 broadcasting
[1,16]<stdout>:Rank 8 broadcasting
[1,18]<stdout>:Rank 10 broadcasting
[1,22]<stdout>:Rank 14 broadcasting
[1,49]<stdout>:Rank 25 broadcasting
[1,21]<stdout>:Rank 13 broadcasting
[1,19]<stdout>:Rank 11 broadcasting
[1,20]<stdout>:Rank 12 broadcasting
[1,34]<stdout>:Rank 18 broadcasting
[1,85]<stdout>:Rank 45 broadcasting
[1,50]<stdout>:Rank 26 broadcasting
[1,83]<stdout>:Rank 43 broadcasting
[1,53]<stdout>:Rank 29 broadcasting
[1,36]<stdout>:Rank 20 broadcasting
[1,65]<stdout>:Rank 33 broadcasting
[1,113]<stdout>:Rank 57 broadcasting
[1,0]<stdout>:Rank 0 broadcasting
[1,35]<stdout>:Rank 19 broadcasting
[1,115]<stdout>:Rank 59 broadcasting
[1,99]<stdout>:Rank 51 broadcasting
[1,97]<stdout>:Rank 49 broadcasting
[1,114]<stdout>:Rank 58 broadcasting
[1,17]<stdout>:Rank 9 broadcasting
[1,86]<stdout>:Rank 46 broadcasting
[1,4]<stdout>:Rank 4 broadcasting
[1,2]<stdout>:Rank 2 broadcasting
[1,6]<stdout>:Rank 6 broadcasting
[1,0]<stdout>:Variable broadcast done.
[1,6]<stdout>:Variable broadcast done.
[1,5]<stdout>:Variable broadcast done.
[1,16]<stdout>:Variable broadcast done.
[1,19]<stdout>:Variable broadcast done.
[1,18]<stdout>:Variable broadcast done.
[1,21]<stdout>:Variable broadcast done.
[1,17]<stdout>:Variable broadcast done.
[1,22]<stdout>:Variable broadcast done.
[1,23]<stdout>:Variable broadcast done.
[1,20]<stdout>:Variable broadcast done.
[1,34]<stdout>:Variable broadcast done.
[1,32]<stdout>:Variable broadcast done.
[1,35]<stdout>:Variable broadcast done.
[1,37]<stdout>:Variable broadcast done.
[1,33]<stdout>:Variable broadcast done.
[1,38]<stdout>:Variable broadcast done.
[1,39]<stdout>:Variable broadcast done.
[1,36]<stdout>:Variable broadcast done.
[1,64]<stdout>:Variable broadcast done.
[1,52]<stdout>:Variable broadcast done.
[1,66]<stdout>:Variable broadcast done.
[1,51]<stdout>:Variable broadcast done.
[1,70]<stdout>:Variable broadcast done.
[1,55]<stdout>:Variable broadcast done.
[1,68]<stdout>:Variable broadcast done.
[1,48]<stdout>:Variable broadcast done.
[1,71]<stdout>:Variable broadcast done.
[1,50]<stdout>:Variable broadcast done.
[1,67]<stdout>:Variable broadcast done.
[1,53]<stdout>:Variable broadcast done.
[1,100]<stdout>:Variable broadcast done.
[1,69]<stdout>:Variable broadcast done.
[1,54]<stdout>:Variable broadcast done.
[1,82]<stdout>:Variable broadcast done.
[1,96]<stdout>:Variable broadcast done.
[1,65]<stdout>:Variable broadcast done.
[1,49]<stdout>:Variable broadcast done.
[1,81]<stdout>:Variable broadcast done.
[1,98]<stdout>:Variable broadcast done.
[1,87]<stdout>:Variable broadcast done.
[1,97]<stdout>:Variable broadcast done.
[1,85]<stdout>:Variable broadcast done.
[1,103]<stdout>:Variable broadcast done.
[1,80]<stdout>:Variable broadcast done.
[1,99]<stdout>:Variable broadcast done.
[1,84]<stdout>:Variable broadcast done.
[1,1]<stdout>:Variable broadcast done.
[1,102]<stdout>:Variable broadcast done.
[1,83]<stdout>:Variable broadcast done.
[1,3]<stdout>:Variable broadcast done.
[1,101]<stdout>:Variable broadcast done.
[1,112]<stdout>:Variable broadcast done.
[1,86]<stdout>:Variable broadcast done.
[1,2]<stdout>:Variable broadcast done.
[1,118]<stdout>:Variable broadcast done.
[1,7]<stdout>:Variable broadcast done.
[1,115]<stdout>:Variable broadcast done.
[1,4]<stdout>:Variable broadcast done.
[1,119]<stdout>:Variable broadcast done.
[1,116]<stdout>:Variable broadcast done.
[1,114]<stdout>:Variable broadcast done.
[1,113]<stdout>:Variable broadcast done.
[1,117]<stdout>:Variable broadcast done.
[1,0]<stderr>:2020-09-18 20:38:52,372 - INFO - Epoch [12][50/458]	lr: 0.00160, eta: 0:05:38, time: 0.900, data_time: 0.054, rpn_class_loss: 2.2137, rpn_bbox_loss: 9.9774, rcnn_class_loss: 30.3561, rcnn_bbox_loss: 11.3345, rcnn_mask_loss: 11.5536, reg_loss: 0.4283, loss: 65.8634, learning_rate: 0.0016
[1,0]<stderr>:2020-09-18 20:39:34,052 - INFO - Epoch [12][100/458]	lr: 0.00160, eta: 0:04:56, time: 0.834, data_time: 0.036, rpn_class_loss: 2.3919, rpn_bbox_loss: 10.6000, rcnn_class_loss: 29.7485, rcnn_bbox_loss: 10.9458, rcnn_mask_loss: 11.7335, reg_loss: 0.4283, loss: 65.8479, learning_rate: 0.0016
[1,0]<stderr>:2020-09-18 20:40:14,483 - INFO - Epoch [12][150/458]	lr: 0.00160, eta: 0:04:15, time: 0.809, data_time: 0.039, rpn_class_loss: 1.9956, rpn_bbox_loss: 8.9063, rcnn_class_loss: 26.7732, rcnn_bbox_loss: 9.8397, rcnn_mask_loss: 10.6395, reg_loss: 0.4283, loss: 58.5827, learning_rate: 0.0016
[1,0]<stderr>:2020-09-18 20:40:54,682 - INFO - Epoch [12][200/458]	lr: 0.00160, eta: 0:03:33, time: 0.804, data_time: 0.038, rpn_class_loss: 2.0220, rpn_bbox_loss: 9.4224, rcnn_class_loss: 28.2656, rcnn_bbox_loss: 10.2861, rcnn_mask_loss: 11.4752, reg_loss: 0.4283, loss: 61.8997, learning_rate: 0.0016
[1,0]<stderr>:2020-09-18 20:41:35,282 - INFO - Epoch [12][250/458]	lr: 0.00160, eta: 0:02:52, time: 0.812, data_time: 0.046, rpn_class_loss: 2.3140, rpn_bbox_loss: 10.2249, rcnn_class_loss: 29.3611, rcnn_bbox_loss: 10.6921, rcnn_mask_loss: 11.4368, reg_loss: 0.4283, loss: 64.4571, learning_rate: 0.0016
[1,0]<stderr>:2020-09-18 20:42:14,928 - INFO - Epoch [12][300/458]	lr: 0.00160, eta: 0:02:10, time: 0.793, data_time: 0.034, rpn_class_loss: 2.0773, rpn_bbox_loss: 9.0709, rcnn_class_loss: 27.0733, rcnn_bbox_loss: 9.9701, rcnn_mask_loss: 11.3359, reg_loss: 0.4283, loss: 59.9558, learning_rate: 0.0016
[1,0]<stderr>:2020-09-18 20:42:55,597 - INFO - Epoch [12][350/458]	lr: 0.00160, eta: 0:01:29, time: 0.813, data_time: 0.041, rpn_class_loss: 2.3161, rpn_bbox_loss: 10.0295, rcnn_class_loss: 28.7293, rcnn_bbox_loss: 10.8372, rcnn_mask_loss: 10.7331, reg_loss: 0.4283, loss: 63.0735, learning_rate: 0.0016
[1,0]<stderr>:2020-09-18 20:43:35,781 - INFO - Epoch [12][400/458]	lr: 0.00160, eta: 0:00:48, time: 0.804, data_time: 0.042, rpn_class_loss: 2.6419, rpn_bbox_loss: 12.2217, rcnn_class_loss: 32.5472, rcnn_bbox_loss: 12.1112, rcnn_mask_loss: 10.7099, reg_loss: 0.4283, loss: 70.6602, learning_rate: 0.0016
[1,0]<stderr>:2020-09-18 20:44:15,363 - INFO - Epoch [12][450/458]	lr: 0.00160, eta: 0:00:06, time: 0.792, data_time: 0.037, rpn_class_loss: 1.9682, rpn_bbox_loss: 8.7876, rcnn_class_loss: 28.5711, rcnn_bbox_loss: 10.4151, rcnn_mask_loss: 11.4853, reg_loss: 0.4283, loss: 61.6555, learning_rate: 0.0016
[1,36]<stdout>:Starting new loop for GPU: 20
[1,67]<stdout>:Starting new loop for GPU: 35
[1,66]<stdout>:Starting new loop for GPU: 34
[1,37]<stdout>:Starting new loop for GPU: 21
[1,54]<stdout>:Starting new loop for GPU: 30
[1,112]<stdout>:Starting new loop for GPU: 56
[1,97]<stdout>:Starting new loop for GPU: 49
[1,70]<stdout>:Starting new loop for GPU: 38
[1,96]<stdout>:Starting new loop for GPU: 48
[1,117]<stdout>:Starting new loop for GPU: 61
[1,19]<stdout>:Starting new loop for GPU: 11
[1,116]<stdout>:Starting new loop for GPU: 60
[1,23]<stdout>:Starting new loop for GPU: 15
[1,5]<stdout>:Starting new loop for GPU: 5
[1,17]<stdout>:Starting new loop for GPU: 9
[1,3]<stdout>:Starting new loop for GPU: 3
[1,1]<stdout>:Starting new loop for GPU: 1
[1,80]<stdout>:Starting new loop for GPU: 40
[1,86]<stdout>:Starting new loop for GPU: 46
[1,7]<stdout>:Starting new loop for GPU: 7
[1,115]<stdout>:Starting new loop for GPU: 59
[1,82]<stdout>:Starting new loop for GPU: 42
[1,50]<stdout>:Starting new loop for GPU: 26
[1,100]<stdout>:Starting new loop for GPU: 52
[1,55]<stdout>:Starting new loop for GPU: 31
[1,103]<stdout>:Starting new loop for GPU: 55
[1,51]<stdout>:Starting new loop for GPU: 27
[1,83]<stdout>:Starting new loop for GPU: 43
[1,98]<stdout>:Starting new loop for GPU: 50
[1,18]<stdout>:Starting new loop for GPU: 10
[1,16]<stdout>:Starting new loop for GPU: 8
[1,113]<stdout>:Starting new loop for GPU: 57
[1,22]<stdout>:Starting new loop for GPU: 14
[1,32]<stdout>:Starting new loop for GPU: 16
[1,68]<stdout>:Starting new loop for GPU: 36
[1,48]<stdout>:Starting new loop for GPU: 24
[1,53]<stdout>:Starting new loop for GPU: 29
[1,119]<stdout>:Starting new loop for GPU: 63
[1,64]<stdout>:Starting new loop for GPU: 32
[1,101]<stdout>:Starting new loop for GPU: 53
[1,71]<stdout>:Starting new loop for GPU: 39
[1,87]<stdout>:Starting new loop for GPU: 47
[1,65]<stdout>:Starting new loop for GPU: 33
[1,99]<stdout>:Starting new loop for GPU: 51
[1,39]<stdout>:Starting new loop for GPU: 23
[1,85]<stdout>:Starting new loop for GPU: 45
[1,35]<stdout>:Starting new loop for GPU: 19
[1,69]<stdout>:Starting new loop for GPU: 37
[1,2]<stdout>:Starting new loop for GPU: 2
[1,118]<stdout>:Starting new loop for GPU: 62
[1,33]<stdout>:Starting new loop for GPU: 17
[1,49]<stdout>:Starting new loop for GPU: 25
[1,114]<stdout>:Starting new loop for GPU: 58
[1,81]<stdout>:Starting new loop for GPU: 41
[1,52]<stdout>:Starting new loop for GPU: 28
[1,20]<stdout>:Starting new loop for GPU: 12
[1,38]<stdout>:Starting new loop for GPU: 22
[1,6]<stdout>:Starting new loop for GPU: 6
[1,34]<stdout>:Starting new loop for GPU: 18
[1,102]<stdout>:Starting new loop for GPU: 54
[1,21]<stdout>:Starting new loop for GPU: 13
[1,84]<stdout>:Starting new loop for GPU: 44
[1,4]<stdout>:Starting new loop for GPU: 4
[1,0]<stderr>:2020-09-18 20:44:22,742 - INFO - Saved checkpoint at: /shared/deep-learning-models/models/vision/detection/work_dirs/mask_rcnn_r50v1_d_fpn_1x_coco/011/faster_rcnn
[1,0]<stdout>:terminal width is too small (0), please consider widen the terminal for better progressbar visualization
[1,0]<stdout>:[          ] 0/309, elapsed: 0s, ETA:[1,0]<stdout>:Starting new loop for GPU: 0
[1,54]<stderr>:2020-09-18 20:44:25.607208: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,97]<stderr>:2020-09-18 20:44:25.635258: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,16]<stderr>:2020-09-18 20:44:25.646269: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,66]<stderr>:2020-09-18 20:44:25.662513: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,85]<stderr>:2020-09-18 20:44:25.667361: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,22]<stderr>:2020-09-18 20:44:25.673831: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,70]<stderr>:2020-09-18 20:44:25.676270: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,67]<stderr>:2020-09-18 20:44:25.687014: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,23]<stderr>:2020-09-18 20:44:25.691528: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,71]<stderr>:2020-09-18 20:44:25.704386: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,99]<stderr>:2020-09-18 20:44:25.705167: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,3]<stderr>:2020-09-18 20:44:25.710750: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,69]<stderr>:2020-09-18 20:44:25.716689: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,37]<stderr>:2020-09-18 20:44:25.720006: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,32]<stderr>:2020-09-18 20:44:25.723699: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,82]<stderr>:2020-09-18 20:44:25.727009: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,96]<stderr>:2020-09-18 20:44:25.729637: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,53]<stderr>:2020-09-18 20:44:25.730326: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,100]<stderr>:2020-09-18 20:44:25.731894: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,101]<stderr>:2020-09-18 20:44:25.732512: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,55]<stderr>:2020-09-18 20:44:25.734213: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,98]<stderr>:2020-09-18 20:44:25.734363: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,17]<stderr>:2020-09-18 20:44:25.734269: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,112]<stderr>:2020-09-18 20:44:25.738310: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,5]<stderr>:2020-09-18 20:44:25.737439: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,51]<stderr>:2020-09-18 20:44:25.739764: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,19]<stderr>:2020-09-18 20:44:25.742242: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,49]<stderr>:2020-09-18 20:44:25.746043: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,115]<stderr>:2020-09-18 20:44:25.749314: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,80]<stderr>:2020-09-18 20:44:25.747886: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,86]<stderr>:2020-09-18 20:44:25.749795: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,52]<stderr>:2020-09-18 20:44:25.755701: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,64]<stderr>:2020-09-18 20:44:25.757112: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,50]<stderr>:2020-09-18 20:44:25.757915: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,83]<stderr>:2020-09-18 20:44:25.759498: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,36]<stderr>:2020-09-18 20:44:25.760253: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,68]<stderr>:2020-09-18 20:44:25.763465: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,103]<stderr>:2020-09-18 20:44:25.764542: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,1]<stderr>:2020-09-18 20:44:25.764982: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,48]<stderr>:2020-09-18 20:44:25.765562: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,39]<stderr>:2020-09-18 20:44:25.766441: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,116]<stderr>:2020-09-18 20:44:25.770760: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,18]<stderr>:2020-09-18 20:44:25.770501: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,114]<stderr>:2020-09-18 20:44:25.776335: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,81]<stderr>:2020-09-18 20:44:25.778611: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,20]<stderr>:2020-09-18 20:44:25.782541: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,2]<stderr>:2020-09-18 20:44:25.783666: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,117]<stderr>:2020-09-18 20:44:25.787319: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,113]<stderr>:2020-09-18 20:44:25.789764: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,33]<stderr>:2020-09-18 20:44:25.787215: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,87]<stderr>:2020-09-18 20:44:25.788321: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,7]<stderr>:2020-09-18 20:44:25.790628: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,119]<stderr>:2020-09-18 20:44:25.794583: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,34]<stderr>:2020-09-18 20:44:25.813497: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,118]<stderr>:2020-09-18 20:44:25.819255: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,35]<stderr>:2020-09-18 20:44:25.830278: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,102]<stderr>:2020-09-18 20:44:25.845225: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,38]<stderr>:2020-09-18 20:44:25.846926: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,21]<stderr>:2020-09-18 20:44:25.861627: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,6]<stderr>:2020-09-18 20:44:25.885841: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,84]<stderr>:2020-09-18 20:44:25.930978: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,65]<stderr>:2020-09-18 20:44:25.934660: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,4]<stderr>:2020-09-18 20:44:25.962813: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,0]<stderr>:2020-09-18 20:44:26.569305: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 261/11283 nodes to float16 precision using 12 cast(s) to float16 (excluding Const and Variable casts)
[1,16]<stderr>:2020-09-18 20:44:29.281454: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,54]<stderr>:2020-09-18 20:44:29.290659: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,85]<stderr>:2020-09-18 20:44:29.311691: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,97]<stderr>:2020-09-18 20:44:29.362226: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,22]<stderr>:2020-09-18 20:44:29.389457: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,3]<stderr>:2020-09-18 20:44:29.419808: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,23]<stderr>:2020-09-18 20:44:29.419638: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,70]<stderr>:2020-09-18 20:44:29.420916: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,66]<stderr>:2020-09-18 20:44:29.421289: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,71]<stderr>:2020-09-18 20:44:29.428283: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,99]<stderr>:2020-09-18 20:44:29.431248: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,69]<stderr>:2020-09-18 20:44:29.433648: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,67]<stderr>:2020-09-18 20:44:29.436406: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,82]<stderr>:2020-09-18 20:44:29.479597: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,52]<stderr>:2020-09-18 20:44:29.482442: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,49]<stderr>:2020-09-18 20:44:29.485833: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,101]<stderr>:2020-09-18 20:44:29.486639: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,55]<stderr>:2020-09-18 20:44:29.489103: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,51]<stderr>:2020-09-18 20:44:29.492481: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,32]<stderr>:2020-09-18 20:44:29.496843: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,64]<stderr>:2020-09-18 20:44:29.498548: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,53]<stderr>:2020-09-18 20:44:29.499495: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,115]<stderr>:2020-09-18 20:44:29.501564: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,17]<stderr>:2020-09-18 20:44:29.501730: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,96]<stderr>:2020-09-18 20:44:29.511885: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,98]<stderr>:2020-09-18 20:44:29.512293: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,80]<stderr>:2020-09-18 20:44:29.511426: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,18]<stderr>:2020-09-18 20:44:29.511928: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,87]<stderr>:2020-09-18 20:44:29.514110: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,2]<stderr>:2020-09-18 20:44:29.515651: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,50]<stderr>:2020-09-18 20:44:29.516688: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,100]<stderr>:2020-09-18 20:44:29.516688: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,5]<stderr>:2020-09-18 20:44:29.517030: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,19]<stderr>:2020-09-18 20:44:29.518102: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,7]<stderr>:2020-09-18 20:44:29.522141: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,20]<stderr>:2020-09-18 20:44:29.521770: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,39]<stderr>:2020-09-18 20:44:29.522403: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,48]<stderr>:2020-09-18 20:44:29.527022: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,86]<stderr>:2020-09-18 20:44:29.526927: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,81]<stderr>:2020-09-18 20:44:29.532369: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,83]<stderr>:2020-09-18 20:44:29.535467: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,114]<stderr>:2020-09-18 20:44:29.540828: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,103]<stderr>:2020-09-18 20:44:29.543626: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,112]<stderr>:2020-09-18 20:44:29.544721: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,68]<stderr>:2020-09-18 20:44:29.553923: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,113]<stderr>:2020-09-18 20:44:29.555676: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,1]<stderr>:2020-09-18 20:44:29.556609: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,36]<stderr>:2020-09-18 20:44:29.556225: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,33]<stderr>:2020-09-18 20:44:29.556586: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,34]<stderr>:2020-09-18 20:44:29.559311: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,119]<stderr>:2020-09-18 20:44:29.566938: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,21]<stderr>:2020-09-18 20:44:29.571142: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,37]<stderr>:2020-09-18 20:44:29.575432: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,117]<stderr>:2020-09-18 20:44:29.582243: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,118]<stderr>:2020-09-18 20:44:29.586125: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,116]<stderr>:2020-09-18 20:44:29.588501: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,35]<stderr>:2020-09-18 20:44:29.589417: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,102]<stderr>:2020-09-18 20:44:29.602986: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,38]<stderr>:2020-09-18 20:44:29.635586: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,84]<stderr>:2020-09-18 20:44:29.661456: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,6]<stderr>:2020-09-18 20:44:29.666330: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,4]<stderr>:2020-09-18 20:44:29.723927: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,65]<stderr>:2020-09-18 20:44:29.881471: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,0]<stderr>:2020-09-18 20:44:30.192655: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1924] Converted 0/9867 nodes to float16 precision using 0 cast(s) to float16 (excluding Const and Variable casts)
[1,0]<stdout>:[          ] 1/309, 0.1 task/s, elapsed: 12s, ETA:  3796s[1,0]<stdout>:[          ] 2/309, 0.1 task/s, elapsed: 15s, ETA:  2295s[1,0]<stdout>:[          ] 3/309, 0.2 task/s, elapsed: 17s, ETA:  1710s[1,0]<stdout>:[          ] 4/309, 0.2 task/s, elapsed: 18s, ETA:  1406s[1,0]<stdout>:[          ] 5/309, 0.2 task/s, elapsed: 20s, ETA:  1226s[1,0]<stdout>:[          ] 6/309, 0.3 task/s, elapsed: 22s, ETA:  1109s[1,0]<stdout>:[          ] 7/309, 0.3 task/s, elapsed: 24s, ETA:  1021s[1,0]<stdout>:[          ] 8/309, 0.3 task/s, elapsed: 25s, ETA:   955s[1,0]<stdout>:[          ] 9/309, 0.3 task/s, elapsed: 27s, ETA:   908s[1,0]<stdout>:[          ] 10/309, 0.3 task/s, elapsed: 29s, ETA:   879s[1,0]<stdout>:[          ] 11/309, 0.3 task/s, elapsed: 32s, ETA:   864s[1,0]<stdout>:[          ] 12/309, 0.4 task/s, elapsed: 34s, ETA:   833s[1,0]<stdout>:[          ] 13/309, 0.4 task/s, elapsed: 35s, ETA:   806s[1,0]<stdout>:[          ] 14/309, 0.4 task/s, elapsed: 37s, ETA:   783s[1,0]<stdout>:[          ] 15/309, 0.4 task/s, elapsed: 39s, ETA:   765s[1,0]<stdout>:[          ] 16/309, 0.4 task/s, elapsed: 41s, ETA:   748s[1,0]<stdout>:[          ] 17/309, 0.4 task/s, elapsed: 43s, ETA:   732s[1,0]<stdout>:[          ] 18/309, 0.4 task/s, elapsed: 44s, ETA:   718s[1,0]<stdout>:[          ] 19/309, 0.4 task/s, elapsed: 46s, ETA:   704s[1,0]<stdout>:[          ] 20/309, 0.4 task/s, elapsed: 48s, ETA:   699s[1,0]<stdout>:[          ] 21/309, 0.4 task/s, elapsed: 51s, ETA:   701s[1,0]<stdout>:[          ] 22/309, 0.4 task/s, elapsed: 53s, ETA:   689s[1,0]<stdout>:[          ] 23/309, 0.4 task/s, elapsed: 55s, ETA:   686s[1,0]<stdout>:[          ] 24/309, 0.4 task/s, elapsed: 57s, ETA:   677s[1,0]<stdout>:[          ] 25/309, 0.4 task/s, elapsed: 59s, ETA:   667s[1,0]<stdout>:[          ] 26/309, 0.4 task/s, elapsed: 60s, ETA:   658s[1,0]<stdout>:[          ] 27/309, 0.4 task/s, elapsed: 62s, ETA:   651s[1,0]<stdout>:[          ] 28/309, 0.4 task/s, elapsed: 64s, ETA:   643s[1,0]<stdout>:[          ] 29/309, 0.4 task/s, elapsed: 66s, ETA:   636s[1,0]<stdout>:[          ] 30/309, 0.4 task/s, elapsed: 67s, ETA:   627s[1,0]<stdout>:[>         ] 31/309, 0.4 task/s, elapsed: 69s, ETA:   620s[1,0]<stdout>:[>         ] 32/309, 0.5 task/s, elapsed: 71s, ETA:   613s[1,0]<stdout>:[>         ] 33/309, 0.5 task/s, elapsed: 73s, ETA:   607s[1,0]<stdout>:[>         ] 34/309, 0.5 task/s, elapsed: 74s, ETA:   602s[1,0]<stdout>:[>         ] 35/309, 0.5 task/s, elapsed: 76s, ETA:   597s[1,0]<stdout>:[>         ] 36/309, 0.5 task/s, elapsed: 78s, ETA:   593s[1,0]<stdout>:[>         ] 37/309, 0.5 task/s, elapsed: 80s, ETA:   585s[1,0]<stdout>:[>         ] 38/309, 0.5 task/s, elapsed: 81s, ETA:   577s[1,0]<stdout>:[>         ] 39/309, 0.5 task/s, elapsed: 83s, ETA:   573s[1,0]<stdout>:[>         ] 40/309, 0.5 task/s, elapsed: 85s, ETA:   570s[1,0]<stdout>:[>         ] 41/309, 0.5 task/s, elapsed: 87s, ETA:   566s[1,0]<stdout>:[>         ] 42/309, 0.5 task/s, elapsed: 88s, ETA:   561s[1,0]<stdout>:[>         ] 43/309, 0.5 task/s, elapsed: 91s, ETA:   560s[1,0]<stdout>:[>         ] 44/309, 0.5 task/s, elapsed: 93s, ETA:   558s[1,0]<stdout>:[>         ] 45/309, 0.5 task/s, elapsed: 94s, ETA:   554s[1,0]<stdout>:[>         ] 46/309, 0.5 task/s, elapsed: 96s, ETA:   550s[1,0]<stdout>:[>         ] 47/309, 0.5 task/s, elapsed: 98s, ETA:   546s[1,0]<stdout>:[>         ] 48/309, 0.5 task/s, elapsed: 99s, ETA:   540s[1,0]<stdout>:[>         ] 49/309, 0.5 task/s, elapsed: 101s, ETA:   536s[1,0]<stdout>:[>         ] 50/309, 0.5 task/s, elapsed: 103s, ETA:   533s[1,0]<stdout>:[>         ] 51/309, 0.5 task/s, elapsed: 105s, ETA:   531s[1,0]<stdout>:[>         ] 52/309, 0.5 task/s, elapsed: 107s, ETA:   528s[1,0]<stdout>:[>         ] 53/309, 0.5 task/s, elapsed: 108s, ETA:   523s[1,0]<stdout>:[>         ] 54/309, 0.5 task/s, elapsed: 110s, ETA:   520s[1,0]<stdout>:[>         ] 55/309, 0.5 task/s, elapsed: 111s, ETA:   512s[1,0]<stdout>:[>         ] 56/309, 0.5 task/s, elapsed: 112s, ETA:   507s[1,0]<stdout>:[>         ] 57/309, 0.5 task/s, elapsed: 114s, ETA:   502s[1,0]<stdout>:[>         ] 58/309, 0.5 task/s, elapsed: 115s, ETA:   499s[1,0]<stdout>:[>         ] 59/309, 0.5 task/s, elapsed: 117s, ETA:   496s[1,0]<stdout>:[>         ] 60/309, 0.5 task/s, elapsed: 118s, ETA:   492s[1,0]<stdout>:[>         ] 61/309, 0.5 task/s, elapsed: 120s, ETA:   489s[1,0]<stdout>:[>>        ] 62/309, 0.5 task/s, elapsed: 122s, ETA:   486s[1,0]<stdout>:[>>        ] 63/309, 0.5 task/s, elapsed: 124s, ETA:   484s[1,0]<stdout>:[>>        ] 64/309, 0.5 task/s, elapsed: 126s, ETA:   481s[1,0]<stdout>:[>>        ] 65/309, 0.5 task/s, elapsed: 127s, ETA:   478s[1,0]<stdout>:[>>        ] 66/309, 0.5 task/s, elapsed: 129s, ETA:   475s[1,0]<stdout>:[>>        ] 67/309, 0.5 task/s, elapsed: 131s, ETA:   474s[1,0]<stdout>:[>>        ] 68/309, 0.5 task/s, elapsed: 133s, ETA:   471s[1,0]<stdout>:[>>        ] 69/309, 0.5 task/s, elapsed: 135s, ETA:   471s[1,0]<stdout>:[>>        ] 70/309, 0.5 task/s, elapsed: 137s, ETA:   468s[1,0]<stdout>:[>>        ] 71/309, 0.5 task/s, elapsed: 139s, ETA:   465s[1,0]<stdout>:[>>        ] 72/309, 0.5 task/s, elapsed: 141s, ETA:   463s[1,0]<stdout>:[>>        ] 73/309, 0.5 task/s, elapsed: 142s, ETA:   460s[1,0]<stdout>:[>>        ] 74/309, 0.5 task/s, elapsed: 144s, ETA:   458s[1,0]<stdout>:[>>        ] 75/309, 0.5 task/s, elapsed: 146s, ETA:   455s[1,0]<stdout>:[>>        ] 76/309, 0.5 task/s, elapsed: 148s, ETA:   452s[1,0]<stdout>:[>>        ] 77/309, 0.5 task/s, elapsed: 149s, ETA:   450s[1,0]<stdout>:[>>        ] 78/309, 0.5 task/s, elapsed: 151s, ETA:   447s[1,0]<stdout>:[>>        ] 79/309, 0.5 task/s, elapsed: 153s, ETA:   444s[1,0]<stdout>:[>>        ] 80/309, 0.5 task/s, elapsed: 154s, ETA:   442s[1,0]<stdout>:[>>        ] 81/309, 0.5 task/s, elapsed: 156s, ETA:   440s[1,0]<stdout>:[>>        ] 82/309, 0.5 task/s, elapsed: 158s, ETA:   439s[1,0]<stdout>:[>>        ] 83/309, 0.5 task/s, elapsed: 160s, ETA:   436s[1,0]<stdout>:[>>        ] 84/309, 0.5 task/s, elapsed: 162s, ETA:   434s[1,0]<stdout>:[>>        ] 85/309, 0.5 task/s, elapsed: 164s, ETA:   431s[1,0]<stdout>:[>>        ] 86/309, 0.5 task/s, elapsed: 166s, ETA:   429s[1,0]<stdout>:[>>        ] 87/309, 0.5 task/s, elapsed: 168s, ETA:   429s[1,0]<stdout>:[>>        ] 88/309, 0.5 task/s, elapsed: 170s, ETA:   426s[1,0]<stdout>:[>>        ] 89/309, 0.5 task/s, elapsed: 172s, ETA:   424s[1,0]<stdout>:[>>        ] 90/309, 0.5 task/s, elapsed: 174s, ETA:   423s[1,0]<stdout>:[>>        ] 91/309, 0.5 task/s, elapsed: 175s, ETA:   420s[1,0]<stdout>:[>>        ] 92/309, 0.5 task/s, elapsed: 177s, ETA:   418s[1,0]<stdout>:[>>>       ] 93/309, 0.5 task/s, elapsed: 179s, ETA:   416s[1,0]<stdout>:[>>>       ] 94/309, 0.5 task/s, elapsed: 181s, ETA:   413s[1,0]<stdout>:[>>>       ] 95/309, 0.5 task/s, elapsed: 182s, ETA:   410s[1,0]<stdout>:[>>>       ] 96/309, 0.5 task/s, elapsed: 184s, ETA:   408s[1,0]<stdout>:[>>>       ] 97/309, 0.5 task/s, elapsed: 186s, ETA:   406s[1,0]<stdout>:[>>>       ] 98/309, 0.5 task/s, elapsed: 187s, ETA:   403s[1,0]<stdout>:[>>>       ] 99/309, 0.5 task/s, elapsed: 189s, ETA:   401s[1,0]<stdout>:[>>>       ] 100/309, 0.5 task/s, elapsed: 191s, ETA:   399s[1,0]<stdout>:[>>>       ] 101/309, 0.5 task/s, elapsed: 193s, ETA:   397s[1,0]<stdout>:[>>>       ] 102/309, 0.5 task/s, elapsed: 194s, ETA:   395s[1,0]<stdout>:[>>>       ] 103/309, 0.5 task/s, elapsed: 196s, ETA:   393s[1,0]<stdout>:[>>>       ] 104/309, 0.5 task/s, elapsed: 198s, ETA:   391s[1,0]<stdout>:[>>>       ] 105/309, 0.5 task/s, elapsed: 200s, ETA:   388s[1,0]<stdout>:[>>>       ] 106/309, 0.5 task/s, elapsed: 201s, ETA:   386s[1,0]<stdout>:[>>>       ] 107/309, 0.5 task/s, elapsed: 204s, ETA:   385s[1,0]<stdout>:[>>>       ] 108/309, 0.5 task/s, elapsed: 206s, ETA:   383s[1,0]<stdout>:[>>>       ] 109/309, 0.5 task/s, elapsed: 208s, ETA:   381s[1,0]<stdout>:[>>>       ] 110/309, 0.5 task/s, elapsed: 210s, ETA:   379s[1,0]<stdout>:[>>>       ] 111/309, 0.5 task/s, elapsed: 211s, ETA:   377s[1,0]<stdout>:[>>>       ] 112/309, 0.5 task/s, elapsed: 213s, ETA:   375s[1,0]<stdout>:[>>>       ] 113/309, 0.5 task/s, elapsed: 215s, ETA:   372s[1,0]<stdout>:[>>>       ] 114/309, 0.5 task/s, elapsed: 217s, ETA:   372s[1,0]<stdout>:[>>>       ] 115/309, 0.5 task/s, elapsed: 219s, ETA:   369s[1,0]<stdout>:[>>>       ] 116/309, 0.5 task/s, elapsed: 220s, ETA:   367s[1,0]<stdout>:[>>>       ] 117/309, 0.5 task/s, elapsed: 222s, ETA:   364s[1,0]<stdout>:[>>>       ] 118/309, 0.5 task/s, elapsed: 224s, ETA:   362s[1,0]<stdout>:[>>>       ] 119/309, 0.5 task/s, elapsed: 225s, ETA:   360s[1,0]<stdout>:[>>>       ] 120/309, 0.5 task/s, elapsed: 227s, ETA:   358s[1,0]<stdout>:[>>>       ] 121/309, 0.5 task/s, elapsed: 229s, ETA:   356s[1,0]<stdout>:[>>>       ] 122/309, 0.5 task/s, elapsed: 231s, ETA:   354s[1,0]<stdout>:[>>>       ] 123/309, 0.5 task/s, elapsed: 232s, ETA:   351s[1,0]<stdout>:[>>>>      ] 124/309, 0.5 task/s, elapsed: 234s, ETA:   349s[1,0]<stdout>:[>>>>      ] 125/309, 0.5 task/s, elapsed: 236s, ETA:   348s[1,0]<stdout>:[>>>>      ] 126/309, 0.5 task/s, elapsed: 238s, ETA:   345s[1,0]<stdout>:[>>>>      ] 127/309, 0.5 task/s, elapsed: 239s, ETA:   343s[1,0]<stdout>:[>>>>      ] 128/309, 0.5 task/s, elapsed: 241s, ETA:   341s[1,0]<stdout>:[>>>>      ] 129/309, 0.5 task/s, elapsed: 243s, ETA:   339s[1,0]<stdout>:[>>>>      ] 130/309, 0.5 task/s, elapsed: 244s, ETA:   336s[1,0]<stdout>:[>>>>      ] 131/309, 0.5 task/s, elapsed: 246s, ETA:   334s[1,0]<stdout>:[>>>>      ] 132/309, 0.5 task/s, elapsed: 248s, ETA:   332s[1,0]<stdout>:[>>>>      ] 133/309, 0.5 task/s, elapsed: 249s, ETA:   330s[1,0]<stdout>:[>>>>      ] 134/309, 0.5 task/s, elapsed: 251s, ETA:   328s[1,0]<stdout>:[>>>>      ] 135/309, 0.5 task/s, elapsed: 253s, ETA:   326s[1,0]<stdout>:[>>>>      ] 136/309, 0.5 task/s, elapsed: 254s, ETA:   323s[1,0]<stdout>:[>>>>      ] 137/309, 0.5 task/s, elapsed: 256s, ETA:   321s[1,0]<stdout>:[>>>>      ] 138/309, 0.5 task/s, elapsed: 257s, ETA:   319s[1,0]<stdout>:[>>>>      ] 139/309, 0.5 task/s, elapsed: 259s, ETA:   317s[1,0]<stdout>:[>>>>      ] 140/309, 0.5 task/s, elapsed: 262s, ETA:   316s[1,0]<stdout>:[>>>>      ] 141/309, 0.5 task/s, elapsed: 264s, ETA:   315s[1,0]<stdout>:[>>>>      ] 142/309, 0.5 task/s, elapsed: 266s, ETA:   313s[1,0]<stdout>:[>>>>      ] 143/309, 0.5 task/s, elapsed: 268s, ETA:   311s[1,0]<stdout>:[>>>>      ] 144/309, 0.5 task/s, elapsed: 269s, ETA:   309s[1,0]<stdout>:[>>>>      ] 145/309, 0.5 task/s, elapsed: 271s, ETA:   307s[1,0]<stdout>:[>>>>      ] 146/309, 0.5 task/s, elapsed: 273s, ETA:   305s[1,0]<stdout>:[>>>>      ] 147/309, 0.5 task/s, elapsed: 275s, ETA:   303s[1,0]<stdout>:[>>>>      ] 148/309, 0.5 task/s, elapsed: 277s, ETA:   301s[1,0]<stdout>:[>>>>      ] 149/309, 0.5 task/s, elapsed: 279s, ETA:   299s[1,0]<stdout>:[>>>>      ] 150/309, 0.5 task/s, elapsed: 280s, ETA:   297s[1,0]<stdout>:[>>>>      ] 151/309, 0.5 task/s, elapsed: 282s, ETA:   295s[1,0]<stdout>:[>>>>      ] 152/309, 0.5 task/s, elapsed: 284s, ETA:   293s[1,0]<stdout>:[>>>>      ] 153/309, 0.5 task/s, elapsed: 285s, ETA:   291s[1,0]<stdout>:[>>>>      ] 154/309, 0.5 task/s, elapsed: 286s, ETA:   288s[1,0]<stdout>:[>>>>>     ] 155/309, 0.5 task/s, elapsed: 289s, ETA:   287s[1,0]<stdout>:[>>>>>     ] 156/309, 0.5 task/s, elapsed: 290s, ETA:   285s[1,0]<stdout>:[>>>>>     ] 157/309, 0.5 task/s, elapsed: 292s, ETA:   283s[1,0]<stdout>:[>>>>>     ] 158/309, 0.5 task/s, elapsed: 294s, ETA:   281s[1,0]<stdout>:[>>>>>     ] 159/309, 0.5 task/s, elapsed: 296s, ETA:   279s[1,0]<stdout>:[>>>>>     ] 160/309, 0.5 task/s, elapsed: 298s, ETA:   277s[1,0]<stdout>:[>>>>>     ] 161/309, 0.5 task/s, elapsed: 300s, ETA:   275s[1,0]<stdout>:[>>>>>     ] 162/309, 0.5 task/s, elapsed: 301s, ETA:   273s[1,0]<stdout>:[>>>>>     ] 163/309, 0.5 task/s, elapsed: 307s, ETA:   275s[1,0]<stdout>:[>>>>>     ] 164/309, 0.5 task/s, elapsed: 308s, ETA:   273s[1,0]<stdout>:[>>>>>     ] 165/309, 0.5 task/s, elapsed: 310s, ETA:   271s[1,0]<stdout>:[>>>>>     ] 166/309, 0.5 task/s, elapsed: 311s, ETA:   268s[1,0]<stdout>:[>>>>>     ] 167/309, 0.5 task/s, elapsed: 313s, ETA:   266s[1,0]<stdout>:[>>>>>     ] 168/309, 0.5 task/s, elapsed: 315s, ETA:   264s[1,0]<stdout>:[>>>>>     ] 169/309, 0.5 task/s, elapsed: 316s, ETA:   262s[1,0]<stdout>:[>>>>>     ] 170/309, 0.5 task/s, elapsed: 319s, ETA:   260s[1,0]<stdout>:[>>>>>     ] 171/309, 0.5 task/s, elapsed: 320s, ETA:   258s[1,0]<stdout>:[>>>>>     ] 172/309, 0.5 task/s, elapsed: 322s, ETA:   256s[1,0]<stdout>:[>>>>>     ] 173/309, 0.5 task/s, elapsed: 324s, ETA:   254s[1,0]<stdout>:[>>>>>     ] 174/309, 0.5 task/s, elapsed: 325s, ETA:   252s[1,0]<stdout>:[>>>>>     ] 175/309, 0.5 task/s, elapsed: 327s, ETA:   250s[1,0]<stdout>:[>>>>>     ] 176/309, 0.5 task/s, elapsed: 328s, ETA:   248s[1,0]<stdout>:[>>>>>     ] 177/309, 0.5 task/s, elapsed: 331s, ETA:   247s[1,0]<stdout>:[>>>>>     ] 178/309, 0.5 task/s, elapsed: 333s, ETA:   245s[1,0]<stdout>:[>>>>>     ] 179/309, 0.5 task/s, elapsed: 335s, ETA:   243s[1,0]<stdout>:[>>>>>     ] 180/309, 0.5 task/s, elapsed: 336s, ETA:   241s[1,0]<stdout>:[>>>>>     ] 181/309, 0.5 task/s, elapsed: 338s, ETA:   239s[1,0]<stdout>:[>>>>>     ] 182/309, 0.5 task/s, elapsed: 339s, ETA:   237s[1,0]<stdout>:[>>>>>     ] 183/309, 0.5 task/s, elapsed: 341s, ETA:   235s[1,0]<stdout>:[>>>>>     ] 184/309, 0.5 task/s, elapsed: 343s, ETA:   233s[1,0]<stdout>:[>>>>>     ] 185/309, 0.5 task/s, elapsed: 344s, ETA:   231s[1,0]<stdout>:[>>>>>>    ] 186/309, 0.5 task/s, elapsed: 346s, ETA:   229s[1,0]<stdout>:[>>>>>>    ] 187/309, 0.5 task/s, elapsed: 348s, ETA:   227s[1,0]<stdout>:[>>>>>>    ] 188/309, 0.5 task/s, elapsed: 350s, ETA:   225s[1,0]<stdout>:[>>>>>>    ] 189/309, 0.5 task/s, elapsed: 352s, ETA:   223s[1,0]<stdout>:[>>>>>>    ] 190/309, 0.5 task/s, elapsed: 353s, ETA:   221s[1,0]<stdout>:[>>>>>>    ] 191/309, 0.5 task/s, elapsed: 355s, ETA:   219s[1,0]<stdout>:[>>>>>>    ] 192/309, 0.5 task/s, elapsed: 356s, ETA:   217s[1,0]<stdout>:[>>>>>>    ] 193/309, 0.5 task/s, elapsed: 358s, ETA:   215s[1,0]<stdout>:[>>>>>>    ] 194/309, 0.5 task/s, elapsed: 360s, ETA:   213s[1,0]<stdout>:[>>>>>>    ] 195/309, 0.5 task/s, elapsed: 362s, ETA:   212s[1,0]<stdout>:[>>>>>>    ] 196/309, 0.5 task/s, elapsed: 364s, ETA:   210s[1,0]<stdout>:[>>>>>>    ] 197/309, 0.5 task/s, elapsed: 366s, ETA:   208s[1,0]<stdout>:[>>>>>>    ] 198/309, 0.5 task/s, elapsed: 368s, ETA:   206s[1,0]<stdout>:[>>>>>>    ] 199/309, 0.5 task/s, elapsed: 370s, ETA:   204s[1,0]<stdout>:[>>>>>>    ] 200/309, 0.5 task/s, elapsed: 372s, ETA:   202s[1,0]<stdout>:[>>>>>>    ] 201/309, 0.5 task/s, elapsed: 373s, ETA:   201s[1,0]<stdout>:[>>>>>>    ] 202/309, 0.5 task/s, elapsed: 375s, ETA:   199s[1,0]<stdout>:[>>>>>>    ] 203/309, 0.5 task/s, elapsed: 377s, ETA:   197s[1,0]<stdout>:[>>>>>>    ] 204/309, 0.5 task/s, elapsed: 379s, ETA:   195s[1,0]<stdout>:[>>>>>>    ] 205/309, 0.5 task/s, elapsed: 380s, ETA:   193s[1,0]<stdout>:[>>>>>>    ] 206/309, 0.5 task/s, elapsed: 382s, ETA:   191s[1,0]<stdout>:[>>>>>>    ] 207/309, 0.5 task/s, elapsed: 384s, ETA:   189s[1,0]<stdout>:[>>>>>>    ] 208/309, 0.5 task/s, elapsed: 385s, ETA:   187s[1,0]<stdout>:[>>>>>>    ] 209/309, 0.5 task/s, elapsed: 388s, ETA:   186s[1,0]<stdout>:[>>>>>>    ] 210/309, 0.5 task/s, elapsed: 389s, ETA:   183s[1,0]<stdout>:[>>>>>>    ] 211/309, 0.5 task/s, elapsed: 390s, ETA:   181s[1,0]<stdout>:[>>>>>>    ] 212/309, 0.5 task/s, elapsed: 392s, ETA:   179s[1,0]<stdout>:[>>>>>>    ] 213/309, 0.5 task/s, elapsed: 394s, ETA:   178s[1,0]<stdout>:[>>>>>>    ] 214/309, 0.5 task/s, elapsed: 396s, ETA:   176s[1,0]<stdout>:[>>>>>>    ] 215/309, 0.5 task/s, elapsed: 397s, ETA:   174s[1,0]<stdout>:[>>>>>>    ] 216/309, 0.5 task/s, elapsed: 399s, ETA:   172s[1,0]<stdout>:[>>>>>>>   ] 217/309, 0.5 task/s, elapsed: 401s, ETA:   170s[1,0]<stdout>:[>>>>>>>   ] 218/309, 0.5 task/s, elapsed: 403s, ETA:   168s[1,0]<stdout>:[>>>>>>>   ] 219/309, 0.5 task/s, elapsed: 405s, ETA:   167s[1,0]<stdout>:[>>>>>>>   ] 220/309, 0.5 task/s, elapsed: 407s, ETA:   165s[1,0]<stdout>:[>>>>>>>   ] 221/309, 0.5 task/s, elapsed: 408s, ETA:   163s[1,0]<stdout>:[>>>>>>>   ] 222/309, 0.5 task/s, elapsed: 410s, ETA:   161s[1,0]<stdout>:[>>>>>>>   ] 223/309, 0.5 task/s, elapsed: 412s, ETA:   159s[1,0]<stdout>:[>>>>>>>   ] 224/309, 0.5 task/s, elapsed: 413s, ETA:   157s[1,0]<stdout>:[>>>>>>>   ] 225/309, 0.5 task/s, elapsed: 415s, ETA:   155s[1,0]<stdout>:[>>>>>>>   ] 226/309, 0.5 task/s, elapsed: 417s, ETA:   153s[1,0]<stdout>:[>>>>>>>   ] 227/309, 0.5 task/s, elapsed: 418s, ETA:   151s[1,0]<stdout>:[>>>>>>>   ] 228/309, 0.5 task/s, elapsed: 420s, ETA:   149s[1,0]<stdout>:[>>>>>>>   ] 229/309, 0.5 task/s, elapsed: 421s, ETA:   147s[1,0]<stdout>:[>>>>>>>   ] 230/309, 0.5 task/s, elapsed: 423s, ETA:   145s[1,0]<stdout>:[>>>>>>>   ] 231/309, 0.5 task/s, elapsed: 425s, ETA:   144s[1,0]<stdout>:[>>>>>>>   ] 232/309, 0.5 task/s, elapsed: 427s, ETA:   142s[1,0]<stdout>:[>>>>>>>   ] 233/309, 0.5 task/s, elapsed: 428s, ETA:   140s[1,0]<stdout>:[>>>>>>>   ] 234/309, 0.5 task/s, elapsed: 430s, ETA:   138s[1,0]<stdout>:[>>>>>>>   ] 235/309, 0.5 task/s, elapsed: 431s, ETA:   136s[1,0]<stdout>:[>>>>>>>   ] 236/309, 0.5 task/s, elapsed: 433s, ETA:   134s[1,0]<stdout>:[>>>>>>>   ] 237/309, 0.5 task/s, elapsed: 434s, ETA:   132s[1,0]<stdout>:[>>>>>>>   ] 238/309, 0.5 task/s, elapsed: 436s, ETA:   130s[1,0]<stdout>:[>>>>>>>   ] 239/309, 0.5 task/s, elapsed: 438s, ETA:   128s[1,0]<stdout>:[>>>>>>>   ] 240/309, 0.5 task/s, elapsed: 440s, ETA:   126s[1,0]<stdout>:[>>>>>>>   ] 241/309, 0.5 task/s, elapsed: 441s, ETA:   125s[1,0]<stdout>:[>>>>>>>   ] 242/309, 0.5 task/s, elapsed: 443s, ETA:   123s[1,0]<stdout>:[>>>>>>>   ] 243/309, 0.5 task/s, elapsed: 445s, ETA:   121s[1,0]<stdout>:[>>>>>>>   ] 244/309, 0.5 task/s, elapsed: 447s, ETA:   119s[1,0]<stdout>:[>>>>>>>   ] 245/309, 0.5 task/s, elapsed: 449s, ETA:   117s[1,0]<stdout>:[>>>>>>>   ] 246/309, 0.5 task/s, elapsed: 451s, ETA:   116s[1,0]<stdout>:[>>>>>>>   ] 247/309, 0.5 task/s, elapsed: 453s, ETA:   114s[1,0]<stdout>:[>>>>>>>>  ] 248/309, 0.5 task/s, elapsed: 455s, ETA:   112s[1,0]<stdout>:[>>>>>>>>  ] 249/309, 0.5 task/s, elapsed: 456s, ETA:   110s[1,0]<stdout>:[>>>>>>>>  ] 250/309, 0.5 task/s, elapsed: 458s, ETA:   108s[1,0]<stdout>:[>>>>>>>>  ] 251/309, 0.5 task/s, elapsed: 460s, ETA:   106s[1,0]<stdout>:[>>>>>>>>  ] 252/309, 0.5 task/s, elapsed: 462s, ETA:   104s[1,0]<stdout>:[>>>>>>>>  ] 253/309, 0.5 task/s, elapsed: 464s, ETA:   103s[1,0]<stdout>:[>>>>>>>>  ] 254/309, 0.5 task/s, elapsed: 465s, ETA:   101s[1,0]<stdout>:[>>>>>>>>  ] 255/309, 0.5 task/s, elapsed: 467s, ETA:    99s[1,0]<stdout>:[>>>>>>>>  ] 256/309, 0.5 task/s, elapsed: 469s, ETA:    97s[1,0]<stdout>:[>>>>>>>>  ] 257/309, 0.5 task/s, elapsed: 471s, ETA:    95s[1,0]<stdout>:[>>>>>>>>  ] 258/309, 0.5 task/s, elapsed: 472s, ETA:    93s[1,0]<stdout>:[>>>>>>>>  ] 259/309, 0.5 task/s, elapsed: 474s, ETA:    91s[1,0]<stdout>:[>>>>>>>>  ] 260/309, 0.5 task/s, elapsed: 475s, ETA:    90s[1,0]<stdout>:[>>>>>>>>  ] 261/309, 0.5 task/s, elapsed: 478s, ETA:    88s[1,0]<stdout>:[>>>>>>>>  ] 262/309, 0.5 task/s, elapsed: 479s, ETA:    86s[1,0]<stdout>:[>>>>>>>>  ] 263/309, 0.5 task/s, elapsed: 481s, ETA:    84s[1,0]<stdout>:[>>>>>>>>  ] 264/309, 0.5 task/s, elapsed: 483s, ETA:    82s[1,0]<stdout>:[>>>>>>>>  ] 265/309, 0.5 task/s, elapsed: 485s, ETA:    80s[1,0]<stdout>:[>>>>>>>>  ] 266/309, 0.5 task/s, elapsed: 486s, ETA:    79s[1,0]<stdout>:[>>>>>>>>  ] 267/309, 0.5 task/s, elapsed: 488s, ETA:    77s[1,0]<stdout>:[>>>>>>>>  ] 268/309, 0.5 task/s, elapsed: 490s, ETA:    75s[1,0]<stdout>:[>>>>>>>>  ] 269/309, 0.5 task/s, elapsed: 492s, ETA:    73s[1,0]<stdout>:[>>>>>>>>  ] 270/309, 0.5 task/s, elapsed: 494s, ETA:    71s[1,0]<stdout>:[>>>>>>>>  ] 271/309, 0.5 task/s, elapsed: 495s, ETA:    69s[1,0]<stdout>:[>>>>>>>>  ] 272/309, 0.5 task/s, elapsed: 498s, ETA:    68s[1,0]<stdout>:[>>>>>>>>  ] 273/309, 0.5 task/s, elapsed: 499s, ETA:    66s[1,0]<stdout>:[>>>>>>>>  ] 274/309, 0.5 task/s, elapsed: 501s, ETA:    64s[1,0]<stdout>:[>>>>>>>>  ] 275/309, 0.5 task/s, elapsed: 503s, ETA:    62s[1,0]<stdout>:[>>>>>>>>  ] 276/309, 0.5 task/s, elapsed: 504s, ETA:    60s[1,0]<stdout>:[>>>>>>>>  ] 277/309, 0.5 task/s, elapsed: 506s, ETA:    58s[1,0]<stdout>:[>>>>>>>>  ] 278/309, 0.5 task/s, elapsed: 507s, ETA:    57s[1,0]<stdout>:[>>>>>>>>> ] 279/309, 0.5 task/s, elapsed: 509s, ETA:    55s[1,0]<stdout>:[>>>>>>>>> ] 280/309, 0.5 task/s, elapsed: 511s, ETA:    53s[1,0]<stdout>:[>>>>>>>>> ] 281/309, 0.5 task/s, elapsed: 513s, ETA:    51s[1,0]<stdout>:[>>>>>>>>> ] 282/309, 0.5 task/s, elapsed: 514s, ETA:    49s[1,0]<stdout>:[>>>>>>>>> ] 283/309, 0.5 task/s, elapsed: 517s, ETA:    47s[1,0]<stdout>:[>>>>>>>>> ] 284/309, 0.5 task/s, elapsed: 518s, ETA:    46s[1,0]<stdout>:[>>>>>>>>> ] 285/309, 0.5 task/s, elapsed: 520s, ETA:    44s[1,0]<stdout>:[>>>>>>>>> ] 286/309, 0.5 task/s, elapsed: 522s, ETA:    42s[1,0]<stdout>:[>>>>>>>>> ] 287/309, 0.5 task/s, elapsed: 524s, ETA:    40s[1,0]<stdout>:[>>>>>>>>> ] 288/309, 0.5 task/s, elapsed: 525s, ETA:    38s[1,0]<stdout>:[>>>>>>>>> ] 289/309, 0.5 task/s, elapsed: 527s, ETA:    36s[1,0]<stdout>:[>>>>>>>>> ] 290/309, 0.5 task/s, elapsed: 529s, ETA:    35s[1,0]<stdout>:[>>>>>>>>> ] 291/309, 0.5 task/s, elapsed: 531s, ETA:    33s[1,0]<stdout>:[>>>>>>>>> ] 292/309, 0.5 task/s, elapsed: 532s, ETA:    31s[1,0]<stdout>:[>>>>>>>>> ] 293/309, 0.5 task/s, elapsed: 534s, ETA:    29s[1,0]<stdout>:[>>>>>>>>> ] 294/309, 0.5 task/s, elapsed: 536s, ETA:    27s[1,0]<stdout>:[>>>>>>>>> ] 295/309, 0.5 task/s, elapsed: 538s, ETA:    26s[1,0]<stdout>:[>>>>>>>>> ] 296/309, 0.5 task/s, elapsed: 540s, ETA:    24s[1,0]<stdout>:[>>>>>>>>> ] 297/309, 0.5 task/s, elapsed: 542s, ETA:    22s[1,0]<stdout>:[>>>>>>>>> ] 298/309, 0.5 task/s, elapsed: 544s, ETA:    20s[1,0]<stdout>:[>>>>>>>>> ] 299/309, 0.5 task/s, elapsed: 545s, ETA:    18s[1,0]<stdout>:[>>>>>>>>> ] 300/309, 0.5 task/s, elapsed: 547s, ETA:    16s[1,0]<stdout>:[>>>>>>>>> ] 301/309, 0.5 task/s, elapsed: 549s, ETA:    15s[1,0]<stdout>:[>>>>>>>>> ] 302/309, 0.5 task/s, elapsed: 550s, ETA:    13s[1,102]<stdout>:Starting new loop for GPU: 54
[1,0]<stdout>:[>>>>>>>>> ] 303/309, 0.5 task/s, elapsed: 552s, ETA:    11s[1,3]<stdout>:let's go hook
[1,3]<stdout>:4944
[1,0]<stdout>:[>>>>>>>>> ] 304/309, 0.5 task/s, elapsed: 554s, ETA:     9s[1,99]<stdout>:Starting new loop for GPU: 51
[1,96]<stdout>:Starting new loop for GPU: 48
[1,116]<stdout>:Starting new loop for GPU: 60
[1,67]<stdout>:Starting new loop for GPU: 35
[1,102]<stdout>:let's go hook
[1,102]<stdout>:4944
[1,0]<stdout>:[>>>>>>>>> ] 305/309, 0.5 task/s, elapsed: 556s, ETA:     7s[1,84]<stdout>:Starting new loop for GPU: 44
[1,52]<stdout>:Starting new loop for GPU: 28
[1,51]<stdout>:Starting new loop for GPU: 27
[1,100]<stdout>:Starting new loop for GPU: 52
[1,68]<stdout>:Starting new loop for GPU: 36
[1,67]<stdout>:let's go hook
[1,67]<stdout>:4944
[1,70]<stdout>:Starting new loop for GPU: 38
[1,64]<stdout>:Starting new loop for GPU: 32
[1,115]<stdout>:Starting new loop for GPU: 59
[1,83]<stdout>:Starting new loop for GPU: 43
[1,20]<stdout>:Starting new loop for GPU: 12
[1,0]<stdout>:[>>>>>>>>> ] 306/309, 0.5 task/s, elapsed: 558s, ETA:     5s[1,20]<stdout>:let's go hook
[1,20]<stdout>:4944
[1,51]<stdout>:let's go hook
[1,51]<stdout>:4944
[1,96]<stdout>:let's go hook
[1,96]<stdout>:4944
[1,4]<stdout>:let's go hook
[1,4]<stdout>:4944
[1,52]<stdout>:let's go hook
[1,52]<stdout>:4944
[1,98]<stdout>:Starting new loop for GPU: 50
[1,68]<stdout>:let's go hook
[1,68]<stdout>:4944
[1,99]<stdout>:let's go hook
[1,99]<stdout>:4944
[1,54]<stdout>:Starting new loop for GPU: 30
[1,64]<stdout>:let's go hook
[1,64]<stdout>:4944
[1,0]<stdout>:[>>>>>>>>> ] 307/309, 0.5 task/s, elapsed: 560s, ETA:     4s[1,19]<stdout>:Starting new loop for GPU: 11
[1,84]<stdout>:let's go hook
[1,84]<stdout>:4944
[1,70]<stdout>:let's go hook
[1,70]<stdout>:4944
[1,19]<stdout>:let's go hook
[1,19]<stdout>:4944
[1,116]<stdout>:let's go hook
[1,116]<stdout>:4944
[1,38]<stdout>:Starting new loop for GPU: 22
[1,100]<stdout>:let's go hook
[1,100]<stdout>:4944
[1,38]<stdout>:let's go hook
[1,38]<stdout>:4944
[1,35]<stdout>:Starting new loop for GPU: 19
[1,54]<stdout>:let's go hook
[1,54]<stdout>:4944
[1,35]<stdout>:let's go hook
[1,35]<stdout>:4944
[1,101]<stdout>:Starting new loop for GPU: 53
[1,86]<stdout>:Starting new loop for GPU: 46
[1,118]<stdout>:Starting new loop for GPU: 62
[1,32]<stdout>:Starting new loop for GPU: 16
[1,83]<stdout>:let's go hook
[1,83]<stdout>:4944
[1,6]<stdout>:let's go hook
[1,6]<stdout>:4944
[1,32]<stdout>:let's go hook
[1,32]<stdout>:4944
[1,22]<stdout>:Starting new loop for GPU: 14
[1,112]<stdout>:Starting new loop for GPU: 56
[1,0]<stdout>:[>>>>>>>>> ] 308/309, 0.5 task/s, elapsed: 561s, ETA:     2s[1,22]<stdout>:let's go hook
[1,22]<stdout>:4944
[1,69]<stdout>:Starting new loop for GPU: 37
[1,98]<stdout>:let's go hook
[1,98]<stdout>:4944
[1,103]<stdout>:Starting new loop for GPU: 55
[1,36]<stdout>:Starting new loop for GPU: 20
[1,36]<stdout>:let's go hook
[1,36]<stdout>:4944
[1,113]<stdout>:Starting new loop for GPU: 57
[1,115]<stdout>:let's go hook
[1,115]<stdout>:4944
[1,0]<stdout>:[>>>>>>>>>>] 309/309, 0.5 task/s, elapsed: 563s, ETA:     0s[1,0]<stdout>:let's go hook
[1,0]<stdout>:4944
[1,69]<stdout>:let's go hook
[1,69]<stdout>:4944
[1,66]<stdout>:Starting new loop for GPU: 34
[1,5]<stdout>:let's go hook
[1,5]<stdout>:4944
[1,82]<stdout>:Starting new loop for GPU: 42
[1,101]<stdout>:let's go hook
[1,101]<stdout>:4944
[1,86]<stdout>:let's go hook
[1,86]<stdout>:4944
[1,49]<stdout>:Starting new loop for GPU: 25
[1,71]<stdout>:Starting new loop for GPU: 39
[1,66]<stdout>:let's go hook
[1,66]<stdout>:4944
[1,2]<stdout>:let's go hook
[1,2]<stdout>:4944
[1,37]<stdout>:Starting new loop for GPU: 21
[1,34]<stdout>:Starting new loop for GPU: 18
[1,103]<stdout>:let's go hook
[1,103]<stdout>:4944
[1,37]<stdout>:let's go hook
[1,37]<stdout>:4944
[1,34]<stdout>:let's go hook
[1,34]<stdout>:4944
[1,48]<stdout>:Starting new loop for GPU: 24
[1,81]<stdout>:Starting new loop for GPU: 41
[1,65]<stdout>:Starting new loop for GPU: 33
[1,80]<stdout>:Starting new loop for GPU: 40
[1,117]<stdout>:Starting new loop for GPU: 61
[1,112]<stdout>:let's go hook
[1,112]<stdout>:4944
[1,118]<stdout>:let's go hook
[1,118]<stdout>:4944
[1,97]<stdout>:Starting new loop for GPU: 49
[1,7]<stdout>:let's go hook
[1,7]<stdout>:4944
[1,71]<stdout>:let's go hook
[1,71]<stdout>:4944
[1,119]<stdout>:Starting new loop for GPU: 63
[1,49]<stdout>:let's go hook
[1,49]<stdout>:4944
[1,82]<stdout>:let's go hook
[1,82]<stdout>:4944
[1,17]<stdout>:Starting new loop for GPU: 9
[1,85]<stdout>:Starting new loop for GPU: 45
[1,48]<stdout>:let's go hook
[1,48]<stdout>:4944
[1,17]<stdout>:let's go hook
[1,17]<stdout>:4944
[1,65]<stdout>:let's go hook
[1,65]<stdout>:4944
[1,1]<stdout>:let's go hook
[1,1]<stdout>:4944
[1,39]<stdout>:Starting new loop for GPU: 23
[1,16]<stdout>:Starting new loop for GPU: 8
[1,87]<stdout>:Starting new loop for GPU: 47
[1,39]<stdout>:let's go hook
[1,39]<stdout>:4944
[1,16]<stdout>:let's go hook
[1,16]<stdout>:4944
[1,114]<stdout>:Starting new loop for GPU: 58
[1,113]<stdout>:let's go hook
[1,113]<stdout>:4944
[1,53]<stdout>:Starting new loop for GPU: 29
[1,50]<stdout>:Starting new loop for GPU: 26
[1,33]<stdout>:Starting new loop for GPU: 17
[1,80]<stdout>:let's go hook
[1,80]<stdout>:4944
[1,33]<stdout>:let's go hook
[1,33]<stdout>:4944
[1,18]<stdout>:Starting new loop for GPU: 10
[1,18]<stdout>:let's go hook
[1,18]<stdout>:4944
[1,55]<stdout>:Starting new loop for GPU: 31
[1,81]<stdout>:let's go hook
[1,81]<stdout>:4944
[1,97]<stdout>:let's go hook
[1,97]<stdout>:4944
[1,53]<stdout>:let's go hook
[1,53]<stdout>:4944
[1,85]<stdout>:let's go hook
[1,85]<stdout>:4944
[1,50]<stdout>:let's go hook
[1,50]<stdout>:4944
[1,55]<stdout>:let's go hook
[1,55]<stdout>:4944
[1,87]<stdout>:let's go hook
[1,87]<stdout>:4944
[1,117]<stdout>:let's go hook
[1,117]<stdout>:4944
[1,119]<stdout>:let's go hook
[1,119]<stdout>:4944
[1,114]<stdout>:let's go hook
[1,114]<stdout>:4944
[1,21]<stdout>:Starting new loop for GPU: 13
[1,21]<stdout>:let's go hook
[1,21]<stdout>:4944
[1,23]<stdout>:Starting new loop for GPU: 15
[1,23]<stdout>:let's go hook
[1,23]<stdout>:4944
